Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1483 - acc: 0.8510 - val_loss: 0.1300 - val_acc: 0.9056
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1291 - acc: 0.9080 - val_loss: 0.1225 - val_acc: 0.9311
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1245 - acc: 0.9221 - val_loss: 0.1208 - val_acc: 0.9345
Epoch 4/70

1506/1506 [==============================] - 32s 22ms/step - loss: 0.1217 - acc: 0.9320 - val_loss: 0.1225 - val_acc: 0.9247
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1195 - acc: 0.9387 - val_loss: 0.1220 - val_acc: 0.9316
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1178 - acc: 0.9443 - val_loss: 0.1173 - val_acc: 0.9446
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1170 - acc: 0.9472 - val_loss: 0.1159 - val_acc: 0.9504
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1161 - acc: 0.9508 - val_loss: 0.1191 - val_acc: 0.9409
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1151 - acc: 0.9519 - val_loss: 0.1162 - val_acc: 0.9495
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1145 - acc: 0.9555 - val_loss: 0.1157 - val_acc: 0.9515
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1137 - acc: 0.9573 - val_loss: 0.1155 - val_acc: 0.9519
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1131 - acc: 0.9600 - val_loss: 0.1150 - val_acc: 0.9540
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1127 - acc: 0.9602 - val_loss: 0.1175 - val_acc: 0.9461
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1123 - acc: 0.9622 - val_loss: 0.1148 - val_acc: 0.9565
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1115 - acc: 0.9642 - val_loss: 0.1144 - val_acc: 0.9586
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1113 - acc: 0.9655 - val_loss: 0.1144 - val_acc: 0.9565
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1111 - acc: 0.9653 - val_loss: 0.1157 - val_acc: 0.9523
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1105 - acc: 0.9674 - val_loss: 0.1142 - val_acc: 0.9568
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1103 - acc: 0.9678 - val_loss: 0.1143 - val_acc: 0.9581
Epoch 20/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1101 - acc: 0.9692 - val_loss: 0.1151 - val_acc: 0.9547
Epoch 21/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1097 - acc: 0.9695 - val_loss: 0.1143 - val_acc: 0.9592
Manual evaluation: (didn't understand why I made this)
True 8256
False 815
True percentage 0.910153235586
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.90      0.82      0.86       438
      B-LOC       0.74      0.78      0.76       218
      B-ORG       0.73      0.75      0.74       296
      I-ORG       0.58      0.66      0.62       151
      I-PER       0.80      0.70      0.74       214
      I-LOC       0.70      0.78      0.74       141
     B-MISC       0.61      0.31      0.41       141
     I-MISC       0.59      0.34      0.43       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.718406184954
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1493 - acc: 0.8484 - val_loss: 0.1312 - val_acc: 0.9060
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1289 - acc: 0.9087 - val_loss: 0.1291 - val_acc: 0.8907
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1244 - acc: 0.9241 - val_loss: 0.1186 - val_acc: 0.9471
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1223 - acc: 0.9290 - val_loss: 0.1190 - val_acc: 0.9371
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1199 - acc: 0.9373 - val_loss: 0.1172 - val_acc: 0.9462
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1184 - acc: 0.9418 - val_loss: 0.1168 - val_acc: 0.9477
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1175 - acc: 0.9451 - val_loss: 0.1146 - val_acc: 0.9553
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1162 - acc: 0.9501 - val_loss: 0.1144 - val_acc: 0.9565
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1156 - acc: 0.9508 - val_loss: 0.1138 - val_acc: 0.9588
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1143 - acc: 0.9561 - val_loss: 0.1135 - val_acc: 0.9591
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1138 - acc: 0.9572 - val_loss: 0.1136 - val_acc: 0.9574
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1131 - acc: 0.9604 - val_loss: 0.1131 - val_acc: 0.9608
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1127 - acc: 0.9603 - val_loss: 0.1130 - val_acc: 0.9591
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1123 - acc: 0.9629 - val_loss: 0.1134 - val_acc: 0.9579
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1115 - acc: 0.9648 - val_loss: 0.1126 - val_acc: 0.9593
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1114 - acc: 0.9648 - val_loss: 0.1130 - val_acc: 0.9611
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1110 - acc: 0.9656 - val_loss: 0.1125 - val_acc: 0.9599
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1109 - acc: 0.9663 - val_loss: 0.1124 - val_acc: 0.9602
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1101 - acc: 0.9689 - val_loss: 0.1123 - val_acc: 0.9610
Epoch 20/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1098 - acc: 0.9696 - val_loss: 0.1129 - val_acc: 0.9598
Epoch 21/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1102 - acc: 0.9684 - val_loss: 0.1123 - val_acc: 0.9607
Epoch 22/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1094 - acc: 0.9708 - val_loss: 0.1123 - val_acc: 0.9613
Epoch 23/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1092 - acc: 0.9710 - val_loss: 0.1122 - val_acc: 0.9616
Epoch 24/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1091 - acc: 0.9728 - val_loss: 0.1121 - val_acc: 0.9627
Epoch 25/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1084 - acc: 0.9742 - val_loss: 0.1124 - val_acc: 0.9597
Epoch 26/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1088 - acc: 0.9731 - val_loss: 0.1121 - val_acc: 0.9616
Epoch 27/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1084 - acc: 0.9738 - val_loss: 0.1121 - val_acc: 0.9619
Epoch 28/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1082 - acc: 0.9748 - val_loss: 0.1121 - val_acc: 0.9624
Epoch 29/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1083 - acc: 0.9751 - val_loss: 0.1124 - val_acc: 0.9605
Epoch 30/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1080 - acc: 0.9750 - val_loss: 0.1123 - val_acc: 0.9607
Epoch 31/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1077 - acc: 0.9748 - val_loss: 0.1124 - val_acc: 0.9622
Manual evaluation: (didn't understand why I made this)
True 8298
False 773
True percentage 0.914783375593
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.97      0.98      7318
      B-ORG       0.79      0.73      0.76       296
      B-LOC       0.74      0.77      0.76       218
      I-ORG       0.70      0.56      0.62       151
     B-MISC       0.53      0.33      0.41       141
     I-MISC       0.58      0.48      0.53       154
      B-PER       0.92      0.84      0.88       438
      I-PER       0.90      0.66      0.76       214
      I-LOC       0.71      0.79      0.75       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.734545454545
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 2
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1450 - acc: 0.8559 - val_loss: 0.1400 - val_acc: 0.8639
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1283 - acc: 0.9093 - val_loss: 0.1278 - val_acc: 0.9146
Epoch 3/70

1506/1506 [==============================] - 32s 22ms/step - loss: 0.1241 - acc: 0.9235 - val_loss: 0.1231 - val_acc: 0.9281
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1215 - acc: 0.9316 - val_loss: 0.1277 - val_acc: 0.9039
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1197 - acc: 0.9374 - val_loss: 0.1205 - val_acc: 0.9345
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1180 - acc: 0.9432 - val_loss: 0.1200 - val_acc: 0.9366
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1170 - acc: 0.9458 - val_loss: 0.1193 - val_acc: 0.9397
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1162 - acc: 0.9489 - val_loss: 0.1193 - val_acc: 0.9399
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1152 - acc: 0.9545 - val_loss: 0.1181 - val_acc: 0.9436
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1144 - acc: 0.9538 - val_loss: 0.1183 - val_acc: 0.9430
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1140 - acc: 0.9568 - val_loss: 0.1174 - val_acc: 0.9451
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1132 - acc: 0.9589 - val_loss: 0.1185 - val_acc: 0.9424
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1129 - acc: 0.9586 - val_loss: 0.1183 - val_acc: 0.9412
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1120 - acc: 0.9633 - val_loss: 0.1171 - val_acc: 0.9466
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1120 - acc: 0.9617 - val_loss: 0.1170 - val_acc: 0.9466
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1116 - acc: 0.9636 - val_loss: 0.1173 - val_acc: 0.9426
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1110 - acc: 0.9656 - val_loss: 0.1167 - val_acc: 0.9479
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1104 - acc: 0.9680 - val_loss: 0.1169 - val_acc: 0.9468
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1101 - acc: 0.9688 - val_loss: 0.1171 - val_acc: 0.9483
Epoch 20/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1100 - acc: 0.9692 - val_loss: 0.1169 - val_acc: 0.9484
Manual evaluation: (didn't understand why I made this)
True 8251
False 820
True percentage 0.909602028442
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.90      0.85      0.88       438
      B-ORG       0.74      0.75      0.74       296
      I-ORG       0.50      0.68      0.58       151
      I-PER       0.91      0.66      0.76       214
      B-LOC       0.71      0.79      0.75       218
      I-LOC       0.66      0.82      0.73       141
     B-MISC       0.60      0.28      0.38       141
     I-MISC       0.63      0.27      0.38       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.715259259259
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 3
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1474 - acc: 0.8505 - val_loss: 0.1270 - val_acc: 0.9138
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1287 - acc: 0.9092 - val_loss: 0.1224 - val_acc: 0.9273
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1243 - acc: 0.9239 - val_loss: 0.1197 - val_acc: 0.9360
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1216 - acc: 0.9323 - val_loss: 0.1243 - val_acc: 0.9147
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1202 - acc: 0.9364 - val_loss: 0.1165 - val_acc: 0.9454
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1186 - acc: 0.9419 - val_loss: 0.1159 - val_acc: 0.9478
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1173 - acc: 0.9451 - val_loss: 0.1161 - val_acc: 0.9484
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1164 - acc: 0.9485 - val_loss: 0.1154 - val_acc: 0.9509
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1155 - acc: 0.9504 - val_loss: 0.1161 - val_acc: 0.9487
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1146 - acc: 0.9543 - val_loss: 0.1156 - val_acc: 0.9496
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1138 - acc: 0.9567 - val_loss: 0.1144 - val_acc: 0.9526
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1134 - acc: 0.9572 - val_loss: 0.1151 - val_acc: 0.9502
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1128 - acc: 0.9581 - val_loss: 0.1138 - val_acc: 0.9539
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1123 - acc: 0.9607 - val_loss: 0.1136 - val_acc: 0.9580
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1116 - acc: 0.9649 - val_loss: 0.1138 - val_acc: 0.9561
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1114 - acc: 0.9644 - val_loss: 0.1138 - val_acc: 0.9555
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1108 - acc: 0.9666 - val_loss: 0.1135 - val_acc: 0.9572
Epoch 18/70

1506/1506 [==============================] - 32s 22ms/step - loss: 0.1109 - acc: 0.9655 - val_loss: 0.1139 - val_acc: 0.9552
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1107 - acc: 0.9674 - val_loss: 0.1164 - val_acc: 0.9492
Epoch 20/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1104 - acc: 0.9675 - val_loss: 0.1134 - val_acc: 0.9553
Epoch 21/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1097 - acc: 0.9702 - val_loss: 0.1136 - val_acc: 0.9557
Epoch 22/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1098 - acc: 0.9694 - val_loss: 0.1136 - val_acc: 0.9570
Epoch 23/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1093 - acc: 0.9717 - val_loss: 0.1131 - val_acc: 0.9579
Epoch 24/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1092 - acc: 0.9707 - val_loss: 0.1134 - val_acc: 0.9585
Epoch 25/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1090 - acc: 0.9725 - val_loss: 0.1131 - val_acc: 0.9576
Epoch 26/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1090 - acc: 0.9732 - val_loss: 0.1133 - val_acc: 0.9567
Manual evaluation: (didn't understand why I made this)
True 8272
False 799
True percentage 0.911917098446
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
     B-MISC       0.55      0.31      0.40       141
     I-MISC       0.56      0.41      0.47       154
      B-ORG       0.74      0.76      0.75       296
      I-ORG       0.63      0.60      0.62       151
      B-PER       0.92      0.84      0.88       438
      I-PER       0.93      0.65      0.77       214
      B-LOC       0.72      0.82      0.77       218
      I-LOC       0.66      0.83      0.74       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.727596439169
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 4
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1502 - acc: 0.8470 - val_loss: 0.1307 - val_acc: 0.9122
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1292 - acc: 0.9073 - val_loss: 0.1217 - val_acc: 0.9292
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1246 - acc: 0.9220 - val_loss: 0.1188 - val_acc: 0.9349
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1219 - acc: 0.9319 - val_loss: 0.1173 - val_acc: 0.9443
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1197 - acc: 0.9384 - val_loss: 0.1157 - val_acc: 0.9483
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1184 - acc: 0.9420 - val_loss: 0.1157 - val_acc: 0.9501
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1175 - acc: 0.9448 - val_loss: 0.1193 - val_acc: 0.9429
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1164 - acc: 0.9481 - val_loss: 0.1169 - val_acc: 0.9469
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1153 - acc: 0.9527 - val_loss: 0.1137 - val_acc: 0.9550
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1146 - acc: 0.9541 - val_loss: 0.1131 - val_acc: 0.9571
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1141 - acc: 0.9561 - val_loss: 0.1135 - val_acc: 0.9535
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1135 - acc: 0.9582 - val_loss: 0.1133 - val_acc: 0.9547
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1129 - acc: 0.9594 - val_loss: 0.1136 - val_acc: 0.9569
Manual evaluation: (didn't understand why I made this)
True 8185
False 886
True percentage 0.902326094146
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.65      0.76      0.70       296
      B-LOC       0.67      0.81      0.74       218
      B-PER       0.91      0.84      0.87       438
      I-PER       0.92      0.65      0.76       214
     B-MISC       0.82      0.06      0.12       141
      I-ORG       0.44      0.63      0.52       151
      I-LOC       0.59      0.84      0.69       141
     I-MISC       0.68      0.11      0.19       154

avg / total       0.94      0.90      0.91      9071

F-1 Score:
0.681723625557
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 5
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1472 - acc: 0.8521 - val_loss: 0.1321 - val_acc: 0.8973
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1285 - acc: 0.9110 - val_loss: 0.1250 - val_acc: 0.9202
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1242 - acc: 0.9221 - val_loss: 0.1228 - val_acc: 0.9256
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1214 - acc: 0.9327 - val_loss: 0.1196 - val_acc: 0.9368
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1198 - acc: 0.9381 - val_loss: 0.1190 - val_acc: 0.9383
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1185 - acc: 0.9413 - val_loss: 0.1219 - val_acc: 0.9255
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1169 - acc: 0.9482 - val_loss: 0.1171 - val_acc: 0.9431
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1159 - acc: 0.9499 - val_loss: 0.1166 - val_acc: 0.9462
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1155 - acc: 0.9512 - val_loss: 0.1166 - val_acc: 0.9492
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1143 - acc: 0.9551 - val_loss: 0.1166 - val_acc: 0.9436
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1137 - acc: 0.9579 - val_loss: 0.1166 - val_acc: 0.9450
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1129 - acc: 0.9587 - val_loss: 0.1158 - val_acc: 0.9474
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1129 - acc: 0.9605 - val_loss: 0.1156 - val_acc: 0.9495
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1121 - acc: 0.9615 - val_loss: 0.1160 - val_acc: 0.9453
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1119 - acc: 0.9632 - val_loss: 0.1159 - val_acc: 0.9466
Epoch 16/70

1506/1506 [==============================] - 32s 22ms/step - loss: 0.1112 - acc: 0.9649 - val_loss: 0.1156 - val_acc: 0.9487
Manual evaluation: (didn't understand why I made this)
True 8242
False 829
True percentage 0.908609855584
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.93      0.83      0.87       438
      B-ORG       0.70      0.77      0.73       296
     I-MISC       0.63      0.31      0.41       154
      B-LOC       0.72      0.77      0.74       218
      I-LOC       0.67      0.81      0.74       141
      I-ORG       0.52      0.66      0.58       151
      I-PER       0.89      0.66      0.76       214
     B-MISC       0.63      0.22      0.33       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.71160155085
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 6
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1449 - acc: 0.8574 - val_loss: 0.1350 - val_acc: 0.8760
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1276 - acc: 0.9129 - val_loss: 0.1250 - val_acc: 0.9145
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1235 - acc: 0.9259 - val_loss: 0.1221 - val_acc: 0.9274
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1212 - acc: 0.9346 - val_loss: 0.1214 - val_acc: 0.9287
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1193 - acc: 0.9400 - val_loss: 0.1197 - val_acc: 0.9397
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1180 - acc: 0.9443 - val_loss: 0.1176 - val_acc: 0.9452
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1170 - acc: 0.9465 - val_loss: 0.1186 - val_acc: 0.9392
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1157 - acc: 0.9502 - val_loss: 0.1188 - val_acc: 0.9392
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1153 - acc: 0.9530 - val_loss: 0.1169 - val_acc: 0.9471
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1141 - acc: 0.9554 - val_loss: 0.1161 - val_acc: 0.9491
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1135 - acc: 0.9584 - val_loss: 0.1159 - val_acc: 0.9523
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1128 - acc: 0.9608 - val_loss: 0.1150 - val_acc: 0.9555
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1127 - acc: 0.9611 - val_loss: 0.1148 - val_acc: 0.9572
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1120 - acc: 0.9625 - val_loss: 0.1148 - val_acc: 0.9567
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1116 - acc: 0.9642 - val_loss: 0.1158 - val_acc: 0.9501
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1116 - acc: 0.9642 - val_loss: 0.1144 - val_acc: 0.9566
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1109 - acc: 0.9672 - val_loss: 0.1146 - val_acc: 0.9589
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1110 - acc: 0.9665 - val_loss: 0.1143 - val_acc: 0.9575
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1101 - acc: 0.9687 - val_loss: 0.1138 - val_acc: 0.9580
Epoch 20/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1098 - acc: 0.9698 - val_loss: 0.1139 - val_acc: 0.9603
Epoch 21/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1094 - acc: 0.9717 - val_loss: 0.1141 - val_acc: 0.9583
Epoch 22/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1094 - acc: 0.9700 - val_loss: 0.1137 - val_acc: 0.9597
Epoch 23/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1093 - acc: 0.9713 - val_loss: 0.1137 - val_acc: 0.9600
Epoch 24/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1090 - acc: 0.9716 - val_loss: 0.1139 - val_acc: 0.9609
Epoch 25/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1090 - acc: 0.9725 - val_loss: 0.1137 - val_acc: 0.9605
Epoch 26/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1090 - acc: 0.9726 - val_loss: 0.1136 - val_acc: 0.9608
Epoch 27/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1084 - acc: 0.9745 - val_loss: 0.1134 - val_acc: 0.9603
Epoch 28/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1084 - acc: 0.9742 - val_loss: 0.1134 - val_acc: 0.9613
Epoch 29/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1078 - acc: 0.9751 - val_loss: 0.1133 - val_acc: 0.9600
Epoch 30/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1079 - acc: 0.9754 - val_loss: 0.1136 - val_acc: 0.9614
Epoch 31/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1076 - acc: 0.9767 - val_loss: 0.1137 - val_acc: 0.9622
Epoch 32/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1078 - acc: 0.9760 - val_loss: 0.1135 - val_acc: 0.9622
Manual evaluation: (didn't understand why I made this)
True 8297
False 774
True percentage 0.914673134164
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.97      0.98      7318
      B-PER       0.93      0.84      0.88       438
      B-LOC       0.73      0.78      0.76       218
      B-ORG       0.76      0.75      0.75       296
      I-PER       0.91      0.66      0.77       214
     B-MISC       0.61      0.35      0.44       141
     I-MISC       0.57      0.45      0.50       154
      I-LOC       0.70      0.82      0.76       141
      I-ORG       0.64      0.62      0.63       151

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.735865988633
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 7
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 24ms/step - loss: 0.1468 - acc: 0.8540 - val_loss: 0.1332 - val_acc: 0.8922
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1283 - acc: 0.9100 - val_loss: 0.1258 - val_acc: 0.9190
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1240 - acc: 0.9235 - val_loss: 0.1224 - val_acc: 0.9311
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1209 - acc: 0.9337 - val_loss: 0.1288 - val_acc: 0.9039
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1197 - acc: 0.9380 - val_loss: 0.1205 - val_acc: 0.9367
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1183 - acc: 0.9426 - val_loss: 0.1189 - val_acc: 0.9427
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1165 - acc: 0.9486 - val_loss: 0.1216 - val_acc: 0.9343
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1162 - acc: 0.9507 - val_loss: 0.1180 - val_acc: 0.9455
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1152 - acc: 0.9529 - val_loss: 0.1171 - val_acc: 0.9488
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1142 - acc: 0.9562 - val_loss: 0.1170 - val_acc: 0.9487
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1136 - acc: 0.9572 - val_loss: 0.1170 - val_acc: 0.9511
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1128 - acc: 0.9599 - val_loss: 0.1245 - val_acc: 0.9235
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1128 - acc: 0.9611 - val_loss: 0.1166 - val_acc: 0.9511
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1121 - acc: 0.9624 - val_loss: 0.1159 - val_acc: 0.9537
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1112 - acc: 0.9655 - val_loss: 0.1156 - val_acc: 0.9540
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1109 - acc: 0.9658 - val_loss: 0.1157 - val_acc: 0.9545
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1108 - acc: 0.9663 - val_loss: 0.1164 - val_acc: 0.9534
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1103 - acc: 0.9676 - val_loss: 0.1163 - val_acc: 0.9513
Manual evaluation: (didn't understand why I made this)
True 8220
False 851
True percentage 0.906184544152
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.98      7318
      B-ORG       0.79      0.63      0.70       296
      I-ORG       0.65      0.36      0.47       151
      B-PER       0.93      0.85      0.89       438
      B-LOC       0.68      0.83      0.75       218
      I-LOC       0.63      0.85      0.72       141
      I-PER       0.95      0.63      0.76       214
     B-MISC       0.38      0.36      0.37       141
     I-MISC       0.42      0.45      0.44       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.6953426283
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 8
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 24ms/step - loss: 0.1459 - acc: 0.8556 - val_loss: 0.1296 - val_acc: 0.9045
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1283 - acc: 0.9125 - val_loss: 0.1212 - val_acc: 0.9321
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1243 - acc: 0.9236 - val_loss: 0.1196 - val_acc: 0.9330
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1218 - acc: 0.9298 - val_loss: 0.1175 - val_acc: 0.9437
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1201 - acc: 0.9355 - val_loss: 0.1161 - val_acc: 0.9473
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1187 - acc: 0.9405 - val_loss: 0.1164 - val_acc: 0.9473
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1174 - acc: 0.9462 - val_loss: 0.1157 - val_acc: 0.9499
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1165 - acc: 0.9484 - val_loss: 0.1160 - val_acc: 0.9507
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1153 - acc: 0.9515 - val_loss: 0.1140 - val_acc: 0.9561
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1149 - acc: 0.9533 - val_loss: 0.1141 - val_acc: 0.9548
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1140 - acc: 0.9563 - val_loss: 0.1135 - val_acc: 0.9577
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1137 - acc: 0.9581 - val_loss: 0.1135 - val_acc: 0.9571
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1129 - acc: 0.9600 - val_loss: 0.1132 - val_acc: 0.9605
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1124 - acc: 0.9614 - val_loss: 0.1129 - val_acc: 0.9587
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1118 - acc: 0.9626 - val_loss: 0.1132 - val_acc: 0.9583
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1112 - acc: 0.9654 - val_loss: 0.1127 - val_acc: 0.9603
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1112 - acc: 0.9651 - val_loss: 0.1127 - val_acc: 0.9623
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1112 - acc: 0.9640 - val_loss: 0.1126 - val_acc: 0.9605
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1104 - acc: 0.9677 - val_loss: 0.1152 - val_acc: 0.9509
Epoch 20/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1103 - acc: 0.9681 - val_loss: 0.1124 - val_acc: 0.9609
Epoch 21/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1102 - acc: 0.9682 - val_loss: 0.1158 - val_acc: 0.9483
Epoch 22/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1102 - acc: 0.9676 - val_loss: 0.1124 - val_acc: 0.9615
Epoch 23/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1096 - acc: 0.9700 - val_loss: 0.1126 - val_acc: 0.9606
Epoch 24/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1092 - acc: 0.9710 - val_loss: 0.1132 - val_acc: 0.9584
Epoch 25/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1092 - acc: 0.9714 - val_loss: 0.1124 - val_acc: 0.9623
Manual evaluation: (didn't understand why I made this)
True 8267
False 804
True percentage 0.911365891302
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.97      0.98      7318
      B-ORG       0.76      0.73      0.74       296
      I-ORG       0.59      0.58      0.59       151
     B-MISC       0.50      0.29      0.37       141
     I-MISC       0.59      0.34      0.43       154
      B-PER       0.92      0.85      0.88       438
      B-LOC       0.71      0.80      0.75       218
      I-LOC       0.67      0.84      0.74       141
      I-PER       0.92      0.66      0.77       214

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.720311097816
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 9
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1460 - acc: 0.8512 - val_loss: 0.1311 - val_acc: 0.8854
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1284 - acc: 0.9092 - val_loss: 0.1227 - val_acc: 0.9259
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1244 - acc: 0.9225 - val_loss: 0.1228 - val_acc: 0.9228
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1215 - acc: 0.9320 - val_loss: 0.1233 - val_acc: 0.9283
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1198 - acc: 0.9378 - val_loss: 0.1209 - val_acc: 0.9358
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1184 - acc: 0.9420 - val_loss: 0.1174 - val_acc: 0.9415
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1171 - acc: 0.9471 - val_loss: 0.1168 - val_acc: 0.9445
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1161 - acc: 0.9494 - val_loss: 0.1163 - val_acc: 0.9449
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1152 - acc: 0.9509 - val_loss: 0.1158 - val_acc: 0.9475
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1147 - acc: 0.9537 - val_loss: 0.1155 - val_acc: 0.9493
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1142 - acc: 0.9555 - val_loss: 0.1150 - val_acc: 0.9498
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1133 - acc: 0.9585 - val_loss: 0.1157 - val_acc: 0.9470
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1127 - acc: 0.9599 - val_loss: 0.1151 - val_acc: 0.9494
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1124 - acc: 0.9619 - val_loss: 0.1153 - val_acc: 0.9484
Manual evaluation: (didn't understand why I made this)
True 8229
False 842
True percentage 0.90717671701
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.91      0.84      0.87       438
          O       0.98      0.97      0.97      7318
      B-ORG       0.69      0.78      0.73       296
     B-MISC       0.59      0.18      0.28       141
      B-LOC       0.75      0.72      0.73       218
      I-LOC       0.76      0.76      0.76       141
     I-MISC       0.62      0.21      0.31       154
      I-PER       0.88      0.66      0.76       214
      I-ORG       0.45      0.68      0.54       151

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.925821264571
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 10
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 25ms/step - loss: 0.1463 - acc: 0.8553 - val_loss: 0.1292 - val_acc: 0.9023
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1285 - acc: 0.9081 - val_loss: 0.1226 - val_acc: 0.9210
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1244 - acc: 0.9222 - val_loss: 0.1192 - val_acc: 0.9385
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1220 - acc: 0.9321 - val_loss: 0.1154 - val_acc: 0.9481
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1196 - acc: 0.9388 - val_loss: 0.1150 - val_acc: 0.9491
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1182 - acc: 0.9431 - val_loss: 0.1141 - val_acc: 0.9553
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1172 - acc: 0.9470 - val_loss: 0.1154 - val_acc: 0.9507
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1163 - acc: 0.9487 - val_loss: 0.1134 - val_acc: 0.9567
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1152 - acc: 0.9532 - val_loss: 0.1130 - val_acc: 0.9587
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1142 - acc: 0.9562 - val_loss: 0.1128 - val_acc: 0.9593
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1139 - acc: 0.9576 - val_loss: 0.1122 - val_acc: 0.9596
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1128 - acc: 0.9616 - val_loss: 0.1124 - val_acc: 0.9621
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1130 - acc: 0.9594 - val_loss: 0.1118 - val_acc: 0.9622
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1119 - acc: 0.9628 - val_loss: 0.1116 - val_acc: 0.9636
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1119 - acc: 0.9628 - val_loss: 0.1114 - val_acc: 0.9641
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1115 - acc: 0.9638 - val_loss: 0.1115 - val_acc: 0.9647
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1109 - acc: 0.9666 - val_loss: 0.1115 - val_acc: 0.9633
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1107 - acc: 0.9674 - val_loss: 0.1127 - val_acc: 0.9629
Manual evaluation: (didn't understand why I made this)
True 8226
False 845
True percentage 0.906845992724
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.92      0.85      0.88       438
          O       0.99      0.96      0.97      7318
      B-LOC       0.72      0.75      0.73       218
      I-LOC       0.67      0.78      0.72       141
      I-PER       0.94      0.63      0.75       214
      B-ORG       0.80      0.68      0.73       296
      I-ORG       0.70      0.42      0.53       151
     B-MISC       0.41      0.42      0.41       141
     I-MISC       0.41      0.57      0.48       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.924879312375
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 11
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 24ms/step - loss: 0.1475 - acc: 0.8531 - val_loss: 0.1395 - val_acc: 0.8691
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1282 - acc: 0.9081 - val_loss: 0.1335 - val_acc: 0.9015
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1244 - acc: 0.9242 - val_loss: 0.1227 - val_acc: 0.9299
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1218 - acc: 0.9319 - val_loss: 0.1224 - val_acc: 0.9293
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1195 - acc: 0.9397 - val_loss: 0.1212 - val_acc: 0.9359
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1186 - acc: 0.9413 - val_loss: 0.1209 - val_acc: 0.9373
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1171 - acc: 0.9462 - val_loss: 0.1196 - val_acc: 0.9446
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1161 - acc: 0.9488 - val_loss: 0.1193 - val_acc: 0.9432
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1151 - acc: 0.9525 - val_loss: 0.1186 - val_acc: 0.9451
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1145 - acc: 0.9547 - val_loss: 0.1194 - val_acc: 0.9450
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1140 - acc: 0.9571 - val_loss: 0.1188 - val_acc: 0.9465
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1130 - acc: 0.9602 - val_loss: 0.1185 - val_acc: 0.9479
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1126 - acc: 0.9620 - val_loss: 0.1183 - val_acc: 0.9481
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1119 - acc: 0.9620 - val_loss: 0.1194 - val_acc: 0.9481
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1117 - acc: 0.9639 - val_loss: 0.1180 - val_acc: 0.9487
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1112 - acc: 0.9653 - val_loss: 0.1179 - val_acc: 0.9487
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1110 - acc: 0.9660 - val_loss: 0.1183 - val_acc: 0.9506
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1107 - acc: 0.9673 - val_loss: 0.1182 - val_acc: 0.9503
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1102 - acc: 0.9690 - val_loss: 0.1183 - val_acc: 0.9511
Manual evaluation: (didn't understand why I made this)
True 8257
False 814
True percentage 0.910263477015
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.77      0.74      0.75       296
     B-MISC       0.67      0.26      0.37       141
     I-MISC       0.55      0.34      0.42       154
      B-PER       0.91      0.84      0.87       438
      B-LOC       0.68      0.82      0.74       218
      I-ORG       0.61      0.58      0.60       151
      I-PER       0.93      0.66      0.77       214
      I-LOC       0.61      0.85      0.71       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.718423409973
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 12
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 24ms/step - loss: 0.1477 - acc: 0.8514 - val_loss: 0.1336 - val_acc: 0.8946
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1289 - acc: 0.9081 - val_loss: 0.1232 - val_acc: 0.9273
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1247 - acc: 0.9218 - val_loss: 0.1230 - val_acc: 0.9256
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1223 - acc: 0.9304 - val_loss: 0.1212 - val_acc: 0.9341
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1201 - acc: 0.9380 - val_loss: 0.1187 - val_acc: 0.9407
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1188 - acc: 0.9403 - val_loss: 0.1178 - val_acc: 0.9466
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1179 - acc: 0.9430 - val_loss: 0.1200 - val_acc: 0.9425
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1168 - acc: 0.9478 - val_loss: 0.1172 - val_acc: 0.9485
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1153 - acc: 0.9524 - val_loss: 0.1160 - val_acc: 0.9535
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1148 - acc: 0.9544 - val_loss: 0.1163 - val_acc: 0.9550
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1142 - acc: 0.9568 - val_loss: 0.1159 - val_acc: 0.9555
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1133 - acc: 0.9585 - val_loss: 0.1153 - val_acc: 0.9576
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1130 - acc: 0.9588 - val_loss: 0.1155 - val_acc: 0.9571
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1127 - acc: 0.9601 - val_loss: 0.1154 - val_acc: 0.9545
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1121 - acc: 0.9621 - val_loss: 0.1148 - val_acc: 0.9578
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1114 - acc: 0.9653 - val_loss: 0.1149 - val_acc: 0.9585
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1114 - acc: 0.9644 - val_loss: 0.1148 - val_acc: 0.9582
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1107 - acc: 0.9667 - val_loss: 0.1146 - val_acc: 0.9593
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1102 - acc: 0.9680 - val_loss: 0.1149 - val_acc: 0.9581
Epoch 20/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1102 - acc: 0.9680 - val_loss: 0.1147 - val_acc: 0.9587
Epoch 21/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1098 - acc: 0.9690 - val_loss: 0.1146 - val_acc: 0.9617
Epoch 22/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1098 - acc: 0.9707 - val_loss: 0.1149 - val_acc: 0.9601
Epoch 23/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1095 - acc: 0.9716 - val_loss: 0.1146 - val_acc: 0.9603
Epoch 24/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1094 - acc: 0.9718 - val_loss: 0.1148 - val_acc: 0.9602
Epoch 25/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1087 - acc: 0.9734 - val_loss: 0.1146 - val_acc: 0.9607
Epoch 26/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1086 - acc: 0.9735 - val_loss: 0.1150 - val_acc: 0.9622
Manual evaluation: (didn't understand why I made this)
True 8281
False 790
True percentage 0.912909271304
Sklearn evaluation:
             precision    recall  f1-score   support

     B-MISC       0.62      0.27      0.38       141
     I-MISC       0.65      0.31      0.42       154
          O       0.98      0.97      0.97      7318
      B-PER       0.93      0.86      0.89       438
      I-PER       0.94      0.65      0.77       214
      B-ORG       0.75      0.75      0.75       296
      B-LOC       0.71      0.79      0.75       218
      I-ORG       0.65      0.60      0.63       151
      I-LOC       0.65      0.85      0.74       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.935322818563
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 13
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 24ms/step - loss: 0.1446 - acc: 0.8569 - val_loss: 0.1307 - val_acc: 0.8903
Epoch 2/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1278 - acc: 0.9109 - val_loss: 0.1230 - val_acc: 0.9226
Epoch 3/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1242 - acc: 0.9227 - val_loss: 0.1183 - val_acc: 0.9438
Epoch 4/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1212 - acc: 0.9315 - val_loss: 0.1187 - val_acc: 0.9361
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1193 - acc: 0.9382 - val_loss: 0.1199 - val_acc: 0.9362
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1181 - acc: 0.9436 - val_loss: 0.1148 - val_acc: 0.9556
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1169 - acc: 0.9461 - val_loss: 0.1153 - val_acc: 0.9562
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1158 - acc: 0.9498 - val_loss: 0.1142 - val_acc: 0.9556
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1150 - acc: 0.9525 - val_loss: 0.1138 - val_acc: 0.9585
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1143 - acc: 0.9552 - val_loss: 0.1135 - val_acc: 0.9605
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1141 - acc: 0.9551 - val_loss: 0.1132 - val_acc: 0.9577
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1132 - acc: 0.9582 - val_loss: 0.1130 - val_acc: 0.9591
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1126 - acc: 0.9603 - val_loss: 0.1127 - val_acc: 0.9600
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1121 - acc: 0.9617 - val_loss: 0.1129 - val_acc: 0.9608
Epoch 15/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1119 - acc: 0.9626 - val_loss: 0.1124 - val_acc: 0.9634
Epoch 16/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1114 - acc: 0.9640 - val_loss: 0.1123 - val_acc: 0.9645
Epoch 17/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1110 - acc: 0.9664 - val_loss: 0.1124 - val_acc: 0.9640
Epoch 18/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1106 - acc: 0.9662 - val_loss: 0.1122 - val_acc: 0.9631
Epoch 19/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1106 - acc: 0.9665 - val_loss: 0.1117 - val_acc: 0.9651
Epoch 20/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1102 - acc: 0.9680 - val_loss: 0.1119 - val_acc: 0.9637
Epoch 21/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1097 - acc: 0.9696 - val_loss: 0.1117 - val_acc: 0.9657
Epoch 22/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1092 - acc: 0.9709 - val_loss: 0.1120 - val_acc: 0.9666
Epoch 23/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1093 - acc: 0.9718 - val_loss: 0.1121 - val_acc: 0.9649
Epoch 24/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1095 - acc: 0.9707 - val_loss: 0.1118 - val_acc: 0.9651
Manual evaluation: (didn't understand why I made this)
True 8270
False 801
True percentage 0.911696615588
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.91      0.84      0.88       438
      B-ORG       0.76      0.76      0.76       296
     B-MISC       0.56      0.30      0.39       141
     I-MISC       0.56      0.40      0.46       154
      I-ORG       0.62      0.59      0.60       151
      B-LOC       0.72      0.78      0.75       218
      I-LOC       0.65      0.82      0.73       141
      I-PER       0.91      0.66      0.77       214

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.725052129878
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 14
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 24ms/step - loss: 0.1489 - acc: 0.8497 - val_loss: 0.1316 - val_acc: 0.8890
Epoch 2/70

1506/1506 [==============================] - 32s 22ms/step - loss: 0.1288 - acc: 0.9085 - val_loss: 0.1260 - val_acc: 0.9151
Epoch 3/70

1506/1506 [==============================] - 32s 22ms/step - loss: 0.1245 - acc: 0.9237 - val_loss: 0.1224 - val_acc: 0.9307
Epoch 4/70

1506/1506 [==============================] - 32s 22ms/step - loss: 0.1221 - acc: 0.9319 - val_loss: 0.1204 - val_acc: 0.9367
Epoch 5/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1200 - acc: 0.9385 - val_loss: 0.1218 - val_acc: 0.9271
Epoch 6/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1188 - acc: 0.9422 - val_loss: 0.1180 - val_acc: 0.9453
Epoch 7/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1173 - acc: 0.9449 - val_loss: 0.1181 - val_acc: 0.9420
Epoch 8/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1164 - acc: 0.9486 - val_loss: 0.1171 - val_acc: 0.9471
Epoch 9/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1153 - acc: 0.9524 - val_loss: 0.1165 - val_acc: 0.9488
Epoch 10/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1145 - acc: 0.9547 - val_loss: 0.1161 - val_acc: 0.9499
Epoch 11/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1141 - acc: 0.9556 - val_loss: 0.1158 - val_acc: 0.9524
Epoch 12/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1133 - acc: 0.9591 - val_loss: 0.1159 - val_acc: 0.9513
Epoch 13/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1129 - acc: 0.9596 - val_loss: 0.1158 - val_acc: 0.9516
Epoch 14/70

1506/1506 [==============================] - 33s 22ms/step - loss: 0.1126 - acc: 0.9612 - val_loss: 0.1168 - val_acc: 0.9533
Manual evaluation: (didn't understand why I made this)
True 8206
False 865
True percentage 0.904641164149
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.80      0.68      0.73       296
      I-ORG       0.65      0.40      0.50       151
      B-PER       0.91      0.84      0.87       438
     B-MISC       0.41      0.43      0.42       141
     I-MISC       0.39      0.60      0.47       154
      B-LOC       0.70      0.79      0.75       218
      I-LOC       0.65      0.79      0.72       141
      I-PER       0.92      0.65      0.77       214

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.698955916473
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 20s 27ms/step - loss: 0.1595 - acc: 0.8143 - val_loss: 0.1334 - val_acc: 0.8886
Epoch 2/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1344 - acc: 0.8916 - val_loss: 0.1332 - val_acc: 0.8926
Epoch 3/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1299 - acc: 0.9030 - val_loss: 0.1271 - val_acc: 0.9083
Epoch 4/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1264 - acc: 0.9164 - val_loss: 0.1239 - val_acc: 0.9191
Epoch 5/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1241 - acc: 0.9242 - val_loss: 0.1224 - val_acc: 0.9205
Epoch 6/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1214 - acc: 0.9318 - val_loss: 0.1221 - val_acc: 0.9224
Epoch 7/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1201 - acc: 0.9357 - val_loss: 0.1209 - val_acc: 0.9248
Epoch 8/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1186 - acc: 0.9426 - val_loss: 0.1203 - val_acc: 0.9308
Epoch 9/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1177 - acc: 0.9469 - val_loss: 0.1211 - val_acc: 0.9289
Epoch 10/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1173 - acc: 0.9472 - val_loss: 0.1214 - val_acc: 0.9317
Epoch 11/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1160 - acc: 0.9494 - val_loss: 0.1204 - val_acc: 0.9280
Manual evaluation: (didn't understand why I made this)
True 8049
False 1022
True percentage 0.887333259839
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-PER       0.89      0.73      0.80       438
      B-LOC       0.68      0.78      0.73       218
      B-ORG       0.59      0.69      0.64       296
      I-ORG       0.37      0.44      0.40       151
      I-PER       0.85      0.64      0.73       214
      I-LOC       0.61      0.81      0.69       141
     B-MISC       0.49      0.23      0.32       141
     I-MISC       0.36      0.23      0.28       154

avg / total       0.93      0.89      0.90      9071

F-1 Score:
0.634677656756
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 20s 27ms/step - loss: 0.1666 - acc: 0.7965 - val_loss: 0.1367 - val_acc: 0.8818
Epoch 2/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1353 - acc: 0.8874 - val_loss: 0.1308 - val_acc: 0.9064
Epoch 3/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1300 - acc: 0.9031 - val_loss: 0.1283 - val_acc: 0.9114
Epoch 4/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1266 - acc: 0.9171 - val_loss: 0.1266 - val_acc: 0.9133
Epoch 5/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1245 - acc: 0.9231 - val_loss: 0.1249 - val_acc: 0.9154
Epoch 6/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1218 - acc: 0.9325 - val_loss: 0.1240 - val_acc: 0.9193
Epoch 7/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1210 - acc: 0.9326 - val_loss: 0.1240 - val_acc: 0.9197
Epoch 8/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1193 - acc: 0.9394 - val_loss: 0.1235 - val_acc: 0.9204
Epoch 9/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1181 - acc: 0.9444 - val_loss: 0.1226 - val_acc: 0.9233
Epoch 10/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1172 - acc: 0.9449 - val_loss: 0.1221 - val_acc: 0.9255
Epoch 11/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1164 - acc: 0.9484 - val_loss: 0.1221 - val_acc: 0.9243
Epoch 12/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1161 - acc: 0.9500 - val_loss: 0.1216 - val_acc: 0.9248
Epoch 13/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1150 - acc: 0.9529 - val_loss: 0.1218 - val_acc: 0.9245
Epoch 14/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1143 - acc: 0.9546 - val_loss: 0.1217 - val_acc: 0.9209
Epoch 15/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1135 - acc: 0.9583 - val_loss: 0.1216 - val_acc: 0.9234
Epoch 16/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1137 - acc: 0.9581 - val_loss: 0.1211 - val_acc: 0.9284
Epoch 17/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1125 - acc: 0.9603 - val_loss: 0.1210 - val_acc: 0.9255
Epoch 18/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1127 - acc: 0.9594 - val_loss: 0.1209 - val_acc: 0.9310
Epoch 19/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1125 - acc: 0.9593 - val_loss: 0.1214 - val_acc: 0.9319
Epoch 20/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1113 - acc: 0.9651 - val_loss: 0.1209 - val_acc: 0.9309
Epoch 21/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1112 - acc: 0.9660 - val_loss: 0.1210 - val_acc: 0.9336
Manual evaluation: (didn't understand why I made this)
True 8170
False 901
True percentage 0.900672472715
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.70      0.69      0.70       296
      B-LOC       0.72      0.78      0.75       218
      I-ORG       0.46      0.58      0.51       151
     B-MISC       0.47      0.29      0.36       141
     I-MISC       0.41      0.30      0.35       154
      B-PER       0.91      0.82      0.86       438
      I-PER       0.91      0.65      0.76       214
      I-LOC       0.73      0.78      0.75       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.68625704957
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 2
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104300 unique words.
4296 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 249
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6675264     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,183,938
Trainable params: 7,183,938
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 20s 27ms/step - loss: 0.1611 - acc: 0.8104 - val_loss: 0.1327 - val_acc: 0.9062
Epoch 2/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1344 - acc: 0.8904 - val_loss: 0.1265 - val_acc: 0.9191
Epoch 3/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1291 - acc: 0.9082 - val_loss: 0.1234 - val_acc: 0.9305
Epoch 4/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1259 - acc: 0.9182 - val_loss: 0.1212 - val_acc: 0.9352
Epoch 5/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1239 - acc: 0.9225 - val_loss: 0.1210 - val_acc: 0.9316
Epoch 6/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1220 - acc: 0.9286 - val_loss: 0.1190 - val_acc: 0.9427
Epoch 7/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1208 - acc: 0.9341 - val_loss: 0.1187 - val_acc: 0.9422
Epoch 8/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1191 - acc: 0.9399 - val_loss: 0.1191 - val_acc: 0.9415
Epoch 9/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1185 - acc: 0.9413 - val_loss: 0.1176 - val_acc: 0.9439
Epoch 10/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1169 - acc: 0.9464 - val_loss: 0.1169 - val_acc: 0.9482
Epoch 11/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1168 - acc: 0.9462 - val_loss: 0.1162 - val_acc: 0.9458
Epoch 12/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1158 - acc: 0.9507 - val_loss: 0.1165 - val_acc: 0.9493
Epoch 13/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1147 - acc: 0.9545 - val_loss: 0.1162 - val_acc: 0.9493
Epoch 14/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1144 - acc: 0.9560 - val_loss: 0.1160 - val_acc: 0.9528
Epoch 15/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1137 - acc: 0.9565 - val_loss: 0.1159 - val_acc: 0.9499
Epoch 16/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1129 - acc: 0.9597 - val_loss: 0.1153 - val_acc: 0.9510
Epoch 17/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1130 - acc: 0.9592 - val_loss: 0.1156 - val_acc: 0.9517
Epoch 18/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1124 - acc: 0.9615 - val_loss: 0.1151 - val_acc: 0.9517
Epoch 19/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1118 - acc: 0.9641 - val_loss: 0.1157 - val_acc: 0.9528
Epoch 20/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1114 - acc: 0.9659 - val_loss: 0.1155 - val_acc: 0.9541
Epoch 21/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1112 - acc: 0.9641 - val_loss: 0.1150 - val_acc: 0.9517
Epoch 22/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1112 - acc: 0.9658 - val_loss: 0.1154 - val_acc: 0.9528
Epoch 23/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1106 - acc: 0.9670 - val_loss: 0.1148 - val_acc: 0.9505
Epoch 24/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1102 - acc: 0.9668 - val_loss: 0.1152 - val_acc: 0.9530
Epoch 25/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1104 - acc: 0.9687 - val_loss: 0.1152 - val_acc: 0.9540
Epoch 26/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1097 - acc: 0.9704 - val_loss: 0.1148 - val_acc: 0.9540
Epoch 27/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1095 - acc: 0.9710 - val_loss: 0.1149 - val_acc: 0.9535
Epoch 28/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1095 - acc: 0.9709 - val_loss: 0.1152 - val_acc: 0.9552
Epoch 29/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1087 - acc: 0.9727 - val_loss: 0.1149 - val_acc: 0.9546
Manual evaluation: (didn't understand why I made this)
True 8175
False 896
True percentage 0.901223679859
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.90      0.82      0.85       438
      B-ORG       0.73      0.71      0.72       296
      I-ORG       0.53      0.52      0.52       151
      I-PER       0.89      0.64      0.75       214
      B-LOC       0.71      0.76      0.73       218
      I-LOC       0.67      0.78      0.72       141
     B-MISC       0.48      0.22      0.30       141
     I-MISC       0.54      0.41      0.47       154

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.695154980439
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 3
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104300 unique words.
4296 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 245
OOV word occurences: 342
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6675264     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,183,938
Trainable params: 7,183,938
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 16s 21ms/step - loss: 0.1574 - acc: 0.8247 - val_loss: 0.1369 - val_acc: 0.8868
Epoch 2/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1327 - acc: 0.8946 - val_loss: 0.1287 - val_acc: 0.9103
Epoch 3/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1280 - acc: 0.9135 - val_loss: 0.1244 - val_acc: 0.9307
Epoch 4/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1247 - acc: 0.9211 - val_loss: 0.1236 - val_acc: 0.9269
Epoch 5/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1221 - acc: 0.9302 - val_loss: 0.1207 - val_acc: 0.9362
Epoch 6/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1205 - acc: 0.9350 - val_loss: 0.1203 - val_acc: 0.9417
Epoch 7/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1195 - acc: 0.9388 - val_loss: 0.1201 - val_acc: 0.9418
Epoch 8/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1185 - acc: 0.9433 - val_loss: 0.1188 - val_acc: 0.9436
Epoch 9/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1173 - acc: 0.9476 - val_loss: 0.1185 - val_acc: 0.9430
Epoch 10/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1164 - acc: 0.9494 - val_loss: 0.1179 - val_acc: 0.9454
Epoch 11/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1153 - acc: 0.9523 - val_loss: 0.1178 - val_acc: 0.9442
Epoch 12/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1145 - acc: 0.9560 - val_loss: 0.1174 - val_acc: 0.9448
Epoch 13/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1137 - acc: 0.9587 - val_loss: 0.1171 - val_acc: 0.9473
Epoch 14/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1139 - acc: 0.9567 - val_loss: 0.1171 - val_acc: 0.9485
Epoch 15/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1128 - acc: 0.9606 - val_loss: 0.1164 - val_acc: 0.9479
Epoch 16/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1119 - acc: 0.9630 - val_loss: 0.1166 - val_acc: 0.9491
Epoch 17/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1120 - acc: 0.9638 - val_loss: 0.1166 - val_acc: 0.9509
Epoch 18/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1111 - acc: 0.9657 - val_loss: 0.1163 - val_acc: 0.9497
Epoch 19/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1112 - acc: 0.9653 - val_loss: 0.1164 - val_acc: 0.9541
Epoch 20/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1105 - acc: 0.9676 - val_loss: 0.1162 - val_acc: 0.9535
Epoch 21/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1103 - acc: 0.9693 - val_loss: 0.1160 - val_acc: 0.9540
Epoch 22/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1099 - acc: 0.9699 - val_loss: 0.1163 - val_acc: 0.9535
Epoch 23/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1096 - acc: 0.9702 - val_loss: 0.1160 - val_acc: 0.9527
Epoch 24/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1096 - acc: 0.9704 - val_loss: 0.1160 - val_acc: 0.9546
Epoch 25/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1092 - acc: 0.9715 - val_loss: 0.1161 - val_acc: 0.9553
Epoch 26/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1089 - acc: 0.9728 - val_loss: 0.1161 - val_acc: 0.9577
Epoch 27/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1088 - acc: 0.9735 - val_loss: 0.1162 - val_acc: 0.9559
Manual evaluation: (didn't understand why I made this)
True 8188
False 883
True percentage 0.902656818432
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
     B-MISC       0.64      0.21      0.32       141
     I-MISC       0.64      0.23      0.34       154
      B-ORG       0.68      0.75      0.71       296
      I-ORG       0.55      0.53      0.54       151
      B-PER       0.91      0.81      0.86       438
      I-PER       0.91      0.64      0.75       214
      B-LOC       0.68      0.77      0.72       218
      I-LOC       0.57      0.84      0.68       141

avg / total       0.94      0.90      0.91      9071

F-1 Score:
0.690174804099
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 4
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104281 unique words.
4277 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 248
OOV word occurences: 376
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6674048     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,182,722
Trainable params: 7,182,722
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 17s 23ms/step - loss: 0.1588 - acc: 0.8153 - val_loss: 0.1334 - val_acc: 0.8933
Epoch 2/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1327 - acc: 0.8963 - val_loss: 0.1270 - val_acc: 0.9101
Epoch 3/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1285 - acc: 0.9095 - val_loss: 0.1254 - val_acc: 0.9173
Epoch 4/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1254 - acc: 0.9186 - val_loss: 0.1224 - val_acc: 0.9277
Epoch 5/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1232 - acc: 0.9277 - val_loss: 0.1213 - val_acc: 0.9297
Epoch 6/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1206 - acc: 0.9381 - val_loss: 0.1204 - val_acc: 0.9363
Epoch 7/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1199 - acc: 0.9369 - val_loss: 0.1200 - val_acc: 0.9364
Epoch 8/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1185 - acc: 0.9420 - val_loss: 0.1194 - val_acc: 0.9360
Epoch 9/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1172 - acc: 0.9470 - val_loss: 0.1193 - val_acc: 0.9417
Epoch 10/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1163 - acc: 0.9492 - val_loss: 0.1186 - val_acc: 0.9431
Epoch 11/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1157 - acc: 0.9524 - val_loss: 0.1184 - val_acc: 0.9426
Epoch 12/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1143 - acc: 0.9568 - val_loss: 0.1182 - val_acc: 0.9458
Epoch 13/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1139 - acc: 0.9569 - val_loss: 0.1182 - val_acc: 0.9458
Epoch 14/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1134 - acc: 0.9575 - val_loss: 0.1179 - val_acc: 0.9468
Epoch 15/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1126 - acc: 0.9607 - val_loss: 0.1179 - val_acc: 0.9474
Epoch 16/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1122 - acc: 0.9618 - val_loss: 0.1178 - val_acc: 0.9458
Epoch 17/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1122 - acc: 0.9620 - val_loss: 0.1175 - val_acc: 0.9486
Epoch 18/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1121 - acc: 0.9615 - val_loss: 0.1176 - val_acc: 0.9470
Epoch 19/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1110 - acc: 0.9669 - val_loss: 0.1177 - val_acc: 0.9486
Epoch 20/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1107 - acc: 0.9670 - val_loss: 0.1174 - val_acc: 0.9486
Epoch 21/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1104 - acc: 0.9673 - val_loss: 0.1175 - val_acc: 0.9480
Epoch 22/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1099 - acc: 0.9691 - val_loss: 0.1175 - val_acc: 0.9469
Epoch 23/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1097 - acc: 0.9702 - val_loss: 0.1174 - val_acc: 0.9508
Epoch 24/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1096 - acc: 0.9703 - val_loss: 0.1176 - val_acc: 0.9458
Epoch 25/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1093 - acc: 0.9695 - val_loss: 0.1174 - val_acc: 0.9492
Epoch 26/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1088 - acc: 0.9736 - val_loss: 0.1173 - val_acc: 0.9503
Epoch 27/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1088 - acc: 0.9726 - val_loss: 0.1179 - val_acc: 0.9486
Epoch 28/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1085 - acc: 0.9730 - val_loss: 0.1173 - val_acc: 0.9520
Epoch 29/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1080 - acc: 0.9765 - val_loss: 0.1175 - val_acc: 0.9501
Epoch 30/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1080 - acc: 0.9756 - val_loss: 0.1175 - val_acc: 0.9524
Epoch 31/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1077 - acc: 0.9756 - val_loss: 0.1178 - val_acc: 0.9504
Manual evaluation: (didn't understand why I made this)
True 8164
False 907
True percentage 0.900011024143
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.73      0.70      0.71       296
      B-LOC       0.72      0.72      0.72       218
      B-PER       0.89      0.77      0.82       438
      I-PER       0.89      0.65      0.75       214
     B-MISC       0.49      0.26      0.34       141
      I-ORG       0.58      0.62      0.60       151
      I-LOC       0.70      0.74      0.72       141
     I-MISC       0.55      0.38      0.45       154

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.689802130898
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 5
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104246 unique words.
4242 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 339
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6671808     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,180,482
Trainable params: 7,180,482
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 18s 23ms/step - loss: 0.1647 - acc: 0.8045 - val_loss: 0.1301 - val_acc: 0.9003
Epoch 2/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1349 - acc: 0.8866 - val_loss: 0.1235 - val_acc: 0.9246
Epoch 3/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1294 - acc: 0.9091 - val_loss: 0.1210 - val_acc: 0.9263
Epoch 4/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1261 - acc: 0.9183 - val_loss: 0.1197 - val_acc: 0.9292
Epoch 5/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1246 - acc: 0.9204 - val_loss: 0.1184 - val_acc: 0.9378
Epoch 6/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1219 - acc: 0.9317 - val_loss: 0.1173 - val_acc: 0.9396
Epoch 7/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1211 - acc: 0.9351 - val_loss: 0.1158 - val_acc: 0.9395
Epoch 8/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1194 - acc: 0.9402 - val_loss: 0.1149 - val_acc: 0.9464
Epoch 9/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1185 - acc: 0.9423 - val_loss: 0.1147 - val_acc: 0.9459
Epoch 10/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1173 - acc: 0.9469 - val_loss: 0.1151 - val_acc: 0.9453
Epoch 11/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1164 - acc: 0.9474 - val_loss: 0.1141 - val_acc: 0.9482
Epoch 12/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1158 - acc: 0.9496 - val_loss: 0.1144 - val_acc: 0.9482
Epoch 13/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1150 - acc: 0.9545 - val_loss: 0.1146 - val_acc: 0.9465
Epoch 14/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1144 - acc: 0.9530 - val_loss: 0.1129 - val_acc: 0.9546
Epoch 15/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1137 - acc: 0.9576 - val_loss: 0.1125 - val_acc: 0.9552
Epoch 16/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1131 - acc: 0.9594 - val_loss: 0.1132 - val_acc: 0.9558
Epoch 17/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1125 - acc: 0.9623 - val_loss: 0.1129 - val_acc: 0.9558
Epoch 18/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1125 - acc: 0.9624 - val_loss: 0.1126 - val_acc: 0.9575
Manual evaluation: (didn't understand why I made this)
True 8163
False 908
True percentage 0.899900782714
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.91      0.82      0.86       438
      B-ORG       0.68      0.70      0.69       296
     I-MISC       0.46      0.36      0.40       154
      B-LOC       0.69      0.75      0.72       218
      I-LOC       0.62      0.83      0.71       141
      I-ORG       0.51      0.47      0.49       151
      I-PER       0.89      0.64      0.75       214
     B-MISC       0.49      0.26      0.34       141

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.680712166172
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 6
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104283 unique words.
4279 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 379
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6674176     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,182,850
Trainable params: 7,182,850
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 18s 24ms/step - loss: 0.1613 - acc: 0.8080 - val_loss: 0.1342 - val_acc: 0.8958
Epoch 2/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1338 - acc: 0.8916 - val_loss: 0.1283 - val_acc: 0.9080
Epoch 3/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1292 - acc: 0.9082 - val_loss: 0.1262 - val_acc: 0.9220
Epoch 4/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1261 - acc: 0.9178 - val_loss: 0.1239 - val_acc: 0.9260
Epoch 5/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1235 - acc: 0.9269 - val_loss: 0.1230 - val_acc: 0.9274
Epoch 6/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1218 - acc: 0.9298 - val_loss: 0.1214 - val_acc: 0.9346
Epoch 7/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1205 - acc: 0.9358 - val_loss: 0.1201 - val_acc: 0.9367
Epoch 8/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1190 - acc: 0.9402 - val_loss: 0.1197 - val_acc: 0.9357
Epoch 9/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1178 - acc: 0.9428 - val_loss: 0.1191 - val_acc: 0.9388
Epoch 10/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1174 - acc: 0.9465 - val_loss: 0.1189 - val_acc: 0.9403
Epoch 11/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1157 - acc: 0.9515 - val_loss: 0.1190 - val_acc: 0.9400
Epoch 12/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1155 - acc: 0.9512 - val_loss: 0.1185 - val_acc: 0.9424
Epoch 13/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1149 - acc: 0.9526 - val_loss: 0.1180 - val_acc: 0.9439
Epoch 14/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1139 - acc: 0.9580 - val_loss: 0.1178 - val_acc: 0.9435
Epoch 15/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1130 - acc: 0.9601 - val_loss: 0.1179 - val_acc: 0.9445
Epoch 16/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1131 - acc: 0.9583 - val_loss: 0.1180 - val_acc: 0.9451
Epoch 17/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1129 - acc: 0.9607 - val_loss: 0.1174 - val_acc: 0.9470
Epoch 18/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1124 - acc: 0.9606 - val_loss: 0.1171 - val_acc: 0.9491
Epoch 19/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1121 - acc: 0.9637 - val_loss: 0.1170 - val_acc: 0.9480
Epoch 20/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1108 - acc: 0.9673 - val_loss: 0.1172 - val_acc: 0.9475
Epoch 21/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1113 - acc: 0.9643 - val_loss: 0.1174 - val_acc: 0.9485
Epoch 22/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1107 - acc: 0.9666 - val_loss: 0.1170 - val_acc: 0.9480
Manual evaluation: (didn't understand why I made this)
True 8168
False 903
True percentage 0.900451989858
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.89      0.74      0.81       438
      B-LOC       0.70      0.74      0.72       218
      B-ORG       0.70      0.71      0.71       296
      I-PER       0.87      0.65      0.75       214
     B-MISC       0.55      0.29      0.38       141
     I-MISC       0.57      0.43      0.49       154
      I-LOC       0.62      0.81      0.70       141
      I-ORG       0.63      0.52      0.57       151

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.687027517387
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 7
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104285 unique words.
4281 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6674304     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,182,978
Trainable params: 7,182,978
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 16s 21ms/step - loss: 0.1577 - acc: 0.8185 - val_loss: 0.1281 - val_acc: 0.9091
Epoch 2/70

753/753 [==============================] - 13s 17ms/step - loss: 0.1321 - acc: 0.8960 - val_loss: 0.1224 - val_acc: 0.9286
Epoch 3/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1278 - acc: 0.9119 - val_loss: 0.1192 - val_acc: 0.9352
Epoch 4/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1245 - acc: 0.9217 - val_loss: 0.1173 - val_acc: 0.9458
Epoch 5/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1224 - acc: 0.9290 - val_loss: 0.1157 - val_acc: 0.9477
Epoch 6/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1208 - acc: 0.9346 - val_loss: 0.1152 - val_acc: 0.9506
Epoch 7/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1191 - acc: 0.9420 - val_loss: 0.1143 - val_acc: 0.9540
Epoch 8/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1185 - acc: 0.9429 - val_loss: 0.1130 - val_acc: 0.9572
Epoch 9/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1172 - acc: 0.9466 - val_loss: 0.1134 - val_acc: 0.9567
Epoch 10/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1160 - acc: 0.9475 - val_loss: 0.1132 - val_acc: 0.9578
Epoch 11/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1152 - acc: 0.9529 - val_loss: 0.1127 - val_acc: 0.9573
Epoch 12/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1142 - acc: 0.9558 - val_loss: 0.1116 - val_acc: 0.9635
Epoch 13/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1141 - acc: 0.9561 - val_loss: 0.1120 - val_acc: 0.9596
Epoch 14/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1137 - acc: 0.9568 - val_loss: 0.1115 - val_acc: 0.9652
Epoch 15/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1129 - acc: 0.9607 - val_loss: 0.1112 - val_acc: 0.9646
Epoch 16/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1122 - acc: 0.9639 - val_loss: 0.1112 - val_acc: 0.9675
Epoch 17/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1120 - acc: 0.9631 - val_loss: 0.1109 - val_acc: 0.9697
Epoch 18/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1112 - acc: 0.9662 - val_loss: 0.1107 - val_acc: 0.9664
Epoch 19/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1112 - acc: 0.9644 - val_loss: 0.1106 - val_acc: 0.9703
Epoch 20/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1110 - acc: 0.9663 - val_loss: 0.1109 - val_acc: 0.9674
Epoch 21/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1108 - acc: 0.9667 - val_loss: 0.1106 - val_acc: 0.9679
Epoch 22/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1105 - acc: 0.9680 - val_loss: 0.1101 - val_acc: 0.9702
Epoch 23/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1098 - acc: 0.9703 - val_loss: 0.1103 - val_acc: 0.9713
Epoch 24/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1098 - acc: 0.9685 - val_loss: 0.1103 - val_acc: 0.9707
Epoch 25/70

753/753 [==============================] - 12s 16ms/step - loss: 0.1092 - acc: 0.9693 - val_loss: 0.1101 - val_acc: 0.9701
Manual evaluation: (didn't understand why I made this)
True 8151
False 920
True percentage 0.898577885569
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.71      0.72      0.72       296
      I-ORG       0.55      0.48      0.51       151
      B-PER       0.90      0.75      0.82       438
      B-LOC       0.70      0.77      0.73       218
      I-LOC       0.62      0.82      0.71       141
      I-PER       0.92      0.61      0.73       214
     B-MISC       0.42      0.24      0.31       141
     I-MISC       0.57      0.31      0.40       154

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.675815797499
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 8
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104294 unique words.
4290 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 246
OOV word occurences: 342
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6674880     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,183,554
Trainable params: 7,183,554
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 20s 27ms/step - loss: 0.1601 - acc: 0.8097 - val_loss: 0.1325 - val_acc: 0.9022
Epoch 2/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1332 - acc: 0.8910 - val_loss: 0.1274 - val_acc: 0.9113
Epoch 3/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1280 - acc: 0.9117 - val_loss: 0.1245 - val_acc: 0.9234
Epoch 4/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1249 - acc: 0.9203 - val_loss: 0.1219 - val_acc: 0.9305
Epoch 5/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1224 - acc: 0.9274 - val_loss: 0.1205 - val_acc: 0.9365
Epoch 6/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1207 - acc: 0.9341 - val_loss: 0.1202 - val_acc: 0.9381
Epoch 7/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1189 - acc: 0.9395 - val_loss: 0.1190 - val_acc: 0.9452
Epoch 8/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1178 - acc: 0.9424 - val_loss: 0.1183 - val_acc: 0.9463
Epoch 9/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1173 - acc: 0.9446 - val_loss: 0.1180 - val_acc: 0.9468
Epoch 10/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1160 - acc: 0.9507 - val_loss: 0.1174 - val_acc: 0.9511
Epoch 11/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1153 - acc: 0.9526 - val_loss: 0.1171 - val_acc: 0.9533
Epoch 12/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1146 - acc: 0.9547 - val_loss: 0.1168 - val_acc: 0.9528
Epoch 13/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1139 - acc: 0.9562 - val_loss: 0.1167 - val_acc: 0.9534
Epoch 14/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1132 - acc: 0.9590 - val_loss: 0.1165 - val_acc: 0.9545
Epoch 15/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1129 - acc: 0.9606 - val_loss: 0.1163 - val_acc: 0.9539
Epoch 16/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1121 - acc: 0.9624 - val_loss: 0.1158 - val_acc: 0.9583
Epoch 17/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1116 - acc: 0.9643 - val_loss: 0.1159 - val_acc: 0.9577
Epoch 18/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1109 - acc: 0.9667 - val_loss: 0.1158 - val_acc: 0.9566
Epoch 19/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1107 - acc: 0.9686 - val_loss: 0.1154 - val_acc: 0.9566
Epoch 20/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1105 - acc: 0.9680 - val_loss: 0.1159 - val_acc: 0.9582
Epoch 21/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1099 - acc: 0.9696 - val_loss: 0.1156 - val_acc: 0.9577
Epoch 22/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1096 - acc: 0.9711 - val_loss: 0.1153 - val_acc: 0.9599
Epoch 23/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1095 - acc: 0.9712 - val_loss: 0.1152 - val_acc: 0.9615
Epoch 24/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1090 - acc: 0.9721 - val_loss: 0.1153 - val_acc: 0.9593
Epoch 25/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1088 - acc: 0.9747 - val_loss: 0.1153 - val_acc: 0.9620
Epoch 26/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1090 - acc: 0.9720 - val_loss: 0.1153 - val_acc: 0.9599
Manual evaluation: (didn't understand why I made this)
True 8188
False 883
True percentage 0.902656818432
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.72      0.72      0.72       296
      I-ORG       0.59      0.50      0.54       151
     B-MISC       0.56      0.26      0.35       141
     I-MISC       0.52      0.44      0.48       154
      B-PER       0.89      0.78      0.83       438
      B-LOC       0.74      0.76      0.75       218
      I-LOC       0.64      0.77      0.70       141
      I-PER       0.86      0.65      0.74       214

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.693470374849
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 9
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104302 unique words.
4298 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 241
OOV word occurences: 338
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6675392     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,184,066
Trainable params: 7,184,066
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 17s 23ms/step - loss: 0.1602 - acc: 0.8091 - val_loss: 0.1325 - val_acc: 0.8813
Epoch 2/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1344 - acc: 0.8912 - val_loss: 0.1240 - val_acc: 0.9299
Epoch 3/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1292 - acc: 0.9071 - val_loss: 0.1227 - val_acc: 0.9342
Epoch 4/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1253 - acc: 0.9193 - val_loss: 0.1209 - val_acc: 0.9386
Epoch 5/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1232 - acc: 0.9253 - val_loss: 0.1196 - val_acc: 0.9429
Epoch 6/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1211 - acc: 0.9349 - val_loss: 0.1189 - val_acc: 0.9450
Epoch 7/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1191 - acc: 0.9418 - val_loss: 0.1182 - val_acc: 0.9478
Epoch 8/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1189 - acc: 0.9426 - val_loss: 0.1177 - val_acc: 0.9521
Epoch 9/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1174 - acc: 0.9466 - val_loss: 0.1172 - val_acc: 0.9505
Epoch 10/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1166 - acc: 0.9477 - val_loss: 0.1175 - val_acc: 0.9505
Epoch 11/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1160 - acc: 0.9516 - val_loss: 0.1170 - val_acc: 0.9500
Epoch 12/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1149 - acc: 0.9547 - val_loss: 0.1176 - val_acc: 0.9532
Epoch 13/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1140 - acc: 0.9581 - val_loss: 0.1170 - val_acc: 0.9543
Epoch 14/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1133 - acc: 0.9591 - val_loss: 0.1165 - val_acc: 0.9559
Epoch 15/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1133 - acc: 0.9591 - val_loss: 0.1165 - val_acc: 0.9548
Epoch 16/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1130 - acc: 0.9607 - val_loss: 0.1167 - val_acc: 0.9570
Epoch 17/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1118 - acc: 0.9643 - val_loss: 0.1167 - val_acc: 0.9548
Epoch 18/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1117 - acc: 0.9629 - val_loss: 0.1165 - val_acc: 0.9548
Manual evaluation: (didn't understand why I made this)
True 8183
False 888
True percentage 0.902105611289
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.89      0.82      0.86       438
          O       0.98      0.96      0.97      7318
      B-ORG       0.68      0.72      0.70       296
     B-MISC       0.62      0.23      0.33       141
      B-LOC       0.75      0.75      0.75       218
      I-LOC       0.59      0.80      0.68       141
     I-MISC       0.57      0.25      0.34       154
      I-PER       0.87      0.64      0.74       214
      I-ORG       0.51      0.56      0.53       151

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.922351276458
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 10
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104275 unique words.
4271 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 243
OOV word occurences: 338
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6673664     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,182,338
Trainable params: 7,182,338
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 18s 23ms/step - loss: 0.1607 - acc: 0.8072 - val_loss: 0.1309 - val_acc: 0.9190
Epoch 2/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1356 - acc: 0.8868 - val_loss: 0.1257 - val_acc: 0.9335
Epoch 3/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1302 - acc: 0.9026 - val_loss: 0.1230 - val_acc: 0.9392
Epoch 4/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1273 - acc: 0.9141 - val_loss: 0.1218 - val_acc: 0.9461
Epoch 5/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1243 - acc: 0.9218 - val_loss: 0.1203 - val_acc: 0.9478
Epoch 6/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1229 - acc: 0.9260 - val_loss: 0.1195 - val_acc: 0.9527
Epoch 7/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1210 - acc: 0.9339 - val_loss: 0.1188 - val_acc: 0.9512
Epoch 8/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1196 - acc: 0.9381 - val_loss: 0.1181 - val_acc: 0.9552
Epoch 9/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1187 - acc: 0.9402 - val_loss: 0.1179 - val_acc: 0.9529
Epoch 10/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1177 - acc: 0.9432 - val_loss: 0.1171 - val_acc: 0.9547
Epoch 11/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1168 - acc: 0.9462 - val_loss: 0.1173 - val_acc: 0.9581
Epoch 12/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1160 - acc: 0.9490 - val_loss: 0.1170 - val_acc: 0.9570
Epoch 13/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1155 - acc: 0.9523 - val_loss: 0.1165 - val_acc: 0.9577
Epoch 14/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1147 - acc: 0.9533 - val_loss: 0.1166 - val_acc: 0.9593
Epoch 15/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1142 - acc: 0.9552 - val_loss: 0.1162 - val_acc: 0.9593
Epoch 16/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1131 - acc: 0.9600 - val_loss: 0.1164 - val_acc: 0.9598
Epoch 17/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1128 - acc: 0.9599 - val_loss: 0.1159 - val_acc: 0.9605
Epoch 18/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1121 - acc: 0.9629 - val_loss: 0.1161 - val_acc: 0.9583
Epoch 19/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1122 - acc: 0.9629 - val_loss: 0.1160 - val_acc: 0.9589
Epoch 20/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1115 - acc: 0.9636 - val_loss: 0.1159 - val_acc: 0.9600
Epoch 21/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1110 - acc: 0.9668 - val_loss: 0.1157 - val_acc: 0.9596
Epoch 22/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1109 - acc: 0.9655 - val_loss: 0.1155 - val_acc: 0.9606
Epoch 23/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1107 - acc: 0.9664 - val_loss: 0.1155 - val_acc: 0.9596
Epoch 24/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1099 - acc: 0.9703 - val_loss: 0.1156 - val_acc: 0.9596
Epoch 25/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1097 - acc: 0.9696 - val_loss: 0.1160 - val_acc: 0.9611
Epoch 26/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1097 - acc: 0.9686 - val_loss: 0.1160 - val_acc: 0.9605
Manual evaluation: (didn't understand why I made this)
True 8194
False 877
True percentage 0.903318267005
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.89      0.80      0.84       438
          O       0.98      0.96      0.97      7318
      B-LOC       0.73      0.70      0.72       218
      I-LOC       0.71      0.76      0.74       141
      I-PER       0.90      0.63      0.74       214
      B-ORG       0.73      0.74      0.74       296
      I-ORG       0.59      0.50      0.54       151
     B-MISC       0.46      0.38      0.42       141
     I-MISC       0.49      0.47      0.48       154

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.924300441826
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 11
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104310 unique words.
4306 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 243
OOV word occurences: 346
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6675904     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,184,578
Trainable params: 7,184,578
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 21s 27ms/step - loss: 0.1625 - acc: 0.8054 - val_loss: 0.1327 - val_acc: 0.8899
Epoch 2/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1336 - acc: 0.8908 - val_loss: 0.1260 - val_acc: 0.9175
Epoch 3/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1291 - acc: 0.9066 - val_loss: 0.1224 - val_acc: 0.9293
Epoch 4/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1252 - acc: 0.9208 - val_loss: 0.1207 - val_acc: 0.9294
Epoch 5/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1228 - acc: 0.9270 - val_loss: 0.1197 - val_acc: 0.9378
Epoch 6/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1211 - acc: 0.9332 - val_loss: 0.1182 - val_acc: 0.9366
Epoch 7/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1198 - acc: 0.9393 - val_loss: 0.1182 - val_acc: 0.9354
Epoch 8/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1186 - acc: 0.9423 - val_loss: 0.1164 - val_acc: 0.9474
Epoch 9/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1172 - acc: 0.9463 - val_loss: 0.1159 - val_acc: 0.9455
Epoch 10/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1162 - acc: 0.9499 - val_loss: 0.1156 - val_acc: 0.9492
Epoch 11/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1157 - acc: 0.9501 - val_loss: 0.1149 - val_acc: 0.9510
Epoch 12/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1150 - acc: 0.9528 - val_loss: 0.1158 - val_acc: 0.9433
Epoch 13/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1141 - acc: 0.9548 - val_loss: 0.1142 - val_acc: 0.9503
Epoch 14/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1136 - acc: 0.9595 - val_loss: 0.1144 - val_acc: 0.9515
Epoch 15/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1132 - acc: 0.9583 - val_loss: 0.1140 - val_acc: 0.9509
Epoch 16/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1123 - acc: 0.9621 - val_loss: 0.1143 - val_acc: 0.9520
Epoch 17/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1124 - acc: 0.9617 - val_loss: 0.1138 - val_acc: 0.9538
Epoch 18/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1118 - acc: 0.9640 - val_loss: 0.1137 - val_acc: 0.9557
Epoch 19/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1112 - acc: 0.9643 - val_loss: 0.1138 - val_acc: 0.9526
Epoch 20/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1107 - acc: 0.9668 - val_loss: 0.1134 - val_acc: 0.9574
Epoch 21/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1103 - acc: 0.9683 - val_loss: 0.1131 - val_acc: 0.9569
Epoch 22/70

753/753 [==============================] - 16s 22ms/step - loss: 0.1102 - acc: 0.9687 - val_loss: 0.1135 - val_acc: 0.9567
Epoch 23/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1097 - acc: 0.9698 - val_loss: 0.1133 - val_acc: 0.9556
Epoch 24/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1097 - acc: 0.9706 - val_loss: 0.1135 - val_acc: 0.9567
Manual evaluation: (didn't understand why I made this)
True 8180
False 891
True percentage 0.901774887003
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.71      0.70      0.70       296
     B-MISC       0.51      0.26      0.34       141
     I-MISC       0.61      0.31      0.41       154
      B-PER       0.88      0.81      0.84       438
      B-LOC       0.70      0.76      0.73       218
      I-ORG       0.46      0.60      0.52       151
      I-PER       0.90      0.65      0.76       214
      I-LOC       0.70      0.77      0.73       141

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.688642493257
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 12
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104291 unique words.
4287 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 245
OOV word occurences: 347
Padded until 63 tokens.
Padded until 24 chars.
Padded until 63 tokens.
Padded until 24 chars.
Padded until 63 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 63, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 63, 64)       6674688     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 63, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 63, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 63, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 63, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 63, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,183,362
Trainable params: 7,183,362
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 17s 22ms/step - loss: 0.1589 - acc: 0.8196 - val_loss: 0.1315 - val_acc: 0.9123
Epoch 2/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1338 - acc: 0.8912 - val_loss: 0.1273 - val_acc: 0.9189
Epoch 3/70

753/753 [==============================] - 13s 17ms/step - loss: 0.1283 - acc: 0.9108 - val_loss: 0.1257 - val_acc: 0.9225
Epoch 4/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1256 - acc: 0.9181 - val_loss: 0.1245 - val_acc: 0.9268
Epoch 5/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1233 - acc: 0.9269 - val_loss: 0.1236 - val_acc: 0.9340
Epoch 6/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1216 - acc: 0.9308 - val_loss: 0.1229 - val_acc: 0.9364
Epoch 7/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1206 - acc: 0.9349 - val_loss: 0.1221 - val_acc: 0.9346
Epoch 8/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1191 - acc: 0.9388 - val_loss: 0.1216 - val_acc: 0.9407
Epoch 9/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1187 - acc: 0.9397 - val_loss: 0.1211 - val_acc: 0.9400
Epoch 10/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1172 - acc: 0.9447 - val_loss: 0.1212 - val_acc: 0.9388
Epoch 11/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1158 - acc: 0.9489 - val_loss: 0.1211 - val_acc: 0.9383
Epoch 12/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1153 - acc: 0.9528 - val_loss: 0.1209 - val_acc: 0.9418
Epoch 13/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1144 - acc: 0.9527 - val_loss: 0.1214 - val_acc: 0.9424
Epoch 14/70

753/753 [==============================] - 13s 17ms/step - loss: 0.1140 - acc: 0.9552 - val_loss: 0.1212 - val_acc: 0.9412
Epoch 15/70

753/753 [==============================] - 13s 18ms/step - loss: 0.1136 - acc: 0.9560 - val_loss: 0.1211 - val_acc: 0.9412
Manual evaluation: (didn't understand why I made this)
True 8139
False 932
True percentage 0.897254988425
Sklearn evaluation:
             precision    recall  f1-score   support

     B-MISC       0.62      0.17      0.27       141
     I-MISC       0.54      0.21      0.30       154
          O       0.99      0.96      0.97      7318
      B-PER       0.89      0.80      0.84       438
      I-PER       0.85      0.62      0.72       214
      B-ORG       0.63      0.76      0.69       296
      B-LOC       0.72      0.75      0.74       218
      I-ORG       0.41      0.60      0.49       151
      I-LOC       0.69      0.78      0.73       141

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.921373829123
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 13
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104277 unique words.
4273 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 363
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6673792     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,182,466
Trainable params: 7,182,466
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 18s 23ms/step - loss: 0.1615 - acc: 0.8117 - val_loss: 0.1313 - val_acc: 0.8933
Epoch 2/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1342 - acc: 0.8939 - val_loss: 0.1253 - val_acc: 0.9202
Epoch 3/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1298 - acc: 0.9039 - val_loss: 0.1230 - val_acc: 0.9298
Epoch 4/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1260 - acc: 0.9162 - val_loss: 0.1218 - val_acc: 0.9342
Epoch 5/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1231 - acc: 0.9265 - val_loss: 0.1202 - val_acc: 0.9360
Epoch 6/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1218 - acc: 0.9296 - val_loss: 0.1199 - val_acc: 0.9421
Epoch 7/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1204 - acc: 0.9360 - val_loss: 0.1194 - val_acc: 0.9424
Epoch 8/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1187 - acc: 0.9420 - val_loss: 0.1192 - val_acc: 0.9436
Epoch 9/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1172 - acc: 0.9471 - val_loss: 0.1192 - val_acc: 0.9429
Epoch 10/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1168 - acc: 0.9478 - val_loss: 0.1191 - val_acc: 0.9428
Epoch 11/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1163 - acc: 0.9481 - val_loss: 0.1187 - val_acc: 0.9472
Epoch 12/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1150 - acc: 0.9544 - val_loss: 0.1185 - val_acc: 0.9466
Epoch 13/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1151 - acc: 0.9536 - val_loss: 0.1191 - val_acc: 0.9485
Epoch 14/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1140 - acc: 0.9568 - val_loss: 0.1186 - val_acc: 0.9488
Epoch 15/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1136 - acc: 0.9573 - val_loss: 0.1186 - val_acc: 0.9472
Manual evaluation: (didn't understand why I made this)
True 8154
False 917
True percentage 0.898908609856
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.91      0.76      0.83       438
      B-ORG       0.70      0.73      0.71       296
     B-MISC       0.53      0.25      0.34       141
     I-MISC       0.54      0.27      0.36       154
      I-ORG       0.48      0.56      0.52       151
      B-LOC       0.69      0.75      0.72       218
      I-LOC       0.63      0.82      0.71       141
      I-PER       0.89      0.64      0.75       214

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.678088367899
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 14
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104284 unique words.
4280 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 242
OOV word occurences: 354
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6674240     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,182,914
Trainable params: 7,182,914
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 18s 24ms/step - loss: 0.1565 - acc: 0.8202 - val_loss: 0.1372 - val_acc: 0.8904
Epoch 2/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1314 - acc: 0.8994 - val_loss: 0.1304 - val_acc: 0.9075
Epoch 3/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1270 - acc: 0.9138 - val_loss: 0.1287 - val_acc: 0.9073
Epoch 4/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1243 - acc: 0.9206 - val_loss: 0.1267 - val_acc: 0.9157
Epoch 5/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1220 - acc: 0.9293 - val_loss: 0.1250 - val_acc: 0.9228
Epoch 6/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1203 - acc: 0.9354 - val_loss: 0.1249 - val_acc: 0.9250
Epoch 7/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1189 - acc: 0.9399 - val_loss: 0.1233 - val_acc: 0.9254
Epoch 8/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1179 - acc: 0.9430 - val_loss: 0.1246 - val_acc: 0.9264
Epoch 9/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1164 - acc: 0.9482 - val_loss: 0.1229 - val_acc: 0.9336
Epoch 10/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1158 - acc: 0.9499 - val_loss: 0.1232 - val_acc: 0.9290
Epoch 11/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1149 - acc: 0.9540 - val_loss: 0.1216 - val_acc: 0.9346
Epoch 12/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1145 - acc: 0.9543 - val_loss: 0.1218 - val_acc: 0.9336
Epoch 13/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1134 - acc: 0.9578 - val_loss: 0.1209 - val_acc: 0.9352
Epoch 14/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1128 - acc: 0.9610 - val_loss: 0.1216 - val_acc: 0.9365
Epoch 15/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1117 - acc: 0.9640 - val_loss: 0.1211 - val_acc: 0.9387
Epoch 16/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1122 - acc: 0.9617 - val_loss: 0.1206 - val_acc: 0.9393
Epoch 17/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1112 - acc: 0.9661 - val_loss: 0.1214 - val_acc: 0.9381
Epoch 18/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1111 - acc: 0.9661 - val_loss: 0.1212 - val_acc: 0.9358
Epoch 19/70

753/753 [==============================] - 14s 19ms/step - loss: 0.1110 - acc: 0.9635 - val_loss: 0.1205 - val_acc: 0.9387
Epoch 20/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1105 - acc: 0.9681 - val_loss: 0.1207 - val_acc: 0.9381
Epoch 21/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1097 - acc: 0.9700 - val_loss: 0.1207 - val_acc: 0.9398
Epoch 22/70

753/753 [==============================] - 14s 18ms/step - loss: 0.1095 - acc: 0.9704 - val_loss: 0.1212 - val_acc: 0.9387
Manual evaluation: (didn't understand why I made this)
True 8161
False 910
True percentage 0.899680299857
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.69      0.65      0.67       296
      I-ORG       0.45      0.56      0.50       151
      B-PER       0.88      0.82      0.85       438
     B-MISC       0.49      0.29      0.37       141
     I-MISC       0.54      0.31      0.40       154
      B-LOC       0.70      0.78      0.74       218
      I-LOC       0.65      0.81      0.72       141
      I-PER       0.94      0.61      0.74       214

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.67995240928
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.2048 - acc: 0.6903 - val_loss: 0.1390 - val_acc: 0.8671
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1466 - acc: 0.8526 - val_loss: 0.1298 - val_acc: 0.8973
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1394 - acc: 0.8755 - val_loss: 0.1308 - val_acc: 0.9169
Epoch 4/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1349 - acc: 0.8882 - val_loss: 0.1277 - val_acc: 0.9117
Epoch 5/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1319 - acc: 0.8977 - val_loss: 0.1248 - val_acc: 0.9297
Epoch 6/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1285 - acc: 0.9123 - val_loss: 0.1246 - val_acc: 0.9315
Epoch 7/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1279 - acc: 0.9116 - val_loss: 0.1227 - val_acc: 0.9353
Epoch 8/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1256 - acc: 0.9195 - val_loss: 0.1218 - val_acc: 0.9367
Epoch 9/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1242 - acc: 0.9230 - val_loss: 0.1230 - val_acc: 0.9349
Epoch 10/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1221 - acc: 0.9318 - val_loss: 0.1200 - val_acc: 0.9457
Epoch 11/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1212 - acc: 0.9314 - val_loss: 0.1198 - val_acc: 0.9400
Epoch 12/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1206 - acc: 0.9365 - val_loss: 0.1192 - val_acc: 0.9390
Epoch 13/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1197 - acc: 0.9409 - val_loss: 0.1196 - val_acc: 0.9424
Epoch 14/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1187 - acc: 0.9426 - val_loss: 0.1190 - val_acc: 0.9471
Epoch 15/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1174 - acc: 0.9465 - val_loss: 0.1191 - val_acc: 0.9428
Epoch 16/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1173 - acc: 0.9472 - val_loss: 0.1191 - val_acc: 0.9382
Epoch 17/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1167 - acc: 0.9446 - val_loss: 0.1194 - val_acc: 0.9467
Manual evaluation: (didn't understand why I made this)
True 7873
False 1198
True percentage 0.867930768383
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.80      0.68      0.74       438
      B-LOC       0.65      0.70      0.67       218
      B-ORG       0.53      0.64      0.58       296
      I-ORG       0.27      0.52      0.36       151
      I-PER       0.76      0.62      0.68       214
      I-LOC       0.59      0.58      0.59       141
     B-MISC       0.43      0.09      0.14       141
     I-MISC       0.33      0.05      0.08       154

avg / total       0.91      0.87      0.88      9071

F-1 Score:
0.565734681737
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1815 - acc: 0.7543 - val_loss: 0.1468 - val_acc: 0.8321
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1407 - acc: 0.8672 - val_loss: 0.1412 - val_acc: 0.8652
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1348 - acc: 0.8922 - val_loss: 0.1376 - val_acc: 0.8630
Epoch 4/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1307 - acc: 0.9051 - val_loss: 0.1349 - val_acc: 0.8730
Epoch 5/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1272 - acc: 0.9156 - val_loss: 0.1367 - val_acc: 0.8584
Epoch 6/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1260 - acc: 0.9188 - val_loss: 0.1338 - val_acc: 0.8893
Epoch 7/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1232 - acc: 0.9271 - val_loss: 0.1302 - val_acc: 0.9014
Epoch 8/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1220 - acc: 0.9311 - val_loss: 0.1288 - val_acc: 0.9057
Epoch 9/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1214 - acc: 0.9330 - val_loss: 0.1262 - val_acc: 0.9140
Epoch 10/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1198 - acc: 0.9392 - val_loss: 0.1285 - val_acc: 0.9055
Epoch 11/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1192 - acc: 0.9397 - val_loss: 0.1287 - val_acc: 0.9055
Epoch 12/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1170 - acc: 0.9456 - val_loss: 0.1289 - val_acc: 0.9043
Manual evaluation: (didn't understand why I made this)
True 7975
False 1096
True percentage 0.879175394113
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-ORG       0.49      0.73      0.58       296
      B-LOC       0.80      0.59      0.68       218
      I-ORG       0.30      0.54      0.38       151
     B-MISC       0.71      0.04      0.07       141
     I-MISC       0.57      0.13      0.21       154
      B-PER       0.86      0.75      0.80       438
      I-PER       0.74      0.60      0.66       214
      I-LOC       0.78      0.65      0.71       141

avg / total       0.92      0.88      0.89      9071

F-1 Score:
0.596354944727
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 2
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103893 unique words.
3889 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 263
OOV word occurences: 414
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 66, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 66)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 66, 64)       6649216     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 66, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 66, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 66, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 66, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 66, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,890
Trainable params: 7,157,890
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 9s 30ms/step - loss: 0.1832 - acc: 0.7458 - val_loss: 0.1420 - val_acc: 0.8609
Epoch 2/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1391 - acc: 0.8736 - val_loss: 0.1362 - val_acc: 0.8845
Epoch 3/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1338 - acc: 0.8920 - val_loss: 0.1343 - val_acc: 0.8738
Epoch 4/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1302 - acc: 0.9034 - val_loss: 0.1319 - val_acc: 0.8879
Epoch 5/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1280 - acc: 0.9124 - val_loss: 0.1292 - val_acc: 0.9048
Epoch 6/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1259 - acc: 0.9180 - val_loss: 0.1276 - val_acc: 0.9078
Epoch 7/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1231 - acc: 0.9231 - val_loss: 0.1259 - val_acc: 0.9137
Epoch 8/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1223 - acc: 0.9305 - val_loss: 0.1260 - val_acc: 0.9078
Epoch 9/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1207 - acc: 0.9347 - val_loss: 0.1247 - val_acc: 0.9192
Epoch 10/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1201 - acc: 0.9346 - val_loss: 0.1239 - val_acc: 0.9232
Epoch 11/70

300/300 [==============================] - 6s 18ms/step - loss: 0.1189 - acc: 0.9390 - val_loss: 0.1242 - val_acc: 0.9236
Epoch 12/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1173 - acc: 0.9458 - val_loss: 0.1243 - val_acc: 0.9222
Epoch 13/70

300/300 [==============================] - 6s 18ms/step - loss: 0.1176 - acc: 0.9450 - val_loss: 0.1229 - val_acc: 0.9277
Epoch 14/70

300/300 [==============================] - 6s 18ms/step - loss: 0.1159 - acc: 0.9519 - val_loss: 0.1231 - val_acc: 0.9277
Epoch 15/70

300/300 [==============================] - 6s 18ms/step - loss: 0.1153 - acc: 0.9505 - val_loss: 0.1230 - val_acc: 0.9247
Epoch 16/70

300/300 [==============================] - 6s 18ms/step - loss: 0.1149 - acc: 0.9518 - val_loss: 0.1263 - val_acc: 0.9148
Manual evaluation: (didn't understand why I made this)
True 7921
False 1150
True percentage 0.873222356962
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.85      0.71      0.77       438
      B-ORG       0.53      0.67      0.59       296
      I-ORG       0.25      0.62      0.36       151
      I-PER       0.75      0.62      0.68       214
      B-LOC       0.80      0.64      0.71       218
      I-LOC       0.82      0.38      0.51       141
     B-MISC       0.44      0.06      0.10       141
     I-MISC       0.44      0.03      0.05       154

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.568835098336
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 3
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103883 unique words.
3879 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 262
OOV word occurences: 391
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648576     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,250
Trainable params: 7,157,250
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.1790 - acc: 0.7613 - val_loss: 0.1407 - val_acc: 0.8722
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1408 - acc: 0.8630 - val_loss: 0.1369 - val_acc: 0.8877
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1345 - acc: 0.8932 - val_loss: 0.1364 - val_acc: 0.8881
Epoch 4/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1308 - acc: 0.8997 - val_loss: 0.1325 - val_acc: 0.9151
Epoch 5/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1288 - acc: 0.9073 - val_loss: 0.1304 - val_acc: 0.9120
Epoch 6/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1258 - acc: 0.9187 - val_loss: 0.1295 - val_acc: 0.9177
Epoch 7/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1249 - acc: 0.9220 - val_loss: 0.1274 - val_acc: 0.9226
Epoch 8/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1221 - acc: 0.9315 - val_loss: 0.1269 - val_acc: 0.9173
Epoch 9/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1205 - acc: 0.9363 - val_loss: 0.1274 - val_acc: 0.9252
Epoch 10/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1194 - acc: 0.9402 - val_loss: 0.1259 - val_acc: 0.9199
Epoch 11/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1193 - acc: 0.9398 - val_loss: 0.1273 - val_acc: 0.9252
Epoch 12/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1182 - acc: 0.9430 - val_loss: 0.1272 - val_acc: 0.9252
Epoch 13/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1169 - acc: 0.9502 - val_loss: 0.1273 - val_acc: 0.9292
Manual evaluation: (didn't understand why I made this)
True 7983
False 1088
True percentage 0.880057325543
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
     B-MISC       0.35      0.15      0.21       141
     I-MISC       0.35      0.19      0.24       154
      B-ORG       0.62      0.56      0.59       296
      I-ORG       0.30      0.32      0.31       151
      B-PER       0.82      0.74      0.78       438
      I-PER       0.74      0.61      0.67       214
      B-LOC       0.67      0.70      0.68       218
      I-LOC       0.60      0.77      0.67       141

avg / total       0.91      0.88      0.89      9071

F-1 Score:
0.59335347432
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 4
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103910 unique words.
3906 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 410
Padded until 63 tokens.
Padded until 24 chars.
Padded until 63 tokens.
Padded until 24 chars.
Padded until 63 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 63, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 63, 64)       6650304     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 63, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 63, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 63, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 63, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 63, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,158,978
Trainable params: 7,158,978
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 9s 30ms/step - loss: 0.1917 - acc: 0.7150 - val_loss: 0.1347 - val_acc: 0.8847
Epoch 2/70

300/300 [==============================] - 6s 18ms/step - loss: 0.1439 - acc: 0.8550 - val_loss: 0.1292 - val_acc: 0.9036
Epoch 3/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1372 - acc: 0.8823 - val_loss: 0.1264 - val_acc: 0.9262
Epoch 4/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1326 - acc: 0.8956 - val_loss: 0.1244 - val_acc: 0.9247
Epoch 5/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1287 - acc: 0.9099 - val_loss: 0.1246 - val_acc: 0.9217
Epoch 6/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1268 - acc: 0.9136 - val_loss: 0.1222 - val_acc: 0.9292
Epoch 7/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1254 - acc: 0.9205 - val_loss: 0.1212 - val_acc: 0.9322
Epoch 8/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1237 - acc: 0.9259 - val_loss: 0.1197 - val_acc: 0.9413
Epoch 9/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1220 - acc: 0.9307 - val_loss: 0.1189 - val_acc: 0.9352
Epoch 10/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1215 - acc: 0.9335 - val_loss: 0.1195 - val_acc: 0.9398
Epoch 11/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1205 - acc: 0.9332 - val_loss: 0.1183 - val_acc: 0.9458
Epoch 12/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1193 - acc: 0.9381 - val_loss: 0.1180 - val_acc: 0.9428
Epoch 13/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1188 - acc: 0.9412 - val_loss: 0.1182 - val_acc: 0.9383
Epoch 14/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1177 - acc: 0.9436 - val_loss: 0.1174 - val_acc: 0.9428
Epoch 15/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1165 - acc: 0.9456 - val_loss: 0.1173 - val_acc: 0.9413
Epoch 16/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1157 - acc: 0.9522 - val_loss: 0.1175 - val_acc: 0.9413
Epoch 17/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1157 - acc: 0.9511 - val_loss: 0.1167 - val_acc: 0.9413
Epoch 18/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1142 - acc: 0.9585 - val_loss: 0.1172 - val_acc: 0.9413
Epoch 19/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1138 - acc: 0.9588 - val_loss: 0.1165 - val_acc: 0.9443
Epoch 20/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1134 - acc: 0.9602 - val_loss: 0.1166 - val_acc: 0.9428
Epoch 21/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1128 - acc: 0.9622 - val_loss: 0.1166 - val_acc: 0.9488
Epoch 22/70

300/300 [==============================] - 5s 18ms/step - loss: 0.1132 - acc: 0.9564 - val_loss: 0.1168 - val_acc: 0.9473
Manual evaluation: (didn't understand why I made this)
True 7985
False 1086
True percentage 0.8802778084
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-ORG       0.65      0.51      0.57       296
      B-LOC       0.61      0.73      0.66       218
      B-PER       0.88      0.70      0.78       438
      I-PER       0.78      0.61      0.69       214
     B-MISC       0.39      0.30      0.34       141
      I-ORG       0.44      0.37      0.40       151
      I-LOC       0.53      0.82      0.64       141
     I-MISC       0.46      0.30      0.36       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.608381067229
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 5
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103878 unique words.
3874 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 396
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6648256     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,156,930
Trainable params: 7,156,930
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1988 - acc: 0.7187 - val_loss: 0.1465 - val_acc: 0.8424
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1470 - acc: 0.8471 - val_loss: 0.1395 - val_acc: 0.8692
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1386 - acc: 0.8730 - val_loss: 0.1299 - val_acc: 0.9133
Epoch 4/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1350 - acc: 0.8863 - val_loss: 0.1283 - val_acc: 0.9053
Epoch 5/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1315 - acc: 0.8990 - val_loss: 0.1264 - val_acc: 0.9147
Epoch 6/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1302 - acc: 0.9047 - val_loss: 0.1263 - val_acc: 0.9026
Epoch 7/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1285 - acc: 0.9106 - val_loss: 0.1250 - val_acc: 0.9130
Epoch 8/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1258 - acc: 0.9196 - val_loss: 0.1241 - val_acc: 0.9238
Epoch 9/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1243 - acc: 0.9224 - val_loss: 0.1239 - val_acc: 0.9117
Epoch 10/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1241 - acc: 0.9227 - val_loss: 0.1253 - val_acc: 0.9063
Epoch 11/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1221 - acc: 0.9286 - val_loss: 0.1221 - val_acc: 0.9224
Epoch 12/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1206 - acc: 0.9340 - val_loss: 0.1224 - val_acc: 0.9171
Epoch 13/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1194 - acc: 0.9365 - val_loss: 0.1215 - val_acc: 0.9227
Epoch 14/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1187 - acc: 0.9437 - val_loss: 0.1206 - val_acc: 0.9238
Epoch 15/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1185 - acc: 0.9402 - val_loss: 0.1213 - val_acc: 0.9238
Epoch 16/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1172 - acc: 0.9447 - val_loss: 0.1221 - val_acc: 0.9224
Epoch 17/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1168 - acc: 0.9489 - val_loss: 0.1209 - val_acc: 0.9224
Manual evaluation: (didn't understand why I made this)
True 7978
False 1093
True percentage 0.879506118399
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.85      0.73      0.78       438
      B-ORG       0.52      0.60      0.56       296
     I-MISC       0.33      0.13      0.19       154
      B-LOC       0.74      0.67      0.70       218
      I-LOC       0.69      0.76      0.72       141
      I-ORG       0.35      0.52      0.42       151
      I-PER       0.78      0.61      0.69       214
     B-MISC       0.40      0.13      0.19       141

avg / total       0.91      0.88      0.89      9071

F-1 Score:
0.600060368246
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 6
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103898 unique words.
3894 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 257
OOV word occurences: 401
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6649536     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,158,210
Trainable params: 7,158,210
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1823 - acc: 0.7370 - val_loss: 0.1387 - val_acc: 0.8858
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1414 - acc: 0.8653 - val_loss: 0.1305 - val_acc: 0.9144
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1347 - acc: 0.8908 - val_loss: 0.1282 - val_acc: 0.8943
Epoch 4/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1306 - acc: 0.9014 - val_loss: 0.1316 - val_acc: 0.8892
Epoch 5/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1278 - acc: 0.9105 - val_loss: 0.1260 - val_acc: 0.9129
Epoch 6/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1259 - acc: 0.9197 - val_loss: 0.1203 - val_acc: 0.9341
Epoch 7/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1248 - acc: 0.9219 - val_loss: 0.1212 - val_acc: 0.9323
Epoch 8/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1224 - acc: 0.9289 - val_loss: 0.1191 - val_acc: 0.9385
Epoch 9/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1213 - acc: 0.9339 - val_loss: 0.1210 - val_acc: 0.9279
Epoch 10/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1187 - acc: 0.9439 - val_loss: 0.1200 - val_acc: 0.9345
Epoch 11/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1192 - acc: 0.9405 - val_loss: 0.1201 - val_acc: 0.9330
Manual evaluation: (didn't understand why I made this)
True 7904
False 1167
True percentage 0.871348252673
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-PER       0.81      0.63      0.71       438
      B-LOC       0.75      0.62      0.68       218
      B-ORG       0.57      0.51      0.54       296
      I-PER       0.66      0.61      0.63       214
     B-MISC       0.34      0.44      0.38       141
     I-MISC       0.33      0.57      0.42       154
      I-LOC       0.67      0.70      0.69       141
      I-ORG       0.51      0.30      0.38       151

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.576350364964
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 7
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103902 unique words.
3898 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 399
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6649792     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,158,466
Trainable params: 7,158,466
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1803 - acc: 0.7585 - val_loss: 0.1367 - val_acc: 0.8808
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1403 - acc: 0.8696 - val_loss: 0.1273 - val_acc: 0.8961
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1346 - acc: 0.8872 - val_loss: 0.1270 - val_acc: 0.9038
Epoch 4/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1311 - acc: 0.9038 - val_loss: 0.1284 - val_acc: 0.9000
Epoch 5/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1281 - acc: 0.9100 - val_loss: 0.1218 - val_acc: 0.9262
Epoch 6/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1253 - acc: 0.9229 - val_loss: 0.1192 - val_acc: 0.9381
Epoch 7/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1242 - acc: 0.9264 - val_loss: 0.1183 - val_acc: 0.9457
Epoch 8/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1225 - acc: 0.9296 - val_loss: 0.1176 - val_acc: 0.9368
Epoch 9/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1212 - acc: 0.9340 - val_loss: 0.1168 - val_acc: 0.9441
Epoch 10/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1210 - acc: 0.9311 - val_loss: 0.1170 - val_acc: 0.9457
Epoch 11/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1201 - acc: 0.9388 - val_loss: 0.1163 - val_acc: 0.9472
Epoch 12/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1181 - acc: 0.9424 - val_loss: 0.1159 - val_acc: 0.9472
Epoch 13/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1175 - acc: 0.9450 - val_loss: 0.1151 - val_acc: 0.9547
Epoch 14/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1169 - acc: 0.9461 - val_loss: 0.1159 - val_acc: 0.9472
Epoch 15/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1156 - acc: 0.9527 - val_loss: 0.1152 - val_acc: 0.9519
Epoch 16/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1150 - acc: 0.9539 - val_loss: 0.1151 - val_acc: 0.9519
Epoch 17/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1147 - acc: 0.9559 - val_loss: 0.1151 - val_acc: 0.9472
Epoch 18/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1140 - acc: 0.9567 - val_loss: 0.1146 - val_acc: 0.9517
Epoch 19/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1134 - acc: 0.9584 - val_loss: 0.1145 - val_acc: 0.9551
Epoch 20/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1131 - acc: 0.9586 - val_loss: 0.1143 - val_acc: 0.9551
Epoch 21/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1125 - acc: 0.9620 - val_loss: 0.1141 - val_acc: 0.9551
Epoch 22/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1129 - acc: 0.9592 - val_loss: 0.1145 - val_acc: 0.9491
Epoch 23/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1119 - acc: 0.9632 - val_loss: 0.1140 - val_acc: 0.9521
Epoch 24/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1111 - acc: 0.9654 - val_loss: 0.1148 - val_acc: 0.9506
Epoch 25/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1104 - acc: 0.9700 - val_loss: 0.1143 - val_acc: 0.9521
Epoch 26/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1111 - acc: 0.9659 - val_loss: 0.1139 - val_acc: 0.9521
Epoch 27/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1106 - acc: 0.9667 - val_loss: 0.1139 - val_acc: 0.9536
Epoch 28/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1098 - acc: 0.9706 - val_loss: 0.1140 - val_acc: 0.9506
Epoch 29/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1093 - acc: 0.9704 - val_loss: 0.1144 - val_acc: 0.9551
Manual evaluation: (didn't understand why I made this)
True 8063
False 1008
True percentage 0.888876639841
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.59      0.72      0.65       296
      I-ORG       0.43      0.49      0.46       151
      B-PER       0.87      0.72      0.79       438
      B-LOC       0.74      0.70      0.72       218
      I-LOC       0.72      0.76      0.74       141
      I-PER       0.87      0.60      0.71       214
     B-MISC       0.43      0.14      0.21       141
     I-MISC       0.47      0.25      0.32       154

avg / total       0.92      0.89      0.90      9071

F-1 Score:
0.64004876562
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 8
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103934 unique words.
3930 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 264
OOV word occurences: 416
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6651840     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,160,514
Trainable params: 7,160,514
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 9s 30ms/step - loss: 0.1820 - acc: 0.7440 - val_loss: 0.1491 - val_acc: 0.8404
Epoch 2/70

300/300 [==============================] - 6s 20ms/step - loss: 0.1414 - acc: 0.8608 - val_loss: 0.1363 - val_acc: 0.8622
Epoch 3/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1347 - acc: 0.8896 - val_loss: 0.1366 - val_acc: 0.8636
Epoch 4/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1305 - acc: 0.9043 - val_loss: 0.1265 - val_acc: 0.9127
Epoch 5/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1281 - acc: 0.9122 - val_loss: 0.1288 - val_acc: 0.8963
Epoch 6/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1257 - acc: 0.9212 - val_loss: 0.1329 - val_acc: 0.8868
Epoch 7/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1241 - acc: 0.9215 - val_loss: 0.1269 - val_acc: 0.8991
Manual evaluation: (didn't understand why I made this)
True 7834
False 1237
True percentage 0.863631352662
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.44      0.63      0.52       296
      I-ORG       0.26      0.52      0.35       151
     B-MISC       0.38      0.02      0.04       141
     I-MISC       0.35      0.18      0.24       154
      B-PER       0.84      0.68      0.75       438
      B-LOC       0.85      0.45      0.59       218
      I-LOC       0.77      0.28      0.41       141
      I-PER       0.73      0.58      0.65       214

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.524539877301
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 9
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103926 unique words.
3922 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 257
OOV word occurences: 371
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 66, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 66)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 66, 64)       6651328     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 66, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 66, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 66, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 66, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 66, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,160,002
Trainable params: 7,160,002
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 9s 30ms/step - loss: 0.1899 - acc: 0.7315 - val_loss: 0.1362 - val_acc: 0.8795
Epoch 2/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1414 - acc: 0.8700 - val_loss: 0.1291 - val_acc: 0.9348
Epoch 3/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1354 - acc: 0.8884 - val_loss: 0.1253 - val_acc: 0.9253
Epoch 4/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1310 - acc: 0.9032 - val_loss: 0.1239 - val_acc: 0.9239
Epoch 5/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1289 - acc: 0.9049 - val_loss: 0.1230 - val_acc: 0.9360
Epoch 6/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1272 - acc: 0.9163 - val_loss: 0.1200 - val_acc: 0.9471
Epoch 7/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1243 - acc: 0.9233 - val_loss: 0.1197 - val_acc: 0.9459
Epoch 8/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1226 - acc: 0.9336 - val_loss: 0.1180 - val_acc: 0.9514
Epoch 9/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1214 - acc: 0.9337 - val_loss: 0.1172 - val_acc: 0.9499
Epoch 10/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1199 - acc: 0.9374 - val_loss: 0.1166 - val_acc: 0.9541
Epoch 11/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1186 - acc: 0.9446 - val_loss: 0.1162 - val_acc: 0.9554
Epoch 12/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1176 - acc: 0.9445 - val_loss: 0.1160 - val_acc: 0.9582
Epoch 13/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1173 - acc: 0.9480 - val_loss: 0.1169 - val_acc: 0.9554
Epoch 14/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1162 - acc: 0.9524 - val_loss: 0.1161 - val_acc: 0.9555
Epoch 15/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1160 - acc: 0.9505 - val_loss: 0.1152 - val_acc: 0.9596
Epoch 16/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1152 - acc: 0.9545 - val_loss: 0.1158 - val_acc: 0.9554
Epoch 17/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1144 - acc: 0.9567 - val_loss: 0.1157 - val_acc: 0.9596
Epoch 18/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1139 - acc: 0.9583 - val_loss: 0.1152 - val_acc: 0.9541
Manual evaluation: (didn't understand why I made this)
True 8052
False 1019
True percentage 0.887663984125
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.89      0.81      0.85       438
          O       0.98      0.96      0.97      7318
      B-ORG       0.65      0.60      0.62       296
     B-MISC       0.30      0.09      0.14       141
      B-LOC       0.67      0.67      0.67       218
      I-LOC       0.63      0.71      0.67       141
     I-MISC       0.51      0.23      0.32       154
      I-PER       0.85      0.64      0.73       214
      I-ORG       0.35      0.43      0.38       151

avg / total       0.92      0.89      0.90      9071

F-1 Score:
0.90913384897
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 10
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 257
OOV word occurences: 421
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1834 - acc: 0.7363 - val_loss: 0.1419 - val_acc: 0.8698
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1427 - acc: 0.8620 - val_loss: 0.1339 - val_acc: 0.8980
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1367 - acc: 0.8799 - val_loss: 0.1310 - val_acc: 0.8951
Epoch 4/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1321 - acc: 0.8961 - val_loss: 0.1314 - val_acc: 0.8908
Epoch 5/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1302 - acc: 0.9033 - val_loss: 0.1288 - val_acc: 0.9050
Epoch 6/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1269 - acc: 0.9162 - val_loss: 0.1295 - val_acc: 0.9022
Epoch 7/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1249 - acc: 0.9203 - val_loss: 0.1264 - val_acc: 0.9122
Epoch 8/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1229 - acc: 0.9287 - val_loss: 0.1255 - val_acc: 0.9122
Epoch 9/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1216 - acc: 0.9302 - val_loss: 0.1253 - val_acc: 0.9237
Epoch 10/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1212 - acc: 0.9329 - val_loss: 0.1251 - val_acc: 0.9266
Epoch 11/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1195 - acc: 0.9389 - val_loss: 0.1243 - val_acc: 0.9282
Epoch 12/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1194 - acc: 0.9384 - val_loss: 0.1247 - val_acc: 0.9222
Epoch 13/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1175 - acc: 0.9449 - val_loss: 0.1236 - val_acc: 0.9238
Epoch 14/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1170 - acc: 0.9472 - val_loss: 0.1236 - val_acc: 0.9210
Epoch 15/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1169 - acc: 0.9474 - val_loss: 0.1248 - val_acc: 0.9222
Epoch 16/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1163 - acc: 0.9470 - val_loss: 0.1236 - val_acc: 0.9225
Epoch 17/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1155 - acc: 0.9533 - val_loss: 0.1243 - val_acc: 0.9251
Manual evaluation: (didn't understand why I made this)
True 8003
False 1068
True percentage 0.882262154118
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.85      0.71      0.78       438
          O       0.98      0.96      0.97      7318
      B-LOC       0.72      0.65      0.68       218
      I-LOC       0.73      0.73      0.73       141
      I-PER       0.79      0.62      0.70       214
      B-ORG       0.60      0.54      0.57       296
      I-ORG       0.36      0.46      0.40       151
     B-MISC       0.29      0.11      0.16       141
     I-MISC       0.53      0.28      0.37       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.909198392055
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 11
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103917 unique words.
3913 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 260
OOV word occurences: 433
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6650752     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,426
Trainable params: 7,159,426
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 10s 35ms/step - loss: 0.1846 - acc: 0.7449 - val_loss: 0.1573 - val_acc: 0.8100
Epoch 2/70

300/300 [==============================] - 7s 23ms/step - loss: 0.1392 - acc: 0.8703 - val_loss: 0.1534 - val_acc: 0.8157
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1333 - acc: 0.8947 - val_loss: 0.1517 - val_acc: 0.8242
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1310 - acc: 0.8995 - val_loss: 0.1464 - val_acc: 0.8500
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1280 - acc: 0.9145 - val_loss: 0.1443 - val_acc: 0.8585
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1256 - acc: 0.9210 - val_loss: 0.1421 - val_acc: 0.8600
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1235 - acc: 0.9250 - val_loss: 0.1427 - val_acc: 0.8557
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1221 - acc: 0.9306 - val_loss: 0.1404 - val_acc: 0.8714
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1207 - acc: 0.9350 - val_loss: 0.1402 - val_acc: 0.8728
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1197 - acc: 0.9385 - val_loss: 0.1404 - val_acc: 0.8642
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1188 - acc: 0.9417 - val_loss: 0.1404 - val_acc: 0.8685
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1178 - acc: 0.9417 - val_loss: 0.1424 - val_acc: 0.8642
Manual evaluation: (didn't understand why I made this)
True 7912
False 1159
True percentage 0.872230184103
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.53      0.60      0.56       296
     B-MISC       0.47      0.06      0.11       141
     I-MISC       0.49      0.12      0.19       154
      B-PER       0.90      0.67      0.77       438
      B-LOC       0.67      0.70      0.69       218
      I-ORG       0.27      0.44      0.33       151
      I-PER       0.74      0.61      0.67       214
      I-LOC       0.68      0.78      0.73       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.582571602681
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 12
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103899 unique words.
3895 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 254
OOV word occurences: 367
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6649600     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,158,274
Trainable params: 7,158,274
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1867 - acc: 0.7336 - val_loss: 0.1539 - val_acc: 0.8234
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1427 - acc: 0.8610 - val_loss: 0.1478 - val_acc: 0.8230
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1362 - acc: 0.8824 - val_loss: 0.1352 - val_acc: 0.9002
Epoch 4/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1314 - acc: 0.9019 - val_loss: 0.1363 - val_acc: 0.8907
Epoch 5/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1287 - acc: 0.9081 - val_loss: 0.1304 - val_acc: 0.9057
Epoch 6/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1264 - acc: 0.9160 - val_loss: 0.1307 - val_acc: 0.9068
Epoch 7/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1246 - acc: 0.9211 - val_loss: 0.1293 - val_acc: 0.9170
Epoch 8/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1236 - acc: 0.9266 - val_loss: 0.1277 - val_acc: 0.9071
Epoch 9/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1217 - acc: 0.9349 - val_loss: 0.1266 - val_acc: 0.9199
Epoch 10/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1208 - acc: 0.9314 - val_loss: 0.1264 - val_acc: 0.9228
Epoch 11/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1189 - acc: 0.9395 - val_loss: 0.1257 - val_acc: 0.9228
Epoch 12/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1186 - acc: 0.9464 - val_loss: 0.1253 - val_acc: 0.9213
Epoch 13/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1176 - acc: 0.9466 - val_loss: 0.1245 - val_acc: 0.9242
Epoch 14/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1172 - acc: 0.9439 - val_loss: 0.1240 - val_acc: 0.9213
Epoch 15/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1164 - acc: 0.9492 - val_loss: 0.1255 - val_acc: 0.9213
Epoch 16/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1158 - acc: 0.9507 - val_loss: 0.1246 - val_acc: 0.9213
Epoch 17/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1160 - acc: 0.9487 - val_loss: 0.1236 - val_acc: 0.9242
Epoch 18/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1140 - acc: 0.9548 - val_loss: 0.1225 - val_acc: 0.9261
Epoch 19/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1134 - acc: 0.9609 - val_loss: 0.1238 - val_acc: 0.9301
Epoch 20/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1136 - acc: 0.9584 - val_loss: 0.1218 - val_acc: 0.9286
Epoch 21/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1131 - acc: 0.9626 - val_loss: 0.1223 - val_acc: 0.9272
Epoch 22/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1119 - acc: 0.9638 - val_loss: 0.1229 - val_acc: 0.9272
Epoch 23/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1120 - acc: 0.9619 - val_loss: 0.1220 - val_acc: 0.9315
Manual evaluation: (didn't understand why I made this)
True 8081
False 990
True percentage 0.890860985558
Sklearn evaluation:
             precision    recall  f1-score   support

     B-MISC       0.49      0.27      0.35       141
     I-MISC       0.36      0.29      0.32       154
          O       0.98      0.96      0.97      7318
      B-PER       0.88      0.81      0.84       438
      I-PER       0.86      0.63      0.72       214
      B-ORG       0.71      0.56      0.63       296
      B-LOC       0.64      0.79      0.71       218
      I-ORG       0.46      0.42      0.44       151
      I-LOC       0.61      0.81      0.69       141

avg / total       0.93      0.89      0.91      9071

F-1 Score:
0.9162157544
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 13
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103907 unique words.
3903 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 262
OOV word occurences: 409
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6650112     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,158,786
Trainable params: 7,158,786
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 9s 31ms/step - loss: 0.1854 - acc: 0.7328 - val_loss: 0.1457 - val_acc: 0.8510
Epoch 2/70

300/300 [==============================] - 6s 20ms/step - loss: 0.1422 - acc: 0.8681 - val_loss: 0.1380 - val_acc: 0.8706
Epoch 3/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1351 - acc: 0.8907 - val_loss: 0.1375 - val_acc: 0.8892
Epoch 4/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1322 - acc: 0.9006 - val_loss: 0.1305 - val_acc: 0.9075
Epoch 5/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1287 - acc: 0.9111 - val_loss: 0.1311 - val_acc: 0.9075
Epoch 6/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1264 - acc: 0.9164 - val_loss: 0.1295 - val_acc: 0.9101
Epoch 7/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1240 - acc: 0.9242 - val_loss: 0.1270 - val_acc: 0.9128
Epoch 8/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1232 - acc: 0.9258 - val_loss: 0.1259 - val_acc: 0.9154
Epoch 9/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1225 - acc: 0.9311 - val_loss: 0.1250 - val_acc: 0.9154
Epoch 10/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1200 - acc: 0.9400 - val_loss: 0.1235 - val_acc: 0.9219
Epoch 11/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1191 - acc: 0.9404 - val_loss: 0.1240 - val_acc: 0.9180
Epoch 12/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1187 - acc: 0.9400 - val_loss: 0.1238 - val_acc: 0.9219
Epoch 13/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1174 - acc: 0.9458 - val_loss: 0.1229 - val_acc: 0.9235
Epoch 14/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1164 - acc: 0.9491 - val_loss: 0.1239 - val_acc: 0.9235
Epoch 15/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1161 - acc: 0.9477 - val_loss: 0.1219 - val_acc: 0.9274
Epoch 16/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1147 - acc: 0.9552 - val_loss: 0.1222 - val_acc: 0.9274
Epoch 17/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1143 - acc: 0.9576 - val_loss: 0.1219 - val_acc: 0.9248
Epoch 18/70

300/300 [==============================] - 6s 19ms/step - loss: 0.1131 - acc: 0.9607 - val_loss: 0.1225 - val_acc: 0.9261
Manual evaluation: (didn't understand why I made this)
True 8018
False 1053
True percentage 0.883915775548
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.87      0.75      0.80       438
      B-ORG       0.64      0.66      0.65       296
     B-MISC       0.44      0.23      0.31       141
     I-MISC       0.40      0.25      0.31       154
      I-ORG       0.36      0.55      0.43       151
      B-LOC       0.68      0.77      0.72       218
      I-LOC       0.75      0.59      0.66       141
      I-PER       0.87      0.61      0.71       214

avg / total       0.93      0.88      0.90      9071

F-1 Score:
0.632616487455
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 14
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103918 unique words.
3914 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 257
OOV word occurences: 424
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6650816     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,490
Trainable params: 7,159,490
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.1782 - acc: 0.7667 - val_loss: 0.1427 - val_acc: 0.8497
Epoch 2/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1378 - acc: 0.8813 - val_loss: 0.1320 - val_acc: 0.9021
Epoch 3/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1324 - acc: 0.8983 - val_loss: 0.1289 - val_acc: 0.9190
Epoch 4/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1293 - acc: 0.9095 - val_loss: 0.1259 - val_acc: 0.9158
Epoch 5/70

300/300 [==============================] - 5s 17ms/step - loss: 0.1268 - acc: 0.9184 - val_loss: 0.1245 - val_acc: 0.9143
Epoch 6/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1242 - acc: 0.9267 - val_loss: 0.1251 - val_acc: 0.9141
Epoch 7/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1228 - acc: 0.9275 - val_loss: 0.1219 - val_acc: 0.9367
Epoch 8/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1211 - acc: 0.9321 - val_loss: 0.1212 - val_acc: 0.9367
Epoch 9/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1201 - acc: 0.9359 - val_loss: 0.1206 - val_acc: 0.9365
Epoch 10/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1191 - acc: 0.9390 - val_loss: 0.1213 - val_acc: 0.9395
Epoch 11/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1176 - acc: 0.9427 - val_loss: 0.1210 - val_acc: 0.9350
Epoch 12/70

300/300 [==============================] - 5s 16ms/step - loss: 0.1164 - acc: 0.9550 - val_loss: 0.1217 - val_acc: 0.9320
Manual evaluation: (didn't understand why I made this)
True 7957
False 1114
True percentage 0.877191048396
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-ORG       0.66      0.51      0.57       296
      I-ORG       0.38      0.14      0.20       151
      B-PER       0.83      0.70      0.76       438
     B-MISC       0.32      0.33      0.32       141
     I-MISC       0.39      0.45      0.42       154
      B-LOC       0.73      0.67      0.70       218
      I-LOC       0.53      0.80      0.64       141
      I-PER       0.80      0.61      0.69       214

avg / total       0.92      0.88      0.89      9071

F-1 Score:
0.594316807739
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 39ms/step - loss: 0.2251 - acc: 0.6162 - val_loss: 0.1656 - val_acc: 0.7868
Epoch 2/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1543 - acc: 0.8308 - val_loss: 0.1456 - val_acc: 0.8505
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1442 - acc: 0.8613 - val_loss: 0.1420 - val_acc: 0.8627
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1381 - acc: 0.8830 - val_loss: 0.1355 - val_acc: 0.8922
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1359 - acc: 0.8770 - val_loss: 0.1327 - val_acc: 0.8922
Epoch 6/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1331 - acc: 0.8951 - val_loss: 0.1309 - val_acc: 0.8971
Epoch 7/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1300 - acc: 0.9014 - val_loss: 0.1305 - val_acc: 0.8946
Epoch 8/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1285 - acc: 0.9093 - val_loss: 0.1307 - val_acc: 0.8873
Epoch 9/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1278 - acc: 0.9093 - val_loss: 0.1275 - val_acc: 0.9020
Epoch 10/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1255 - acc: 0.9158 - val_loss: 0.1259 - val_acc: 0.9093
Epoch 11/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1246 - acc: 0.9244 - val_loss: 0.1237 - val_acc: 0.9216
Epoch 12/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1224 - acc: 0.9260 - val_loss: 0.1248 - val_acc: 0.9216
Epoch 13/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1207 - acc: 0.9345 - val_loss: 0.1242 - val_acc: 0.9191
Epoch 14/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1216 - acc: 0.9298 - val_loss: 0.1245 - val_acc: 0.9240
Manual evaluation: (didn't understand why I made this)
True 7759
False 1312
True percentage 0.855363245508
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-PER       0.89      0.62      0.73       438
      B-LOC       0.75      0.50      0.60       218
      B-ORG       0.44      0.67      0.53       296
      I-ORG       0.20      0.53      0.30       151
      I-PER       0.81      0.56      0.66       214
      I-LOC       0.53      0.23      0.33       141
     B-MISC       0.44      0.16      0.24       141
     I-MISC       0.26      0.07      0.11       154

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.504327066547
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 38ms/step - loss: 0.2142 - acc: 0.6559 - val_loss: 0.1552 - val_acc: 0.8171
Epoch 2/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1485 - acc: 0.8517 - val_loss: 0.1470 - val_acc: 0.8266
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1417 - acc: 0.8705 - val_loss: 0.1422 - val_acc: 0.8432
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1361 - acc: 0.8822 - val_loss: 0.1408 - val_acc: 0.8432
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1329 - acc: 0.8907 - val_loss: 0.1401 - val_acc: 0.8504
Epoch 6/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1297 - acc: 0.9064 - val_loss: 0.1361 - val_acc: 0.8812
Epoch 7/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1283 - acc: 0.9100 - val_loss: 0.1358 - val_acc: 0.8717
Epoch 8/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1265 - acc: 0.9175 - val_loss: 0.1362 - val_acc: 0.8670
Epoch 9/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1255 - acc: 0.9229 - val_loss: 0.1339 - val_acc: 0.8836
Epoch 10/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1247 - acc: 0.9252 - val_loss: 0.1317 - val_acc: 0.8836
Epoch 11/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1225 - acc: 0.9275 - val_loss: 0.1306 - val_acc: 0.8931
Epoch 12/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1198 - acc: 0.9416 - val_loss: 0.1302 - val_acc: 0.8907
Epoch 13/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1194 - acc: 0.9403 - val_loss: 0.1299 - val_acc: 0.8884
Epoch 14/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1184 - acc: 0.9441 - val_loss: 0.1306 - val_acc: 0.8860
Epoch 15/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1184 - acc: 0.9410 - val_loss: 0.1297 - val_acc: 0.8789
Epoch 16/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1176 - acc: 0.9489 - val_loss: 0.1289 - val_acc: 0.8979
Epoch 17/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1160 - acc: 0.9518 - val_loss: 0.1274 - val_acc: 0.9026
Epoch 18/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1151 - acc: 0.9515 - val_loss: 0.1279 - val_acc: 0.8955
Epoch 19/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1143 - acc: 0.9588 - val_loss: 0.1274 - val_acc: 0.9097
Epoch 20/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1141 - acc: 0.9567 - val_loss: 0.1271 - val_acc: 0.9050
Epoch 21/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1142 - acc: 0.9563 - val_loss: 0.1275 - val_acc: 0.9074
Epoch 22/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1133 - acc: 0.9592 - val_loss: 0.1295 - val_acc: 0.8860
Epoch 23/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1129 - acc: 0.9571 - val_loss: 0.1286 - val_acc: 0.8931
Manual evaluation: (didn't understand why I made this)
True 7880
False 1191
True percentage 0.868702458384
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.53      0.59      0.56       296
      B-LOC       0.66      0.67      0.66       218
      I-ORG       0.27      0.42      0.33       151
     B-MISC       0.45      0.18      0.26       141
     I-MISC       0.44      0.18      0.25       154
      B-PER       0.84      0.69      0.76       438
      I-PER       0.76      0.49      0.59       214
      I-LOC       0.55      0.80      0.66       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.568283249033
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 2
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103737 unique words.
3733 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 270
OOV word occurences: 444
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 66, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 66)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 66, 64)       6639232     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 66, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 66, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 66, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 66, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 66, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,147,906
Trainable params: 7,147,906
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 42ms/step - loss: 0.2078 - acc: 0.6622 - val_loss: 0.1490 - val_acc: 0.8356
Epoch 2/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1430 - acc: 0.8632 - val_loss: 0.1402 - val_acc: 0.8598
Epoch 3/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1369 - acc: 0.8858 - val_loss: 0.1351 - val_acc: 0.8814
Epoch 4/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1334 - acc: 0.8945 - val_loss: 0.1362 - val_acc: 0.8652
Epoch 5/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1308 - acc: 0.8970 - val_loss: 0.1337 - val_acc: 0.8976
Epoch 6/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1281 - acc: 0.9076 - val_loss: 0.1299 - val_acc: 0.9003
Epoch 7/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1258 - acc: 0.9186 - val_loss: 0.1302 - val_acc: 0.9003
Epoch 8/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1240 - acc: 0.9227 - val_loss: 0.1285 - val_acc: 0.9111
Epoch 9/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1225 - acc: 0.9273 - val_loss: 0.1279 - val_acc: 0.9164
Epoch 10/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1212 - acc: 0.9323 - val_loss: 0.1292 - val_acc: 0.9111
Epoch 11/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1202 - acc: 0.9400 - val_loss: 0.1286 - val_acc: 0.9003
Epoch 12/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1194 - acc: 0.9371 - val_loss: 0.1265 - val_acc: 0.9191
Epoch 13/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1183 - acc: 0.9438 - val_loss: 0.1263 - val_acc: 0.9164
Epoch 14/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1173 - acc: 0.9446 - val_loss: 0.1279 - val_acc: 0.9164
Epoch 15/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1156 - acc: 0.9519 - val_loss: 0.1275 - val_acc: 0.9057
Epoch 16/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1157 - acc: 0.9534 - val_loss: 0.1253 - val_acc: 0.9164
Epoch 17/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1148 - acc: 0.9530 - val_loss: 0.1247 - val_acc: 0.9191
Epoch 18/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1152 - acc: 0.9536 - val_loss: 0.1249 - val_acc: 0.9137
Epoch 19/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1133 - acc: 0.9604 - val_loss: 0.1242 - val_acc: 0.9191
Epoch 20/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1135 - acc: 0.9585 - val_loss: 0.1237 - val_acc: 0.9191
Epoch 21/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1135 - acc: 0.9574 - val_loss: 0.1240 - val_acc: 0.9218
Epoch 22/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1117 - acc: 0.9698 - val_loss: 0.1253 - val_acc: 0.9191
Epoch 23/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1121 - acc: 0.9622 - val_loss: 0.1238 - val_acc: 0.9191
Manual evaluation: (didn't understand why I made this)
True 7898
False 1173
True percentage 0.870686804101
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-PER       0.82      0.71      0.76       438
      B-ORG       0.59      0.47      0.52       296
      I-ORG       0.30      0.39      0.34       151
      I-PER       0.72      0.60      0.66       214
      B-LOC       0.65      0.68      0.67       218
      I-LOC       0.71      0.72      0.71       141
     B-MISC       0.33      0.21      0.25       141
     I-MISC       0.39      0.20      0.26       154

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.575517661389
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 3
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103737 unique words.
3733 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 268
OOV word occurences: 401
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639232     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,147,906
Trainable params: 7,147,906
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 39ms/step - loss: 0.2171 - acc: 0.7164 - val_loss: 0.1539 - val_acc: 0.8399
Epoch 2/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1506 - acc: 0.8330 - val_loss: 0.1403 - val_acc: 0.8904
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1429 - acc: 0.8598 - val_loss: 0.1416 - val_acc: 0.8567
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1383 - acc: 0.8676 - val_loss: 0.1320 - val_acc: 0.9017
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1337 - acc: 0.8945 - val_loss: 0.1303 - val_acc: 0.9045
Epoch 6/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1318 - acc: 0.8943 - val_loss: 0.1280 - val_acc: 0.9242
Epoch 7/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1281 - acc: 0.9103 - val_loss: 0.1266 - val_acc: 0.9298
Epoch 8/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1263 - acc: 0.9169 - val_loss: 0.1256 - val_acc: 0.9354
Epoch 9/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1259 - acc: 0.9183 - val_loss: 0.1248 - val_acc: 0.9270
Epoch 10/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1244 - acc: 0.9223 - val_loss: 0.1232 - val_acc: 0.9298
Epoch 11/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1218 - acc: 0.9376 - val_loss: 0.1237 - val_acc: 0.9354
Epoch 12/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1218 - acc: 0.9338 - val_loss: 0.1223 - val_acc: 0.9354
Epoch 13/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1203 - acc: 0.9349 - val_loss: 0.1214 - val_acc: 0.9438
Epoch 14/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1190 - acc: 0.9425 - val_loss: 0.1215 - val_acc: 0.9438
Epoch 15/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1182 - acc: 0.9432 - val_loss: 0.1225 - val_acc: 0.9298
Epoch 16/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1170 - acc: 0.9481 - val_loss: 0.1213 - val_acc: 0.9382
Epoch 17/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1169 - acc: 0.9485 - val_loss: 0.1211 - val_acc: 0.9438
Epoch 18/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1157 - acc: 0.9515 - val_loss: 0.1213 - val_acc: 0.9298
Epoch 19/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1152 - acc: 0.9536 - val_loss: 0.1210 - val_acc: 0.9354
Epoch 20/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1152 - acc: 0.9521 - val_loss: 0.1215 - val_acc: 0.9326
Epoch 21/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1142 - acc: 0.9568 - val_loss: 0.1211 - val_acc: 0.9298
Epoch 22/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1136 - acc: 0.9596 - val_loss: 0.1216 - val_acc: 0.9326
Manual evaluation: (didn't understand why I made this)
True 7923
False 1148
True percentage 0.873442839819
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.96      0.96      7318
     B-MISC       0.41      0.16      0.23       141
     I-MISC       0.50      0.19      0.27       154
      B-ORG       0.51      0.56      0.53       296
      I-ORG       0.29      0.34      0.32       151
      B-PER       0.87      0.63      0.74       438
      I-PER       0.78      0.60      0.68       214
      B-LOC       0.73      0.60      0.66       218
      I-LOC       0.63      0.74      0.68       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.569996868149
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 4
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103757 unique words.
3753 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 440
Padded until 63 tokens.
Padded until 24 chars.
Padded until 63 tokens.
Padded until 24 chars.
Padded until 63 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 63, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 63, 64)       6640512     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 63, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 63, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 63, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 63, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 63, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,186
Trainable params: 7,149,186
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 40ms/step - loss: 0.2153 - acc: 0.6545 - val_loss: 0.1560 - val_acc: 0.8179
Epoch 2/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1530 - acc: 0.8275 - val_loss: 0.1452 - val_acc: 0.8537
Epoch 3/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1436 - acc: 0.8633 - val_loss: 0.1438 - val_acc: 0.8507
Epoch 4/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1402 - acc: 0.8770 - val_loss: 0.1420 - val_acc: 0.8537
Epoch 5/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1358 - acc: 0.8851 - val_loss: 0.1458 - val_acc: 0.8627
Epoch 6/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1343 - acc: 0.8894 - val_loss: 0.1367 - val_acc: 0.8776
Epoch 7/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1304 - acc: 0.9110 - val_loss: 0.1357 - val_acc: 0.8866
Epoch 8/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1279 - acc: 0.9148 - val_loss: 0.1365 - val_acc: 0.8806
Epoch 9/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1266 - acc: 0.9202 - val_loss: 0.1318 - val_acc: 0.9075
Epoch 10/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1255 - acc: 0.9199 - val_loss: 0.1302 - val_acc: 0.9015
Epoch 11/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1236 - acc: 0.9308 - val_loss: 0.1306 - val_acc: 0.8985
Epoch 12/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1223 - acc: 0.9326 - val_loss: 0.1303 - val_acc: 0.9045
Epoch 13/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1212 - acc: 0.9380 - val_loss: 0.1291 - val_acc: 0.9075
Epoch 14/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1201 - acc: 0.9448 - val_loss: 0.1313 - val_acc: 0.9045
Epoch 15/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1197 - acc: 0.9388 - val_loss: 0.1276 - val_acc: 0.9104
Epoch 16/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1178 - acc: 0.9454 - val_loss: 0.1281 - val_acc: 0.9075
Epoch 17/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1180 - acc: 0.9456 - val_loss: 0.1288 - val_acc: 0.9075
Epoch 18/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1164 - acc: 0.9529 - val_loss: 0.1288 - val_acc: 0.9045
Manual evaluation: (didn't understand why I made this)
True 7875
False 1196
True percentage 0.86815125124
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.53      0.53      0.53       296
      B-LOC       0.68      0.61      0.64       218
      B-PER       0.80      0.67      0.73       438
      I-PER       0.74      0.50      0.60       214
     B-MISC       0.35      0.21      0.26       141
      I-ORG       0.33      0.48      0.39       151
      I-LOC       0.67      0.67      0.67       141
     I-MISC       0.40      0.23      0.30       154

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.561116166212
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 5
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103724 unique words.
3720 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 274
OOV word occurences: 443
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6638400     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,147,074
Trainable params: 7,147,074
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 41ms/step - loss: 0.2186 - acc: 0.6431 - val_loss: 0.1553 - val_acc: 0.8153
Epoch 2/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1506 - acc: 0.8382 - val_loss: 0.1459 - val_acc: 0.8443
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1436 - acc: 0.8557 - val_loss: 0.1418 - val_acc: 0.8734
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1393 - acc: 0.8740 - val_loss: 0.1402 - val_acc: 0.8813
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1362 - acc: 0.8837 - val_loss: 0.1363 - val_acc: 0.8813
Epoch 6/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1345 - acc: 0.8902 - val_loss: 0.1355 - val_acc: 0.8734
Epoch 7/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1307 - acc: 0.9027 - val_loss: 0.1331 - val_acc: 0.8786
Epoch 8/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1289 - acc: 0.9124 - val_loss: 0.1328 - val_acc: 0.8918
Epoch 9/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1293 - acc: 0.9090 - val_loss: 0.1320 - val_acc: 0.8892
Epoch 10/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1258 - acc: 0.9186 - val_loss: 0.1302 - val_acc: 0.8918
Epoch 11/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1243 - acc: 0.9293 - val_loss: 0.1301 - val_acc: 0.8892
Epoch 12/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1229 - acc: 0.9294 - val_loss: 0.1306 - val_acc: 0.8945
Epoch 13/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1217 - acc: 0.9352 - val_loss: 0.1285 - val_acc: 0.8971
Epoch 14/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1209 - acc: 0.9389 - val_loss: 0.1289 - val_acc: 0.8971
Epoch 15/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1204 - acc: 0.9382 - val_loss: 0.1300 - val_acc: 0.8945
Epoch 16/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1200 - acc: 0.9391 - val_loss: 0.1278 - val_acc: 0.8945
Epoch 17/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1174 - acc: 0.9459 - val_loss: 0.1262 - val_acc: 0.9129
Epoch 18/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1186 - acc: 0.9439 - val_loss: 0.1268 - val_acc: 0.9050
Epoch 19/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1163 - acc: 0.9511 - val_loss: 0.1261 - val_acc: 0.9050
Epoch 20/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1157 - acc: 0.9519 - val_loss: 0.1254 - val_acc: 0.9103
Epoch 21/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1157 - acc: 0.9556 - val_loss: 0.1251 - val_acc: 0.9103
Epoch 22/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1153 - acc: 0.9540 - val_loss: 0.1251 - val_acc: 0.9182
Epoch 23/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1134 - acc: 0.9630 - val_loss: 0.1234 - val_acc: 0.9129
Epoch 24/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1136 - acc: 0.9610 - val_loss: 0.1247 - val_acc: 0.9129
Epoch 25/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1141 - acc: 0.9562 - val_loss: 0.1243 - val_acc: 0.9050
Epoch 26/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1140 - acc: 0.9549 - val_loss: 0.1245 - val_acc: 0.9129
Manual evaluation: (didn't understand why I made this)
True 7895
False 1176
True percentage 0.870356079815
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-PER       0.85      0.67      0.75       438
      B-ORG       0.55      0.57      0.56       296
     I-MISC       0.31      0.19      0.24       154
      B-LOC       0.66      0.71      0.68       218
      I-LOC       0.59      0.78      0.67       141
      I-ORG       0.41      0.46      0.43       151
      I-PER       0.78      0.59      0.67       214
     B-MISC       0.35      0.13      0.19       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.586102719033
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 6
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103757 unique words.
3753 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 268
OOV word occurences: 497
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6640512     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,186
Trainable params: 7,149,186
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 39ms/step - loss: 0.2281 - acc: 0.6397 - val_loss: 0.1491 - val_acc: 0.8487
Epoch 2/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1502 - acc: 0.8368 - val_loss: 0.1378 - val_acc: 0.8852
Epoch 3/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1401 - acc: 0.8748 - val_loss: 0.1349 - val_acc: 0.8908
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1374 - acc: 0.8784 - val_loss: 0.1333 - val_acc: 0.8936
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1338 - acc: 0.8951 - val_loss: 0.1316 - val_acc: 0.9188
Epoch 6/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1316 - acc: 0.8975 - val_loss: 0.1319 - val_acc: 0.9020
Epoch 7/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1290 - acc: 0.9058 - val_loss: 0.1315 - val_acc: 0.9048
Epoch 8/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1280 - acc: 0.9116 - val_loss: 0.1303 - val_acc: 0.9048
Epoch 9/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1245 - acc: 0.9243 - val_loss: 0.1269 - val_acc: 0.9188
Epoch 10/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1254 - acc: 0.9212 - val_loss: 0.1256 - val_acc: 0.9356
Epoch 11/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1217 - acc: 0.9346 - val_loss: 0.1262 - val_acc: 0.9272
Epoch 12/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1214 - acc: 0.9345 - val_loss: 0.1256 - val_acc: 0.9328
Epoch 13/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1201 - acc: 0.9377 - val_loss: 0.1258 - val_acc: 0.9160
Epoch 14/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1185 - acc: 0.9445 - val_loss: 0.1254 - val_acc: 0.9356
Epoch 15/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1179 - acc: 0.9478 - val_loss: 0.1245 - val_acc: 0.9300
Epoch 16/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1171 - acc: 0.9502 - val_loss: 0.1253 - val_acc: 0.9244
Epoch 17/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1167 - acc: 0.9547 - val_loss: 0.1228 - val_acc: 0.9440
Epoch 18/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1155 - acc: 0.9582 - val_loss: 0.1254 - val_acc: 0.9132
Epoch 19/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1157 - acc: 0.9541 - val_loss: 0.1239 - val_acc: 0.9188
Epoch 20/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1148 - acc: 0.9554 - val_loss: 0.1249 - val_acc: 0.9160
Manual evaluation: (didn't understand why I made this)
True 7756
False 1315
True percentage 0.855032521221
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-PER       0.80      0.48      0.60       438
      B-LOC       0.66      0.65      0.66       218
      B-ORG       0.47      0.53      0.50       296
      I-PER       0.68      0.40      0.50       214
     B-MISC       0.46      0.19      0.27       141
     I-MISC       0.37      0.26      0.31       154
      I-LOC       0.64      0.64      0.64       141
      I-ORG       0.26      0.50      0.34       151

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.502274795268
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 7
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103765 unique words.
3761 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 432
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6641024     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,698
Trainable params: 7,149,698
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 39ms/step - loss: 0.2135 - acc: 0.6457 - val_loss: 0.1440 - val_acc: 0.8580
Epoch 2/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1477 - acc: 0.8488 - val_loss: 0.1354 - val_acc: 0.8971
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1386 - acc: 0.8759 - val_loss: 0.1300 - val_acc: 0.9115
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1350 - acc: 0.8863 - val_loss: 0.1296 - val_acc: 0.9074
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1306 - acc: 0.9055 - val_loss: 0.1296 - val_acc: 0.9115
Epoch 6/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1271 - acc: 0.9179 - val_loss: 0.1258 - val_acc: 0.9156
Epoch 7/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1265 - acc: 0.9205 - val_loss: 0.1259 - val_acc: 0.9156
Epoch 8/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1249 - acc: 0.9197 - val_loss: 0.1229 - val_acc: 0.9259
Epoch 9/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1232 - acc: 0.9257 - val_loss: 0.1232 - val_acc: 0.9300
Epoch 10/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1223 - acc: 0.9318 - val_loss: 0.1236 - val_acc: 0.9218
Epoch 11/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1207 - acc: 0.9384 - val_loss: 0.1215 - val_acc: 0.9362
Epoch 12/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1198 - acc: 0.9373 - val_loss: 0.1215 - val_acc: 0.9383
Epoch 13/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1192 - acc: 0.9433 - val_loss: 0.1207 - val_acc: 0.9424
Epoch 14/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1176 - acc: 0.9459 - val_loss: 0.1207 - val_acc: 0.9444
Epoch 15/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1170 - acc: 0.9458 - val_loss: 0.1210 - val_acc: 0.9342
Epoch 16/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1165 - acc: 0.9470 - val_loss: 0.1200 - val_acc: 0.9403
Epoch 17/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1160 - acc: 0.9502 - val_loss: 0.1197 - val_acc: 0.9362
Epoch 18/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1150 - acc: 0.9581 - val_loss: 0.1191 - val_acc: 0.9465
Epoch 19/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1133 - acc: 0.9620 - val_loss: 0.1191 - val_acc: 0.9465
Epoch 20/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1133 - acc: 0.9579 - val_loss: 0.1191 - val_acc: 0.9527
Epoch 21/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1129 - acc: 0.9612 - val_loss: 0.1186 - val_acc: 0.9506
Epoch 22/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1132 - acc: 0.9603 - val_loss: 0.1183 - val_acc: 0.9486
Epoch 23/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1123 - acc: 0.9635 - val_loss: 0.1192 - val_acc: 0.9465
Epoch 24/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1114 - acc: 0.9652 - val_loss: 0.1184 - val_acc: 0.9527
Epoch 25/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1121 - acc: 0.9596 - val_loss: 0.1199 - val_acc: 0.9444
Manual evaluation: (didn't understand why I made this)
True 7924
False 1147
True percentage 0.873553081248
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-ORG       0.58      0.60      0.59       296
      I-ORG       0.34      0.42      0.37       151
      B-PER       0.84      0.67      0.75       438
      B-LOC       0.70      0.70      0.70       218
      I-LOC       0.70      0.71      0.70       141
      I-PER       0.87      0.50      0.64       214
     B-MISC       0.25      0.07      0.11       141
     I-MISC       0.41      0.21      0.28       154

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.585259212992
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 8
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103765 unique words.
3761 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 269
OOV word occurences: 429
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641024     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,698
Trainable params: 7,149,698
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 39ms/step - loss: 0.2199 - acc: 0.6390 - val_loss: 0.1264 - val_acc: 0.9079
Epoch 2/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1482 - acc: 0.8477 - val_loss: 0.1216 - val_acc: 0.9377
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1400 - acc: 0.8747 - val_loss: 0.1196 - val_acc: 0.9377
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1372 - acc: 0.8766 - val_loss: 0.1189 - val_acc: 0.9377
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1329 - acc: 0.8979 - val_loss: 0.1187 - val_acc: 0.9404
Epoch 6/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1304 - acc: 0.9045 - val_loss: 0.1184 - val_acc: 0.9431
Epoch 7/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1280 - acc: 0.9109 - val_loss: 0.1177 - val_acc: 0.9458
Epoch 8/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1262 - acc: 0.9159 - val_loss: 0.1170 - val_acc: 0.9485
Epoch 9/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1246 - acc: 0.9249 - val_loss: 0.1174 - val_acc: 0.9431
Epoch 10/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1230 - acc: 0.9329 - val_loss: 0.1174 - val_acc: 0.9431
Epoch 11/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1225 - acc: 0.9272 - val_loss: 0.1160 - val_acc: 0.9485
Epoch 12/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1213 - acc: 0.9332 - val_loss: 0.1164 - val_acc: 0.9458
Epoch 13/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1197 - acc: 0.9406 - val_loss: 0.1159 - val_acc: 0.9539
Epoch 14/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1185 - acc: 0.9395 - val_loss: 0.1160 - val_acc: 0.9458
Epoch 15/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1190 - acc: 0.9463 - val_loss: 0.1153 - val_acc: 0.9485
Epoch 16/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1175 - acc: 0.9449 - val_loss: 0.1150 - val_acc: 0.9593
Epoch 17/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1171 - acc: 0.9501 - val_loss: 0.1153 - val_acc: 0.9431
Epoch 18/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1159 - acc: 0.9549 - val_loss: 0.1151 - val_acc: 0.9512
Epoch 19/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1159 - acc: 0.9530 - val_loss: 0.1151 - val_acc: 0.9485
Manual evaluation: (didn't understand why I made this)
True 7951
False 1120
True percentage 0.876529599824
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-ORG       0.57      0.54      0.55       296
      I-ORG       0.33      0.53      0.41       151
     B-MISC       0.43      0.19      0.26       141
     I-MISC       0.48      0.21      0.29       154
      B-PER       0.83      0.70      0.76       438
      B-LOC       0.70      0.68      0.69       218
      I-LOC       0.73      0.70      0.72       141
      I-PER       0.76      0.58      0.66       214

avg / total       0.92      0.88      0.89      9071

F-1 Score:
0.594955940444
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 9
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103759 unique words.
3755 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 541
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 66, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 66)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 66, 64)       6640640     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 66, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 66, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 66, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 66, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 66, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,314
Trainable params: 7,149,314
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 41ms/step - loss: 0.2272 - acc: 0.5990 - val_loss: 0.1492 - val_acc: 0.8352
Epoch 2/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1515 - acc: 0.8388 - val_loss: 0.1371 - val_acc: 0.8901
Epoch 3/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1413 - acc: 0.8734 - val_loss: 0.1333 - val_acc: 0.8846
Epoch 4/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1366 - acc: 0.8845 - val_loss: 0.1297 - val_acc: 0.9148
Epoch 5/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1345 - acc: 0.8910 - val_loss: 0.1284 - val_acc: 0.8984
Epoch 6/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1294 - acc: 0.9111 - val_loss: 0.1330 - val_acc: 0.8874
Epoch 7/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1286 - acc: 0.9118 - val_loss: 0.1262 - val_acc: 0.9093
Epoch 8/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1255 - acc: 0.9237 - val_loss: 0.1274 - val_acc: 0.9011
Epoch 9/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1245 - acc: 0.9254 - val_loss: 0.1253 - val_acc: 0.9148
Epoch 10/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1227 - acc: 0.9395 - val_loss: 0.1282 - val_acc: 0.9038
Epoch 11/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1210 - acc: 0.9416 - val_loss: 0.1251 - val_acc: 0.9121
Epoch 12/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1200 - acc: 0.9419 - val_loss: 0.1245 - val_acc: 0.9203
Epoch 13/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1193 - acc: 0.9450 - val_loss: 0.1272 - val_acc: 0.8984
Epoch 14/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1187 - acc: 0.9435 - val_loss: 0.1258 - val_acc: 0.9093
Epoch 15/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1164 - acc: 0.9533 - val_loss: 0.1254 - val_acc: 0.9093
Manual evaluation: (didn't understand why I made this)
True 7703
False 1368
True percentage 0.849189725499
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.85      0.54      0.66       438
          O       0.97      0.95      0.96      7318
      B-ORG       0.49      0.49      0.49       296
     B-MISC       0.23      0.07      0.11       141
      B-LOC       0.71      0.51      0.60       218
      I-LOC       0.84      0.29      0.43       141
     I-MISC       0.22      0.05      0.08       154
      I-PER       0.71      0.48      0.57       214
      I-ORG       0.24      0.60      0.34       151

avg / total       0.90      0.85      0.87      9071

F-1 Score:
0.88437388935
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 10
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103760 unique words.
3756 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 540
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6640704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,378
Trainable params: 7,149,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 39ms/step - loss: 0.2312 - acc: 0.6347 - val_loss: 0.1832 - val_acc: 0.7190
Epoch 2/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1506 - acc: 0.8339 - val_loss: 0.1683 - val_acc: 0.7752
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1405 - acc: 0.8637 - val_loss: 0.1677 - val_acc: 0.7869
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1358 - acc: 0.8807 - val_loss: 0.1734 - val_acc: 0.7494
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1338 - acc: 0.8884 - val_loss: 0.1580 - val_acc: 0.8126
Epoch 6/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1297 - acc: 0.9022 - val_loss: 0.1618 - val_acc: 0.8009
Epoch 7/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1273 - acc: 0.9116 - val_loss: 0.1577 - val_acc: 0.8197
Epoch 8/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1260 - acc: 0.9172 - val_loss: 0.1545 - val_acc: 0.8197
Epoch 9/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1243 - acc: 0.9227 - val_loss: 0.1568 - val_acc: 0.8103
Epoch 10/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1236 - acc: 0.9247 - val_loss: 0.1502 - val_acc: 0.8454
Epoch 11/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1221 - acc: 0.9309 - val_loss: 0.1511 - val_acc: 0.8361
Epoch 12/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1201 - acc: 0.9370 - val_loss: 0.1526 - val_acc: 0.8407
Epoch 13/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1193 - acc: 0.9395 - val_loss: 0.1508 - val_acc: 0.8431
Manual evaluation: (didn't understand why I made this)
True 7712
False 1359
True percentage 0.850181898357
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.73      0.54      0.62       438
          O       0.98      0.95      0.96      7318
      B-LOC       0.72      0.50      0.59       218
      I-LOC       0.64      0.60      0.62       141
      I-PER       0.62      0.45      0.52       214
      B-ORG       0.40      0.42      0.41       296
      I-ORG       0.22      0.28      0.25       151
     B-MISC       0.36      0.13      0.19       141
     I-MISC       0.46      0.35      0.40       154

avg / total       0.90      0.85      0.87      9071

F-1 Score:
0.887793873189
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 11
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103763 unique words.
3759 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 459
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Padded until 24 chars.
Padded until 66 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 66, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 66)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 66, 64)       6640896     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 66, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 66, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 66, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 66, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 66, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,570
Trainable params: 7,149,570
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 42ms/step - loss: 0.2464 - acc: 0.6028 - val_loss: 0.1476 - val_acc: 0.8364
Epoch 2/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1532 - acc: 0.8254 - val_loss: 0.1359 - val_acc: 0.8892
Epoch 3/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1449 - acc: 0.8557 - val_loss: 0.1319 - val_acc: 0.8971
Epoch 4/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1396 - acc: 0.8678 - val_loss: 0.1298 - val_acc: 0.8997
Epoch 5/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1372 - acc: 0.8833 - val_loss: 0.1296 - val_acc: 0.9208
Epoch 6/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1338 - acc: 0.8903 - val_loss: 0.1278 - val_acc: 0.9156
Epoch 7/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1316 - acc: 0.9043 - val_loss: 0.1257 - val_acc: 0.9182
Epoch 8/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1297 - acc: 0.9036 - val_loss: 0.1260 - val_acc: 0.9129
Epoch 9/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1267 - acc: 0.9148 - val_loss: 0.1253 - val_acc: 0.9288
Epoch 10/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1260 - acc: 0.9164 - val_loss: 0.1254 - val_acc: 0.9235
Epoch 11/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1249 - acc: 0.9225 - val_loss: 0.1249 - val_acc: 0.9288
Epoch 12/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1228 - acc: 0.9324 - val_loss: 0.1236 - val_acc: 0.9340
Epoch 13/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1217 - acc: 0.9293 - val_loss: 0.1248 - val_acc: 0.9288
Epoch 14/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1214 - acc: 0.9313 - val_loss: 0.1237 - val_acc: 0.9340
Epoch 15/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1203 - acc: 0.9370 - val_loss: 0.1235 - val_acc: 0.9367
Epoch 16/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1200 - acc: 0.9420 - val_loss: 0.1230 - val_acc: 0.9367
Epoch 17/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1181 - acc: 0.9449 - val_loss: 0.1230 - val_acc: 0.9288
Epoch 18/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1175 - acc: 0.9491 - val_loss: 0.1223 - val_acc: 0.9420
Epoch 19/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1166 - acc: 0.9467 - val_loss: 0.1230 - val_acc: 0.9314
Epoch 20/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1154 - acc: 0.9532 - val_loss: 0.1220 - val_acc: 0.9393
Epoch 21/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1155 - acc: 0.9520 - val_loss: 0.1225 - val_acc: 0.9393
Epoch 22/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1150 - acc: 0.9536 - val_loss: 0.1221 - val_acc: 0.9340
Epoch 23/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1140 - acc: 0.9581 - val_loss: 0.1219 - val_acc: 0.9367
Epoch 24/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1148 - acc: 0.9529 - val_loss: 0.1217 - val_acc: 0.9261
Epoch 25/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1121 - acc: 0.9678 - val_loss: 0.1214 - val_acc: 0.9446
Epoch 26/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1127 - acc: 0.9617 - val_loss: 0.1219 - val_acc: 0.9393
Epoch 27/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1118 - acc: 0.9666 - val_loss: 0.1212 - val_acc: 0.9420
Epoch 28/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1116 - acc: 0.9695 - val_loss: 0.1217 - val_acc: 0.9340
Epoch 29/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1115 - acc: 0.9649 - val_loss: 0.1212 - val_acc: 0.9420
Epoch 30/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1106 - acc: 0.9733 - val_loss: 0.1212 - val_acc: 0.9340
Manual evaluation: (didn't understand why I made this)
True 7835
False 1236
True percentage 0.863741594091
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.51      0.51      0.51       296
     B-MISC       0.30      0.16      0.21       141
     I-MISC       0.48      0.33      0.39       154
      B-PER       0.85      0.66      0.74       438
      B-LOC       0.67      0.68      0.68       218
      I-ORG       0.24      0.29      0.27       151
      I-PER       0.74      0.46      0.57       214
      I-LOC       0.61      0.76      0.68       141

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.554945054945
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 12
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103756 unique words.
3752 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 417
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6640448     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,122
Trainable params: 7,149,122
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 38ms/step - loss: 0.2100 - acc: 0.6654 - val_loss: 0.1658 - val_acc: 0.7857
Epoch 2/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1476 - acc: 0.8466 - val_loss: 0.1572 - val_acc: 0.8067
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1389 - acc: 0.8815 - val_loss: 0.1540 - val_acc: 0.8172
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1367 - acc: 0.8743 - val_loss: 0.1485 - val_acc: 0.8424
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1318 - acc: 0.9006 - val_loss: 0.1527 - val_acc: 0.8172
Epoch 6/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1298 - acc: 0.9012 - val_loss: 0.1474 - val_acc: 0.8424
Epoch 7/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1277 - acc: 0.9126 - val_loss: 0.1475 - val_acc: 0.8487
Epoch 8/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1256 - acc: 0.9197 - val_loss: 0.1450 - val_acc: 0.8571
Epoch 9/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1241 - acc: 0.9241 - val_loss: 0.1458 - val_acc: 0.8592
Epoch 10/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1217 - acc: 0.9311 - val_loss: 0.1426 - val_acc: 0.8508
Epoch 11/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1210 - acc: 0.9324 - val_loss: 0.1412 - val_acc: 0.8592
Epoch 12/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1195 - acc: 0.9409 - val_loss: 0.1419 - val_acc: 0.8655
Epoch 13/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1194 - acc: 0.9426 - val_loss: 0.1423 - val_acc: 0.8655
Epoch 14/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1177 - acc: 0.9403 - val_loss: 0.1403 - val_acc: 0.8592
Epoch 15/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1174 - acc: 0.9495 - val_loss: 0.1403 - val_acc: 0.8676
Epoch 16/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1167 - acc: 0.9462 - val_loss: 0.1411 - val_acc: 0.8697
Epoch 17/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1160 - acc: 0.9512 - val_loss: 0.1400 - val_acc: 0.8718
Epoch 18/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1140 - acc: 0.9546 - val_loss: 0.1399 - val_acc: 0.8845
Epoch 19/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1142 - acc: 0.9592 - val_loss: 0.1396 - val_acc: 0.8824
Epoch 20/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1134 - acc: 0.9623 - val_loss: 0.1394 - val_acc: 0.8887
Epoch 21/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1138 - acc: 0.9589 - val_loss: 0.1402 - val_acc: 0.8824
Epoch 22/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1127 - acc: 0.9630 - val_loss: 0.1381 - val_acc: 0.8845
Epoch 23/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1125 - acc: 0.9620 - val_loss: 0.1381 - val_acc: 0.8761
Epoch 24/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1114 - acc: 0.9682 - val_loss: 0.1384 - val_acc: 0.8887
Epoch 25/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1121 - acc: 0.9630 - val_loss: 0.1387 - val_acc: 0.8866
Epoch 26/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1104 - acc: 0.9726 - val_loss: 0.1371 - val_acc: 0.8929
Epoch 27/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1106 - acc: 0.9676 - val_loss: 0.1378 - val_acc: 0.8887
Epoch 28/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1105 - acc: 0.9684 - val_loss: 0.1392 - val_acc: 0.8887
Epoch 29/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1097 - acc: 0.9705 - val_loss: 0.1390 - val_acc: 0.8971
Manual evaluation: (didn't understand why I made this)
True 7902
False 1169
True percentage 0.871127769816
Sklearn evaluation:
             precision    recall  f1-score   support

     B-MISC       0.33      0.15      0.20       141
     I-MISC       0.27      0.11      0.16       154
          O       0.98      0.95      0.97      7318
      B-PER       0.88      0.75      0.81       438
      I-PER       0.81      0.60      0.69       214
      B-ORG       0.53      0.51      0.52       296
      B-LOC       0.64      0.63      0.64       218
      I-ORG       0.29      0.48      0.36       151
      I-LOC       0.50      0.50      0.50       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.899657534247
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 13
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103769 unique words.
3765 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 264
OOV word occurences: 411
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6641280     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,954
Trainable params: 7,149,954
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 42ms/step - loss: 0.2260 - acc: 0.6288 - val_loss: 0.1400 - val_acc: 0.8771
Epoch 2/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1532 - acc: 0.8324 - val_loss: 0.1328 - val_acc: 0.9125
Epoch 3/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1459 - acc: 0.8558 - val_loss: 0.1270 - val_acc: 0.9314
Epoch 4/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1389 - acc: 0.8755 - val_loss: 0.1243 - val_acc: 0.9314
Epoch 5/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1369 - acc: 0.8824 - val_loss: 0.1236 - val_acc: 0.9409
Epoch 6/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1321 - acc: 0.9021 - val_loss: 0.1231 - val_acc: 0.9314
Epoch 7/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1311 - acc: 0.9029 - val_loss: 0.1213 - val_acc: 0.9314
Epoch 8/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1298 - acc: 0.9034 - val_loss: 0.1216 - val_acc: 0.9314
Epoch 9/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1273 - acc: 0.9151 - val_loss: 0.1213 - val_acc: 0.9433
Epoch 10/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1249 - acc: 0.9208 - val_loss: 0.1187 - val_acc: 0.9527
Epoch 11/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1246 - acc: 0.9241 - val_loss: 0.1178 - val_acc: 0.9504
Epoch 12/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1230 - acc: 0.9312 - val_loss: 0.1168 - val_acc: 0.9480
Epoch 13/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1231 - acc: 0.9303 - val_loss: 0.1176 - val_acc: 0.9527
Epoch 14/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1220 - acc: 0.9317 - val_loss: 0.1168 - val_acc: 0.9574
Epoch 15/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1209 - acc: 0.9340 - val_loss: 0.1167 - val_acc: 0.9551
Epoch 16/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1198 - acc: 0.9397 - val_loss: 0.1169 - val_acc: 0.9504
Epoch 17/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1183 - acc: 0.9424 - val_loss: 0.1161 - val_acc: 0.9480
Epoch 18/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1187 - acc: 0.9421 - val_loss: 0.1162 - val_acc: 0.9551
Epoch 19/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1159 - acc: 0.9533 - val_loss: 0.1159 - val_acc: 0.9527
Epoch 20/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1161 - acc: 0.9501 - val_loss: 0.1165 - val_acc: 0.9504
Epoch 21/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1166 - acc: 0.9479 - val_loss: 0.1163 - val_acc: 0.9504
Epoch 22/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1142 - acc: 0.9584 - val_loss: 0.1155 - val_acc: 0.9574
Epoch 23/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1143 - acc: 0.9578 - val_loss: 0.1173 - val_acc: 0.9480
Epoch 24/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1135 - acc: 0.9589 - val_loss: 0.1162 - val_acc: 0.9574
Epoch 25/70

150/150 [==============================] - 3s 19ms/step - loss: 0.1131 - acc: 0.9643 - val_loss: 0.1158 - val_acc: 0.9551
Manual evaluation: (didn't understand why I made this)
True 7919
False 1152
True percentage 0.873001874104
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-PER       0.83      0.71      0.76       438
      B-ORG       0.49      0.67      0.56       296
     B-MISC       0.42      0.22      0.29       141
     I-MISC       0.40      0.27      0.33       154
      I-ORG       0.34      0.54      0.42       151
      B-LOC       0.74      0.62      0.67       218
      I-LOC       0.79      0.62      0.70       141
      I-PER       0.86      0.57      0.69       214

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.595920780372
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 14
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103757 unique words.
3753 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 447
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6640512     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,149,186
Trainable params: 7,149,186
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 6s 39ms/step - loss: 0.2112 - acc: 0.6625 - val_loss: 0.1485 - val_acc: 0.8375
Epoch 2/70

150/150 [==============================] - 3s 18ms/step - loss: 0.1475 - acc: 0.8415 - val_loss: 0.1445 - val_acc: 0.8512
Epoch 3/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1385 - acc: 0.8786 - val_loss: 0.1427 - val_acc: 0.8567
Epoch 4/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1338 - acc: 0.8896 - val_loss: 0.1368 - val_acc: 0.8898
Epoch 5/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1307 - acc: 0.9004 - val_loss: 0.1352 - val_acc: 0.8815
Epoch 6/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1291 - acc: 0.9082 - val_loss: 0.1335 - val_acc: 0.8898
Epoch 7/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1259 - acc: 0.9220 - val_loss: 0.1341 - val_acc: 0.8898
Epoch 8/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1233 - acc: 0.9320 - val_loss: 0.1306 - val_acc: 0.8953
Epoch 9/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1236 - acc: 0.9301 - val_loss: 0.1311 - val_acc: 0.9091
Epoch 10/70

150/150 [==============================] - 3s 17ms/step - loss: 0.1210 - acc: 0.9411 - val_loss: 0.1302 - val_acc: 0.8981
Epoch 11/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1199 - acc: 0.9397 - val_loss: 0.1298 - val_acc: 0.9036
Epoch 12/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1182 - acc: 0.9452 - val_loss: 0.1303 - val_acc: 0.9063
Epoch 13/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1187 - acc: 0.9435 - val_loss: 0.1299 - val_acc: 0.9118
Epoch 14/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1168 - acc: 0.9537 - val_loss: 0.1294 - val_acc: 0.9008
Epoch 15/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1159 - acc: 0.9507 - val_loss: 0.1293 - val_acc: 0.9118
Epoch 16/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1150 - acc: 0.9558 - val_loss: 0.1288 - val_acc: 0.9146
Epoch 17/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1154 - acc: 0.9575 - val_loss: 0.1303 - val_acc: 0.9091
Epoch 18/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1143 - acc: 0.9596 - val_loss: 0.1283 - val_acc: 0.9146
Epoch 19/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1138 - acc: 0.9608 - val_loss: 0.1287 - val_acc: 0.9146
Epoch 20/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1139 - acc: 0.9626 - val_loss: 0.1300 - val_acc: 0.9091
Epoch 21/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1129 - acc: 0.9649 - val_loss: 0.1281 - val_acc: 0.9146
Epoch 22/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1116 - acc: 0.9674 - val_loss: 0.1283 - val_acc: 0.9063
Epoch 23/70

150/150 [==============================] - 2s 17ms/step - loss: 0.1110 - acc: 0.9691 - val_loss: 0.1283 - val_acc: 0.9118
Epoch 24/70

150/150 [==============================] - 2s 16ms/step - loss: 0.1112 - acc: 0.9668 - val_loss: 0.1290 - val_acc: 0.9063
Manual evaluation: (didn't understand why I made this)
True 7906
False 1165
True percentage 0.871568735531
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-ORG       0.61      0.43      0.50       296
      I-ORG       0.26      0.11      0.16       151
      B-PER       0.85      0.66      0.74       438
     B-MISC       0.37      0.30      0.33       141
     I-MISC       0.35      0.36      0.35       154
      B-LOC       0.64      0.76      0.69       218
      I-LOC       0.55      0.81      0.65       141
      I-PER       0.73      0.57      0.64       214

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.568022011617
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 62ms/step - loss: 0.2926 - acc: 0.4565 - val_loss: 0.2234 - val_acc: 0.6681
Epoch 2/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1542 - acc: 0.8336 - val_loss: 0.2213 - val_acc: 0.6765
Epoch 3/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1481 - acc: 0.8438 - val_loss: 0.1945 - val_acc: 0.7269
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1391 - acc: 0.8734 - val_loss: 0.1925 - val_acc: 0.7101
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1389 - acc: 0.8714 - val_loss: 0.1849 - val_acc: 0.7479
Epoch 6/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1349 - acc: 0.8823 - val_loss: 0.1995 - val_acc: 0.7059
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1323 - acc: 0.8946 - val_loss: 0.1818 - val_acc: 0.7479
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1303 - acc: 0.8939 - val_loss: 0.1855 - val_acc: 0.7353
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1288 - acc: 0.9094 - val_loss: 0.1787 - val_acc: 0.7605
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1262 - acc: 0.9188 - val_loss: 0.1806 - val_acc: 0.7605
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1256 - acc: 0.9147 - val_loss: 0.1912 - val_acc: 0.7437
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1238 - acc: 0.9280 - val_loss: 0.1826 - val_acc: 0.7479
Manual evaluation: (didn't understand why I made this)
True 7542
False 1529
True percentage 0.831440855473
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-PER       0.61      0.61      0.61       438
      B-LOC       0.48      0.72      0.58       218
      B-ORG       0.46      0.32      0.38       296
      I-ORG       0.15      0.34      0.20       151
      I-PER       0.77      0.19      0.31       214
      I-LOC       0.28      0.38      0.32       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       1.00      0.01      0.01       154

avg / total       0.89      0.83      0.84      9071

F-1 Score:
0.401801801802
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 61ms/step - loss: 0.2806 - acc: 0.4365 - val_loss: 0.2008 - val_acc: 0.7800
Epoch 2/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1631 - acc: 0.8139 - val_loss: 0.1692 - val_acc: 0.7850
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1504 - acc: 0.8393 - val_loss: 0.1596 - val_acc: 0.7900
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1446 - acc: 0.8596 - val_loss: 0.1508 - val_acc: 0.8000
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1409 - acc: 0.8710 - val_loss: 0.1477 - val_acc: 0.8150
Epoch 6/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1380 - acc: 0.8753 - val_loss: 0.1517 - val_acc: 0.8050
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1344 - acc: 0.8861 - val_loss: 0.1405 - val_acc: 0.8650
Epoch 8/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1336 - acc: 0.8937 - val_loss: 0.1428 - val_acc: 0.8300
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1323 - acc: 0.9019 - val_loss: 0.1410 - val_acc: 0.8300
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1295 - acc: 0.9108 - val_loss: 0.1406 - val_acc: 0.8300
Manual evaluation: (didn't understand why I made this)
True 7474
False 1597
True percentage 0.82394443832
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.95      7318
      B-ORG       0.34      0.50      0.40       296
      B-LOC       1.00      0.19      0.32       218
      I-ORG       0.17      0.45      0.25       151
     B-MISC       0.10      0.01      0.01       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.69      0.43      0.53       438
      I-PER       0.62      0.33      0.43       214
      I-LOC       0.82      0.16      0.27       141

avg / total       0.87      0.82      0.83      9071

F-1 Score:
0.354132636393
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 2
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103664 unique words.
3660 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 278
OOV word occurences: 483
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634560     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,234
Trainable params: 7,143,234
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 61ms/step - loss: 0.2722 - acc: 0.4818 - val_loss: 0.1695 - val_acc: 0.7872
Epoch 2/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1551 - acc: 0.8356 - val_loss: 0.1487 - val_acc: 0.8457
Epoch 3/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1429 - acc: 0.8600 - val_loss: 0.1476 - val_acc: 0.8404
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1412 - acc: 0.8618 - val_loss: 0.1446 - val_acc: 0.8511
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1353 - acc: 0.8894 - val_loss: 0.1444 - val_acc: 0.8298
Epoch 6/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1313 - acc: 0.9000 - val_loss: 0.1441 - val_acc: 0.8457
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1290 - acc: 0.9012 - val_loss: 0.1415 - val_acc: 0.8830
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1275 - acc: 0.9123 - val_loss: 0.1423 - val_acc: 0.8564
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1267 - acc: 0.9093 - val_loss: 0.1387 - val_acc: 0.8617
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1230 - acc: 0.9335 - val_loss: 0.1369 - val_acc: 0.8830
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1217 - acc: 0.9339 - val_loss: 0.1374 - val_acc: 0.8564
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1196 - acc: 0.9426 - val_loss: 0.1391 - val_acc: 0.8830
Epoch 13/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1193 - acc: 0.9430 - val_loss: 0.1329 - val_acc: 0.9149
Epoch 14/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1193 - acc: 0.9371 - val_loss: 0.1346 - val_acc: 0.8936
Epoch 15/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1172 - acc: 0.9470 - val_loss: 0.1351 - val_acc: 0.8883
Epoch 16/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1182 - acc: 0.9414 - val_loss: 0.1336 - val_acc: 0.8936
Manual evaluation: (didn't understand why I made this)
True 7685
False 1386
True percentage 0.847205379782
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-PER       0.77      0.58      0.66       438
      B-ORG       0.41      0.42      0.42       296
      I-ORG       0.22      0.47      0.30       151
      I-PER       0.67      0.54      0.60       214
      B-LOC       0.73      0.53      0.62       218
      I-LOC       0.77      0.42      0.54       141
     B-MISC       0.17      0.06      0.09       141
     I-MISC       0.26      0.10      0.15       154

avg / total       0.89      0.85      0.86      9071

F-1 Score:
0.474470734745
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 3
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103670 unique words.
3666 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 274
OOV word occurences: 437
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,618
Trainable params: 7,143,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 63ms/step - loss: 0.2547 - acc: 0.5231 - val_loss: 0.1635 - val_acc: 0.8251
Epoch 2/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1519 - acc: 0.8396 - val_loss: 0.1545 - val_acc: 0.8289
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1453 - acc: 0.8586 - val_loss: 0.1554 - val_acc: 0.8251
Epoch 4/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1419 - acc: 0.8696 - val_loss: 0.1454 - val_acc: 0.8441
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1362 - acc: 0.8861 - val_loss: 0.1390 - val_acc: 0.8821
Epoch 6/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1325 - acc: 0.9034 - val_loss: 0.1410 - val_acc: 0.8403
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1323 - acc: 0.9011 - val_loss: 0.1364 - val_acc: 0.8631
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1279 - acc: 0.9117 - val_loss: 0.1360 - val_acc: 0.8935
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1265 - acc: 0.9262 - val_loss: 0.1351 - val_acc: 0.8897
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1266 - acc: 0.9249 - val_loss: 0.1330 - val_acc: 0.8821
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1244 - acc: 0.9259 - val_loss: 0.1361 - val_acc: 0.8745
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1231 - acc: 0.9328 - val_loss: 0.1337 - val_acc: 0.8897
Epoch 13/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1215 - acc: 0.9322 - val_loss: 0.1332 - val_acc: 0.8935
Manual evaluation: (didn't understand why I made this)
True 7773
False 1298
True percentage 0.85690662551
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.96      7318
     B-MISC       0.48      0.07      0.12       141
     I-MISC       0.50      0.06      0.10       154
      B-ORG       0.51      0.46      0.48       296
      I-ORG       0.25      0.08      0.12       151
      B-PER       0.77      0.58      0.66       438
      I-PER       0.54      0.56      0.55       214
      B-LOC       0.67      0.66      0.67       218
      I-LOC       0.41      0.79      0.54       141

avg / total       0.89      0.86      0.86      9071

F-1 Score:
0.505878614554
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 4
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103681 unique words.
3677 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 531
Padded until 63 tokens.
Padded until 24 chars.
Padded until 63 tokens.
Padded until 24 chars.
Padded until 63 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 63, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 63, 64)       6635648     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 63, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 63, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 63, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 63, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 63, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,144,322
Trainable params: 7,144,322
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 63ms/step - loss: 0.2911 - acc: 0.4431 - val_loss: 0.1672 - val_acc: 0.8101
Epoch 2/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1726 - acc: 0.7864 - val_loss: 0.1478 - val_acc: 0.8659
Epoch 3/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1571 - acc: 0.8142 - val_loss: 0.1392 - val_acc: 0.9050
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1494 - acc: 0.8418 - val_loss: 0.1349 - val_acc: 0.9106
Epoch 5/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1442 - acc: 0.8612 - val_loss: 0.1331 - val_acc: 0.9274
Epoch 6/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1401 - acc: 0.8719 - val_loss: 0.1308 - val_acc: 0.9330
Epoch 7/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1376 - acc: 0.8785 - val_loss: 0.1295 - val_acc: 0.9218
Epoch 8/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1342 - acc: 0.8922 - val_loss: 0.1274 - val_acc: 0.9330
Epoch 9/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1315 - acc: 0.9052 - val_loss: 0.1254 - val_acc: 0.9330
Epoch 10/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1297 - acc: 0.9084 - val_loss: 0.1257 - val_acc: 0.9385
Epoch 11/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1279 - acc: 0.9266 - val_loss: 0.1248 - val_acc: 0.9385
Epoch 12/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1275 - acc: 0.9205 - val_loss: 0.1247 - val_acc: 0.9441
Epoch 13/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1257 - acc: 0.9187 - val_loss: 0.1242 - val_acc: 0.9330
Epoch 14/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1246 - acc: 0.9256 - val_loss: 0.1254 - val_acc: 0.9274
Epoch 15/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1236 - acc: 0.9274 - val_loss: 0.1247 - val_acc: 0.9274
Epoch 16/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1239 - acc: 0.9280 - val_loss: 0.1233 - val_acc: 0.9330
Epoch 17/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1219 - acc: 0.9412 - val_loss: 0.1233 - val_acc: 0.9330
Epoch 18/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1215 - acc: 0.9317 - val_loss: 0.1238 - val_acc: 0.9330
Epoch 19/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1200 - acc: 0.9412 - val_loss: 0.1233 - val_acc: 0.9330
Epoch 20/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1198 - acc: 0.9424 - val_loss: 0.1237 - val_acc: 0.9274
Epoch 21/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1182 - acc: 0.9419 - val_loss: 0.1225 - val_acc: 0.9330
Epoch 22/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1178 - acc: 0.9475 - val_loss: 0.1241 - val_acc: 0.9274
Epoch 23/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1167 - acc: 0.9513 - val_loss: 0.1232 - val_acc: 0.9385
Epoch 24/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1165 - acc: 0.9505 - val_loss: 0.1237 - val_acc: 0.9330
Manual evaluation: (didn't understand why I made this)
True 7766
False 1305
True percentage 0.856134935509
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-ORG       0.49      0.46      0.47       296
      B-LOC       0.66      0.65      0.66       218
      B-PER       0.80      0.53      0.64       438
      I-PER       0.64      0.42      0.50       214
     B-MISC       0.31      0.14      0.20       141
      I-ORG       0.31      0.33      0.32       151
      I-LOC       0.62      0.73      0.67       141
     I-MISC       0.41      0.20      0.27       154

avg / total       0.90      0.86      0.87      9071

F-1 Score:
0.51115360102
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 5
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 463
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 61ms/step - loss: 0.2849 - acc: 0.4089 - val_loss: 0.1555 - val_acc: 0.8295
Epoch 2/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1651 - acc: 0.8032 - val_loss: 0.1434 - val_acc: 0.8523
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1555 - acc: 0.8214 - val_loss: 0.1356 - val_acc: 0.8920
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1472 - acc: 0.8607 - val_loss: 0.1328 - val_acc: 0.8807
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1433 - acc: 0.8637 - val_loss: 0.1305 - val_acc: 0.8977
Epoch 6/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1417 - acc: 0.8663 - val_loss: 0.1309 - val_acc: 0.8920
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1382 - acc: 0.8829 - val_loss: 0.1246 - val_acc: 0.9148
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1350 - acc: 0.8855 - val_loss: 0.1282 - val_acc: 0.8977
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1331 - acc: 0.8897 - val_loss: 0.1277 - val_acc: 0.8807
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1336 - acc: 0.8909 - val_loss: 0.1238 - val_acc: 0.9261
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1309 - acc: 0.8988 - val_loss: 0.1229 - val_acc: 0.9318
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1306 - acc: 0.9103 - val_loss: 0.1225 - val_acc: 0.9034
Epoch 13/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1291 - acc: 0.9079 - val_loss: 0.1235 - val_acc: 0.9091
Epoch 14/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1268 - acc: 0.9128 - val_loss: 0.1227 - val_acc: 0.9034
Epoch 15/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1262 - acc: 0.9079 - val_loss: 0.1208 - val_acc: 0.9205
Epoch 16/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1239 - acc: 0.9153 - val_loss: 0.1248 - val_acc: 0.8920
Epoch 17/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1239 - acc: 0.9169 - val_loss: 0.1205 - val_acc: 0.9205
Epoch 18/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1222 - acc: 0.9278 - val_loss: 0.1225 - val_acc: 0.9091
Epoch 19/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1216 - acc: 0.9330 - val_loss: 0.1210 - val_acc: 0.9261
Epoch 20/70

74/74 [==============================] - 1s 17ms/step - loss: 0.1212 - acc: 0.9300 - val_loss: 0.1202 - val_acc: 0.9261
Epoch 21/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1208 - acc: 0.9299 - val_loss: 0.1201 - val_acc: 0.9205
Epoch 22/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1197 - acc: 0.9315 - val_loss: 0.1189 - val_acc: 0.9261
Epoch 23/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1181 - acc: 0.9442 - val_loss: 0.1227 - val_acc: 0.9148
Epoch 24/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1186 - acc: 0.9444 - val_loss: 0.1220 - val_acc: 0.9034
Epoch 25/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1173 - acc: 0.9537 - val_loss: 0.1206 - val_acc: 0.9205
Manual evaluation: (didn't understand why I made this)
True 7774
False 1297
True percentage 0.857016866939
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.96      7318
      B-PER       0.79      0.64      0.71       438
      B-ORG       0.44      0.39      0.42       296
     I-MISC       0.29      0.29      0.29       154
      B-LOC       0.69      0.52      0.59       218
      I-LOC       0.53      0.64      0.58       141
      I-ORG       0.33      0.19      0.24       151
      I-PER       0.73      0.52      0.60       214
     B-MISC       0.70      0.11      0.20       141

avg / total       0.89      0.86      0.87      9071

F-1 Score:
0.512179487179
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 6
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103665 unique words.
3661 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 278
OOV word occurences: 547
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634624     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,298
Trainable params: 7,143,298
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 62ms/step - loss: 0.2935 - acc: 0.4484 - val_loss: 0.1730 - val_acc: 0.8305
Epoch 2/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1674 - acc: 0.7980 - val_loss: 0.1409 - val_acc: 0.8644
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1515 - acc: 0.8513 - val_loss: 0.1390 - val_acc: 0.8686
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1491 - acc: 0.8471 - val_loss: 0.1337 - val_acc: 0.8856
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1430 - acc: 0.8725 - val_loss: 0.1348 - val_acc: 0.8686
Epoch 6/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1373 - acc: 0.8841 - val_loss: 0.1324 - val_acc: 0.8941
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1343 - acc: 0.8877 - val_loss: 0.1297 - val_acc: 0.9068
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1331 - acc: 0.8989 - val_loss: 0.1305 - val_acc: 0.8941
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1319 - acc: 0.8996 - val_loss: 0.1285 - val_acc: 0.8983
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1308 - acc: 0.9109 - val_loss: 0.1276 - val_acc: 0.9068
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1284 - acc: 0.9112 - val_loss: 0.1271 - val_acc: 0.9025
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1277 - acc: 0.9122 - val_loss: 0.1263 - val_acc: 0.9110
Epoch 13/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1263 - acc: 0.9166 - val_loss: 0.1241 - val_acc: 0.9153
Epoch 14/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1245 - acc: 0.9205 - val_loss: 0.1254 - val_acc: 0.9068
Epoch 15/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1234 - acc: 0.9254 - val_loss: 0.1237 - val_acc: 0.9110
Epoch 16/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1218 - acc: 0.9259 - val_loss: 0.1238 - val_acc: 0.9068
Epoch 17/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1217 - acc: 0.9348 - val_loss: 0.1236 - val_acc: 0.9110
Epoch 18/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1221 - acc: 0.9283 - val_loss: 0.1225 - val_acc: 0.9237
Epoch 19/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1195 - acc: 0.9388 - val_loss: 0.1215 - val_acc: 0.9195
Epoch 20/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1182 - acc: 0.9499 - val_loss: 0.1219 - val_acc: 0.9322
Epoch 21/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1180 - acc: 0.9429 - val_loss: 0.1248 - val_acc: 0.9110
Epoch 22/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1172 - acc: 0.9453 - val_loss: 0.1224 - val_acc: 0.9068
Manual evaluation: (didn't understand why I made this)
True 7612
False 1459
True percentage 0.839157755485
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.93      0.96      7318
      B-PER       0.73      0.43      0.55       438
      B-LOC       0.55      0.65      0.59       218
      B-ORG       0.46      0.49      0.47       296
      I-PER       0.57      0.39      0.47       214
     B-MISC       0.43      0.20      0.27       141
     I-MISC       0.39      0.20      0.27       154
      I-LOC       0.77      0.55      0.64       141
      I-ORG       0.25      0.66      0.37       151

avg / total       0.90      0.84      0.86      9071

F-1 Score:
0.471670127559
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 7
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103678 unique words.
3674 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 274
OOV word occurences: 443
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6635456     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,144,130
Trainable params: 7,144,130
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 63ms/step - loss: 0.2676 - acc: 0.4930 - val_loss: 0.1631 - val_acc: 0.7883
Epoch 2/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1584 - acc: 0.8273 - val_loss: 0.1404 - val_acc: 0.9144
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1476 - acc: 0.8526 - val_loss: 0.1369 - val_acc: 0.8739
Epoch 4/70

74/74 [==============================] - 1s 20ms/step - loss: 0.1397 - acc: 0.8719 - val_loss: 0.1255 - val_acc: 0.9505
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1357 - acc: 0.8854 - val_loss: 0.1284 - val_acc: 0.9279
Epoch 6/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1345 - acc: 0.8826 - val_loss: 0.1372 - val_acc: 0.8514
Epoch 7/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1312 - acc: 0.9056 - val_loss: 0.1236 - val_acc: 0.9369
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1293 - acc: 0.8977 - val_loss: 0.1258 - val_acc: 0.9234
Epoch 9/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1282 - acc: 0.9104 - val_loss: 0.1226 - val_acc: 0.9369
Epoch 10/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1261 - acc: 0.9151 - val_loss: 0.1255 - val_acc: 0.9279
Epoch 11/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1235 - acc: 0.9275 - val_loss: 0.1283 - val_acc: 0.8919
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1230 - acc: 0.9254 - val_loss: 0.1261 - val_acc: 0.9099
Manual evaluation: (didn't understand why I made this)
True 7650
False 1421
True percentage 0.843346929776
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.96      7318
      B-ORG       0.42      0.45      0.43       296
      I-ORG       0.18      0.36      0.24       151
      B-PER       0.75      0.55      0.64       438
      B-LOC       0.62      0.63      0.63       218
      I-LOC       0.47      0.13      0.20       141
      I-PER       0.59      0.56      0.58       214
     B-MISC       0.50      0.01      0.01       141
     I-MISC       0.33      0.01      0.03       154

avg / total       0.88      0.84      0.85      9071

F-1 Score:
0.446687697161
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 8
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103686 unique words.
3682 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 274
OOV word occurences: 444
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6635968     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,144,642
Trainable params: 7,144,642
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 62ms/step - loss: 0.2659 - acc: 0.4588 - val_loss: 0.1714 - val_acc: 0.7935
Epoch 2/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1688 - acc: 0.8020 - val_loss: 0.1474 - val_acc: 0.8315
Epoch 3/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1489 - acc: 0.8414 - val_loss: 0.1434 - val_acc: 0.8587
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1429 - acc: 0.8579 - val_loss: 0.1366 - val_acc: 0.8967
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1383 - acc: 0.8718 - val_loss: 0.1376 - val_acc: 0.8804
Epoch 6/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1347 - acc: 0.8841 - val_loss: 0.1360 - val_acc: 0.8967
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1324 - acc: 0.8917 - val_loss: 0.1349 - val_acc: 0.8859
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1296 - acc: 0.9088 - val_loss: 0.1335 - val_acc: 0.9022
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1287 - acc: 0.9023 - val_loss: 0.1340 - val_acc: 0.9022
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1279 - acc: 0.9018 - val_loss: 0.1316 - val_acc: 0.9130
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1251 - acc: 0.9186 - val_loss: 0.1344 - val_acc: 0.8967
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1238 - acc: 0.9278 - val_loss: 0.1325 - val_acc: 0.9076
Epoch 13/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1239 - acc: 0.9213 - val_loss: 0.1301 - val_acc: 0.8967
Epoch 14/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1212 - acc: 0.9330 - val_loss: 0.1315 - val_acc: 0.9022
Epoch 15/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1220 - acc: 0.9349 - val_loss: 0.1297 - val_acc: 0.9185
Epoch 16/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1214 - acc: 0.9338 - val_loss: 0.1318 - val_acc: 0.8967
Epoch 17/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1191 - acc: 0.9432 - val_loss: 0.1307 - val_acc: 0.8859
Epoch 18/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1192 - acc: 0.9414 - val_loss: 0.1300 - val_acc: 0.9130
Manual evaluation: (didn't understand why I made this)
True 7836
False 1235
True percentage 0.86385183552
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.46      0.44      0.45       296
      I-ORG       0.32      0.25      0.28       151
     B-MISC       0.31      0.26      0.28       141
     I-MISC       0.40      0.41      0.40       154
      B-PER       0.81      0.70      0.75       438
      B-LOC       0.79      0.46      0.58       218
      I-LOC       0.59      0.67      0.63       141
      I-PER       0.74      0.52      0.61       214

avg / total       0.90      0.86      0.88      9071

F-1 Score:
0.54108956602
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 9
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103670 unique words.
3666 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 550
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,618
Trainable params: 7,143,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 61ms/step - loss: 0.2528 - acc: 0.4954 - val_loss: 0.1582 - val_acc: 0.8109
Epoch 2/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1570 - acc: 0.8340 - val_loss: 0.1481 - val_acc: 0.8607
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1431 - acc: 0.8637 - val_loss: 0.1465 - val_acc: 0.8308
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1357 - acc: 0.8925 - val_loss: 0.1486 - val_acc: 0.8458
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1340 - acc: 0.8960 - val_loss: 0.1443 - val_acc: 0.8358
Epoch 6/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1313 - acc: 0.9000 - val_loss: 0.1375 - val_acc: 0.8856
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1293 - acc: 0.9163 - val_loss: 0.1357 - val_acc: 0.9005
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1261 - acc: 0.9121 - val_loss: 0.1363 - val_acc: 0.8905
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1248 - acc: 0.9233 - val_loss: 0.1365 - val_acc: 0.8856
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1240 - acc: 0.9272 - val_loss: 0.1414 - val_acc: 0.8607
Manual evaluation: (didn't understand why I made this)
True 7350
False 1721
True percentage 0.810274501158
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.87      0.31      0.46       438
          O       0.98      0.93      0.95      7318
      B-ORG       0.28      0.49      0.36       296
     B-MISC       0.02      0.01      0.01       141
      B-LOC       0.72      0.31      0.44       218
      I-LOC       1.00      0.02      0.04       141
     I-MISC       0.24      0.06      0.09       154
      I-PER       0.85      0.31      0.45       214
      I-ORG       0.17      0.68      0.27       151

avg / total       0.90      0.81      0.83      9071

F-1 Score:
0.848873463145
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 10
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103683 unique words.
3679 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 277
OOV word occurences: 547
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6635776     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,144,450
Trainable params: 7,144,450
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 62ms/step - loss: 0.2770 - acc: 0.4789 - val_loss: 0.1803 - val_acc: 0.8169
Epoch 2/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1649 - acc: 0.8219 - val_loss: 0.1586 - val_acc: 0.7887
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1474 - acc: 0.8530 - val_loss: 0.1485 - val_acc: 0.8099
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1397 - acc: 0.8702 - val_loss: 0.1488 - val_acc: 0.8028
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1374 - acc: 0.8730 - val_loss: 0.1430 - val_acc: 0.8521
Epoch 6/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1334 - acc: 0.8936 - val_loss: 0.1455 - val_acc: 0.8169
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1314 - acc: 0.8994 - val_loss: 0.1402 - val_acc: 0.8732
Epoch 8/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1298 - acc: 0.9014 - val_loss: 0.1377 - val_acc: 0.8873
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1278 - acc: 0.9120 - val_loss: 0.1379 - val_acc: 0.8944
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1248 - acc: 0.9247 - val_loss: 0.1395 - val_acc: 0.8380
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1234 - acc: 0.9275 - val_loss: 0.1384 - val_acc: 0.8592
Manual evaluation: (didn't understand why I made this)
True 7487
False 1584
True percentage 0.825377576893
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.66      0.48      0.55       438
          O       0.97      0.95      0.96      7318
      B-LOC       0.77      0.40      0.53       218
      I-LOC       0.74      0.12      0.21       141
      I-PER       0.67      0.14      0.23       214
      B-ORG       0.33      0.44      0.38       296
      I-ORG       0.17      0.54      0.26       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.87      0.83      0.84      9071

F-1 Score:
0.864319220949
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 11
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103675 unique words.
3671 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 279
OOV word occurences: 492
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6635264     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,938
Trainable params: 7,143,938
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 61ms/step - loss: 0.2572 - acc: 0.4888 - val_loss: 0.1551 - val_acc: 0.8352
Epoch 2/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1569 - acc: 0.8282 - val_loss: 0.1352 - val_acc: 0.9091
Epoch 3/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1466 - acc: 0.8481 - val_loss: 0.1373 - val_acc: 0.8693
Epoch 4/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1411 - acc: 0.8650 - val_loss: 0.1280 - val_acc: 0.9205
Epoch 5/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1388 - acc: 0.8638 - val_loss: 0.1234 - val_acc: 0.9318
Epoch 6/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1366 - acc: 0.8742 - val_loss: 0.1286 - val_acc: 0.9318
Epoch 7/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1322 - acc: 0.9074 - val_loss: 0.1267 - val_acc: 0.9261
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1301 - acc: 0.9070 - val_loss: 0.1249 - val_acc: 0.9148
Manual evaluation: (didn't understand why I made this)
True 7394
False 1677
True percentage 0.815125124022
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-ORG       0.36      0.38      0.37       296
     B-MISC       0.17      0.23      0.20       141
     I-MISC       0.24      0.42      0.30       154
      B-PER       0.71      0.39      0.51       438
      B-LOC       0.64      0.37      0.47       218
      I-ORG       0.12      0.30      0.17       151
      I-PER       0.84      0.10      0.18       214
      I-LOC       0.59      0.13      0.22       141

avg / total       0.89      0.82      0.84      9071

F-1 Score:
0.329518072289
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 12
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103676 unique words.
3672 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 273
OOV word occurences: 424
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6635328     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,144,002
Trainable params: 7,144,002
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 65ms/step - loss: 0.2606 - acc: 0.4874 - val_loss: 0.2010 - val_acc: 0.6943
Epoch 2/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1570 - acc: 0.8418 - val_loss: 0.1749 - val_acc: 0.7516
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1461 - acc: 0.8557 - val_loss: 0.1777 - val_acc: 0.7261
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1404 - acc: 0.8762 - val_loss: 0.1679 - val_acc: 0.7580
Epoch 5/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1345 - acc: 0.9016 - val_loss: 0.1613 - val_acc: 0.7962
Epoch 6/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1332 - acc: 0.9019 - val_loss: 0.1614 - val_acc: 0.8089
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1320 - acc: 0.9097 - val_loss: 0.1562 - val_acc: 0.8280
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1280 - acc: 0.9163 - val_loss: 0.1571 - val_acc: 0.8089
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1267 - acc: 0.9165 - val_loss: 0.1540 - val_acc: 0.8344
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1258 - acc: 0.9200 - val_loss: 0.1542 - val_acc: 0.8280
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1223 - acc: 0.9327 - val_loss: 0.1537 - val_acc: 0.8471
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1225 - acc: 0.9343 - val_loss: 0.1561 - val_acc: 0.8344
Epoch 13/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1220 - acc: 0.9333 - val_loss: 0.1575 - val_acc: 0.7962
Epoch 14/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1210 - acc: 0.9382 - val_loss: 0.1537 - val_acc: 0.8471
Manual evaluation: (didn't understand why I made this)
True 7750
False 1321
True percentage 0.854371072649
Sklearn evaluation:
             precision    recall  f1-score   support

     B-MISC       1.00      0.02      0.04       141
     I-MISC       0.31      0.08      0.13       154
          O       0.98      0.95      0.96      7318
      B-PER       0.71      0.73      0.72       438
      I-PER       0.65      0.56      0.60       214
      B-ORG       0.39      0.51      0.44       296
      B-LOC       0.59      0.50      0.54       218
      I-ORG       0.24      0.31      0.27       151
      I-LOC       0.61      0.47      0.53       141

avg / total       0.90      0.85      0.87      9071

F-1 Score:
0.881643336747
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 13
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103690 unique words.
3686 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 274
OOV word occurences: 514
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6636224     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,144,898
Trainable params: 7,144,898
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 65ms/step - loss: 0.2683 - acc: 0.4866 - val_loss: 0.1672 - val_acc: 0.7926
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1597 - acc: 0.8275 - val_loss: 0.1525 - val_acc: 0.8351
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1528 - acc: 0.8259 - val_loss: 0.1505 - val_acc: 0.8351
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1457 - acc: 0.8608 - val_loss: 0.1473 - val_acc: 0.8511
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1420 - acc: 0.8638 - val_loss: 0.1453 - val_acc: 0.8404
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1405 - acc: 0.8692 - val_loss: 0.1471 - val_acc: 0.8617
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1339 - acc: 0.8962 - val_loss: 0.1410 - val_acc: 0.8777
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1349 - acc: 0.8871 - val_loss: 0.1378 - val_acc: 0.8936
Epoch 9/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1335 - acc: 0.8898 - val_loss: 0.1376 - val_acc: 0.8883
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1301 - acc: 0.9085 - val_loss: 0.1383 - val_acc: 0.8670
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1284 - acc: 0.9158 - val_loss: 0.1376 - val_acc: 0.8883
Epoch 12/70

74/74 [==============================] - 2s 20ms/step - loss: 0.1263 - acc: 0.9172 - val_loss: 0.1371 - val_acc: 0.8883
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1256 - acc: 0.9267 - val_loss: 0.1346 - val_acc: 0.8989
Epoch 14/70

74/74 [==============================] - 2s 20ms/step - loss: 0.1255 - acc: 0.9154 - val_loss: 0.1317 - val_acc: 0.9043
Epoch 15/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1238 - acc: 0.9227 - val_loss: 0.1383 - val_acc: 0.8830
Epoch 16/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1222 - acc: 0.9299 - val_loss: 0.1338 - val_acc: 0.8936
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1208 - acc: 0.9355 - val_loss: 0.1318 - val_acc: 0.9096
Manual evaluation: (didn't understand why I made this)
True 7742
False 1329
True percentage 0.853489141219
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-PER       0.73      0.55      0.63       438
      B-ORG       0.50      0.52      0.51       296
     B-MISC       0.36      0.21      0.27       141
     I-MISC       0.27      0.31      0.29       154
      I-ORG       0.33      0.28      0.31       151
      B-LOC       0.72      0.58      0.64       218
      I-LOC       0.62      0.71      0.66       141
      I-PER       0.72      0.43      0.53       214

avg / total       0.90      0.85      0.87      9071

F-1 Score:
0.515572001233
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 14
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103668 unique words.
3664 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 279
OOV word occurences: 475
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634816     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,490
Trainable params: 7,143,490
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 5s 62ms/step - loss: 0.2423 - acc: 0.5627 - val_loss: 0.1548 - val_acc: 0.8387
Epoch 2/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1516 - acc: 0.8462 - val_loss: 0.1442 - val_acc: 0.8656
Epoch 3/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1399 - acc: 0.8730 - val_loss: 0.1444 - val_acc: 0.8441
Epoch 4/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1370 - acc: 0.8817 - val_loss: 0.1407 - val_acc: 0.8656
Epoch 5/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1363 - acc: 0.8916 - val_loss: 0.1415 - val_acc: 0.8710
Epoch 6/70

74/74 [==============================] - 1s 19ms/step - loss: 0.1301 - acc: 0.9060 - val_loss: 0.1352 - val_acc: 0.8656
Epoch 7/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1310 - acc: 0.9106 - val_loss: 0.1301 - val_acc: 0.8978
Epoch 8/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1249 - acc: 0.9351 - val_loss: 0.1348 - val_acc: 0.8871
Epoch 9/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1230 - acc: 0.9327 - val_loss: 0.1323 - val_acc: 0.8871
Epoch 10/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1225 - acc: 0.9310 - val_loss: 0.1286 - val_acc: 0.8978
Epoch 11/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1208 - acc: 0.9412 - val_loss: 0.1286 - val_acc: 0.9032
Epoch 12/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1181 - acc: 0.9517 - val_loss: 0.1255 - val_acc: 0.9086
Epoch 13/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1192 - acc: 0.9425 - val_loss: 0.1289 - val_acc: 0.8978
Epoch 14/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1184 - acc: 0.9471 - val_loss: 0.1259 - val_acc: 0.9032
Epoch 15/70

74/74 [==============================] - 1s 18ms/step - loss: 0.1162 - acc: 0.9524 - val_loss: 0.1344 - val_acc: 0.8763
Manual evaluation: (didn't understand why I made this)
True 7460
False 1611
True percentage 0.822401058318
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-ORG       0.30      0.58      0.39       296
      I-ORG       0.16      0.53      0.24       151
      B-PER       0.82      0.45      0.58       438
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.40      0.08      0.13       154
      B-LOC       0.77      0.22      0.34       218
      I-LOC       0.00      0.00      0.00       141
      I-PER       0.55      0.33      0.42       214

avg / total       0.88      0.82      0.84      9071

F-1 Score:
0.351728320194
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 128ms/step - loss: 0.3614 - acc: 0.0551 - val_loss: 0.2322 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.2249 - acc: 0.7940 - val_loss: 0.2224 - val_acc: 0.7010
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.2348 - acc: 0.6465 - val_loss: 0.1823 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1827 - acc: 0.7975 - val_loss: 0.1544 - val_acc: 0.8351
Epoch 5/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1540 - acc: 0.8295 - val_loss: 0.1492 - val_acc: 0.8660
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1473 - acc: 0.8650 - val_loss: 0.1462 - val_acc: 0.8660
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1430 - acc: 0.8703 - val_loss: 0.1440 - val_acc: 0.8660
Epoch 8/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1397 - acc: 0.8792 - val_loss: 0.1428 - val_acc: 0.8557
Epoch 9/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1391 - acc: 0.8792 - val_loss: 0.1407 - val_acc: 0.8866
Epoch 10/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1358 - acc: 0.9059 - val_loss: 0.1399 - val_acc: 0.8969
Epoch 11/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1318 - acc: 0.9005 - val_loss: 0.1391 - val_acc: 0.8969
Epoch 12/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1304 - acc: 0.9165 - val_loss: 0.1382 - val_acc: 0.8969
Epoch 13/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1299 - acc: 0.9130 - val_loss: 0.1375 - val_acc: 0.8969
Epoch 14/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1267 - acc: 0.9307 - val_loss: 0.1372 - val_acc: 0.8763
Epoch 15/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1268 - acc: 0.9307 - val_loss: 0.1367 - val_acc: 0.8763
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1240 - acc: 0.9467 - val_loss: 0.1365 - val_acc: 0.8866
Epoch 17/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1244 - acc: 0.9325 - val_loss: 0.1359 - val_acc: 0.8866
Epoch 18/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1235 - acc: 0.9325 - val_loss: 0.1357 - val_acc: 0.8763
Epoch 19/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1209 - acc: 0.9520 - val_loss: 0.1362 - val_acc: 0.8763
Epoch 20/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1208 - acc: 0.9485 - val_loss: 0.1358 - val_acc: 0.8660
Epoch 21/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1197 - acc: 0.9556 - val_loss: 0.1347 - val_acc: 0.8763
Epoch 22/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1176 - acc: 0.9485 - val_loss: 0.1342 - val_acc: 0.8660
Epoch 23/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1167 - acc: 0.9503 - val_loss: 0.1344 - val_acc: 0.8660
Epoch 24/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1163 - acc: 0.9609 - val_loss: 0.1345 - val_acc: 0.8660
Epoch 25/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1165 - acc: 0.9591 - val_loss: 0.1342 - val_acc: 0.8660
Epoch 26/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1150 - acc: 0.9645 - val_loss: 0.1340 - val_acc: 0.8660
Epoch 27/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1154 - acc: 0.9680 - val_loss: 0.1336 - val_acc: 0.8763
Epoch 28/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1148 - acc: 0.9645 - val_loss: 0.1345 - val_acc: 0.8660
Epoch 29/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1122 - acc: 0.9787 - val_loss: 0.1344 - val_acc: 0.8660
Epoch 30/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1114 - acc: 0.9805 - val_loss: 0.1344 - val_acc: 0.8660
Manual evaluation: (didn't understand why I made this)
True 7309
False 1762
True percentage 0.80575460258
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.95      7318
      B-PER       0.51      0.47      0.49       438
      B-LOC       0.47      0.58      0.52       218
      B-ORG       0.27      0.34      0.30       296
      I-ORG       0.16      0.39      0.22       151
      I-PER       0.63      0.06      0.10       214
      I-LOC       0.21      0.18      0.19       141
     B-MISC       0.12      0.01      0.01       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.86      0.81      0.82      9071

F-1 Score:
0.319831983198
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 126ms/step - loss: 0.3227 - acc: 0.1797 - val_loss: 0.1557 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1886 - acc: 0.8122 - val_loss: 0.1478 - val_acc: 0.8916
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1683 - acc: 0.8189 - val_loss: 0.1402 - val_acc: 0.8554
Epoch 4/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1550 - acc: 0.8324 - val_loss: 0.1358 - val_acc: 0.9277
Epoch 5/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1473 - acc: 0.8784 - val_loss: 0.1313 - val_acc: 0.9277
Epoch 6/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1419 - acc: 0.8730 - val_loss: 0.1294 - val_acc: 0.9398
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1382 - acc: 0.8824 - val_loss: 0.1287 - val_acc: 0.9157
Epoch 8/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1359 - acc: 0.8932 - val_loss: 0.1276 - val_acc: 0.9398
Epoch 9/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1322 - acc: 0.9068 - val_loss: 0.1269 - val_acc: 0.9398
Epoch 10/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1302 - acc: 0.9081 - val_loss: 0.1267 - val_acc: 0.9277
Epoch 11/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1290 - acc: 0.9176 - val_loss: 0.1263 - val_acc: 0.9277
Epoch 12/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1260 - acc: 0.9257 - val_loss: 0.1261 - val_acc: 0.9398
Epoch 13/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1250 - acc: 0.9311 - val_loss: 0.1259 - val_acc: 0.9277
Epoch 14/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1236 - acc: 0.9365 - val_loss: 0.1255 - val_acc: 0.9398
Epoch 15/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1240 - acc: 0.9216 - val_loss: 0.1256 - val_acc: 0.9277
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1230 - acc: 0.9338 - val_loss: 0.1253 - val_acc: 0.9398
Epoch 17/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1215 - acc: 0.9351 - val_loss: 0.1251 - val_acc: 0.9398
Epoch 18/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1202 - acc: 0.9432 - val_loss: 0.1255 - val_acc: 0.9398
Epoch 19/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1180 - acc: 0.9514 - val_loss: 0.1259 - val_acc: 0.9398
Epoch 20/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1197 - acc: 0.9500 - val_loss: 0.1260 - val_acc: 0.9398
Manual evaluation: (didn't understand why I made this)
True 7385
False 1686
True percentage 0.814132951163
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.95      7318
      B-ORG       0.30      0.40      0.34       296
      B-LOC       0.78      0.13      0.23       218
      I-ORG       0.17      0.56      0.26       151
     B-MISC       0.11      0.02      0.04       141
     I-MISC       0.33      0.06      0.11       154
      B-PER       0.61      0.44      0.51       438
      I-PER       0.71      0.31      0.44       214
      I-LOC       1.00      0.01      0.03       141

avg / total       0.88      0.81      0.83      9071

F-1 Score:
0.320076360165
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 2
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103627 unique words.
3623 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 488
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632192     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,866
Trainable params: 7,140,866
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 130ms/step - loss: 0.3390 - acc: 0.0529 - val_loss: 0.1986 - val_acc: 0.8000
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1768 - acc: 0.8398 - val_loss: 0.2239 - val_acc: 0.6909
Epoch 3/70

29/29 [==============================] - 1s 17ms/step - loss: 0.2033 - acc: 0.6750 - val_loss: 0.2026 - val_acc: 0.8000
Epoch 4/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1775 - acc: 0.8445 - val_loss: 0.1737 - val_acc: 0.7636
Epoch 5/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1507 - acc: 0.8569 - val_loss: 0.1646 - val_acc: 0.7818
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1420 - acc: 0.8538 - val_loss: 0.1614 - val_acc: 0.8000
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1370 - acc: 0.8802 - val_loss: 0.1601 - val_acc: 0.8000
Epoch 8/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1334 - acc: 0.8927 - val_loss: 0.1589 - val_acc: 0.8000
Epoch 9/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1316 - acc: 0.9098 - val_loss: 0.1578 - val_acc: 0.8000
Epoch 10/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1299 - acc: 0.8958 - val_loss: 0.1577 - val_acc: 0.8000
Epoch 11/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1287 - acc: 0.9082 - val_loss: 0.1571 - val_acc: 0.7818
Epoch 12/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1247 - acc: 0.9238 - val_loss: 0.1566 - val_acc: 0.7818
Epoch 13/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1242 - acc: 0.9331 - val_loss: 0.1545 - val_acc: 0.8000
Epoch 14/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1245 - acc: 0.9207 - val_loss: 0.1557 - val_acc: 0.7636
Epoch 15/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1220 - acc: 0.9409 - val_loss: 0.1547 - val_acc: 0.8000
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1230 - acc: 0.9253 - val_loss: 0.1564 - val_acc: 0.7455
Manual evaluation: (didn't understand why I made this)
True 7493
False 1578
True percentage 0.826039025466
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.95      0.95      7318
      B-PER       0.55      0.48      0.52       438
      B-ORG       0.29      0.28      0.29       296
      I-ORG       0.18      0.11      0.14       151
      I-PER       0.61      0.21      0.32       214
      B-LOC       0.53      0.50      0.52       218
      I-LOC       0.39      0.72      0.50       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.83      0.83      9071

F-1 Score:
0.372260385999
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 3
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103621 unique words.
3617 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 279
OOV word occurences: 474
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631808     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,482
Trainable params: 7,140,482
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 145ms/step - loss: 0.3338 - acc: 0.1517 - val_loss: 0.2074 - val_acc: 0.8148
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.2223 - acc: 0.7899 - val_loss: 0.2595 - val_acc: 0.4815
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.2830 - acc: 0.4392 - val_loss: 0.1654 - val_acc: 0.8148
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1789 - acc: 0.7899 - val_loss: 0.1512 - val_acc: 0.8148
Epoch 5/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1608 - acc: 0.8199 - val_loss: 0.1489 - val_acc: 0.8395
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1557 - acc: 0.8136 - val_loss: 0.1466 - val_acc: 0.8395
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1505 - acc: 0.8389 - val_loss: 0.1451 - val_acc: 0.8519
Epoch 8/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1483 - acc: 0.8547 - val_loss: 0.1439 - val_acc: 0.8395
Epoch 9/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1446 - acc: 0.8531 - val_loss: 0.1422 - val_acc: 0.8519
Epoch 10/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1445 - acc: 0.8689 - val_loss: 0.1406 - val_acc: 0.8642
Epoch 11/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1405 - acc: 0.8689 - val_loss: 0.1398 - val_acc: 0.8642
Epoch 12/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1371 - acc: 0.8910 - val_loss: 0.1391 - val_acc: 0.8765
Epoch 13/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1371 - acc: 0.9068 - val_loss: 0.1384 - val_acc: 0.8642
Epoch 14/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1364 - acc: 0.8863 - val_loss: 0.1376 - val_acc: 0.8765
Epoch 15/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1327 - acc: 0.9131 - val_loss: 0.1360 - val_acc: 0.8765
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1321 - acc: 0.9036 - val_loss: 0.1350 - val_acc: 0.8889
Epoch 17/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1294 - acc: 0.9194 - val_loss: 0.1350 - val_acc: 0.8889
Epoch 18/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1279 - acc: 0.9210 - val_loss: 0.1346 - val_acc: 0.8889
Epoch 19/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1266 - acc: 0.9321 - val_loss: 0.1340 - val_acc: 0.8889
Epoch 20/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1265 - acc: 0.9258 - val_loss: 0.1323 - val_acc: 0.8889
Epoch 21/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1232 - acc: 0.9431 - val_loss: 0.1337 - val_acc: 0.8889
Epoch 22/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1251 - acc: 0.9321 - val_loss: 0.1325 - val_acc: 0.8889
Epoch 23/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1264 - acc: 0.9289 - val_loss: 0.1330 - val_acc: 0.8889
Manual evaluation: (didn't understand why I made this)
True 7522
False 1549
True percentage 0.829236026899
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
     B-MISC       0.11      0.01      0.03       141
     I-MISC       0.21      0.03      0.05       154
      B-ORG       0.29      0.44      0.35       296
      I-ORG       0.22      0.31      0.26       151
      B-PER       0.80      0.39      0.53       438
      I-PER       0.52      0.50      0.51       214
      B-LOC       0.46      0.45      0.46       218
      I-LOC       0.43      0.74      0.54       141

avg / total       0.87      0.83      0.85      9071

F-1 Score:
0.400481058328
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 4
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103612 unique words.
3608 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 280
OOV word occurences: 551
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631232     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,906
Trainable params: 7,139,906
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 5s 160ms/step - loss: 0.3941 - acc: 0.0256 - val_loss: 0.1884 - val_acc: 0.8171
Epoch 2/70

29/29 [==============================] - 1s 20ms/step - loss: 0.2036 - acc: 0.7674 - val_loss: 0.1823 - val_acc: 0.7805
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1857 - acc: 0.7582 - val_loss: 0.1564 - val_acc: 0.8171
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1614 - acc: 0.7894 - val_loss: 0.1575 - val_acc: 0.8537
Epoch 5/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1558 - acc: 0.8297 - val_loss: 0.1522 - val_acc: 0.8293
Epoch 6/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1463 - acc: 0.8443 - val_loss: 0.1512 - val_acc: 0.8537
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1426 - acc: 0.8736 - val_loss: 0.1498 - val_acc: 0.8537
Epoch 8/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1389 - acc: 0.8755 - val_loss: 0.1496 - val_acc: 0.8659
Epoch 9/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1342 - acc: 0.8956 - val_loss: 0.1497 - val_acc: 0.8415
Epoch 10/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1333 - acc: 0.8993 - val_loss: 0.1486 - val_acc: 0.8537
Epoch 11/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1299 - acc: 0.9066 - val_loss: 0.1485 - val_acc: 0.8537
Epoch 12/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1294 - acc: 0.9286 - val_loss: 0.1482 - val_acc: 0.8659
Epoch 13/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1263 - acc: 0.9304 - val_loss: 0.1490 - val_acc: 0.8537
Epoch 14/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1246 - acc: 0.9341 - val_loss: 0.1489 - val_acc: 0.8659
Epoch 15/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1239 - acc: 0.9377 - val_loss: 0.1501 - val_acc: 0.8537
Manual evaluation: (didn't understand why I made this)
True 7420
False 1651
True percentage 0.817991401169
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-ORG       0.30      0.35      0.32       296
      B-LOC       0.46      0.66      0.54       218
      B-PER       0.58      0.37      0.45       438
      I-PER       0.63      0.19      0.29       214
     B-MISC       0.09      0.01      0.01       141
      I-ORG       0.29      0.19      0.23       151
      I-LOC       0.29      0.84      0.44       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.86      0.82      0.83      9071

F-1 Score:
0.364860728497
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 5
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103616 unique words.
3612 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631488     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,162
Trainable params: 7,140,162
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 130ms/step - loss: 0.3253 - acc: 0.1134 - val_loss: 0.1649 - val_acc: 0.8687
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1907 - acc: 0.7955 - val_loss: 0.1540 - val_acc: 0.8384
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1667 - acc: 0.8383 - val_loss: 0.1374 - val_acc: 0.8788
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1509 - acc: 0.8401 - val_loss: 0.1395 - val_acc: 0.8485
Epoch 5/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1478 - acc: 0.8532 - val_loss: 0.1342 - val_acc: 0.8889
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1433 - acc: 0.8550 - val_loss: 0.1364 - val_acc: 0.8788
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1393 - acc: 0.8866 - val_loss: 0.1332 - val_acc: 0.8687
Epoch 8/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1358 - acc: 0.8810 - val_loss: 0.1337 - val_acc: 0.8586
Epoch 9/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1332 - acc: 0.8866 - val_loss: 0.1340 - val_acc: 0.8788
Epoch 10/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1302 - acc: 0.9182 - val_loss: 0.1331 - val_acc: 0.8788
Epoch 11/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1295 - acc: 0.9164 - val_loss: 0.1350 - val_acc: 0.8687
Epoch 12/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1283 - acc: 0.9219 - val_loss: 0.1304 - val_acc: 0.8788
Epoch 13/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1264 - acc: 0.9294 - val_loss: 0.1334 - val_acc: 0.8687
Epoch 14/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1241 - acc: 0.9442 - val_loss: 0.1334 - val_acc: 0.8788
Epoch 15/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1248 - acc: 0.9405 - val_loss: 0.1323 - val_acc: 0.8687
Manual evaluation: (didn't understand why I made this)
True 7352
False 1719
True percentage 0.810494984015
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.69      0.33      0.44       438
      B-ORG       0.31      0.43      0.36       296
     I-MISC       0.13      0.03      0.04       154
      B-LOC       0.56      0.55      0.55       218
      I-LOC       0.40      0.41      0.40       141
      I-ORG       0.16      0.46      0.24       151
      I-PER       0.86      0.08      0.15       214
     B-MISC       0.22      0.01      0.03       141

avg / total       0.87      0.81      0.83      9071

F-1 Score:
0.335499845249
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 6
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103625 unique words.
3621 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 280
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632064     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,738
Trainable params: 7,140,738
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 128ms/step - loss: 0.3330 - acc: 0.1852 - val_loss: 0.2074 - val_acc: 0.7879
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.2070 - acc: 0.7881 - val_loss: 0.1801 - val_acc: 0.7879
Epoch 3/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1751 - acc: 0.8163 - val_loss: 0.1657 - val_acc: 0.7778
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1576 - acc: 0.8069 - val_loss: 0.1625 - val_acc: 0.7980
Epoch 5/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1489 - acc: 0.8446 - val_loss: 0.1587 - val_acc: 0.7879
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1447 - acc: 0.8587 - val_loss: 0.1587 - val_acc: 0.7879
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1403 - acc: 0.8681 - val_loss: 0.1574 - val_acc: 0.7879
Epoch 8/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1368 - acc: 0.8854 - val_loss: 0.1584 - val_acc: 0.7879
Epoch 9/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1363 - acc: 0.8885 - val_loss: 0.1572 - val_acc: 0.7778
Epoch 10/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1319 - acc: 0.8948 - val_loss: 0.1571 - val_acc: 0.7879
Epoch 11/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1299 - acc: 0.9137 - val_loss: 0.1562 - val_acc: 0.7879
Epoch 12/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1268 - acc: 0.9199 - val_loss: 0.1578 - val_acc: 0.7980
Epoch 13/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1268 - acc: 0.9246 - val_loss: 0.1573 - val_acc: 0.7879
Epoch 14/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1256 - acc: 0.9105 - val_loss: 0.1550 - val_acc: 0.7980
Epoch 15/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1236 - acc: 0.9231 - val_loss: 0.1567 - val_acc: 0.7980
Epoch 16/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1237 - acc: 0.9199 - val_loss: 0.1553 - val_acc: 0.7980
Epoch 17/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1241 - acc: 0.9278 - val_loss: 0.1580 - val_acc: 0.7980
Manual evaluation: (didn't understand why I made this)
True 7241
False 1830
True percentage 0.798258185426
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.92      0.95      7318
      B-PER       0.60      0.11      0.19       438
      B-LOC       0.58      0.53      0.56       218
      B-ORG       0.29      0.47      0.36       296
      I-PER       0.23      0.08      0.12       214
     B-MISC       0.19      0.07      0.10       141
     I-MISC       0.30      0.13      0.18       154
      I-LOC       0.67      0.13      0.21       141
      I-ORG       0.16      0.68      0.26       151

avg / total       0.87      0.80      0.82      9071

F-1 Score:
0.280805687204
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 7
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 279
OOV word occurences: 462
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 129ms/step - loss: 0.3814 - acc: 0.0223 - val_loss: 0.1571 - val_acc: 0.8710
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.2055 - acc: 0.7815 - val_loss: 0.1781 - val_acc: 0.8065
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.2141 - acc: 0.6746 - val_loss: 0.1428 - val_acc: 0.8710
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1772 - acc: 0.7815 - val_loss: 0.1330 - val_acc: 0.9194
Epoch 5/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1622 - acc: 0.8230 - val_loss: 0.1298 - val_acc: 0.8871
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1538 - acc: 0.8246 - val_loss: 0.1260 - val_acc: 0.9194
Epoch 7/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1482 - acc: 0.8660 - val_loss: 0.1250 - val_acc: 0.9194
Epoch 8/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1465 - acc: 0.8565 - val_loss: 0.1233 - val_acc: 0.9194
Epoch 9/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1448 - acc: 0.8596 - val_loss: 0.1234 - val_acc: 0.9032
Epoch 10/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1395 - acc: 0.8708 - val_loss: 0.1215 - val_acc: 0.9194
Epoch 11/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1352 - acc: 0.8963 - val_loss: 0.1197 - val_acc: 0.9194
Epoch 12/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1350 - acc: 0.8915 - val_loss: 0.1207 - val_acc: 0.9032
Epoch 13/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1339 - acc: 0.8979 - val_loss: 0.1187 - val_acc: 0.9194
Epoch 14/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1321 - acc: 0.9059 - val_loss: 0.1200 - val_acc: 0.9032
Epoch 15/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1313 - acc: 0.8995 - val_loss: 0.1168 - val_acc: 0.9516
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1285 - acc: 0.9394 - val_loss: 0.1184 - val_acc: 0.9194
Epoch 17/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1279 - acc: 0.9203 - val_loss: 0.1170 - val_acc: 0.9355
Epoch 18/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1261 - acc: 0.9394 - val_loss: 0.1173 - val_acc: 0.9355
Manual evaluation: (didn't understand why I made this)
True 7432
False 1639
True percentage 0.819314298313
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.95      0.95      7318
      B-ORG       0.32      0.39      0.35       296
      I-ORG       0.17      0.44      0.25       151
      B-PER       0.68      0.36      0.47       438
      B-LOC       0.52      0.38      0.44       218
      I-LOC       0.62      0.04      0.07       141
      I-PER       0.65      0.22      0.33       214
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.24      0.05      0.08       154

avg / total       0.85      0.82      0.82      9071

F-1 Score:
0.320346320346
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 8
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103637 unique words.
3633 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 278
OOV word occurences: 454
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632832     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,141,506
Trainable params: 7,141,506
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 130ms/step - loss: 0.3173 - acc: 0.1532 - val_loss: 0.2938 - val_acc: 0.7143
Epoch 2/70

29/29 [==============================] - 1s 18ms/step - loss: 0.2184 - acc: 0.8071 - val_loss: 0.2177 - val_acc: 0.6250
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1804 - acc: 0.7858 - val_loss: 0.2099 - val_acc: 0.7143
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1661 - acc: 0.8071 - val_loss: 0.1872 - val_acc: 0.7143
Epoch 5/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1500 - acc: 0.8511 - val_loss: 0.1832 - val_acc: 0.7321
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1434 - acc: 0.8596 - val_loss: 0.1824 - val_acc: 0.7054
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1388 - acc: 0.8894 - val_loss: 0.1808 - val_acc: 0.7054
Epoch 8/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1349 - acc: 0.9021 - val_loss: 0.1791 - val_acc: 0.7054
Epoch 9/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1347 - acc: 0.8979 - val_loss: 0.1765 - val_acc: 0.7500
Epoch 10/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1336 - acc: 0.9050 - val_loss: 0.1770 - val_acc: 0.6964
Epoch 11/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1310 - acc: 0.9050 - val_loss: 0.1758 - val_acc: 0.7321
Epoch 12/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1288 - acc: 0.9035 - val_loss: 0.1772 - val_acc: 0.6964
Epoch 13/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1284 - acc: 0.9191 - val_loss: 0.1756 - val_acc: 0.7232
Epoch 14/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1242 - acc: 0.9191 - val_loss: 0.1764 - val_acc: 0.6875
Epoch 15/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1246 - acc: 0.9234 - val_loss: 0.1752 - val_acc: 0.6964
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1247 - acc: 0.9206 - val_loss: 0.1720 - val_acc: 0.6964
Epoch 17/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1216 - acc: 0.9447 - val_loss: 0.1749 - val_acc: 0.6875
Epoch 18/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1213 - acc: 0.9333 - val_loss: 0.1726 - val_acc: 0.7054
Epoch 19/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1222 - acc: 0.9376 - val_loss: 0.1785 - val_acc: 0.6786
Manual evaluation: (didn't understand why I made this)
True 7457
False 1614
True percentage 0.822070334032
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.96      7318
      B-ORG       0.28      0.35      0.31       296
      I-ORG       0.23      0.31      0.27       151
     B-MISC       0.28      0.28      0.28       141
     I-MISC       0.29      0.29      0.29       154
      B-PER       0.49      0.41      0.45       438
      B-LOC       0.58      0.51      0.55       218
      I-LOC       0.44      0.69      0.54       141
      I-PER       0.55      0.12      0.20       214

avg / total       0.87      0.82      0.84      9071

F-1 Score:
0.377622377622
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 9
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103624 unique words.
3620 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 278
OOV word occurences: 552
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632000     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,674
Trainable params: 7,140,674
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 128ms/step - loss: 0.3579 - acc: 0.1144 - val_loss: 0.2136 - val_acc: 0.8276
Epoch 2/70

29/29 [==============================] - 1s 18ms/step - loss: 0.2136 - acc: 0.8182 - val_loss: 0.1772 - val_acc: 0.8276
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1758 - acc: 0.8166 - val_loss: 0.1591 - val_acc: 0.8276
Epoch 4/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1563 - acc: 0.8229 - val_loss: 0.1522 - val_acc: 0.8276
Epoch 5/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1457 - acc: 0.8668 - val_loss: 0.1476 - val_acc: 0.8621
Epoch 6/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1415 - acc: 0.8574 - val_loss: 0.1468 - val_acc: 0.8506
Epoch 7/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1379 - acc: 0.8871 - val_loss: 0.1444 - val_acc: 0.8736
Epoch 8/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1344 - acc: 0.8887 - val_loss: 0.1439 - val_acc: 0.8851
Epoch 9/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1310 - acc: 0.9232 - val_loss: 0.1429 - val_acc: 0.8966
Epoch 10/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1309 - acc: 0.9107 - val_loss: 0.1418 - val_acc: 0.8621
Epoch 11/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1282 - acc: 0.9216 - val_loss: 0.1419 - val_acc: 0.8851
Epoch 12/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1253 - acc: 0.9201 - val_loss: 0.1408 - val_acc: 0.8966
Epoch 13/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1248 - acc: 0.9389 - val_loss: 0.1410 - val_acc: 0.8851
Epoch 14/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1235 - acc: 0.9373 - val_loss: 0.1408 - val_acc: 0.8966
Epoch 15/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1218 - acc: 0.9373 - val_loss: 0.1399 - val_acc: 0.8851
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1206 - acc: 0.9404 - val_loss: 0.1404 - val_acc: 0.9080
Epoch 17/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1196 - acc: 0.9483 - val_loss: 0.1397 - val_acc: 0.8851
Epoch 18/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1172 - acc: 0.9624 - val_loss: 0.1397 - val_acc: 0.8966
Epoch 19/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1174 - acc: 0.9624 - val_loss: 0.1392 - val_acc: 0.8966
Epoch 20/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1170 - acc: 0.9451 - val_loss: 0.1398 - val_acc: 0.9080
Epoch 21/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1169 - acc: 0.9530 - val_loss: 0.1388 - val_acc: 0.9080
Epoch 22/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1152 - acc: 0.9608 - val_loss: 0.1384 - val_acc: 0.9080
Epoch 23/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1148 - acc: 0.9608 - val_loss: 0.1392 - val_acc: 0.9080
Epoch 24/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1151 - acc: 0.9592 - val_loss: 0.1377 - val_acc: 0.9195
Epoch 25/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1130 - acc: 0.9702 - val_loss: 0.1381 - val_acc: 0.9195
Epoch 26/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1122 - acc: 0.9718 - val_loss: 0.1389 - val_acc: 0.9080
Epoch 27/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1113 - acc: 0.9702 - val_loss: 0.1380 - val_acc: 0.9195
Manual evaluation: (didn't understand why I made this)
True 7264
False 1807
True percentage 0.800793738287
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.64      0.21      0.32       438
          O       0.97      0.93      0.95      7318
      B-ORG       0.27      0.43      0.33       296
     B-MISC       0.10      0.09      0.09       141
      B-LOC       0.44      0.27      0.33       218
      I-LOC       0.50      0.02      0.04       141
     I-MISC       0.12      0.10      0.11       154
      I-PER       0.57      0.32      0.41       214
      I-ORG       0.20      0.51      0.29       151

avg / total       0.86      0.80      0.82      9071

F-1 Score:
0.843281387827
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 10
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103625 unique words.
3621 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 280
OOV word occurences: 555
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6632064     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,738
Trainable params: 7,140,738
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 128ms/step - loss: 0.3619 - acc: 0.0263 - val_loss: 0.1346 - val_acc: 0.9277
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1839 - acc: 0.8065 - val_loss: 0.1648 - val_acc: 0.8434
Epoch 3/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1803 - acc: 0.8204 - val_loss: 0.1207 - val_acc: 0.9518
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1496 - acc: 0.8313 - val_loss: 0.1236 - val_acc: 0.9277
Epoch 5/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1418 - acc: 0.8669 - val_loss: 0.1209 - val_acc: 0.9398
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1338 - acc: 0.8932 - val_loss: 0.1208 - val_acc: 0.9518
Manual evaluation: (didn't understand why I made this)
True 7182
False 1889
True percentage 0.791753941131
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.46      0.31      0.37       438
          O       0.96      0.92      0.94      7318
      B-LOC       0.60      0.01      0.03       218
      I-LOC       0.24      0.33      0.28       141
      I-PER       0.75      0.20      0.31       214
      B-ORG       0.22      0.51      0.31       296
      I-ORG       0.16      0.28      0.21       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.79      0.80      9071

F-1 Score:
0.83621047636
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 11
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103626 unique words.
3622 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632128     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,802
Trainable params: 7,140,802
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 127ms/step - loss: 0.3542 - acc: 0.0501 - val_loss: 0.1923 - val_acc: 0.8167
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1926 - acc: 0.7980 - val_loss: 0.1743 - val_acc: 0.8000
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1722 - acc: 0.7997 - val_loss: 0.1602 - val_acc: 0.8167
Epoch 4/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1575 - acc: 0.8130 - val_loss: 0.1681 - val_acc: 0.7833
Epoch 5/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1499 - acc: 0.8598 - val_loss: 0.1517 - val_acc: 0.8500
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1450 - acc: 0.8514 - val_loss: 0.1617 - val_acc: 0.7833
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1426 - acc: 0.8698 - val_loss: 0.1500 - val_acc: 0.8333
Epoch 8/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1383 - acc: 0.8798 - val_loss: 0.1553 - val_acc: 0.8333
Epoch 9/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1353 - acc: 0.8998 - val_loss: 0.1491 - val_acc: 0.8333
Epoch 10/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1317 - acc: 0.9032 - val_loss: 0.1533 - val_acc: 0.8167
Epoch 11/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1298 - acc: 0.9048 - val_loss: 0.1452 - val_acc: 0.8333
Epoch 12/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1289 - acc: 0.9065 - val_loss: 0.1522 - val_acc: 0.8167
Epoch 13/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1273 - acc: 0.9149 - val_loss: 0.1450 - val_acc: 0.8500
Epoch 14/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1270 - acc: 0.9082 - val_loss: 0.1480 - val_acc: 0.8333
Epoch 15/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1252 - acc: 0.9182 - val_loss: 0.1465 - val_acc: 0.8333
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1229 - acc: 0.9232 - val_loss: 0.1492 - val_acc: 0.8167
Manual evaluation: (didn't understand why I made this)
True 7065
False 2006
True percentage 0.77885569397
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.91      0.95      7318
      B-ORG       0.19      0.27      0.23       296
     B-MISC       0.14      0.14      0.14       141
     I-MISC       0.19      0.17      0.18       154
      B-PER       0.42      0.33      0.37       438
      B-LOC       0.51      0.09      0.16       218
      I-ORG       0.15      0.61      0.24       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.84      0.78      0.80      9071

F-1 Score:
0.221769499418
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 12
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103622 unique words.
3618 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 557
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631872     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,546
Trainable params: 7,140,546
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 129ms/step - loss: 0.3119 - acc: 0.1651 - val_loss: 0.1805 - val_acc: 0.8816
Epoch 2/70

29/29 [==============================] - 1s 19ms/step - loss: 0.2092 - acc: 0.8365 - val_loss: 0.1672 - val_acc: 0.8553
Epoch 3/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1781 - acc: 0.8019 - val_loss: 0.1594 - val_acc: 0.8816
Epoch 4/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1656 - acc: 0.8396 - val_loss: 0.1479 - val_acc: 0.8553
Epoch 5/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1468 - acc: 0.8569 - val_loss: 0.1428 - val_acc: 0.8553
Epoch 6/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1420 - acc: 0.8836 - val_loss: 0.1409 - val_acc: 0.8684
Epoch 7/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1388 - acc: 0.8884 - val_loss: 0.1389 - val_acc: 0.8684
Epoch 8/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1341 - acc: 0.9135 - val_loss: 0.1377 - val_acc: 0.8816
Epoch 9/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1336 - acc: 0.9009 - val_loss: 0.1363 - val_acc: 0.8947
Epoch 10/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1313 - acc: 0.9057 - val_loss: 0.1356 - val_acc: 0.8947
Epoch 11/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1294 - acc: 0.9009 - val_loss: 0.1347 - val_acc: 0.8947
Epoch 12/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1281 - acc: 0.9135 - val_loss: 0.1342 - val_acc: 0.8947
Epoch 13/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1260 - acc: 0.9292 - val_loss: 0.1330 - val_acc: 0.9079
Epoch 14/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1259 - acc: 0.9292 - val_loss: 0.1321 - val_acc: 0.8947
Epoch 15/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1209 - acc: 0.9450 - val_loss: 0.1314 - val_acc: 0.9079
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1214 - acc: 0.9450 - val_loss: 0.1309 - val_acc: 0.9079
Epoch 17/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1208 - acc: 0.9371 - val_loss: 0.1300 - val_acc: 0.9079
Epoch 18/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1200 - acc: 0.9418 - val_loss: 0.1304 - val_acc: 0.9079
Epoch 19/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1192 - acc: 0.9513 - val_loss: 0.1297 - val_acc: 0.9079
Epoch 20/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1163 - acc: 0.9623 - val_loss: 0.1284 - val_acc: 0.9079
Epoch 21/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1155 - acc: 0.9654 - val_loss: 0.1286 - val_acc: 0.9079
Epoch 22/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1141 - acc: 0.9686 - val_loss: 0.1282 - val_acc: 0.9079
Epoch 23/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1162 - acc: 0.9623 - val_loss: 0.1290 - val_acc: 0.9079
Epoch 24/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1141 - acc: 0.9623 - val_loss: 0.1278 - val_acc: 0.9079
Epoch 25/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1121 - acc: 0.9686 - val_loss: 0.1281 - val_acc: 0.9079
Epoch 26/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1129 - acc: 0.9670 - val_loss: 0.1276 - val_acc: 0.9211
Epoch 27/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1116 - acc: 0.9717 - val_loss: 0.1277 - val_acc: 0.9211
Epoch 28/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1119 - acc: 0.9638 - val_loss: 0.1276 - val_acc: 0.9211
Epoch 29/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1118 - acc: 0.9654 - val_loss: 0.1284 - val_acc: 0.9211
Epoch 30/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1096 - acc: 0.9796 - val_loss: 0.1283 - val_acc: 0.9211
Epoch 31/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1091 - acc: 0.9780 - val_loss: 0.1282 - val_acc: 0.9211
Manual evaluation: (didn't understand why I made this)
True 7366
False 1705
True percentage 0.812038364017
Sklearn evaluation:
             precision    recall  f1-score   support

     B-MISC       0.15      0.04      0.06       141
     I-MISC       0.20      0.25      0.22       154
          O       0.97      0.94      0.95      7318
      B-PER       0.60      0.41      0.48       438
      I-PER       0.49      0.42      0.45       214
      B-ORG       0.29      0.43      0.35       296
      B-LOC       0.70      0.13      0.22       218
      I-ORG       0.18      0.30      0.23       151
      I-LOC       0.33      0.01      0.03       141

avg / total       0.86      0.81      0.83      9071

F-1 Score:
0.845605973578
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 13
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103625 unique words.
3621 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 561
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6632064     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,738
Trainable params: 7,140,738
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 150ms/step - loss: 0.3018 - acc: 0.2052 - val_loss: 0.2220 - val_acc: 0.8370
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2580 - acc: 0.7672 - val_loss: 0.1638 - val_acc: 0.8043
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1863 - acc: 0.7458 - val_loss: 0.1425 - val_acc: 0.8587
Epoch 4/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1683 - acc: 0.7917 - val_loss: 0.1387 - val_acc: 0.8478
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1575 - acc: 0.8132 - val_loss: 0.1387 - val_acc: 0.8587
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1532 - acc: 0.8423 - val_loss: 0.1367 - val_acc: 0.8587
Epoch 7/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1486 - acc: 0.8545 - val_loss: 0.1349 - val_acc: 0.8804
Epoch 8/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1459 - acc: 0.8606 - val_loss: 0.1347 - val_acc: 0.8696
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1421 - acc: 0.8760 - val_loss: 0.1342 - val_acc: 0.8696
Epoch 10/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1395 - acc: 0.8867 - val_loss: 0.1318 - val_acc: 0.8804
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1389 - acc: 0.8851 - val_loss: 0.1330 - val_acc: 0.8696
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1382 - acc: 0.8806 - val_loss: 0.1323 - val_acc: 0.8804
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1330 - acc: 0.9081 - val_loss: 0.1326 - val_acc: 0.8696
Manual evaluation: (didn't understand why I made this)
True 7378
False 1693
True percentage 0.813361261162
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.94      0.95      7318
      B-PER       0.63      0.34      0.44       438
      B-ORG       0.35      0.44      0.39       296
     B-MISC       0.45      0.06      0.11       141
     I-MISC       0.24      0.33      0.28       154
      I-ORG       0.18      0.33      0.23       151
      B-LOC       0.55      0.26      0.36       218
      I-LOC       0.67      0.09      0.15       141
      I-PER       0.70      0.20      0.31       214

avg / total       0.87      0.81      0.83      9071

F-1 Score:
0.327653997379
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 14
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103624 unique words.
3620 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632000     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,674
Trainable params: 7,140,674
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 4s 129ms/step - loss: 0.3837 - acc: 0.0579 - val_loss: 0.1572 - val_acc: 0.8837
Epoch 2/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1826 - acc: 0.8199 - val_loss: 0.1729 - val_acc: 0.8023
Epoch 3/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1709 - acc: 0.8248 - val_loss: 0.1421 - val_acc: 0.8953
Epoch 4/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1599 - acc: 0.8296 - val_loss: 0.1416 - val_acc: 0.8837
Epoch 5/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1437 - acc: 0.8730 - val_loss: 0.1348 - val_acc: 0.9302
Epoch 6/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1393 - acc: 0.8730 - val_loss: 0.1352 - val_acc: 0.9186
Epoch 7/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1361 - acc: 0.8891 - val_loss: 0.1354 - val_acc: 0.8953
Epoch 8/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1309 - acc: 0.9212 - val_loss: 0.1326 - val_acc: 0.9302
Epoch 9/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1304 - acc: 0.9148 - val_loss: 0.1320 - val_acc: 0.9070
Epoch 10/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1267 - acc: 0.9277 - val_loss: 0.1311 - val_acc: 0.9070
Epoch 11/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1258 - acc: 0.9309 - val_loss: 0.1319 - val_acc: 0.8953
Epoch 12/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1242 - acc: 0.9325 - val_loss: 0.1342 - val_acc: 0.9070
Epoch 13/70

29/29 [==============================] - 0s 17ms/step - loss: 0.1212 - acc: 0.9421 - val_loss: 0.1310 - val_acc: 0.9070
Epoch 14/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1200 - acc: 0.9534 - val_loss: 0.1294 - val_acc: 0.9302
Epoch 15/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1201 - acc: 0.9502 - val_loss: 0.1308 - val_acc: 0.9186
Epoch 16/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1210 - acc: 0.9373 - val_loss: 0.1300 - val_acc: 0.9419
Epoch 17/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1173 - acc: 0.9582 - val_loss: 0.1285 - val_acc: 0.9186
Epoch 18/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1155 - acc: 0.9662 - val_loss: 0.1271 - val_acc: 0.9535
Epoch 19/70

29/29 [==============================] - 1s 17ms/step - loss: 0.1171 - acc: 0.9550 - val_loss: 0.1281 - val_acc: 0.9186
Epoch 20/70

29/29 [==============================] - 1s 18ms/step - loss: 0.1137 - acc: 0.9646 - val_loss: 0.1271 - val_acc: 0.9535
Epoch 21/70

29/29 [==============================] - 1s 19ms/step - loss: 0.1146 - acc: 0.9678 - val_loss: 0.1286 - val_acc: 0.9070
Manual evaluation: (didn't understand why I made this)
True 7452
False 1619
True percentage 0.821519126888
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.95      7318
      B-ORG       0.31      0.41      0.35       296
      I-ORG       0.16      0.21      0.18       151
      B-PER       0.60      0.43      0.50       438
     B-MISC       0.30      0.18      0.22       141
     I-MISC       0.22      0.14      0.17       154
      B-LOC       0.75      0.28      0.41       218
      I-LOC       0.72      0.26      0.38       141
      I-PER       0.45      0.33      0.38       214

avg / total       0.87      0.82      0.84      9071

F-1 Score:
0.35648
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 3s 249ms/step - loss: 0.3570 - acc: 0.0285 - val_loss: 0.1315 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1954 - acc: 0.7829 - val_loss: 0.1916 - val_acc: 0.8333
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2316 - acc: 0.6157 - val_loss: 0.1261 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1845 - acc: 0.7829 - val_loss: 0.1260 - val_acc: 0.9667
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1524 - acc: 0.8185 - val_loss: 0.1238 - val_acc: 0.9667
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1478 - acc: 0.8434 - val_loss: 0.1229 - val_acc: 0.9333
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1417 - acc: 0.8754 - val_loss: 0.1222 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1380 - acc: 0.9004 - val_loss: 0.1203 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1341 - acc: 0.9146 - val_loss: 0.1211 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1310 - acc: 0.9359 - val_loss: 0.1202 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1270 - acc: 0.9324 - val_loss: 0.1198 - val_acc: 0.9000
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1253 - acc: 0.9324 - val_loss: 0.1183 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1241 - acc: 0.9324 - val_loss: 0.1203 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1240 - acc: 0.9431 - val_loss: 0.1180 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1205 - acc: 0.9502 - val_loss: 0.1188 - val_acc: 0.9000
Epoch 16/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1178 - acc: 0.9573 - val_loss: 0.1176 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1197 - acc: 0.9502 - val_loss: 0.1168 - val_acc: 0.9333
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1172 - acc: 0.9502 - val_loss: 0.1184 - val_acc: 0.9333
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1140 - acc: 0.9751 - val_loss: 0.1171 - val_acc: 0.9333
Epoch 20/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1139 - acc: 0.9715 - val_loss: 0.1179 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7223
False 1848
True percentage 0.796273839709
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.94      7318
      B-PER       0.40      0.45      0.43       438
      B-LOC       0.39      0.57      0.46       218
      B-ORG       0.35      0.13      0.19       296
      I-ORG       0.12      0.20      0.15       151
      I-PER       0.62      0.02      0.05       214
      I-LOC       0.17      0.27      0.21       141
     B-MISC       0.11      0.04      0.06       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.80      0.81      9071

F-1 Score:
0.273152478952
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 260ms/step - loss: 0.3347 - acc: 0.0422 - val_loss: 0.1804 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.2430 - acc: 0.8074 - val_loss: 0.1632 - val_acc: 0.8500
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1766 - acc: 0.7546 - val_loss: 0.1378 - val_acc: 0.9167
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1527 - acc: 0.8259 - val_loss: 0.1386 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1411 - acc: 0.8813 - val_loss: 0.1359 - val_acc: 0.9167
Epoch 6/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1387 - acc: 0.8760 - val_loss: 0.1354 - val_acc: 0.9167
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1345 - acc: 0.8892 - val_loss: 0.1337 - val_acc: 0.9167
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1332 - acc: 0.9024 - val_loss: 0.1349 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1288 - acc: 0.9077 - val_loss: 0.1318 - val_acc: 0.9167
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1283 - acc: 0.9314 - val_loss: 0.1323 - val_acc: 0.9000
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1278 - acc: 0.9050 - val_loss: 0.1296 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1239 - acc: 0.9235 - val_loss: 0.1306 - val_acc: 0.9000
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1196 - acc: 0.9551 - val_loss: 0.1289 - val_acc: 0.9167
Epoch 14/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1201 - acc: 0.9499 - val_loss: 0.1281 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1200 - acc: 0.9472 - val_loss: 0.1298 - val_acc: 0.9000
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1183 - acc: 0.9472 - val_loss: 0.1275 - val_acc: 0.9000
Epoch 17/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1183 - acc: 0.9499 - val_loss: 0.1269 - val_acc: 0.9500
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1172 - acc: 0.9499 - val_loss: 0.1265 - val_acc: 0.9167
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1162 - acc: 0.9525 - val_loss: 0.1279 - val_acc: 0.9000
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1133 - acc: 0.9683 - val_loss: 0.1257 - val_acc: 0.9333
Epoch 21/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1125 - acc: 0.9736 - val_loss: 0.1243 - val_acc: 0.9500
Epoch 22/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1134 - acc: 0.9736 - val_loss: 0.1250 - val_acc: 0.9333
Epoch 23/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1132 - acc: 0.9683 - val_loss: 0.1237 - val_acc: 0.9500
Epoch 24/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1107 - acc: 0.9763 - val_loss: 0.1242 - val_acc: 0.9500
Epoch 25/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1103 - acc: 0.9842 - val_loss: 0.1240 - val_acc: 0.9500
Epoch 26/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1092 - acc: 0.9842 - val_loss: 0.1227 - val_acc: 0.9500
Epoch 27/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1099 - acc: 0.9894 - val_loss: 0.1247 - val_acc: 0.9333
Epoch 28/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1120 - acc: 0.9710 - val_loss: 0.1247 - val_acc: 0.9167
Epoch 29/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1094 - acc: 0.9815 - val_loss: 0.1236 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7240
False 1831
True percentage 0.798147943997
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-ORG       0.19      0.29      0.23       296
      B-LOC       0.84      0.10      0.17       218
      I-ORG       0.16      0.60      0.25       151
     B-MISC       0.12      0.08      0.10       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.65      0.35      0.46       438
      I-PER       0.65      0.16      0.26       214
      I-LOC       0.80      0.03      0.05       141

avg / total       0.87      0.80      0.81      9071

F-1 Score:
0.253538848695
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 2
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103607 unique words.
3603 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 488
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630912     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,586
Trainable params: 7,139,586
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 252ms/step - loss: 0.3343 - acc: 0.1195 - val_loss: 0.1676 - val_acc: 0.8913
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1892 - acc: 0.8635 - val_loss: 0.1449 - val_acc: 0.8478
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1428 - acc: 0.8805 - val_loss: 0.1318 - val_acc: 0.8696
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1400 - acc: 0.8737 - val_loss: 0.1324 - val_acc: 0.8696
Epoch 5/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1303 - acc: 0.9113 - val_loss: 0.1311 - val_acc: 0.8913
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1253 - acc: 0.9352 - val_loss: 0.1287 - val_acc: 0.9130
Epoch 7/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1224 - acc: 0.9420 - val_loss: 0.1299 - val_acc: 0.9348
Epoch 8/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1215 - acc: 0.9317 - val_loss: 0.1276 - val_acc: 0.9130
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1194 - acc: 0.9522 - val_loss: 0.1264 - val_acc: 0.9130
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1165 - acc: 0.9454 - val_loss: 0.1279 - val_acc: 0.8913
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1153 - acc: 0.9659 - val_loss: 0.1238 - val_acc: 0.8913
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1123 - acc: 0.9590 - val_loss: 0.1254 - val_acc: 0.8696
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1123 - acc: 0.9659 - val_loss: 0.1245 - val_acc: 0.9130
Epoch 14/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1128 - acc: 0.9761 - val_loss: 0.1252 - val_acc: 0.9130
Manual evaluation: (didn't understand why I made this)
True 7315
False 1756
True percentage 0.806416051152
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.47      0.36      0.41       438
      B-ORG       0.17      0.28      0.21       296
      I-ORG       0.29      0.06      0.10       151
      I-PER       0.69      0.04      0.08       214
      B-LOC       0.40      0.60      0.48       218
      I-LOC       0.30      0.62      0.41       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.81      0.81      9071

F-1 Score:
0.293087557604
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 3
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103605 unique words.
3601 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630784     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,458
Trainable params: 7,139,458
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 252ms/step - loss: 0.4189 - acc: 0.0101 - val_loss: 0.2040 - val_acc: 0.8088
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.2047 - acc: 0.7980 - val_loss: 0.1778 - val_acc: 0.8088
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1688 - acc: 0.7980 - val_loss: 0.1825 - val_acc: 0.8088
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1562 - acc: 0.8215 - val_loss: 0.1852 - val_acc: 0.7500
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1622 - acc: 0.8721 - val_loss: 0.1854 - val_acc: 0.8088
Manual evaluation: (didn't understand why I made this)
True 7165
False 1906
True percentage 0.789879836843
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.85      0.97      0.90      7318
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-ORG       0.41      0.10      0.17       296
      I-ORG       0.00      0.00      0.00       151
      B-PER       1.00      0.01      0.02       438
      I-PER       0.82      0.04      0.08       214
      B-LOC       0.00      0.00      0.00       218
      I-LOC       0.47      0.26      0.34       141

avg / total       0.77      0.79      0.74      9071

F-1 Score:
0.0842433697348
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 4
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 3s 247ms/step - loss: 0.3680 - acc: 0.0599 - val_loss: 0.3489 - val_acc: 0.5882
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.2478 - acc: 0.7715 - val_loss: 0.3263 - val_acc: 0.3824
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2946 - acc: 0.4719 - val_loss: 0.2767 - val_acc: 0.5882
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1946 - acc: 0.7790 - val_loss: 0.2485 - val_acc: 0.5882
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1717 - acc: 0.8090 - val_loss: 0.2426 - val_acc: 0.5882
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1639 - acc: 0.8539 - val_loss: 0.2394 - val_acc: 0.5882
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1587 - acc: 0.8689 - val_loss: 0.2344 - val_acc: 0.5882
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1523 - acc: 0.8764 - val_loss: 0.2297 - val_acc: 0.6176
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1452 - acc: 0.9026 - val_loss: 0.2317 - val_acc: 0.6176
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1428 - acc: 0.9251 - val_loss: 0.2325 - val_acc: 0.6471
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1409 - acc: 0.9213 - val_loss: 0.2288 - val_acc: 0.6471
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1396 - acc: 0.9326 - val_loss: 0.2250 - val_acc: 0.6471
Epoch 13/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1378 - acc: 0.9476 - val_loss: 0.2249 - val_acc: 0.6765
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1391 - acc: 0.9288 - val_loss: 0.2249 - val_acc: 0.6471
Epoch 15/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1350 - acc: 0.9326 - val_loss: 0.2249 - val_acc: 0.6471
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1355 - acc: 0.9326 - val_loss: 0.2222 - val_acc: 0.6471
Epoch 17/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1295 - acc: 0.9625 - val_loss: 0.2208 - val_acc: 0.6176
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1308 - acc: 0.9663 - val_loss: 0.2293 - val_acc: 0.6471
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1286 - acc: 0.9588 - val_loss: 0.2324 - val_acc: 0.6471
Epoch 20/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1269 - acc: 0.9663 - val_loss: 0.2313 - val_acc: 0.6765
Manual evaluation: (didn't understand why I made this)
True 7305
False 1612
True percentage 0.819221711338
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.95      7318
      B-ORG       0.19      0.27      0.22       296
      B-LOC       0.45      0.51      0.48       218
      B-PER       0.50      0.26      0.34       438
      I-PER       0.54      0.29      0.37       214
     B-MISC       0.27      0.02      0.04       141
      I-ORG       0.22      0.12      0.16       151
      I-LOC       0.32      0.76      0.45       141

avg / total       0.86      0.82      0.83      8917

F-1 Score:
0.3253210405
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 5
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,010
Trainable params: 7,139,010
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 258ms/step - loss: 0.3547 - acc: 0.0405 - val_loss: 0.2984 - val_acc: 0.6757
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1911 - acc: 0.8421 - val_loss: 0.2132 - val_acc: 0.7027
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1610 - acc: 0.8543 - val_loss: 0.1798 - val_acc: 0.7568
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1392 - acc: 0.8745 - val_loss: 0.1760 - val_acc: 0.6757
Epoch 5/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1306 - acc: 0.9069 - val_loss: 0.1668 - val_acc: 0.7027
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1306 - acc: 0.9190 - val_loss: 0.1678 - val_acc: 0.7297
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1268 - acc: 0.9231 - val_loss: 0.1688 - val_acc: 0.7297
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1223 - acc: 0.9393 - val_loss: 0.1615 - val_acc: 0.7568
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1186 - acc: 0.9595 - val_loss: 0.1632 - val_acc: 0.7297
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1195 - acc: 0.9676 - val_loss: 0.1592 - val_acc: 0.7568
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1143 - acc: 0.9798 - val_loss: 0.1598 - val_acc: 0.7568
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1144 - acc: 0.9595 - val_loss: 0.1620 - val_acc: 0.7297
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1138 - acc: 0.9717 - val_loss: 0.1623 - val_acc: 0.7297
Manual evaluation: (didn't understand why I made this)
True 7176
False 1895
True percentage 0.791092492559
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.95      7318
      B-PER       0.60      0.28      0.39       438
      B-ORG       0.20      0.39      0.26       296
     I-MISC       0.20      0.08      0.12       154
      B-LOC       0.19      0.09      0.12       218
      I-LOC       0.23      0.23      0.23       141
      I-ORG       0.18      0.55      0.27       151
      I-PER       0.61      0.09      0.16       214
     B-MISC       0.00      0.00      0.00       141

avg / total       0.85      0.79      0.81      9071

F-1 Score:
0.242351529694
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 6
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103608 unique words.
3604 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 563
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630976     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,650
Trainable params: 7,139,650
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 255ms/step - loss: 0.3369 - acc: 0.0726 - val_loss: 0.2841 - val_acc: 0.6047
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.2208 - acc: 0.7792 - val_loss: 0.2327 - val_acc: 0.6279
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2119 - acc: 0.6688 - val_loss: 0.2200 - val_acc: 0.6047
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1624 - acc: 0.8044 - val_loss: 0.1986 - val_acc: 0.6977
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1519 - acc: 0.8265 - val_loss: 0.1940 - val_acc: 0.7209
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1444 - acc: 0.8738 - val_loss: 0.1839 - val_acc: 0.7442
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1419 - acc: 0.8738 - val_loss: 0.1831 - val_acc: 0.7674
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1378 - acc: 0.8738 - val_loss: 0.1807 - val_acc: 0.7907
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1368 - acc: 0.8927 - val_loss: 0.1777 - val_acc: 0.7907
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1318 - acc: 0.9243 - val_loss: 0.1754 - val_acc: 0.7674
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1287 - acc: 0.9243 - val_loss: 0.1771 - val_acc: 0.7674
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1270 - acc: 0.9243 - val_loss: 0.1750 - val_acc: 0.7907
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1239 - acc: 0.9306 - val_loss: 0.1772 - val_acc: 0.7907
Epoch 14/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1261 - acc: 0.9401 - val_loss: 0.1829 - val_acc: 0.7442
Epoch 15/70

14/14 [==============================] - 0s 29ms/step - loss: 0.1192 - acc: 0.9590 - val_loss: 0.1810 - val_acc: 0.7674
Manual evaluation: (didn't understand why I made this)
True 7316
False 1755
True percentage 0.806526292581
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.95      7318
      B-PER       0.47      0.21      0.29       438
      B-LOC       0.47      0.64      0.54       218
      B-ORG       0.26      0.28      0.27       296
      I-PER       0.26      0.26      0.26       214
     B-MISC       0.43      0.06      0.11       141
     I-MISC       0.41      0.22      0.29       154
      I-LOC       0.44      0.28      0.35       141
      I-ORG       0.17      0.37      0.24       151

avg / total       0.86      0.81      0.83      9071

F-1 Score:
0.309653916211
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 7
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103614 unique words.
3610 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 279
OOV word occurences: 462
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,034
Trainable params: 7,140,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 3s 248ms/step - loss: 0.3706 - acc: 0.0458 - val_loss: 0.2043 - val_acc: 0.7903
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1977 - acc: 0.7923 - val_loss: 0.1840 - val_acc: 0.7419
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1771 - acc: 0.7817 - val_loss: 0.1697 - val_acc: 0.7903
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1656 - acc: 0.7923 - val_loss: 0.1662 - val_acc: 0.7742
Epoch 5/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1550 - acc: 0.8345 - val_loss: 0.1538 - val_acc: 0.7903
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1492 - acc: 0.8451 - val_loss: 0.1506 - val_acc: 0.8387
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1412 - acc: 0.8873 - val_loss: 0.1463 - val_acc: 0.8387
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1387 - acc: 0.8803 - val_loss: 0.1437 - val_acc: 0.8871
Epoch 9/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1309 - acc: 0.9401 - val_loss: 0.1410 - val_acc: 0.8871
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1321 - acc: 0.9085 - val_loss: 0.1385 - val_acc: 0.9032
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1288 - acc: 0.8979 - val_loss: 0.1393 - val_acc: 0.9032
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1303 - acc: 0.9155 - val_loss: 0.1398 - val_acc: 0.8871
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1287 - acc: 0.8979 - val_loss: 0.1385 - val_acc: 0.8548
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1251 - acc: 0.9437 - val_loss: 0.1358 - val_acc: 0.8871
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1228 - acc: 0.9331 - val_loss: 0.1341 - val_acc: 0.8871
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1163 - acc: 0.9754 - val_loss: 0.1335 - val_acc: 0.9032
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1204 - acc: 0.9401 - val_loss: 0.1346 - val_acc: 0.8871
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1168 - acc: 0.9577 - val_loss: 0.1319 - val_acc: 0.9032
Epoch 19/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1208 - acc: 0.9507 - val_loss: 0.1343 - val_acc: 0.8871
Epoch 20/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1147 - acc: 0.9718 - val_loss: 0.1327 - val_acc: 0.9032
Epoch 21/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1184 - acc: 0.9542 - val_loss: 0.1337 - val_acc: 0.8871
Manual evaluation: (didn't understand why I made this)
True 7366
False 1705
True percentage 0.812038364017
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.90      0.96      0.93      7318
      B-ORG       0.40      0.31      0.35       296
      I-ORG       0.17      0.20      0.18       151
      B-PER       0.57      0.27      0.36       438
      B-LOC       0.35      0.09      0.15       218
      I-LOC       0.68      0.13      0.22       141
      I-PER       0.63      0.19      0.29       214
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.35      0.04      0.07       154

avg / total       0.81      0.81      0.80      9071

F-1 Score:
0.256591892956
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 8
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103616 unique words.
3612 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 533
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631488     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,162
Trainable params: 7,140,162
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 251ms/step - loss: 0.4309 - acc: 0.0310 - val_loss: 0.2065 - val_acc: 0.7500
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1943 - acc: 0.7887 - val_loss: 0.1880 - val_acc: 0.7188
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1795 - acc: 0.7887 - val_loss: 0.1710 - val_acc: 0.7500
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1623 - acc: 0.7972 - val_loss: 0.1629 - val_acc: 0.7188
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1540 - acc: 0.8451 - val_loss: 0.1567 - val_acc: 0.7188
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1463 - acc: 0.8479 - val_loss: 0.1553 - val_acc: 0.7500
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1431 - acc: 0.8732 - val_loss: 0.1512 - val_acc: 0.7812
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1394 - acc: 0.8704 - val_loss: 0.1493 - val_acc: 0.7812
Epoch 9/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1355 - acc: 0.8958 - val_loss: 0.1481 - val_acc: 0.7812
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1315 - acc: 0.9014 - val_loss: 0.1466 - val_acc: 0.7812
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1308 - acc: 0.9014 - val_loss: 0.1435 - val_acc: 0.8438
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1284 - acc: 0.9352 - val_loss: 0.1461 - val_acc: 0.7812
Epoch 13/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1273 - acc: 0.9211 - val_loss: 0.1426 - val_acc: 0.8438
Epoch 14/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1241 - acc: 0.9380 - val_loss: 0.1422 - val_acc: 0.8125
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1236 - acc: 0.9380 - val_loss: 0.1405 - val_acc: 0.8438
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1191 - acc: 0.9521 - val_loss: 0.1389 - val_acc: 0.8438
Epoch 17/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1212 - acc: 0.9521 - val_loss: 0.1400 - val_acc: 0.8438
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1206 - acc: 0.9606 - val_loss: 0.1409 - val_acc: 0.8125
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1207 - acc: 0.9521 - val_loss: 0.1395 - val_acc: 0.8125
Manual evaluation: (didn't understand why I made this)
True 7333
False 1738
True percentage 0.808400396869
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-ORG       0.19      0.23      0.21       296
      I-ORG       0.23      0.46      0.30       151
     B-MISC       0.16      0.11      0.13       141
     I-MISC       0.40      0.08      0.13       154
      B-PER       0.65      0.25      0.36       438
      B-LOC       0.41      0.56      0.47       218
      I-LOC       0.50      0.64      0.56       141
      I-PER       0.41      0.09      0.15       214

avg / total       0.86      0.81      0.82      9071

F-1 Score:
0.311841289523
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 9
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 557
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 3s 248ms/step - loss: 0.2980 - acc: 0.2964 - val_loss: 0.2764 - val_acc: 0.7500
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.2241 - acc: 0.8000 - val_loss: 0.1873 - val_acc: 0.7500
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1764 - acc: 0.8071 - val_loss: 0.1903 - val_acc: 0.7500
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1603 - acc: 0.8071 - val_loss: 0.1658 - val_acc: 0.7692
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1478 - acc: 0.8643 - val_loss: 0.1652 - val_acc: 0.7500
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1409 - acc: 0.8786 - val_loss: 0.1620 - val_acc: 0.7885
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1338 - acc: 0.8929 - val_loss: 0.1599 - val_acc: 0.7692
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1285 - acc: 0.9393 - val_loss: 0.1582 - val_acc: 0.8077
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1275 - acc: 0.9429 - val_loss: 0.1598 - val_acc: 0.7885
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1244 - acc: 0.9393 - val_loss: 0.1585 - val_acc: 0.7885
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1203 - acc: 0.9500 - val_loss: 0.1588 - val_acc: 0.7885
Manual evaluation: (didn't understand why I made this)
True 7103
False 1968
True percentage 0.783044868261
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.46      0.09      0.16       438
          O       0.96      0.92      0.94      7318
      B-ORG       0.22      0.40      0.28       296
     B-MISC       0.06      0.04      0.05       141
      B-LOC       0.29      0.35      0.32       218
      I-LOC       0.68      0.19      0.30       141
     I-MISC       0.19      0.41      0.26       154
      I-PER       0.49      0.14      0.22       214
      I-ORG       0.16      0.09      0.11       151

avg / total       0.84      0.78      0.80      9071

F-1 Score:
0.828047136073
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 10
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103608 unique words.
3604 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 559
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6630976     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,650
Trainable params: 7,139,650
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 3s 249ms/step - loss: 0.4186 - acc: 0.0213 - val_loss: 0.1422 - val_acc: 0.9286
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1978 - acc: 0.7508 - val_loss: 0.1907 - val_acc: 0.7679
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1908 - acc: 0.7477 - val_loss: 0.1409 - val_acc: 0.9107
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1644 - acc: 0.7872 - val_loss: 0.1516 - val_acc: 0.8214
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1457 - acc: 0.8784 - val_loss: 0.1492 - val_acc: 0.8393
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1407 - acc: 0.8784 - val_loss: 0.1482 - val_acc: 0.8393
Manual evaluation: (didn't understand why I made this)
True 7116
False 1955
True percentage 0.784478006835
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.45      0.39      0.42       438
          O       0.95      0.92      0.93      7318
      B-LOC       0.34      0.07      0.11       218
      I-LOC       0.00      0.00      0.00       141
      I-PER       0.93      0.06      0.11       214
      B-ORG       0.21      0.40      0.28       296
      I-ORG       0.14      0.34      0.20       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.82      0.78      0.79      9071

F-1 Score:
0.828462364309
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 11
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 7 unique labels.
Found additional 103610 unique words.
3606 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631104     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 8)        3160        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,968
Trainable params: 7,138,968
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 261ms/step - loss: 0.3423 - acc: 0.2958 - val_loss: 0.2936 - val_acc: 0.7442
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2548 - acc: 0.8099 - val_loss: 0.2232 - val_acc: 0.7442
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2230 - acc: 0.7817 - val_loss: 0.2057 - val_acc: 0.7442
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1981 - acc: 0.8204 - val_loss: 0.1808 - val_acc: 0.8605
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1820 - acc: 0.8627 - val_loss: 0.1895 - val_acc: 0.7674
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1725 - acc: 0.8697 - val_loss: 0.1820 - val_acc: 0.8140
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1652 - acc: 0.9049 - val_loss: 0.1783 - val_acc: 0.7907
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1628 - acc: 0.9190 - val_loss: 0.1784 - val_acc: 0.7907
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1560 - acc: 0.9437 - val_loss: 0.1751 - val_acc: 0.8140
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1542 - acc: 0.9401 - val_loss: 0.1828 - val_acc: 0.7907
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1517 - acc: 0.9225 - val_loss: 0.1703 - val_acc: 0.8837
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1530 - acc: 0.9577 - val_loss: 0.1826 - val_acc: 0.7907
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1494 - acc: 0.9507 - val_loss: 0.1705 - val_acc: 0.8605
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1475 - acc: 0.9577 - val_loss: 0.1857 - val_acc: 0.7907
Manual evaluation: (didn't understand why I made this)
True 6882
False 1834
True percentage 0.789582377237
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.90      0.93      7318
      B-ORG       0.15      0.08      0.10       296
     B-MISC       0.12      0.46      0.20       141
     I-MISC       0.14      0.37      0.21       154
      B-PER       0.47      0.17      0.25       438
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.11      0.31      0.16       151

avg / total       0.85      0.79      0.81      8716

F-1 Score:
0.173913043478
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 12
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103610 unique words.
3606 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631104     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,778
Trainable params: 7,139,778
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 250ms/step - loss: 0.3345 - acc: 0.0942 - val_loss: 0.1977 - val_acc: 0.8333
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1886 - acc: 0.8207 - val_loss: 0.1972 - val_acc: 0.7667
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1721 - acc: 0.8085 - val_loss: 0.1551 - val_acc: 0.8667
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1504 - acc: 0.8450 - val_loss: 0.1580 - val_acc: 0.8667
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1382 - acc: 0.8936 - val_loss: 0.1604 - val_acc: 0.8000
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1338 - acc: 0.9058 - val_loss: 0.1589 - val_acc: 0.8333
Manual evaluation: (didn't understand why I made this)
True 7107
False 1964
True percentage 0.783485833976
Sklearn evaluation:
             precision    recall  f1-score   support

     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.18      0.09      0.12       154
          O       0.95      0.93      0.94      7318
      B-PER       0.45      0.17      0.25       438
      I-PER       1.00      0.00      0.01       214
      B-ORG       0.23      0.51      0.32       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.15      0.43      0.22       151
      I-LOC       0.00      0.00      0.00       141

avg / total       0.82      0.78      0.79      9071

F-1 Score:
0.814882760993
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 13
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 565
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 254ms/step - loss: 0.3457 - acc: 0.1195 - val_loss: 0.2202 - val_acc: 0.7556
Epoch 2/70

14/14 [==============================] - 0s 30ms/step - loss: 0.1950 - acc: 0.7901 - val_loss: 0.1779 - val_acc: 0.7556
Epoch 3/70

14/14 [==============================] - 0s 30ms/step - loss: 0.1829 - acc: 0.7755 - val_loss: 0.1645 - val_acc: 0.7556
Epoch 4/70

14/14 [==============================] - 0s 28ms/step - loss: 0.1722 - acc: 0.7872 - val_loss: 0.1561 - val_acc: 0.7778
Epoch 5/70

14/14 [==============================] - 0s 28ms/step - loss: 0.1579 - acc: 0.8367 - val_loss: 0.1529 - val_acc: 0.7778
Epoch 6/70

14/14 [==============================] - 0s 29ms/step - loss: 0.1495 - acc: 0.8484 - val_loss: 0.1511 - val_acc: 0.7778
Epoch 7/70

14/14 [==============================] - 0s 29ms/step - loss: 0.1416 - acc: 0.8630 - val_loss: 0.1464 - val_acc: 0.8000
Epoch 8/70

14/14 [==============================] - 0s 31ms/step - loss: 0.1401 - acc: 0.8834 - val_loss: 0.1464 - val_acc: 0.8000
Epoch 9/70

14/14 [==============================] - 0s 29ms/step - loss: 0.1336 - acc: 0.8950 - val_loss: 0.1454 - val_acc: 0.8000
Epoch 10/70

14/14 [==============================] - 0s 29ms/step - loss: 0.1344 - acc: 0.8950 - val_loss: 0.1454 - val_acc: 0.7778
Epoch 11/70

14/14 [==============================] - 0s 32ms/step - loss: 0.1329 - acc: 0.9038 - val_loss: 0.1428 - val_acc: 0.8000
Epoch 12/70

14/14 [==============================] - 0s 31ms/step - loss: 0.1320 - acc: 0.9009 - val_loss: 0.1456 - val_acc: 0.7778
Epoch 13/70

14/14 [==============================] - 0s 30ms/step - loss: 0.1291 - acc: 0.8950 - val_loss: 0.1429 - val_acc: 0.8000
Epoch 14/70

14/14 [==============================] - 0s 28ms/step - loss: 0.1245 - acc: 0.9359 - val_loss: 0.1417 - val_acc: 0.8000
Epoch 15/70

14/14 [==============================] - 0s 28ms/step - loss: 0.1235 - acc: 0.9446 - val_loss: 0.1428 - val_acc: 0.7778
Epoch 16/70

14/14 [==============================] - 0s 28ms/step - loss: 0.1217 - acc: 0.9417 - val_loss: 0.1384 - val_acc: 0.8000
Epoch 17/70

14/14 [==============================] - 0s 28ms/step - loss: 0.1204 - acc: 0.9621 - val_loss: 0.1401 - val_acc: 0.8000
Epoch 18/70

14/14 [==============================] - 0s 30ms/step - loss: 0.1205 - acc: 0.9446 - val_loss: 0.1380 - val_acc: 0.8222
Epoch 19/70

14/14 [==============================] - 0s 29ms/step - loss: 0.1145 - acc: 0.9796 - val_loss: 0.1417 - val_acc: 0.8000
Epoch 20/70

14/14 [==============================] - 0s 29ms/step - loss: 0.1142 - acc: 0.9708 - val_loss: 0.1435 - val_acc: 0.8000
Epoch 21/70

14/14 [==============================] - 0s 28ms/step - loss: 0.1153 - acc: 0.9650 - val_loss: 0.1405 - val_acc: 0.8222
Manual evaluation: (didn't understand why I made this)
True 7260
False 1811
True percentage 0.800352772572
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.92      0.95      7318
      B-PER       0.49      0.30      0.37       438
      B-ORG       0.23      0.31      0.27       296
     B-MISC       0.21      0.21      0.21       141
     I-MISC       0.26      0.48      0.34       154
      I-ORG       0.20      0.22      0.21       151
      B-LOC       0.60      0.37      0.46       218
      I-LOC       0.44      0.48      0.46       141
      I-PER       0.52      0.14      0.22       214

avg / total       0.86      0.80      0.83      9071

F-1 Score:
0.321120047662
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 14
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103604 unique words.
3600 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 559
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630720     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,394
Trainable params: 7,139,394
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 4s 250ms/step - loss: 0.4070 - acc: 0.0171 - val_loss: 0.2346 - val_acc: 0.7500
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1953 - acc: 0.8055 - val_loss: 0.2145 - val_acc: 0.6562
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.2004 - acc: 0.7509 - val_loss: 0.1958 - val_acc: 0.7500
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1701 - acc: 0.8055 - val_loss: 0.1677 - val_acc: 0.7812
Epoch 5/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1463 - acc: 0.8737 - val_loss: 0.1654 - val_acc: 0.7812
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1403 - acc: 0.8601 - val_loss: 0.1620 - val_acc: 0.7812
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1353 - acc: 0.8942 - val_loss: 0.1620 - val_acc: 0.8125
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1300 - acc: 0.9113 - val_loss: 0.1608 - val_acc: 0.8125
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1272 - acc: 0.9317 - val_loss: 0.1591 - val_acc: 0.8125
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1247 - acc: 0.9317 - val_loss: 0.1587 - val_acc: 0.8125
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1231 - acc: 0.9420 - val_loss: 0.1574 - val_acc: 0.8125
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1195 - acc: 0.9590 - val_loss: 0.1561 - val_acc: 0.7812
Epoch 13/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1163 - acc: 0.9727 - val_loss: 0.1561 - val_acc: 0.8125
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1160 - acc: 0.9693 - val_loss: 0.1573 - val_acc: 0.8438
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1179 - acc: 0.9727 - val_loss: 0.1566 - val_acc: 0.8125
Epoch 16/70

14/14 [==============================] - 0s 27ms/step - loss: 0.1146 - acc: 0.9761 - val_loss: 0.1560 - val_acc: 0.8125
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1119 - acc: 0.9863 - val_loss: 0.1568 - val_acc: 0.8125
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1115 - acc: 0.9761 - val_loss: 0.1580 - val_acc: 0.8125
Epoch 19/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1095 - acc: 0.9863 - val_loss: 0.1620 - val_acc: 0.8125
Manual evaluation: (didn't understand why I made this)
True 7282
False 1789
True percentage 0.802778084004
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.94      0.94      7318
      B-ORG       0.24      0.17      0.20       296
      I-ORG       0.21      0.13      0.16       151
      B-PER       0.46      0.37      0.41       438
     B-MISC       0.18      0.16      0.17       141
     I-MISC       0.18      0.38      0.25       154
      B-LOC       0.92      0.05      0.10       218
      I-LOC       0.66      0.55      0.60       141
      I-PER       0.59      0.11      0.18       214

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.281084656085
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 497ms/step - loss: 0.4028 - acc: 0.0556 - val_loss: 0.2223 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 42ms/step - loss: 0.2445 - acc: 0.7698 - val_loss: 0.2009 - val_acc: 0.7931
Epoch 3/70

7/7 [==============================] - 0s 40ms/step - loss: 0.2223 - acc: 0.6825 - val_loss: 0.1830 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1733 - acc: 0.7937 - val_loss: 0.1679 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1598 - acc: 0.8413 - val_loss: 0.1827 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1484 - acc: 0.8889 - val_loss: 0.1754 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1449 - acc: 0.8968 - val_loss: 0.1749 - val_acc: 0.8621
Manual evaluation: (didn't understand why I made this)
True 7168
False 1749
True percentage 0.803857799708
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.92      0.94      7318
      B-PER       0.36      0.44      0.40       438
      B-LOC       0.36      0.64      0.46       218
      B-ORG       0.15      0.03      0.06       296
      I-ORG       0.14      0.42      0.21       151
      I-PER       0.30      0.01      0.03       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.80      0.81      8917

F-1 Score:
0.267499178442
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 489ms/step - loss: 0.3711 - acc: 0.0370 - val_loss: 0.2108 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1736 - acc: 0.7963 - val_loss: 0.2891 - val_acc: 0.5000
Epoch 3/70

7/7 [==============================] - 0s 39ms/step - loss: 0.2122 - acc: 0.6481 - val_loss: 0.1997 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1812 - acc: 0.7963 - val_loss: 0.1883 - val_acc: 0.8158
Epoch 5/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1473 - acc: 0.8519 - val_loss: 0.1761 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1336 - acc: 0.9012 - val_loss: 0.1779 - val_acc: 0.8158
Epoch 7/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1255 - acc: 0.9321 - val_loss: 0.1785 - val_acc: 0.8158
Epoch 8/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1234 - acc: 0.9321 - val_loss: 0.1806 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7164
False 1907
True percentage 0.789769595414
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.94      0.95      7318
      B-ORG       0.26      0.35      0.30       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.14      0.69      0.23       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.59      0.10      0.17       438
      I-PER       0.29      0.03      0.05       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.81      0.79      0.79      9071

F-1 Score:
0.172483221477
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 2
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103599 unique words.
3595 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 488
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630400     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,074
Trainable params: 7,139,074
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 491ms/step - loss: 0.3208 - acc: 0.2083 - val_loss: 0.1537 - val_acc: 0.9259
Epoch 2/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1952 - acc: 0.8403 - val_loss: 0.1715 - val_acc: 0.8889
Epoch 3/70

7/7 [==============================] - 0s 39ms/step - loss: 0.2116 - acc: 0.7431 - val_loss: 0.1402 - val_acc: 0.9259
Epoch 4/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1735 - acc: 0.8403 - val_loss: 0.1191 - val_acc: 0.9259
Epoch 5/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1363 - acc: 0.8611 - val_loss: 0.1144 - val_acc: 0.9630
Epoch 6/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1319 - acc: 0.8958 - val_loss: 0.1112 - val_acc: 0.9630
Epoch 7/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1298 - acc: 0.9028 - val_loss: 0.1101 - val_acc: 0.9630
Epoch 8/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1226 - acc: 0.9514 - val_loss: 0.1086 - val_acc: 0.9630
Epoch 9/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1206 - acc: 0.9514 - val_loss: 0.1096 - val_acc: 0.9630
Epoch 10/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1184 - acc: 0.9653 - val_loss: 0.1090 - val_acc: 0.9630
Epoch 11/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1158 - acc: 0.9722 - val_loss: 0.1086 - val_acc: 0.9630
Epoch 12/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1126 - acc: 0.9861 - val_loss: 0.1083 - val_acc: 0.9630
Epoch 13/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1115 - acc: 0.9861 - val_loss: 0.1081 - val_acc: 0.9630
Epoch 14/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1137 - acc: 0.9514 - val_loss: 0.1071 - val_acc: 0.9630
Epoch 15/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1104 - acc: 0.9722 - val_loss: 0.1072 - val_acc: 0.9630
Epoch 16/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1087 - acc: 0.9861 - val_loss: 0.1070 - val_acc: 0.9630
Epoch 17/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1089 - acc: 0.9931 - val_loss: 0.1071 - val_acc: 0.9630
Epoch 18/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1069 - acc: 0.9931 - val_loss: 0.1066 - val_acc: 0.9630
Epoch 19/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1055 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 0.9630
Epoch 20/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1061 - acc: 0.9931 - val_loss: 0.1067 - val_acc: 0.9630
Epoch 21/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1057 - acc: 0.9931 - val_loss: 0.1065 - val_acc: 0.9630
Epoch 22/70

7/7 [==============================] - 0s 42ms/step - loss: 0.1054 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9630
Epoch 23/70

7/7 [==============================] - 0s 42ms/step - loss: 0.1062 - acc: 0.9931 - val_loss: 0.1064 - val_acc: 0.9630
Epoch 24/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1040 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9630
Epoch 25/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1038 - acc: 0.9931 - val_loss: 0.1065 - val_acc: 0.9630
Epoch 26/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1046 - acc: 0.9861 - val_loss: 0.1065 - val_acc: 0.9630
Manual evaluation: (didn't understand why I made this)
True 7256
False 1815
True percentage 0.799911806857
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.93      0.94      7318
      B-PER       0.39      0.52      0.45       438
      B-ORG       0.18      0.11      0.14       296
      I-ORG       0.12      0.03      0.05       151
      I-PER       0.54      0.18      0.27       214
      B-LOC       0.25      0.32      0.28       218
      I-LOC       0.29      0.55      0.38       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.22      0.01      0.02       154

avg / total       0.82      0.80      0.81      9071

F-1 Score:
0.28303068253
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 3
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103599 unique words.
3595 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 559
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630400     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,074
Trainable params: 7,139,074
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 4s 581ms/step - loss: 0.3145 - acc: 0.1812 - val_loss: 0.4109 - val_acc: 0.6364
Epoch 2/70

7/7 [==============================] - 0s 40ms/step - loss: 0.2167 - acc: 0.7919 - val_loss: 0.3894 - val_acc: 0.4091
Epoch 3/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1936 - acc: 0.7383 - val_loss: 0.3325 - val_acc: 0.6364
Epoch 4/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1665 - acc: 0.7919 - val_loss: 0.3103 - val_acc: 0.5909
Epoch 5/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1470 - acc: 0.8658 - val_loss: 0.3131 - val_acc: 0.5909
Epoch 6/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1357 - acc: 0.9060 - val_loss: 0.3176 - val_acc: 0.5909
Epoch 7/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1331 - acc: 0.8859 - val_loss: 0.3215 - val_acc: 0.5909
Manual evaluation: (didn't understand why I made this)
True 7056
False 2015
True percentage 0.777863521111
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.91      0.94      0.92      7318
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-ORG       0.17      0.38      0.23       296
      I-ORG       0.17      0.21      0.18       151
      B-PER       0.45      0.05      0.10       438
      I-PER       0.45      0.16      0.24       214
      B-LOC       0.00      0.00      0.00       218
      I-LOC       0.00      0.00      0.00       141

avg / total       0.78      0.78      0.77      9071

F-1 Score:
0.147283995625
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 4
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103594 unique words.
3590 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630080     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,348
Trainable params: 7,138,348
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 484ms/step - loss: 0.4123 - acc: 0.0000e+00 - val_loss: 0.2466 - val_acc: 0.6842
Epoch 2/70

7/7 [==============================] - 0s 39ms/step - loss: 0.2205 - acc: 0.7521 - val_loss: 0.1740 - val_acc: 0.7895
Epoch 3/70

7/7 [==============================] - 0s 37ms/step - loss: 0.1797 - acc: 0.7778 - val_loss: 0.1779 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1630 - acc: 0.8462 - val_loss: 0.1582 - val_acc: 0.8947
Epoch 5/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1548 - acc: 0.8462 - val_loss: 0.1806 - val_acc: 0.7368
Epoch 6/70

7/7 [==============================] - 0s 36ms/step - loss: 0.1466 - acc: 0.9060 - val_loss: 0.1496 - val_acc: 0.8947
Epoch 7/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1406 - acc: 0.8974 - val_loss: 0.1485 - val_acc: 0.8947
Epoch 8/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1406 - acc: 0.9402 - val_loss: 0.1603 - val_acc: 0.8421
Epoch 9/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1338 - acc: 0.9316 - val_loss: 0.1678 - val_acc: 0.7895
Epoch 10/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1270 - acc: 0.9744 - val_loss: 0.1491 - val_acc: 0.8947
Manual evaluation: (didn't understand why I made this)
True 7155
False 1762
True percentage 0.802399910284
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-ORG       0.19      0.32      0.24       296
      B-LOC       0.32      0.43      0.36       218
      B-PER       0.41      0.08      0.13       438
      I-PER       0.10      0.00      0.01       214
     B-MISC       0.09      0.04      0.06       141
      I-ORG       0.20      0.28      0.24       151
      I-LOC       0.27      0.74      0.40       141

avg / total       0.85      0.80      0.81      8917

F-1 Score:
0.24117085587
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 5
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103593 unique words.
3589 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630016     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,284
Trainable params: 7,138,284
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 4s 515ms/step - loss: 0.4622 - acc: 0.0078 - val_loss: 0.2209 - val_acc: 0.7895
Epoch 2/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1676 - acc: 0.8760 - val_loss: 0.2126 - val_acc: 0.7895
Epoch 3/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1465 - acc: 0.9070 - val_loss: 0.2147 - val_acc: 0.7895
Epoch 4/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1376 - acc: 0.9380 - val_loss: 0.2117 - val_acc: 0.7895
Epoch 5/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1300 - acc: 0.9380 - val_loss: 0.2241 - val_acc: 0.7368
Epoch 6/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1298 - acc: 0.9457 - val_loss: 0.2079 - val_acc: 0.7895
Epoch 7/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1263 - acc: 0.9612 - val_loss: 0.2123 - val_acc: 0.7895
Epoch 8/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1241 - acc: 0.9612 - val_loss: 0.2179 - val_acc: 0.7895
Epoch 9/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1216 - acc: 0.9845 - val_loss: 0.2148 - val_acc: 0.7895
Manual evaluation: (didn't understand why I made this)
True 6931
False 1999
True percentage 0.776147816349
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.91      0.94      7318
      B-PER       0.39      0.02      0.04       438
      B-ORG       0.16      0.39      0.23       296
     I-MISC       0.11      0.12      0.12       154
      B-LOC       0.02      0.00      0.01       218
      I-LOC       0.00      0.00      0.00       141
      I-ORG       0.15      0.66      0.24       151
      I-PER       0.00      0.00      0.00       214

avg / total       0.83      0.78      0.79      8930

F-1 Score:
0.149722735675
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 6
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 565
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,010
Trainable params: 7,139,010
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 490ms/step - loss: 0.3210 - acc: 0.1961 - val_loss: 0.2669 - val_acc: 0.7200
Epoch 2/70

7/7 [==============================] - 0s 40ms/step - loss: 0.2785 - acc: 0.7124 - val_loss: 0.2069 - val_acc: 0.6800
Epoch 3/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1922 - acc: 0.6993 - val_loss: 0.1795 - val_acc: 0.7600
Epoch 4/70

7/7 [==============================] - 0s 44ms/step - loss: 0.1741 - acc: 0.7451 - val_loss: 0.1855 - val_acc: 0.6800
Epoch 5/70

7/7 [==============================] - 0s 42ms/step - loss: 0.1563 - acc: 0.8562 - val_loss: 0.1781 - val_acc: 0.7200
Epoch 6/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1478 - acc: 0.8627 - val_loss: 0.1874 - val_acc: 0.6800
Epoch 7/70

7/7 [==============================] - 0s 37ms/step - loss: 0.1420 - acc: 0.8889 - val_loss: 0.1780 - val_acc: 0.7600
Epoch 8/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1375 - acc: 0.9216 - val_loss: 0.1823 - val_acc: 0.6800
Epoch 9/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1329 - acc: 0.9346 - val_loss: 0.1741 - val_acc: 0.7200
Epoch 10/70

7/7 [==============================] - 0s 41ms/step - loss: 0.1301 - acc: 0.9346 - val_loss: 0.1850 - val_acc: 0.6800
Epoch 11/70

7/7 [==============================] - 0s 42ms/step - loss: 0.1276 - acc: 0.9346 - val_loss: 0.1750 - val_acc: 0.6800
Epoch 12/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1253 - acc: 0.9346 - val_loss: 0.1807 - val_acc: 0.6800
Manual evaluation: (didn't understand why I made this)
True 7119
False 1952
True percentage 0.784808731121
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.90      0.94      7318
      B-PER       0.35      0.34      0.34       438
      B-LOC       0.36      0.60      0.45       218
      B-ORG       0.31      0.28      0.29       296
      I-PER       0.15      0.07      0.09       214
     B-MISC       0.22      0.27      0.24       141
     I-MISC       0.34      0.36      0.35       154
      I-LOC       0.32      0.27      0.29       141
      I-ORG       0.14      0.22      0.17       151

avg / total       0.85      0.78      0.81      9071

F-1 Score:
0.302150237364
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 7
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103604 unique words.
3600 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 280
OOV word occurences: 471
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630720     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,988
Trainable params: 7,138,988
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 482ms/step - loss: 0.3373 - acc: 0.2579 - val_loss: 0.4562 - val_acc: 0.6552
Epoch 2/70

7/7 [==============================] - 0s 41ms/step - loss: 0.2602 - acc: 0.8113 - val_loss: 0.2932 - val_acc: 0.5517
Epoch 3/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1751 - acc: 0.8239 - val_loss: 0.2884 - val_acc: 0.6552
Epoch 4/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1699 - acc: 0.8176 - val_loss: 0.2824 - val_acc: 0.5517
Epoch 5/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1604 - acc: 0.8616 - val_loss: 0.2613 - val_acc: 0.6552
Epoch 6/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1519 - acc: 0.8679 - val_loss: 0.2675 - val_acc: 0.6207
Epoch 7/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1434 - acc: 0.8994 - val_loss: 0.2555 - val_acc: 0.6207
Epoch 8/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1389 - acc: 0.9245 - val_loss: 0.2616 - val_acc: 0.6207
Epoch 9/70

7/7 [==============================] - 0s 37ms/step - loss: 0.1396 - acc: 0.9308 - val_loss: 0.2690 - val_acc: 0.6552
Epoch 10/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1344 - acc: 0.9119 - val_loss: 0.2718 - val_acc: 0.6207
Manual evaluation: (didn't understand why I made this)
True 7262
False 1655
True percentage 0.814399461702
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.95      0.94      7318
      B-ORG       0.21      0.30      0.25       296
      I-ORG       0.16      0.39      0.22       151
      B-PER       0.49      0.41      0.45       438
      B-LOC       0.00      0.00      0.00       218
      I-LOC       0.00      0.00      0.00       141
      I-PER       0.20      0.00      0.01       214
     B-MISC       0.00      0.00      0.00       141

avg / total       0.80      0.81      0.81      8917

F-1 Score:
0.238730616661
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 8
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 565
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 481ms/step - loss: 0.3216 - acc: 0.2147 - val_loss: 0.1958 - val_acc: 0.8333
Epoch 2/70

7/7 [==============================] - 0s 40ms/step - loss: 0.2189 - acc: 0.7975 - val_loss: 0.2695 - val_acc: 0.4444
Epoch 3/70

7/7 [==============================] - 0s 40ms/step - loss: 0.2309 - acc: 0.5951 - val_loss: 0.1609 - val_acc: 0.8333
Epoch 4/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1633 - acc: 0.7975 - val_loss: 0.1622 - val_acc: 0.8333
Epoch 5/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1451 - acc: 0.8712 - val_loss: 0.1520 - val_acc: 0.8333
Epoch 6/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1367 - acc: 0.8957 - val_loss: 0.1562 - val_acc: 0.8333
Epoch 7/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1346 - acc: 0.9141 - val_loss: 0.1561 - val_acc: 0.8333
Epoch 8/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1271 - acc: 0.9387 - val_loss: 0.1535 - val_acc: 0.8333
Manual evaluation: (didn't understand why I made this)
True 7312
False 1759
True percentage 0.806085326866
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.95      0.94      7318
      B-ORG       0.24      0.07      0.11       296
      I-ORG       0.25      0.01      0.03       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.43      0.29      0.34       438
      B-LOC       0.39      0.60      0.47       218
      I-LOC       0.31      0.70      0.43       141
      I-PER       0.00      0.00      0.00       214

avg / total       0.80      0.81      0.80      9071

F-1 Score:
0.26982418371
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 9
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103595 unique words.
3591 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,818
Trainable params: 7,138,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 483ms/step - loss: 0.3125 - acc: 0.1328 - val_loss: 0.3208 - val_acc: 0.6667
Epoch 2/70

7/7 [==============================] - 0s 42ms/step - loss: 0.2305 - acc: 0.8047 - val_loss: 0.2132 - val_acc: 0.7222
Epoch 3/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1961 - acc: 0.7188 - val_loss: 0.2603 - val_acc: 0.6667
Epoch 4/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1754 - acc: 0.8047 - val_loss: 0.1910 - val_acc: 0.7222
Epoch 5/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1457 - acc: 0.8516 - val_loss: 0.1840 - val_acc: 0.7222
Epoch 6/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1327 - acc: 0.9141 - val_loss: 0.1823 - val_acc: 0.7222
Epoch 7/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1288 - acc: 0.9297 - val_loss: 0.1840 - val_acc: 0.7222
Epoch 8/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1259 - acc: 0.9297 - val_loss: 0.1823 - val_acc: 0.7778
Epoch 9/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1190 - acc: 0.9609 - val_loss: 0.1824 - val_acc: 0.7222
Manual evaluation: (didn't understand why I made this)
True 6989
False 2082
True percentage 0.770477345386
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.47      0.02      0.03       438
          O       0.92      0.93      0.93      7318
      B-ORG       0.16      0.44      0.24       296
     B-MISC       0.05      0.01      0.01       141
      B-LOC       0.17      0.23      0.19       218
      I-LOC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      I-PER       0.00      0.00      0.00       214
      I-ORG       0.23      0.02      0.04       151

avg / total       0.78      0.77      0.76      9071

F-1 Score:
0.815130465238
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 10
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103601 unique words.
3597 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 559
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6630528     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,202
Trainable params: 7,139,202
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 485ms/step - loss: 0.2878 - acc: 0.3547 - val_loss: 0.3658 - val_acc: 0.6471
Epoch 2/70

7/7 [==============================] - 0s 39ms/step - loss: 0.2730 - acc: 0.6860 - val_loss: 0.2717 - val_acc: 0.6471
Epoch 3/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1948 - acc: 0.7500 - val_loss: 0.2273 - val_acc: 0.5882
Epoch 4/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1483 - acc: 0.8721 - val_loss: 0.2083 - val_acc: 0.5882
Epoch 5/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1376 - acc: 0.8953 - val_loss: 0.2181 - val_acc: 0.5294
Epoch 6/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1363 - acc: 0.8895 - val_loss: 0.2063 - val_acc: 0.5882
Epoch 7/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1282 - acc: 0.9244 - val_loss: 0.2213 - val_acc: 0.5882
Epoch 8/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1249 - acc: 0.9186 - val_loss: 0.1969 - val_acc: 0.5882
Epoch 9/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1226 - acc: 0.9360 - val_loss: 0.2103 - val_acc: 0.5882
Epoch 10/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1248 - acc: 0.9244 - val_loss: 0.1943 - val_acc: 0.7059
Epoch 11/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1170 - acc: 0.9651 - val_loss: 0.2107 - val_acc: 0.5882
Epoch 12/70

7/7 [==============================] - 0s 44ms/step - loss: 0.1166 - acc: 0.9593 - val_loss: 0.1973 - val_acc: 0.7647
Epoch 13/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1143 - acc: 0.9767 - val_loss: 0.2110 - val_acc: 0.5882
Manual evaluation: (didn't understand why I made this)
True 7025
False 2046
True percentage 0.774446036821
Sklearn evaluation:
             precision    recall  f1-score   support

      B-PER       0.31      0.39      0.34       438
          O       0.98      0.91      0.94      7318
      B-LOC       0.36      0.06      0.11       218
      I-LOC       0.09      0.06      0.07       141
      I-PER       0.38      0.34      0.36       214
      B-ORG       0.16      0.24      0.19       296
      I-ORG       0.19      0.29      0.23       151
     B-MISC       0.07      0.09      0.08       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.83      0.77      0.80      9071

F-1 Score:
0.826587852102
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 11
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 7 unique labels.
Found additional 103596 unique words.
3592 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630208     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 8)        3160        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,072
Trainable params: 7,138,072
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 483ms/step - loss: 0.3973 - acc: 0.1556 - val_loss: 0.1580 - val_acc: 0.9583
Epoch 2/70

7/7 [==============================] - 0s 39ms/step - loss: 0.2662 - acc: 0.8000 - val_loss: 0.2066 - val_acc: 0.8333
Epoch 3/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1966 - acc: 0.8667 - val_loss: 0.1553 - val_acc: 0.9583
Epoch 4/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1880 - acc: 0.8074 - val_loss: 0.1989 - val_acc: 0.8333
Epoch 5/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1686 - acc: 0.9111 - val_loss: 0.1689 - val_acc: 0.8333
Epoch 6/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1717 - acc: 0.8593 - val_loss: 0.1927 - val_acc: 0.8333
Manual evaluation: (didn't understand why I made this)
True 6920
False 1796
True percentage 0.79394217531
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.91      0.93      7318
      B-ORG       0.17      0.09      0.12       296
     B-MISC       0.08      0.17      0.11       141
     I-MISC       0.11      0.50      0.17       154
      B-PER       0.35      0.31      0.33       438
      B-LOC       0.00      0.00      0.00       218
      I-ORG       1.00      0.01      0.01       151

avg / total       0.85      0.79      0.81      8716

F-1 Score:
0.177566926466
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 12
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 7 unique labels.
Found additional 103599 unique words.
3595 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 559
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630400     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 8)        3160        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,264
Trainable params: 7,138,264
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 482ms/step - loss: 0.4079 - acc: 0.1554 - val_loss: 0.2541 - val_acc: 0.7692
Epoch 2/70

7/7 [==============================] - 0s 39ms/step - loss: 0.2098 - acc: 0.8581 - val_loss: 0.2214 - val_acc: 0.7692
Epoch 3/70

7/7 [==============================] - 0s 38ms/step - loss: 0.2130 - acc: 0.8446 - val_loss: 0.2389 - val_acc: 0.7692
Epoch 4/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1982 - acc: 0.8581 - val_loss: 0.1948 - val_acc: 0.8462
Epoch 5/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1669 - acc: 0.8919 - val_loss: 0.1997 - val_acc: 0.8462
Epoch 6/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1616 - acc: 0.8986 - val_loss: 0.1989 - val_acc: 0.8462
Epoch 7/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1515 - acc: 0.9392 - val_loss: 0.2000 - val_acc: 0.8462
Manual evaluation: (didn't understand why I made this)
True 7129
False 1650
True percentage 0.812051486502
Sklearn evaluation:
             precision    recall  f1-score   support

     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.13      0.54      0.21       154
          O       0.92      0.95      0.93      7318
      B-PER       0.61      0.03      0.06       438
      I-PER       0.31      0.10      0.15       214
      B-ORG       0.33      0.27      0.30       296
      B-LOC       0.00      0.00      0.00       218

avg / total       0.82      0.81      0.80      8779

F-1 Score:
0.831370262391
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 13
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103599 unique words.
3595 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 565
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Padded until 24 chars.
Padded until 67 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 67, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 67)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 67, 64)       6630400     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 67, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 67, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 67, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 67, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 67, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,074
Trainable params: 7,139,074
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 493ms/step - loss: 0.3468 - acc: 0.0924 - val_loss: 0.2992 - val_acc: 0.6538
Epoch 2/70

7/7 [==============================] - 0s 44ms/step - loss: 0.2009 - acc: 0.7663 - val_loss: 0.2870 - val_acc: 0.5000
Epoch 3/70

7/7 [==============================] - 0s 43ms/step - loss: 0.2056 - acc: 0.7228 - val_loss: 0.2552 - val_acc: 0.6538
Epoch 4/70

7/7 [==============================] - 0s 44ms/step - loss: 0.1646 - acc: 0.7772 - val_loss: 0.2271 - val_acc: 0.6538
Epoch 5/70

7/7 [==============================] - 0s 43ms/step - loss: 0.1471 - acc: 0.8750 - val_loss: 0.2313 - val_acc: 0.6538
Epoch 6/70

7/7 [==============================] - 0s 45ms/step - loss: 0.1380 - acc: 0.8859 - val_loss: 0.2319 - val_acc: 0.6538
Epoch 7/70

7/7 [==============================] - 0s 43ms/step - loss: 0.1315 - acc: 0.9130 - val_loss: 0.2343 - val_acc: 0.6538
Manual evaluation: (didn't understand why I made this)
True 7089
False 1982
True percentage 0.781501488259
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.93      0.94      7318
      B-PER       0.69      0.11      0.18       438
      B-ORG       0.26      0.30      0.28       296
     B-MISC       0.09      0.13      0.11       141
     I-MISC       0.16      0.64      0.26       154
      I-ORG       0.20      0.01      0.02       151
      B-LOC       1.00      0.09      0.16       218
      I-LOC       0.00      0.00      0.00       141
      I-PER       0.00      0.00      0.00       214

avg / total       0.83      0.78      0.78      9071

F-1 Score:
0.181575433912
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 14
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 3s 487ms/step - loss: 0.3071 - acc: 0.3576 - val_loss: 0.1358 - val_acc: 0.9200
Epoch 2/70

7/7 [==============================] - 0s 39ms/step - loss: 0.2345 - acc: 0.7748 - val_loss: 0.1530 - val_acc: 0.8400
Epoch 3/70

7/7 [==============================] - 0s 40ms/step - loss: 0.1811 - acc: 0.7152 - val_loss: 0.1311 - val_acc: 0.9200
Epoch 4/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1516 - acc: 0.7881 - val_loss: 0.1393 - val_acc: 0.8400
Epoch 5/70

7/7 [==============================] - 0s 39ms/step - loss: 0.1446 - acc: 0.8675 - val_loss: 0.1236 - val_acc: 0.8800
Epoch 6/70

7/7 [==============================] - 0s 37ms/step - loss: 0.1353 - acc: 0.8874 - val_loss: 0.1286 - val_acc: 0.8800
Epoch 7/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1288 - acc: 0.9205 - val_loss: 0.1290 - val_acc: 0.8800
Epoch 8/70

7/7 [==============================] - 0s 38ms/step - loss: 0.1262 - acc: 0.9470 - val_loss: 0.1320 - val_acc: 0.8800
Manual evaluation: (didn't understand why I made this)
True 7137
False 1934
True percentage 0.786793076838
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.92      0.94      0.93      7318
      B-ORG       0.16      0.08      0.11       296
      I-ORG       0.14      0.03      0.05       151
      B-PER       0.28      0.53      0.36       438
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.38      0.07      0.12       154
      B-LOC       0.00      0.00      0.00       218
      I-LOC       0.08      0.01      0.01       141
      I-PER       0.82      0.04      0.08       214

avg / total       0.79      0.79      0.78      9071

F-1 Score:
0.199220134704
