Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104748 unique words.
4744 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 97
OOV word occurences: 99
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6703936     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,610
Trainable params: 7,212,610
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 37s 24ms/step - loss: 0.1454 - acc: 0.8542 - val_loss: 0.1280 - val_acc: 0.9101
Epoch 2/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1282 - acc: 0.9104 - val_loss: 0.1217 - val_acc: 0.9307
Epoch 3/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1244 - acc: 0.9228 - val_loss: 0.1199 - val_acc: 0.9307
Epoch 4/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1215 - acc: 0.9316 - val_loss: 0.1196 - val_acc: 0.9377
Epoch 5/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1195 - acc: 0.9383 - val_loss: 0.1198 - val_acc: 0.9349
Epoch 6/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1181 - acc: 0.9433 - val_loss: 0.1174 - val_acc: 0.9442
Epoch 7/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1166 - acc: 0.9481 - val_loss: 0.1159 - val_acc: 0.9502
Epoch 8/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1162 - acc: 0.9494 - val_loss: 0.1153 - val_acc: 0.9518
Epoch 9/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1149 - acc: 0.9537 - val_loss: 0.1147 - val_acc: 0.9557
Epoch 10/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1143 - acc: 0.9565 - val_loss: 0.1142 - val_acc: 0.9554
Epoch 11/70

1506/1506 [==============================] - 35s 24ms/step - loss: 0.1136 - acc: 0.9576 - val_loss: 0.1141 - val_acc: 0.9583
Epoch 12/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1131 - acc: 0.9597 - val_loss: 0.1144 - val_acc: 0.9569
Epoch 13/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1125 - acc: 0.9623 - val_loss: 0.1133 - val_acc: 0.9588
Epoch 14/70

1506/1506 [==============================] - 35s 24ms/step - loss: 0.1118 - acc: 0.9637 - val_loss: 0.1136 - val_acc: 0.9586
Epoch 15/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1116 - acc: 0.9649 - val_loss: 0.1136 - val_acc: 0.9572
Epoch 16/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1111 - acc: 0.9656 - val_loss: 0.1141 - val_acc: 0.9575
Val slice seed: 0
Embedding Trainable: True
GRU Trainable: True
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3208
False 243
True percentage 0.929585627354
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.98      2796
      B-PER       0.95      0.96      0.96       126
      B-ORG       0.76      0.89      0.82       140
      I-ORG       0.66      0.83      0.74        72
      I-PER       0.96      0.85      0.90        52
      B-LOC       0.86      0.86      0.86        81
     B-MISC       0.80      0.38      0.52        73
      I-LOC       0.90      0.80      0.85        45
     I-MISC       0.67      0.42      0.52        66

avg / total       0.96      0.93      0.94      3451

F-1 Score:
0.7984375
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104744 unique words.
4740 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 101
OOV word occurences: 105
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6703680     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,354
Trainable params: 7,212,354
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1465 - acc: 0.8536 - val_loss: 0.1296 - val_acc: 0.9067
Epoch 2/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1277 - acc: 0.9119 - val_loss: 0.1252 - val_acc: 0.9126
Epoch 3/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1237 - acc: 0.9248 - val_loss: 0.1235 - val_acc: 0.9197
Epoch 4/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1213 - acc: 0.9328 - val_loss: 0.1249 - val_acc: 0.9226
Epoch 5/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1194 - acc: 0.9391 - val_loss: 0.1242 - val_acc: 0.9248
Epoch 6/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1177 - acc: 0.9441 - val_loss: 0.1316 - val_acc: 0.9076
Val slice seed: 1
Embedding Trainable: True
GRU Trainable: True
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3119
False 422
True percentage 0.880824625812
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.97      2844
      B-ORG       0.49      0.85      0.62       153
      I-ORG       0.33      0.86      0.47        83
      B-PER       0.97      0.76      0.85       154
      B-LOC       0.80      0.54      0.64        72
      I-LOC       0.91      0.65      0.76        48
      I-PER       1.00      0.58      0.73        73
     B-MISC       1.00      0.03      0.07        58
     I-MISC       1.00      0.05      0.10        56

avg / total       0.95      0.88      0.89      3541

F-1 Score:
0.607541899441
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104751 unique words.
4747 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 94
OOV word occurences: 95
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6704128     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,802
Trainable params: 7,212,802
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1495 - acc: 0.8468 - val_loss: 0.1258 - val_acc: 0.9131
Epoch 2/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1291 - acc: 0.9060 - val_loss: 0.1194 - val_acc: 0.9336
Epoch 3/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1250 - acc: 0.9205 - val_loss: 0.1205 - val_acc: 0.9347
Epoch 4/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1223 - acc: 0.9301 - val_loss: 0.1178 - val_acc: 0.9388
Epoch 5/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1204 - acc: 0.9351 - val_loss: 0.1146 - val_acc: 0.9546
Epoch 6/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1193 - acc: 0.9390 - val_loss: 0.1128 - val_acc: 0.9593
Epoch 7/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1180 - acc: 0.9431 - val_loss: 0.1146 - val_acc: 0.9510
Epoch 8/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1168 - acc: 0.9482 - val_loss: 0.1133 - val_acc: 0.9582
Epoch 9/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1157 - acc: 0.9520 - val_loss: 0.1135 - val_acc: 0.9540
Val slice seed: 2
Embedding Trainable: True
GRU Trainable: True
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3283
False 254
True percentage 0.928187729714
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.97      0.98      2890
      B-PER       0.93      0.96      0.95       139
      B-ORG       0.68      0.90      0.78       143
      I-ORG       0.58      0.83      0.68        77
     B-MISC       0.67      0.16      0.25        64
     I-MISC       0.81      0.21      0.34        61
      I-PER       0.94      0.91      0.92        53
      B-LOC       0.87      0.81      0.84        67
      I-LOC       1.00      0.84      0.91        43

avg / total       0.96      0.93      0.93      3537

F-1 Score:
0.767899291896
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104748 unique words.
4744 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 97
OOV word occurences: 99
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6703936     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,610
Trainable params: 7,212,610
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1497 - acc: 0.8447 - val_loss: 0.1301 - val_acc: 0.9050
Epoch 2/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1293 - acc: 0.9069 - val_loss: 0.1231 - val_acc: 0.9281
Epoch 3/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1249 - acc: 0.9208 - val_loss: 0.1205 - val_acc: 0.9354
Epoch 4/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1223 - acc: 0.9299 - val_loss: 0.1200 - val_acc: 0.9367
Epoch 5/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1201 - acc: 0.9370 - val_loss: 0.1174 - val_acc: 0.9453
Epoch 6/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1189 - acc: 0.9411 - val_loss: 0.1179 - val_acc: 0.9427
Epoch 7/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1175 - acc: 0.9458 - val_loss: 0.1158 - val_acc: 0.9521
Epoch 8/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1160 - acc: 0.9488 - val_loss: 0.1155 - val_acc: 0.9508
Epoch 9/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1155 - acc: 0.9523 - val_loss: 0.1149 - val_acc: 0.9531
Epoch 10/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1150 - acc: 0.9536 - val_loss: 0.1148 - val_acc: 0.9531
Epoch 11/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1142 - acc: 0.9574 - val_loss: 0.1147 - val_acc: 0.9524
Epoch 12/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1137 - acc: 0.9588 - val_loss: 0.1138 - val_acc: 0.9597
Epoch 13/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1131 - acc: 0.9606 - val_loss: 0.1144 - val_acc: 0.9545
Epoch 14/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1127 - acc: 0.9612 - val_loss: 0.1139 - val_acc: 0.9605
Epoch 15/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1120 - acc: 0.9639 - val_loss: 0.1141 - val_acc: 0.9543
Val slice seed: 0
Embedding Trainable: True
GRU Trainable: False
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3197
False 254
True percentage 0.926398145465
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.98      2796
      B-PER       0.95      0.96      0.96       126
      B-ORG       0.75      0.89      0.81       140
      I-ORG       0.69      0.78      0.73        72
      I-PER       0.94      0.85      0.89        52
      B-LOC       0.87      0.85      0.86        81
     B-MISC       0.70      0.36      0.47        73
      I-LOC       0.81      0.84      0.83        45
     I-MISC       0.63      0.36      0.46        66

avg / total       0.95      0.93      0.94      3451

F-1 Score:
0.786217697729
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104744 unique words.
4740 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 101
OOV word occurences: 105
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6703680     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,354
Trainable params: 7,212,354
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1438 - acc: 0.8622 - val_loss: 0.1306 - val_acc: 0.8988
Epoch 2/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1274 - acc: 0.9127 - val_loss: 0.1265 - val_acc: 0.9166
Epoch 3/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1232 - acc: 0.9276 - val_loss: 0.1257 - val_acc: 0.9167
Epoch 4/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1214 - acc: 0.9329 - val_loss: 0.1197 - val_acc: 0.9381
Epoch 5/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1191 - acc: 0.9397 - val_loss: 0.1205 - val_acc: 0.9392
Epoch 6/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1179 - acc: 0.9454 - val_loss: 0.1200 - val_acc: 0.9398
Epoch 7/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1162 - acc: 0.9504 - val_loss: 0.1212 - val_acc: 0.9334
Val slice seed: 1
Embedding Trainable: True
GRU Trainable: False
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3208
False 333
True percentage 0.905958768709
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      2844
      B-ORG       0.64      0.86      0.73       153
      I-ORG       0.44      0.78      0.57        83
      B-PER       0.94      0.87      0.90       154
      B-LOC       0.77      0.68      0.72        72
      I-LOC       0.82      0.75      0.78        48
      I-PER       0.89      0.77      0.82        73
     B-MISC       0.92      0.21      0.34        58
     I-MISC       0.71      0.27      0.39        56

avg / total       0.95      0.91      0.92      3541

F-1 Score:
0.712446351931
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104751 unique words.
4747 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 94
OOV word occurences: 95
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6704128     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,802
Trainable params: 7,212,802
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 36s 24ms/step - loss: 0.1477 - acc: 0.8517 - val_loss: 0.1253 - val_acc: 0.9178
Epoch 2/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1294 - acc: 0.9057 - val_loss: 0.1207 - val_acc: 0.9221
Epoch 3/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1250 - acc: 0.9208 - val_loss: 0.1176 - val_acc: 0.9425
Epoch 4/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1223 - acc: 0.9304 - val_loss: 0.1162 - val_acc: 0.9452
Epoch 5/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1205 - acc: 0.9349 - val_loss: 0.1140 - val_acc: 0.9535
Epoch 6/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1191 - acc: 0.9400 - val_loss: 0.1130 - val_acc: 0.9605
Epoch 7/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1177 - acc: 0.9440 - val_loss: 0.1123 - val_acc: 0.9622
Epoch 8/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1166 - acc: 0.9483 - val_loss: 0.1123 - val_acc: 0.9624
Epoch 9/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1160 - acc: 0.9511 - val_loss: 0.1121 - val_acc: 0.9616
Epoch 10/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1151 - acc: 0.9541 - val_loss: 0.1115 - val_acc: 0.9632
Epoch 11/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1146 - acc: 0.9528 - val_loss: 0.1113 - val_acc: 0.9651
Epoch 12/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1137 - acc: 0.9574 - val_loss: 0.1121 - val_acc: 0.9633
Epoch 13/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1137 - acc: 0.9563 - val_loss: 0.1108 - val_acc: 0.9657
Epoch 14/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1131 - acc: 0.9597 - val_loss: 0.1118 - val_acc: 0.9629
Epoch 15/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1127 - acc: 0.9607 - val_loss: 0.1113 - val_acc: 0.9676
Epoch 16/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1118 - acc: 0.9627 - val_loss: 0.1106 - val_acc: 0.9681
Epoch 17/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1116 - acc: 0.9640 - val_loss: 0.1102 - val_acc: 0.9680
Epoch 18/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1111 - acc: 0.9665 - val_loss: 0.1102 - val_acc: 0.9679
Epoch 19/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1109 - acc: 0.9666 - val_loss: 0.1105 - val_acc: 0.9685
Epoch 20/70

1506/1506 [==============================] - 35s 23ms/step - loss: 0.1103 - acc: 0.9679 - val_loss: 0.1105 - val_acc: 0.9679
Val slice seed: 2
Embedding Trainable: True
GRU Trainable: False
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3332
False 205
True percentage 0.942041277919
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.97      0.98      2890
      B-PER       0.94      0.96      0.95       139
      B-ORG       0.83      0.89      0.86       143
      I-ORG       0.82      0.81      0.81        77
     B-MISC       0.79      0.53      0.64        64
     I-MISC       0.82      0.54      0.65        61
      I-PER       0.91      0.91      0.91        53
      B-LOC       0.82      0.88      0.85        67
      I-LOC       0.90      0.86      0.88        43

avg / total       0.97      0.94      0.95      3537

F-1 Score:
0.84135753749
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104748 unique words.
4744 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 97
OOV word occurences: 99
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6703936     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,610
Trainable params: 497,026
Non-trainable params: 6,715,584
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 28s 19ms/step - loss: 0.1492 - acc: 0.8431 - val_loss: 0.1321 - val_acc: 0.8929
Epoch 2/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1338 - acc: 0.8867 - val_loss: 0.1295 - val_acc: 0.9048
Epoch 3/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1306 - acc: 0.9002 - val_loss: 0.1256 - val_acc: 0.9197
Epoch 4/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1296 - acc: 0.9021 - val_loss: 0.1236 - val_acc: 0.9270
Epoch 5/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1287 - acc: 0.9070 - val_loss: 0.1256 - val_acc: 0.9166
Epoch 6/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1281 - acc: 0.9093 - val_loss: 0.1222 - val_acc: 0.9320
Epoch 7/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1270 - acc: 0.9139 - val_loss: 0.1247 - val_acc: 0.9198
Epoch 8/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1265 - acc: 0.9146 - val_loss: 0.1229 - val_acc: 0.9290
Epoch 9/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1258 - acc: 0.9162 - val_loss: 0.1211 - val_acc: 0.9321
Epoch 10/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1252 - acc: 0.9179 - val_loss: 0.1207 - val_acc: 0.9336
Epoch 11/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1247 - acc: 0.9185 - val_loss: 0.1198 - val_acc: 0.9400
Epoch 12/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1248 - acc: 0.9186 - val_loss: 0.1204 - val_acc: 0.9361
Epoch 13/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1244 - acc: 0.9210 - val_loss: 0.1217 - val_acc: 0.9308
Epoch 14/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1238 - acc: 0.9228 - val_loss: 0.1203 - val_acc: 0.9376
Val slice seed: 0
Embedding Trainable: False
GRU Trainable: True
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3142
False 309
True percentage 0.910460736019
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      2796
      B-PER       0.84      0.91      0.87       126
      B-ORG       0.66      0.77      0.71       140
      I-ORG       0.55      0.78      0.65        72
      I-PER       0.85      0.87      0.86        52
      B-LOC       0.84      0.80      0.82        81
     B-MISC       0.86      0.16      0.28        73
      I-LOC       0.78      0.71      0.74        45
     I-MISC       0.80      0.24      0.37        66

avg / total       0.94      0.91      0.92      3451

F-1 Score:
0.711568938193
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104744 unique words.
4740 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 101
OOV word occurences: 105
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6703680     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,354
Trainable params: 497,026
Non-trainable params: 6,715,328
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 28s 19ms/step - loss: 0.1500 - acc: 0.8417 - val_loss: 0.1396 - val_acc: 0.8660
Epoch 2/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1333 - acc: 0.8913 - val_loss: 0.1303 - val_acc: 0.8986
Epoch 3/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1310 - acc: 0.9002 - val_loss: 0.1284 - val_acc: 0.9097
Epoch 4/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1291 - acc: 0.9073 - val_loss: 0.1307 - val_acc: 0.9037
Epoch 5/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1276 - acc: 0.9109 - val_loss: 0.1262 - val_acc: 0.9165
Epoch 6/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1269 - acc: 0.9136 - val_loss: 0.1271 - val_acc: 0.9094
Epoch 7/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1262 - acc: 0.9164 - val_loss: 0.1252 - val_acc: 0.9202
Epoch 8/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1255 - acc: 0.9157 - val_loss: 0.1247 - val_acc: 0.9233
Epoch 9/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1249 - acc: 0.9193 - val_loss: 0.1289 - val_acc: 0.9078
Epoch 10/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1250 - acc: 0.9187 - val_loss: 0.1258 - val_acc: 0.9132
Epoch 11/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1240 - acc: 0.9226 - val_loss: 0.1243 - val_acc: 0.9237
Epoch 12/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1245 - acc: 0.9196 - val_loss: 0.1233 - val_acc: 0.9232
Epoch 13/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1239 - acc: 0.9237 - val_loss: 0.1257 - val_acc: 0.9167
Epoch 14/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1239 - acc: 0.9228 - val_loss: 0.1245 - val_acc: 0.9222
Epoch 15/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1235 - acc: 0.9235 - val_loss: 0.1229 - val_acc: 0.9231
Epoch 16/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1229 - acc: 0.9258 - val_loss: 0.1228 - val_acc: 0.9254
Epoch 17/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1232 - acc: 0.9263 - val_loss: 0.1231 - val_acc: 0.9247
Epoch 18/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1229 - acc: 0.9269 - val_loss: 0.1223 - val_acc: 0.9263
Epoch 19/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1227 - acc: 0.9267 - val_loss: 0.1250 - val_acc: 0.9183
Epoch 20/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1222 - acc: 0.9284 - val_loss: 0.1227 - val_acc: 0.9260
Epoch 21/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1221 - acc: 0.9295 - val_loss: 0.1223 - val_acc: 0.9273
Epoch 22/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1216 - acc: 0.9304 - val_loss: 0.1243 - val_acc: 0.9176
Epoch 23/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1219 - acc: 0.9285 - val_loss: 0.1236 - val_acc: 0.9245
Epoch 24/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1216 - acc: 0.9287 - val_loss: 0.1216 - val_acc: 0.9297
Epoch 25/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1217 - acc: 0.9290 - val_loss: 0.1219 - val_acc: 0.9295
Epoch 26/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1217 - acc: 0.9296 - val_loss: 0.1227 - val_acc: 0.9236
Epoch 27/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1211 - acc: 0.9322 - val_loss: 0.1214 - val_acc: 0.9296
Epoch 28/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1215 - acc: 0.9304 - val_loss: 0.1238 - val_acc: 0.9228
Epoch 29/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1212 - acc: 0.9315 - val_loss: 0.1214 - val_acc: 0.9282
Epoch 30/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1208 - acc: 0.9342 - val_loss: 0.1227 - val_acc: 0.9263
Val slice seed: 1
Embedding Trainable: False
GRU Trainable: True
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3183
False 358
True percentage 0.89889861621
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      2844
      B-ORG       0.63      0.78      0.70       153
      I-ORG       0.41      0.77      0.53        83
      B-PER       0.85      0.89      0.87       154
      B-LOC       0.81      0.60      0.69        72
      I-LOC       0.91      0.62      0.74        48
      I-PER       0.86      0.74      0.79        73
     B-MISC       0.59      0.22      0.32        58
     I-MISC       0.71      0.27      0.39        56

avg / total       0.94      0.90      0.91      3541

F-1 Score:
0.681460272011
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104751 unique words.
4747 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 94
OOV word occurences: 95
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6704128     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,802
Trainable params: 497,026
Non-trainable params: 6,715,776
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 28s 19ms/step - loss: 0.1504 - acc: 0.8387 - val_loss: 0.1278 - val_acc: 0.9065
Epoch 2/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1343 - acc: 0.8892 - val_loss: 0.1229 - val_acc: 0.9245
Epoch 3/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1315 - acc: 0.8986 - val_loss: 0.1209 - val_acc: 0.9305
Epoch 4/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1295 - acc: 0.9047 - val_loss: 0.1202 - val_acc: 0.9320
Epoch 5/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1290 - acc: 0.9057 - val_loss: 0.1198 - val_acc: 0.9283
Epoch 6/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1278 - acc: 0.9120 - val_loss: 0.1257 - val_acc: 0.9199
Epoch 7/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1275 - acc: 0.9110 - val_loss: 0.1211 - val_acc: 0.9302
Epoch 8/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1268 - acc: 0.9127 - val_loss: 0.1189 - val_acc: 0.9363
Epoch 9/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1261 - acc: 0.9171 - val_loss: 0.1173 - val_acc: 0.9413
Epoch 10/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1259 - acc: 0.9159 - val_loss: 0.1187 - val_acc: 0.9397
Epoch 11/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1258 - acc: 0.9175 - val_loss: 0.1162 - val_acc: 0.9467
Epoch 12/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1245 - acc: 0.9209 - val_loss: 0.1167 - val_acc: 0.9441
Epoch 13/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1246 - acc: 0.9218 - val_loss: 0.1171 - val_acc: 0.9412
Epoch 14/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1241 - acc: 0.9211 - val_loss: 0.1164 - val_acc: 0.9455
Val slice seed: 2
Embedding Trainable: False
GRU Trainable: True
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3255
False 282
True percentage 0.920271416455
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.98      2890
      B-PER       0.82      0.91      0.87       139
      B-ORG       0.70      0.78      0.74       143
      I-ORG       0.70      0.64      0.67        77
     B-MISC       0.57      0.33      0.42        64
     I-MISC       0.72      0.43      0.54        61
      I-PER       0.75      0.92      0.83        53
      B-LOC       0.82      0.82      0.82        67
      I-LOC       0.82      0.84      0.83        43

avg / total       0.94      0.92      0.93      3537

F-1 Score:
0.741784037559
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104748 unique words.
4744 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 97
OOV word occurences: 99
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6703936     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,610
Trainable params: 497,026
Non-trainable params: 6,715,584
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 28s 19ms/step - loss: 0.1483 - acc: 0.8443 - val_loss: 0.1326 - val_acc: 0.8892
Epoch 2/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1331 - acc: 0.8940 - val_loss: 0.1251 - val_acc: 0.9202
Epoch 3/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1304 - acc: 0.9030 - val_loss: 0.1248 - val_acc: 0.9188
Epoch 4/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1291 - acc: 0.9074 - val_loss: 0.1239 - val_acc: 0.9266
Epoch 5/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1274 - acc: 0.9117 - val_loss: 0.1229 - val_acc: 0.9259
Epoch 6/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1269 - acc: 0.9127 - val_loss: 0.1216 - val_acc: 0.9355
Epoch 7/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1261 - acc: 0.9158 - val_loss: 0.1226 - val_acc: 0.9305
Epoch 8/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1263 - acc: 0.9162 - val_loss: 0.1217 - val_acc: 0.9294
Epoch 9/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1254 - acc: 0.9186 - val_loss: 0.1224 - val_acc: 0.9288
Val slice seed: 0
Embedding Trainable: False
GRU Trainable: False
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3113
False 338
True percentage 0.902057374674
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      2796
      B-PER       0.86      0.90      0.88       126
      B-ORG       0.55      0.81      0.66       140
      I-ORG       0.49      0.81      0.61        72
      I-PER       0.87      0.87      0.87        52
      B-LOC       0.92      0.75      0.83        81
     B-MISC       1.00      0.03      0.05        73
      I-LOC       0.84      0.69      0.76        45
     I-MISC       0.73      0.12      0.21        66

avg / total       0.94      0.90      0.91      3451

F-1 Score:
0.676034348165
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104744 unique words.
4740 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 101
OOV word occurences: 105
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6703680     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,354
Trainable params: 497,026
Non-trainable params: 6,715,328
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 28s 19ms/step - loss: 0.1508 - acc: 0.8372 - val_loss: 0.1473 - val_acc: 0.8416
Epoch 2/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1342 - acc: 0.8877 - val_loss: 0.1362 - val_acc: 0.8701
Epoch 3/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1315 - acc: 0.8977 - val_loss: 0.1297 - val_acc: 0.9024
Epoch 4/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1295 - acc: 0.9044 - val_loss: 0.1290 - val_acc: 0.9033
Epoch 5/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1284 - acc: 0.9101 - val_loss: 0.1265 - val_acc: 0.9145
Epoch 6/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1275 - acc: 0.9119 - val_loss: 0.1273 - val_acc: 0.9092
Epoch 7/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1274 - acc: 0.9112 - val_loss: 0.1255 - val_acc: 0.9213
Epoch 8/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1262 - acc: 0.9146 - val_loss: 0.1270 - val_acc: 0.9077
Epoch 9/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1259 - acc: 0.9154 - val_loss: 0.1242 - val_acc: 0.9217
Epoch 10/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1256 - acc: 0.9161 - val_loss: 0.1233 - val_acc: 0.9236
Epoch 11/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1250 - acc: 0.9193 - val_loss: 0.1242 - val_acc: 0.9187
Epoch 12/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1252 - acc: 0.9177 - val_loss: 0.1251 - val_acc: 0.9167
Epoch 13/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1245 - acc: 0.9201 - val_loss: 0.1239 - val_acc: 0.9258
Val slice seed: 1
Embedding Trainable: False
GRU Trainable: False
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3181
False 360
True percentage 0.89833380401
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      2844
      B-ORG       0.63      0.72      0.67       153
      I-ORG       0.47      0.73      0.57        83
      B-PER       0.86      0.88      0.87       154
      B-LOC       0.67      0.68      0.68        72
      I-LOC       0.62      0.83      0.71        48
      I-PER       0.90      0.74      0.81        73
     B-MISC       0.67      0.24      0.35        58
     I-MISC       0.75      0.27      0.39        56

avg / total       0.93      0.90      0.91      3541

F-1 Score:
0.684323550465
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Opening file ner_3_train.ner
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104751 unique words.
4747 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 94
OOV word occurences: 95
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Padded until 23 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 23)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 23, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 23, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 23, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6704128     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,212,802
Trainable params: 497,026
Non-trainable params: 6,715,776
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 28s 19ms/step - loss: 0.1507 - acc: 0.8396 - val_loss: 0.1300 - val_acc: 0.8964
Epoch 2/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1340 - acc: 0.8893 - val_loss: 0.1223 - val_acc: 0.9255
Epoch 3/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1309 - acc: 0.8991 - val_loss: 0.1229 - val_acc: 0.9226
Epoch 4/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1296 - acc: 0.9032 - val_loss: 0.1227 - val_acc: 0.9241
Epoch 5/70

1506/1506 [==============================] - 27s 18ms/step - loss: 0.1290 - acc: 0.9054 - val_loss: 0.1244 - val_acc: 0.9112
Val slice seed: 2
Embedding Trainable: False
GRU Trainable: False
Loaded wgt name: 05-17_13_37_921
Manual evaluation: (didn't understand why I made this)
True 3137
False 400
True percentage 0.886909810574
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      2890
      B-PER       0.92      0.69      0.79       139
      B-ORG       0.43      0.88      0.58       143
      I-ORG       0.40      0.77      0.52        77
     B-MISC       0.67      0.03      0.06        64
     I-MISC       0.75      0.20      0.31        61
      I-PER       0.84      0.89      0.86        53
      B-LOC       1.00      0.36      0.53        67
      I-LOC       1.00      0.07      0.13        43

avg / total       0.94      0.89      0.89      3537

F-1 Score:
0.569884169884
