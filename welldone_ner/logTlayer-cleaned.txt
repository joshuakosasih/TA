Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 32ms/step - loss: 0.1462 - acc: 0.8590 - val_loss: 0.1291 - val_acc: 0.9022
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1283 - acc: 0.9087 - val_loss: 0.1222 - val_acc: 0.9342
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1237 - acc: 0.9246 - val_loss: 0.1201 - val_acc: 0.9380
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1211 - acc: 0.9328 - val_loss: 0.1183 - val_acc: 0.9449
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1193 - acc: 0.9381 - val_loss: 0.1186 - val_acc: 0.9407
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1180 - acc: 0.9429 - val_loss: 0.1188 - val_acc: 0.9417
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1169 - acc: 0.9466 - val_loss: 0.1161 - val_acc: 0.9492
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1157 - acc: 0.9509 - val_loss: 0.1175 - val_acc: 0.9448
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1150 - acc: 0.9517 - val_loss: 0.1159 - val_acc: 0.9478
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1142 - acc: 0.9563 - val_loss: 0.1156 - val_acc: 0.9488
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1137 - acc: 0.9571 - val_loss: 0.1151 - val_acc: 0.9532
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1130 - acc: 0.9596 - val_loss: 0.1150 - val_acc: 0.9521
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1126 - acc: 0.9607 - val_loss: 0.1150 - val_acc: 0.9505
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9613 - val_loss: 0.1145 - val_acc: 0.9548
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1117 - acc: 0.9638 - val_loss: 0.1144 - val_acc: 0.9556
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1109 - acc: 0.9662 - val_loss: 0.1143 - val_acc: 0.9545
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1105 - acc: 0.9669 - val_loss: 0.1142 - val_acc: 0.9554
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1104 - acc: 0.9679 - val_loss: 0.1140 - val_acc: 0.9560
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9695 - val_loss: 0.1141 - val_acc: 0.9559
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9684 - val_loss: 0.1138 - val_acc: 0.9564
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1099 - acc: 0.9695 - val_loss: 0.1139 - val_acc: 0.9581
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1094 - acc: 0.9710 - val_loss: 0.1139 - val_acc: 0.9570
Epoch 23/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1095 - acc: 0.9714 - val_loss: 0.1146 - val_acc: 0.9557
Manual evaluation: (didn't understand why I made this)
True 8261
False 810
True percentage 0.91070444273
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.93      0.85      0.88       438
      B-LOC       0.74      0.78      0.76       218
      B-ORG       0.74      0.76      0.75       296
      I-ORG       0.50      0.71      0.59       151
      I-PER       0.93      0.66      0.78       214
      I-LOC       0.69      0.80      0.74       141
     B-MISC       0.60      0.31      0.41       141
     I-MISC       0.57      0.23      0.33       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.720715350224
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1481 - acc: 0.8469 - val_loss: 0.1292 - val_acc: 0.9030
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1287 - acc: 0.9086 - val_loss: 0.1209 - val_acc: 0.9373
Epoch 3/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1244 - acc: 0.9203 - val_loss: 0.1192 - val_acc: 0.9391
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1212 - acc: 0.9327 - val_loss: 0.1171 - val_acc: 0.9491
Epoch 5/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1201 - acc: 0.9360 - val_loss: 0.1165 - val_acc: 0.9491
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1186 - acc: 0.9422 - val_loss: 0.1150 - val_acc: 0.9568
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1174 - acc: 0.9466 - val_loss: 0.1147 - val_acc: 0.9582
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1163 - acc: 0.9498 - val_loss: 0.1144 - val_acc: 0.9582
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1153 - acc: 0.9522 - val_loss: 0.1151 - val_acc: 0.9542
Epoch 10/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1148 - acc: 0.9529 - val_loss: 0.1137 - val_acc: 0.9591
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1139 - acc: 0.9567 - val_loss: 0.1146 - val_acc: 0.9576
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1130 - acc: 0.9593 - val_loss: 0.1135 - val_acc: 0.9590
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1134 - acc: 0.9576 - val_loss: 0.1133 - val_acc: 0.9605
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1124 - acc: 0.9615 - val_loss: 0.1133 - val_acc: 0.9599
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9614 - val_loss: 0.1128 - val_acc: 0.9604
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1116 - acc: 0.9633 - val_loss: 0.1128 - val_acc: 0.9594
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9640 - val_loss: 0.1132 - val_acc: 0.9590
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1105 - acc: 0.9680 - val_loss: 0.1128 - val_acc: 0.9599
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1102 - acc: 0.9690 - val_loss: 0.1128 - val_acc: 0.9602
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9689 - val_loss: 0.1126 - val_acc: 0.9596
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9694 - val_loss: 0.1130 - val_acc: 0.9593
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9688 - val_loss: 0.1127 - val_acc: 0.9601
Epoch 23/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1096 - acc: 0.9690 - val_loss: 0.1127 - val_acc: 0.9584
Manual evaluation: (didn't understand why I made this)
True 8271
False 800
True percentage 0.911806857017
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.98      7318
      B-ORG       0.75      0.74      0.74       296
      B-LOC       0.76      0.74      0.75       218
      I-ORG       0.65      0.55      0.60       151
     B-MISC       0.50      0.43      0.46       141
     I-MISC       0.46      0.49      0.48       154
      B-PER       0.93      0.84      0.88       438
      I-PER       0.93      0.66      0.77       214
      I-LOC       0.75      0.77      0.76       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.724465558195
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1525 - acc: 0.8357 - val_loss: 0.1318 - val_acc: 0.8966
Epoch 2/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1301 - acc: 0.9030 - val_loss: 0.1307 - val_acc: 0.9063
Epoch 3/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1257 - acc: 0.9185 - val_loss: 0.1228 - val_acc: 0.9255
Epoch 4/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1228 - acc: 0.9289 - val_loss: 0.1207 - val_acc: 0.9331
Epoch 5/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1207 - acc: 0.9353 - val_loss: 0.1236 - val_acc: 0.9263
Epoch 6/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1190 - acc: 0.9395 - val_loss: 0.1183 - val_acc: 0.9441
Epoch 7/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1179 - acc: 0.9445 - val_loss: 0.1183 - val_acc: 0.9440
Epoch 8/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1168 - acc: 0.9485 - val_loss: 0.1174 - val_acc: 0.9446
Epoch 9/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1161 - acc: 0.9501 - val_loss: 0.1165 - val_acc: 0.9478
Epoch 10/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1148 - acc: 0.9539 - val_loss: 0.1157 - val_acc: 0.9515
Epoch 11/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1145 - acc: 0.9548 - val_loss: 0.1183 - val_acc: 0.9406
Epoch 12/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1137 - acc: 0.9571 - val_loss: 0.1153 - val_acc: 0.9514
Epoch 13/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1130 - acc: 0.9597 - val_loss: 0.1155 - val_acc: 0.9514
Epoch 14/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1128 - acc: 0.9604 - val_loss: 0.1152 - val_acc: 0.9522
Epoch 15/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1124 - acc: 0.9617 - val_loss: 0.1165 - val_acc: 0.9524
Epoch 16/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1120 - acc: 0.9631 - val_loss: 0.1146 - val_acc: 0.9552
Epoch 17/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1117 - acc: 0.9640 - val_loss: 0.1149 - val_acc: 0.9545
Epoch 18/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1114 - acc: 0.9652 - val_loss: 0.1149 - val_acc: 0.9551
Epoch 19/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1110 - acc: 0.9659 - val_loss: 0.1146 - val_acc: 0.9557
Manual evaluation: (didn't understand why I made this)
True 8247
False 824
True percentage 0.909161062727
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.91      0.84      0.88       438
      B-LOC       0.72      0.78      0.74       218
      B-ORG       0.71      0.76      0.73       296
      I-ORG       0.56      0.60      0.58       151
      I-PER       0.91      0.66      0.76       214
      I-LOC       0.64      0.79      0.70       141
     B-MISC       0.62      0.32      0.42       141
     I-MISC       0.59      0.34      0.43       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.714243235207
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 50s 33ms/step - loss: 0.1535 - acc: 0.8341 - val_loss: 0.1324 - val_acc: 0.8820
Epoch 2/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1303 - acc: 0.9025 - val_loss: 0.1260 - val_acc: 0.9107
Epoch 3/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1257 - acc: 0.9184 - val_loss: 0.1202 - val_acc: 0.9399
Epoch 4/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1231 - acc: 0.9278 - val_loss: 0.1182 - val_acc: 0.9451
Epoch 5/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1205 - acc: 0.9366 - val_loss: 0.1185 - val_acc: 0.9436
Epoch 6/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1189 - acc: 0.9416 - val_loss: 0.1173 - val_acc: 0.9455
Epoch 7/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1181 - acc: 0.9429 - val_loss: 0.1170 - val_acc: 0.9448
Epoch 8/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1169 - acc: 0.9462 - val_loss: 0.1148 - val_acc: 0.9539
Epoch 9/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1159 - acc: 0.9511 - val_loss: 0.1146 - val_acc: 0.9545
Epoch 10/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1149 - acc: 0.9539 - val_loss: 0.1144 - val_acc: 0.9544
Epoch 11/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1144 - acc: 0.9553 - val_loss: 0.1136 - val_acc: 0.9582
Epoch 12/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1139 - acc: 0.9562 - val_loss: 0.1141 - val_acc: 0.9559
Epoch 13/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1133 - acc: 0.9579 - val_loss: 0.1133 - val_acc: 0.9599
Epoch 14/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1130 - acc: 0.9592 - val_loss: 0.1134 - val_acc: 0.9584
Epoch 15/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1122 - acc: 0.9629 - val_loss: 0.1131 - val_acc: 0.9590
Epoch 16/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1120 - acc: 0.9621 - val_loss: 0.1128 - val_acc: 0.9613
Epoch 17/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1117 - acc: 0.9636 - val_loss: 0.1131 - val_acc: 0.9599
Epoch 18/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1112 - acc: 0.9662 - val_loss: 0.1128 - val_acc: 0.9616
Epoch 19/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1106 - acc: 0.9681 - val_loss: 0.1126 - val_acc: 0.9605
Epoch 20/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1106 - acc: 0.9667 - val_loss: 0.1126 - val_acc: 0.9616
Epoch 21/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1104 - acc: 0.9680 - val_loss: 0.1126 - val_acc: 0.9610
Epoch 22/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1100 - acc: 0.9694 - val_loss: 0.1126 - val_acc: 0.9624
Epoch 23/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1096 - acc: 0.9696 - val_loss: 0.1125 - val_acc: 0.9630
Epoch 24/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1095 - acc: 0.9702 - val_loss: 0.1128 - val_acc: 0.9624
Epoch 25/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1092 - acc: 0.9716 - val_loss: 0.1126 - val_acc: 0.9602
Epoch 26/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1089 - acc: 0.9725 - val_loss: 0.1128 - val_acc: 0.9604
Manual evaluation: (didn't understand why I made this)
True 8246
False 825
True percentage 0.909050821299
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.79      0.72      0.75       296
      B-LOC       0.73      0.78      0.76       218
      I-ORG       0.56      0.57      0.56       151
     B-MISC       0.50      0.41      0.45       141
     I-MISC       0.44      0.49      0.47       154
      B-PER       0.91      0.84      0.87       438
      I-PER       0.91      0.66      0.77       214
      I-LOC       0.72      0.77      0.74       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.71701439906
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 50s 33ms/step - loss: 0.1461 - acc: 0.8521 - val_loss: 0.1273 - val_acc: 0.9125
Epoch 2/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1284 - acc: 0.9098 - val_loss: 0.1217 - val_acc: 0.9317
Epoch 3/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1242 - acc: 0.9234 - val_loss: 0.1261 - val_acc: 0.9179
Epoch 4/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1217 - acc: 0.9296 - val_loss: 0.1192 - val_acc: 0.9377
Epoch 5/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1198 - acc: 0.9357 - val_loss: 0.1195 - val_acc: 0.9352
Epoch 6/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1181 - acc: 0.9428 - val_loss: 0.1182 - val_acc: 0.9376
Epoch 7/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1170 - acc: 0.9477 - val_loss: 0.1158 - val_acc: 0.9515
Epoch 8/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1164 - acc: 0.9490 - val_loss: 0.1169 - val_acc: 0.9452
Epoch 9/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1150 - acc: 0.9534 - val_loss: 0.1156 - val_acc: 0.9492
Epoch 10/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1146 - acc: 0.9542 - val_loss: 0.1150 - val_acc: 0.9538
Epoch 11/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1138 - acc: 0.9566 - val_loss: 0.1157 - val_acc: 0.9496
Epoch 12/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1133 - acc: 0.9578 - val_loss: 0.1157 - val_acc: 0.9524
Epoch 13/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1131 - acc: 0.9599 - val_loss: 0.1156 - val_acc: 0.9510
Manual evaluation: (didn't understand why I made this)
True 8194
False 877
True percentage 0.903318267005
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.92      0.84      0.88       438
      B-LOC       0.71      0.78      0.75       218
      B-ORG       0.63      0.77      0.69       296
      I-ORG       0.41      0.67      0.51       151
      I-PER       0.93      0.66      0.77       214
      I-LOC       0.67      0.78      0.72       141
     B-MISC       0.68      0.18      0.28       141
     I-MISC       0.58      0.14      0.23       154

avg / total       0.94      0.90      0.91      9071

F-1 Score:
0.688089622642
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 32ms/step - loss: 0.1498 - acc: 0.8445 - val_loss: 0.1377 - val_acc: 0.8731
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1295 - acc: 0.9070 - val_loss: 0.1217 - val_acc: 0.9336
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1245 - acc: 0.9226 - val_loss: 0.1197 - val_acc: 0.9357
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1221 - acc: 0.9304 - val_loss: 0.1177 - val_acc: 0.9494
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1201 - acc: 0.9361 - val_loss: 0.1180 - val_acc: 0.9448
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1188 - acc: 0.9409 - val_loss: 0.1165 - val_acc: 0.9517
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1177 - acc: 0.9441 - val_loss: 0.1156 - val_acc: 0.9496
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1168 - acc: 0.9476 - val_loss: 0.1148 - val_acc: 0.9522
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1157 - acc: 0.9505 - val_loss: 0.1188 - val_acc: 0.9343
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1152 - acc: 0.9522 - val_loss: 0.1139 - val_acc: 0.9574
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1139 - acc: 0.9572 - val_loss: 0.1135 - val_acc: 0.9576
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1135 - acc: 0.9583 - val_loss: 0.1134 - val_acc: 0.9596
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1129 - acc: 0.9596 - val_loss: 0.1143 - val_acc: 0.9559
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9621 - val_loss: 0.1133 - val_acc: 0.9579
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1117 - acc: 0.9637 - val_loss: 0.1129 - val_acc: 0.9599
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9652 - val_loss: 0.1131 - val_acc: 0.9601
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1110 - acc: 0.9660 - val_loss: 0.1131 - val_acc: 0.9584
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1108 - acc: 0.9665 - val_loss: 0.1131 - val_acc: 0.9604
Manual evaluation: (didn't understand why I made this)
True 8253
False 818
True percentage 0.9098225113
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.97      0.97      7318
      B-ORG       0.74      0.76      0.75       296
      B-LOC       0.74      0.76      0.75       218
      I-ORG       0.55      0.61      0.58       151
     B-MISC       0.55      0.24      0.33       141
     I-MISC       0.61      0.28      0.38       154
      B-PER       0.90      0.84      0.87       438
      I-PER       0.91      0.66      0.76       214
      I-LOC       0.69      0.82      0.75       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.715104009647
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 50s 33ms/step - loss: 0.1480 - acc: 0.8524 - val_loss: 0.1287 - val_acc: 0.9095
Epoch 2/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1289 - acc: 0.9081 - val_loss: 0.1276 - val_acc: 0.8986
Epoch 3/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1246 - acc: 0.9212 - val_loss: 0.1220 - val_acc: 0.9270
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1218 - acc: 0.9322 - val_loss: 0.1189 - val_acc: 0.9391
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1201 - acc: 0.9374 - val_loss: 0.1178 - val_acc: 0.9462
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1183 - acc: 0.9434 - val_loss: 0.1175 - val_acc: 0.9440
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1173 - acc: 0.9468 - val_loss: 0.1167 - val_acc: 0.9490
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1159 - acc: 0.9515 - val_loss: 0.1161 - val_acc: 0.9490
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1157 - acc: 0.9520 - val_loss: 0.1156 - val_acc: 0.9517
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1147 - acc: 0.9552 - val_loss: 0.1157 - val_acc: 0.9512
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1141 - acc: 0.9570 - val_loss: 0.1152 - val_acc: 0.9545
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1135 - acc: 0.9580 - val_loss: 0.1145 - val_acc: 0.9565
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1128 - acc: 0.9609 - val_loss: 0.1146 - val_acc: 0.9557
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9631 - val_loss: 0.1141 - val_acc: 0.9562
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1119 - acc: 0.9645 - val_loss: 0.1144 - val_acc: 0.9576
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9648 - val_loss: 0.1146 - val_acc: 0.9573
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1109 - acc: 0.9662 - val_loss: 0.1145 - val_acc: 0.9576
Manual evaluation: (didn't understand why I made this)
True 8235
False 836
True percentage 0.907838165583
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.97      0.97      7318
      B-PER       0.91      0.84      0.87       438
      B-LOC       0.70      0.78      0.74       218
      B-ORG       0.73      0.75      0.74       296
      I-ORG       0.58      0.56      0.57       151
      I-PER       0.91      0.65      0.76       214
      I-LOC       0.63      0.84      0.72       141
     B-MISC       0.70      0.21      0.33       141
     I-MISC       0.60      0.24      0.34       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.709305850258
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 33ms/step - loss: 0.1463 - acc: 0.8498 - val_loss: 0.1275 - val_acc: 0.9092
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1283 - acc: 0.9088 - val_loss: 0.1216 - val_acc: 0.9321
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1242 - acc: 0.9230 - val_loss: 0.1186 - val_acc: 0.9448
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1219 - acc: 0.9310 - val_loss: 0.1180 - val_acc: 0.9443
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1198 - acc: 0.9372 - val_loss: 0.1164 - val_acc: 0.9503
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1186 - acc: 0.9410 - val_loss: 0.1182 - val_acc: 0.9362
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1174 - acc: 0.9446 - val_loss: 0.1151 - val_acc: 0.9545
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1165 - acc: 0.9486 - val_loss: 0.1152 - val_acc: 0.9513
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1153 - acc: 0.9516 - val_loss: 0.1146 - val_acc: 0.9545
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1145 - acc: 0.9548 - val_loss: 0.1151 - val_acc: 0.9514
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1139 - acc: 0.9575 - val_loss: 0.1130 - val_acc: 0.9585
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1131 - acc: 0.9595 - val_loss: 0.1133 - val_acc: 0.9571
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1127 - acc: 0.9601 - val_loss: 0.1145 - val_acc: 0.9539
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9615 - val_loss: 0.1128 - val_acc: 0.9594
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1113 - acc: 0.9653 - val_loss: 0.1127 - val_acc: 0.9596
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9632 - val_loss: 0.1127 - val_acc: 0.9613
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1110 - acc: 0.9652 - val_loss: 0.1128 - val_acc: 0.9602
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1108 - acc: 0.9666 - val_loss: 0.1124 - val_acc: 0.9610
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1106 - acc: 0.9666 - val_loss: 0.1125 - val_acc: 0.9610
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9690 - val_loss: 0.1123 - val_acc: 0.9613
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1097 - acc: 0.9697 - val_loss: 0.1123 - val_acc: 0.9616
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1092 - acc: 0.9718 - val_loss: 0.1123 - val_acc: 0.9610
Epoch 23/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1092 - acc: 0.9722 - val_loss: 0.1125 - val_acc: 0.9622
Epoch 24/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1089 - acc: 0.9724 - val_loss: 0.1126 - val_acc: 0.9613
Epoch 25/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1090 - acc: 0.9726 - val_loss: 0.1124 - val_acc: 0.9616
Manual evaluation: (didn't understand why I made this)
True 8284
False 787
True percentage 0.91323999559
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.97      0.97      7318
      B-ORG       0.77      0.76      0.76       296
      B-LOC       0.71      0.82      0.76       218
      I-ORG       0.64      0.56      0.60       151
     B-MISC       0.58      0.30      0.39       141
     I-MISC       0.54      0.38      0.44       154
      B-PER       0.93      0.84      0.89       438
      I-PER       0.92      0.66      0.77       214
      I-LOC       0.70      0.82      0.76       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.730445246691
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1482 - acc: 0.8517 - val_loss: 0.1289 - val_acc: 0.9061
Epoch 2/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1286 - acc: 0.9100 - val_loss: 0.1252 - val_acc: 0.9161
Epoch 3/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1249 - acc: 0.9207 - val_loss: 0.1265 - val_acc: 0.9092
Epoch 4/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1217 - acc: 0.9331 - val_loss: 0.1194 - val_acc: 0.9407
Epoch 5/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1201 - acc: 0.9373 - val_loss: 0.1178 - val_acc: 0.9456
Epoch 6/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1180 - acc: 0.9433 - val_loss: 0.1164 - val_acc: 0.9501
Epoch 7/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1173 - acc: 0.9451 - val_loss: 0.1235 - val_acc: 0.9189
Epoch 8/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1165 - acc: 0.9485 - val_loss: 0.1182 - val_acc: 0.9392
Epoch 9/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1155 - acc: 0.9519 - val_loss: 0.1157 - val_acc: 0.9533
Epoch 10/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1148 - acc: 0.9539 - val_loss: 0.1155 - val_acc: 0.9531
Epoch 11/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1140 - acc: 0.9564 - val_loss: 0.1153 - val_acc: 0.9538
Epoch 12/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1132 - acc: 0.9594 - val_loss: 0.1153 - val_acc: 0.9532
Epoch 13/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1127 - acc: 0.9607 - val_loss: 0.1148 - val_acc: 0.9564
Epoch 14/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1122 - acc: 0.9624 - val_loss: 0.1146 - val_acc: 0.9554
Epoch 15/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1117 - acc: 0.9658 - val_loss: 0.1146 - val_acc: 0.9562
Epoch 16/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1119 - acc: 0.9639 - val_loss: 0.1140 - val_acc: 0.9559
Epoch 17/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1112 - acc: 0.9651 - val_loss: 0.1142 - val_acc: 0.9562
Epoch 18/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1111 - acc: 0.9648 - val_loss: 0.1143 - val_acc: 0.9571
Epoch 19/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1102 - acc: 0.9683 - val_loss: 0.1141 - val_acc: 0.9581
Manual evaluation: (didn't understand why I made this)
True 8263
False 808
True percentage 0.910924925587
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.92      0.84      0.88       438
      B-LOC       0.72      0.80      0.76       218
      B-ORG       0.74      0.74      0.74       296
      I-ORG       0.60      0.57      0.59       151
      I-PER       0.90      0.66      0.76       214
      I-LOC       0.63      0.82      0.72       141
     B-MISC       0.58      0.33      0.42       141
     I-MISC       0.56      0.37      0.45       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.720930232558
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 33ms/step - loss: 0.1501 - acc: 0.8431 - val_loss: 0.1293 - val_acc: 0.9028
Epoch 2/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1294 - acc: 0.9076 - val_loss: 0.1213 - val_acc: 0.9363
Epoch 3/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1252 - acc: 0.9177 - val_loss: 0.1225 - val_acc: 0.9186
Epoch 4/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1222 - acc: 0.9296 - val_loss: 0.1178 - val_acc: 0.9459
Epoch 5/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1201 - acc: 0.9353 - val_loss: 0.1190 - val_acc: 0.9380
Epoch 6/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1191 - acc: 0.9405 - val_loss: 0.1215 - val_acc: 0.9300
Epoch 7/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1179 - acc: 0.9447 - val_loss: 0.1152 - val_acc: 0.9545
Epoch 8/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1164 - acc: 0.9483 - val_loss: 0.1147 - val_acc: 0.9573
Epoch 9/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1154 - acc: 0.9518 - val_loss: 0.1145 - val_acc: 0.9576
Epoch 10/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1147 - acc: 0.9527 - val_loss: 0.1141 - val_acc: 0.9570
Epoch 11/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1144 - acc: 0.9558 - val_loss: 0.1143 - val_acc: 0.9585
Epoch 12/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1135 - acc: 0.9572 - val_loss: 0.1145 - val_acc: 0.9588
Epoch 13/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1135 - acc: 0.9567 - val_loss: 0.1135 - val_acc: 0.9613
Epoch 14/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1123 - acc: 0.9611 - val_loss: 0.1133 - val_acc: 0.9616
Epoch 15/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1123 - acc: 0.9611 - val_loss: 0.1133 - val_acc: 0.9599
Epoch 16/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1119 - acc: 0.9628 - val_loss: 0.1131 - val_acc: 0.9613
Epoch 17/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1114 - acc: 0.9641 - val_loss: 0.1132 - val_acc: 0.9616
Epoch 18/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1112 - acc: 0.9650 - val_loss: 0.1129 - val_acc: 0.9621
Epoch 19/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1107 - acc: 0.9677 - val_loss: 0.1134 - val_acc: 0.9621
Epoch 20/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1105 - acc: 0.9679 - val_loss: 0.1132 - val_acc: 0.9601
Epoch 21/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1099 - acc: 0.9691 - val_loss: 0.1132 - val_acc: 0.9590
Manual evaluation: (didn't understand why I made this)
True 8263
False 808
True percentage 0.910924925587
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.81      0.73      0.77       296
      B-LOC       0.71      0.81      0.76       218
      I-ORG       0.60      0.55      0.57       151
     B-MISC       0.45      0.40      0.42       141
     I-MISC       0.52      0.45      0.48       154
      B-PER       0.92      0.84      0.88       438
      I-PER       0.93      0.67      0.78       214
      I-LOC       0.66      0.82      0.73       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.724970553592
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1653 - acc: 0.8036 - val_loss: 0.1343 - val_acc: 0.8816
Epoch 2/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1348 - acc: 0.8878 - val_loss: 0.1279 - val_acc: 0.9126
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1298 - acc: 0.9058 - val_loss: 0.1295 - val_acc: 0.8975
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1269 - acc: 0.9156 - val_loss: 0.1266 - val_acc: 0.9096
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1238 - acc: 0.9258 - val_loss: 0.1227 - val_acc: 0.9222
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1222 - acc: 0.9313 - val_loss: 0.1223 - val_acc: 0.9271
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1210 - acc: 0.9343 - val_loss: 0.1218 - val_acc: 0.9297
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1194 - acc: 0.9413 - val_loss: 0.1206 - val_acc: 0.9279
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1185 - acc: 0.9429 - val_loss: 0.1210 - val_acc: 0.9310
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1175 - acc: 0.9466 - val_loss: 0.1198 - val_acc: 0.9316
Epoch 11/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1166 - acc: 0.9496 - val_loss: 0.1200 - val_acc: 0.9330
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1162 - acc: 0.9510 - val_loss: 0.1191 - val_acc: 0.9354
Epoch 13/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1149 - acc: 0.9536 - val_loss: 0.1187 - val_acc: 0.9367
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1143 - acc: 0.9571 - val_loss: 0.1207 - val_acc: 0.9338
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1136 - acc: 0.9596 - val_loss: 0.1194 - val_acc: 0.9381
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1130 - acc: 0.9600 - val_loss: 0.1208 - val_acc: 0.9343
Manual evaluation: (didn't understand why I made this)
True 8093
False 978
True percentage 0.892183882703
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-PER       0.88      0.76      0.81       438
      B-LOC       0.73      0.72      0.73       218
      B-ORG       0.58      0.76      0.66       296
      I-ORG       0.38      0.62      0.47       151
      I-PER       0.89      0.65      0.75       214
      I-LOC       0.67      0.79      0.73       141
     B-MISC       0.65      0.17      0.27       141
     I-MISC       0.60      0.16      0.25       154

avg / total       0.93      0.89      0.91      9071

F-1 Score:
0.655008891523
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1635 - acc: 0.8077 - val_loss: 0.1372 - val_acc: 0.8854
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1346 - acc: 0.8927 - val_loss: 0.1313 - val_acc: 0.9019
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1295 - acc: 0.9075 - val_loss: 0.1282 - val_acc: 0.9110
Epoch 4/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1255 - acc: 0.9183 - val_loss: 0.1260 - val_acc: 0.9141
Epoch 5/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1239 - acc: 0.9226 - val_loss: 0.1245 - val_acc: 0.9250
Epoch 6/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1227 - acc: 0.9317 - val_loss: 0.1244 - val_acc: 0.9240
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1205 - acc: 0.9347 - val_loss: 0.1240 - val_acc: 0.9193
Epoch 8/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1189 - acc: 0.9410 - val_loss: 0.1228 - val_acc: 0.9260
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1184 - acc: 0.9422 - val_loss: 0.1231 - val_acc: 0.9264
Epoch 10/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1171 - acc: 0.9463 - val_loss: 0.1228 - val_acc: 0.9253
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1162 - acc: 0.9494 - val_loss: 0.1223 - val_acc: 0.9242
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1157 - acc: 0.9515 - val_loss: 0.1214 - val_acc: 0.9307
Epoch 13/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1147 - acc: 0.9544 - val_loss: 0.1215 - val_acc: 0.9290
Epoch 14/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1145 - acc: 0.9560 - val_loss: 0.1215 - val_acc: 0.9326
Epoch 15/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1135 - acc: 0.9601 - val_loss: 0.1217 - val_acc: 0.9309
Manual evaluation: (didn't understand why I made this)
True 8153
False 918
True percentage 0.898798368427
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.69      0.71      0.70       296
      B-LOC       0.73      0.73      0.73       218
      I-ORG       0.46      0.48      0.47       151
     B-MISC       0.45      0.35      0.40       141
     I-MISC       0.42      0.47      0.44       154
      B-PER       0.91      0.80      0.85       438
      I-PER       0.92      0.61      0.74       214
      I-LOC       0.72      0.76      0.74       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.679245283019
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1588 - acc: 0.8172 - val_loss: 0.1329 - val_acc: 0.8957
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1338 - acc: 0.8937 - val_loss: 0.1269 - val_acc: 0.9103
Epoch 3/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1289 - acc: 0.9106 - val_loss: 0.1243 - val_acc: 0.9230
Epoch 4/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1260 - acc: 0.9183 - val_loss: 0.1237 - val_acc: 0.9188
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1229 - acc: 0.9288 - val_loss: 0.1232 - val_acc: 0.9187
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1217 - acc: 0.9311 - val_loss: 0.1221 - val_acc: 0.9217
Epoch 7/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1205 - acc: 0.9363 - val_loss: 0.1210 - val_acc: 0.9244
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1186 - acc: 0.9429 - val_loss: 0.1216 - val_acc: 0.9266
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1173 - acc: 0.9469 - val_loss: 0.1206 - val_acc: 0.9273
Epoch 10/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1171 - acc: 0.9469 - val_loss: 0.1202 - val_acc: 0.9296
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1158 - acc: 0.9525 - val_loss: 0.1202 - val_acc: 0.9292
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1151 - acc: 0.9548 - val_loss: 0.1207 - val_acc: 0.9292
Epoch 13/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1144 - acc: 0.9564 - val_loss: 0.1198 - val_acc: 0.9319
Epoch 14/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1140 - acc: 0.9563 - val_loss: 0.1192 - val_acc: 0.9321
Epoch 15/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1132 - acc: 0.9590 - val_loss: 0.1200 - val_acc: 0.9326
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1125 - acc: 0.9613 - val_loss: 0.1192 - val_acc: 0.9383
Epoch 17/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1125 - acc: 0.9608 - val_loss: 0.1187 - val_acc: 0.9404
Epoch 18/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1119 - acc: 0.9639 - val_loss: 0.1198 - val_acc: 0.9360
Epoch 19/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1117 - acc: 0.9645 - val_loss: 0.1200 - val_acc: 0.9351
Epoch 20/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1112 - acc: 0.9666 - val_loss: 0.1190 - val_acc: 0.9363
Manual evaluation: (didn't understand why I made this)
True 8147
False 924
True percentage 0.898136919854
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.90      0.76      0.82       438
      B-LOC       0.71      0.76      0.73       218
      B-ORG       0.66      0.71      0.69       296
      I-ORG       0.54      0.46      0.50       151
      I-PER       0.92      0.64      0.75       214
      I-LOC       0.66      0.77      0.71       141
     B-MISC       0.51      0.26      0.35       141
     I-MISC       0.50      0.39      0.44       154

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.677341389728
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1616 - acc: 0.8073 - val_loss: 0.1369 - val_acc: 0.8892
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1349 - acc: 0.8880 - val_loss: 0.1315 - val_acc: 0.9039
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1291 - acc: 0.9063 - val_loss: 0.1301 - val_acc: 0.9080
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1260 - acc: 0.9164 - val_loss: 0.1273 - val_acc: 0.9205
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1238 - acc: 0.9259 - val_loss: 0.1253 - val_acc: 0.9227
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1224 - acc: 0.9279 - val_loss: 0.1245 - val_acc: 0.9204
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1205 - acc: 0.9365 - val_loss: 0.1239 - val_acc: 0.9207
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1190 - acc: 0.9408 - val_loss: 0.1230 - val_acc: 0.9238
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1184 - acc: 0.9406 - val_loss: 0.1234 - val_acc: 0.9237
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1170 - acc: 0.9470 - val_loss: 0.1225 - val_acc: 0.9259
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1160 - acc: 0.9496 - val_loss: 0.1225 - val_acc: 0.9269
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1154 - acc: 0.9529 - val_loss: 0.1225 - val_acc: 0.9278
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1145 - acc: 0.9547 - val_loss: 0.1215 - val_acc: 0.9270
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1136 - acc: 0.9595 - val_loss: 0.1212 - val_acc: 0.9280
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1131 - acc: 0.9581 - val_loss: 0.1219 - val_acc: 0.9288
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1127 - acc: 0.9600 - val_loss: 0.1213 - val_acc: 0.9294
Epoch 17/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1122 - acc: 0.9633 - val_loss: 0.1208 - val_acc: 0.9301
Epoch 18/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1125 - acc: 0.9605 - val_loss: 0.1210 - val_acc: 0.9316
Epoch 19/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1115 - acc: 0.9640 - val_loss: 0.1210 - val_acc: 0.9337
Epoch 20/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1108 - acc: 0.9664 - val_loss: 0.1211 - val_acc: 0.9310
Manual evaluation: (didn't understand why I made this)
True 8183
False 888
True percentage 0.902105611289
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.69      0.70      0.70       296
      B-LOC       0.72      0.75      0.74       218
      I-ORG       0.49      0.52      0.50       151
     B-MISC       0.55      0.34      0.42       141
     I-MISC       0.50      0.40      0.44       154
      B-PER       0.89      0.81      0.85       438
      I-PER       0.87      0.65      0.74       214
      I-LOC       0.72      0.79      0.76       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.693452380952
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1672 - acc: 0.7959 - val_loss: 0.1361 - val_acc: 0.8851
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1349 - acc: 0.8887 - val_loss: 0.1301 - val_acc: 0.8997
Epoch 3/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1309 - acc: 0.9023 - val_loss: 0.1274 - val_acc: 0.9077
Epoch 4/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1269 - acc: 0.9124 - val_loss: 0.1253 - val_acc: 0.9126
Epoch 5/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1252 - acc: 0.9201 - val_loss: 0.1232 - val_acc: 0.9187
Epoch 6/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1225 - acc: 0.9292 - val_loss: 0.1224 - val_acc: 0.9235
Epoch 7/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1210 - acc: 0.9357 - val_loss: 0.1214 - val_acc: 0.9307
Epoch 8/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1200 - acc: 0.9370 - val_loss: 0.1211 - val_acc: 0.9289
Epoch 9/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1185 - acc: 0.9435 - val_loss: 0.1213 - val_acc: 0.9315
Epoch 10/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1178 - acc: 0.9436 - val_loss: 0.1200 - val_acc: 0.9331
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1168 - acc: 0.9480 - val_loss: 0.1196 - val_acc: 0.9350
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1169 - acc: 0.9473 - val_loss: 0.1202 - val_acc: 0.9348
Epoch 13/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1153 - acc: 0.9535 - val_loss: 0.1202 - val_acc: 0.9340
Epoch 14/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1145 - acc: 0.9543 - val_loss: 0.1196 - val_acc: 0.9360
Epoch 15/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1135 - acc: 0.9598 - val_loss: 0.1209 - val_acc: 0.9361
Epoch 16/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1133 - acc: 0.9595 - val_loss: 0.1205 - val_acc: 0.9378
Epoch 17/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1133 - acc: 0.9602 - val_loss: 0.1197 - val_acc: 0.9382
Manual evaluation: (didn't understand why I made this)
True 8095
False 976
True percentage 0.892404365561
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.88      0.76      0.82       438
      B-LOC       0.71      0.76      0.74       218
      B-ORG       0.62      0.73      0.67       296
      I-ORG       0.39      0.40      0.39       151
      I-PER       0.89      0.65      0.75       214
      I-LOC       0.64      0.80      0.71       141
     B-MISC       0.43      0.14      0.21       141
     I-MISC       0.45      0.22      0.30       154

avg / total       0.93      0.89      0.91      9071

F-1 Score:
0.65100873231
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1658 - acc: 0.8020 - val_loss: 0.1368 - val_acc: 0.8883
Epoch 2/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1359 - acc: 0.8834 - val_loss: 0.1323 - val_acc: 0.9034
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1301 - acc: 0.9004 - val_loss: 0.1284 - val_acc: 0.9153
Epoch 4/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1270 - acc: 0.9151 - val_loss: 0.1262 - val_acc: 0.9189
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1244 - acc: 0.9236 - val_loss: 0.1252 - val_acc: 0.9186
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1226 - acc: 0.9288 - val_loss: 0.1244 - val_acc: 0.9210
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1210 - acc: 0.9339 - val_loss: 0.1233 - val_acc: 0.9223
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1199 - acc: 0.9376 - val_loss: 0.1232 - val_acc: 0.9219
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1180 - acc: 0.9440 - val_loss: 0.1228 - val_acc: 0.9230
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1178 - acc: 0.9439 - val_loss: 0.1225 - val_acc: 0.9262
Epoch 11/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1168 - acc: 0.9474 - val_loss: 0.1219 - val_acc: 0.9310
Epoch 12/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1161 - acc: 0.9500 - val_loss: 0.1216 - val_acc: 0.9284
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1145 - acc: 0.9543 - val_loss: 0.1211 - val_acc: 0.9275
Epoch 14/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1140 - acc: 0.9563 - val_loss: 0.1210 - val_acc: 0.9317
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1137 - acc: 0.9579 - val_loss: 0.1212 - val_acc: 0.9275
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1132 - acc: 0.9600 - val_loss: 0.1212 - val_acc: 0.9325
Epoch 17/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1127 - acc: 0.9620 - val_loss: 0.1209 - val_acc: 0.9304
Epoch 18/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1122 - acc: 0.9616 - val_loss: 0.1209 - val_acc: 0.9329
Epoch 19/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1117 - acc: 0.9625 - val_loss: 0.1211 - val_acc: 0.9322
Epoch 20/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1113 - acc: 0.9661 - val_loss: 0.1208 - val_acc: 0.9325
Epoch 21/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1103 - acc: 0.9686 - val_loss: 0.1208 - val_acc: 0.9341
Epoch 22/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1105 - acc: 0.9679 - val_loss: 0.1211 - val_acc: 0.9344
Epoch 23/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1099 - acc: 0.9703 - val_loss: 0.1211 - val_acc: 0.9328
Epoch 24/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1099 - acc: 0.9681 - val_loss: 0.1209 - val_acc: 0.9329
Manual evaluation: (didn't understand why I made this)
True 8188
False 883
True percentage 0.902656818432
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.72      0.69      0.70       296
      B-LOC       0.71      0.79      0.75       218
      I-ORG       0.53      0.44      0.48       151
     B-MISC       0.52      0.32      0.39       141
     I-MISC       0.43      0.46      0.44       154
      B-PER       0.91      0.83      0.87       438
      I-PER       0.92      0.64      0.76       214
      I-LOC       0.69      0.79      0.74       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.695755417038
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1618 - acc: 0.8167 - val_loss: 0.1331 - val_acc: 0.8867
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1347 - acc: 0.8884 - val_loss: 0.1284 - val_acc: 0.9074
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1296 - acc: 0.9054 - val_loss: 0.1258 - val_acc: 0.9097
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1261 - acc: 0.9159 - val_loss: 0.1246 - val_acc: 0.9122
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1237 - acc: 0.9274 - val_loss: 0.1234 - val_acc: 0.9200
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1219 - acc: 0.9304 - val_loss: 0.1230 - val_acc: 0.9185
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1210 - acc: 0.9357 - val_loss: 0.1213 - val_acc: 0.9234
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1195 - acc: 0.9378 - val_loss: 0.1211 - val_acc: 0.9251
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1180 - acc: 0.9438 - val_loss: 0.1213 - val_acc: 0.9281
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1175 - acc: 0.9449 - val_loss: 0.1202 - val_acc: 0.9291
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1167 - acc: 0.9489 - val_loss: 0.1201 - val_acc: 0.9305
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1158 - acc: 0.9518 - val_loss: 0.1197 - val_acc: 0.9327
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1149 - acc: 0.9539 - val_loss: 0.1205 - val_acc: 0.9310
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1143 - acc: 0.9560 - val_loss: 0.1197 - val_acc: 0.9326
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1137 - acc: 0.9579 - val_loss: 0.1188 - val_acc: 0.9360
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1135 - acc: 0.9585 - val_loss: 0.1195 - val_acc: 0.9347
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1127 - acc: 0.9628 - val_loss: 0.1196 - val_acc: 0.9373
Epoch 18/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1127 - acc: 0.9600 - val_loss: 0.1197 - val_acc: 0.9376
Manual evaluation: (didn't understand why I made this)
True 8128
False 943
True percentage 0.896042332709
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.89      0.77      0.83       438
      B-LOC       0.70      0.76      0.73       218
      B-ORG       0.68      0.72      0.70       296
      I-ORG       0.42      0.50      0.45       151
      I-PER       0.90      0.64      0.75       214
      I-LOC       0.66      0.79      0.72       141
     B-MISC       0.52      0.23      0.32       141
     I-MISC       0.53      0.25      0.34       154

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.66968053044
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1620 - acc: 0.8132 - val_loss: 0.1364 - val_acc: 0.8889
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1350 - acc: 0.8879 - val_loss: 0.1316 - val_acc: 0.8978
Epoch 3/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1297 - acc: 0.9031 - val_loss: 0.1283 - val_acc: 0.9059
Epoch 4/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1268 - acc: 0.9148 - val_loss: 0.1264 - val_acc: 0.9152
Epoch 5/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1244 - acc: 0.9220 - val_loss: 0.1247 - val_acc: 0.9209
Epoch 6/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1224 - acc: 0.9288 - val_loss: 0.1241 - val_acc: 0.9165
Epoch 7/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1208 - acc: 0.9338 - val_loss: 0.1231 - val_acc: 0.9239
Epoch 8/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1196 - acc: 0.9384 - val_loss: 0.1231 - val_acc: 0.9238
Epoch 9/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1180 - acc: 0.9441 - val_loss: 0.1221 - val_acc: 0.9219
Epoch 10/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1170 - acc: 0.9447 - val_loss: 0.1220 - val_acc: 0.9198
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1166 - acc: 0.9482 - val_loss: 0.1224 - val_acc: 0.9267
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1152 - acc: 0.9553 - val_loss: 0.1217 - val_acc: 0.9252
Epoch 13/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1147 - acc: 0.9528 - val_loss: 0.1212 - val_acc: 0.9289
Epoch 14/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1141 - acc: 0.9555 - val_loss: 0.1207 - val_acc: 0.9263
Epoch 15/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1135 - acc: 0.9562 - val_loss: 0.1209 - val_acc: 0.9278
Epoch 16/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1129 - acc: 0.9600 - val_loss: 0.1207 - val_acc: 0.9283
Epoch 17/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1126 - acc: 0.9607 - val_loss: 0.1208 - val_acc: 0.9316
Manual evaluation: (didn't understand why I made this)
True 8190
False 881
True percentage 0.90287730129
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.73      0.71      0.72       296
      B-LOC       0.74      0.76      0.75       218
      I-ORG       0.49      0.45      0.47       151
     B-MISC       0.49      0.28      0.36       141
     I-MISC       0.48      0.36      0.41       154
      B-PER       0.91      0.81      0.86       438
      I-PER       0.90      0.65      0.75       214
      I-LOC       0.68      0.83      0.75       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.692747517304
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1668 - acc: 0.7917 - val_loss: 0.1342 - val_acc: 0.8907
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1368 - acc: 0.8805 - val_loss: 0.1291 - val_acc: 0.9043
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1305 - acc: 0.9025 - val_loss: 0.1267 - val_acc: 0.9094
Epoch 4/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1272 - acc: 0.9151 - val_loss: 0.1239 - val_acc: 0.9229
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1248 - acc: 0.9219 - val_loss: 0.1241 - val_acc: 0.9188
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1226 - acc: 0.9302 - val_loss: 0.1237 - val_acc: 0.9196
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1212 - acc: 0.9321 - val_loss: 0.1224 - val_acc: 0.9259
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1200 - acc: 0.9377 - val_loss: 0.1205 - val_acc: 0.9309
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1189 - acc: 0.9413 - val_loss: 0.1214 - val_acc: 0.9283
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1179 - acc: 0.9462 - val_loss: 0.1210 - val_acc: 0.9290
Epoch 11/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1173 - acc: 0.9476 - val_loss: 0.1192 - val_acc: 0.9323
Epoch 12/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1165 - acc: 0.9503 - val_loss: 0.1202 - val_acc: 0.9318
Epoch 13/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1155 - acc: 0.9529 - val_loss: 0.1192 - val_acc: 0.9316
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1148 - acc: 0.9562 - val_loss: 0.1199 - val_acc: 0.9333
Epoch 15/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1142 - acc: 0.9579 - val_loss: 0.1199 - val_acc: 0.9364
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1139 - acc: 0.9591 - val_loss: 0.1192 - val_acc: 0.9346
Manual evaluation: (didn't understand why I made this)
True 8111
False 960
True percentage 0.89416822842
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.86      0.74      0.80       438
      B-LOC       0.73      0.74      0.74       218
      B-ORG       0.66      0.72      0.69       296
      I-ORG       0.44      0.49      0.46       151
      I-PER       0.84      0.66      0.74       214
      I-LOC       0.68      0.77      0.72       141
     B-MISC       0.52      0.26      0.35       141
     I-MISC       0.43      0.32      0.37       154

avg / total       0.93      0.89      0.91      9071

F-1 Score:
0.660895522388
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1660 - acc: 0.7977 - val_loss: 0.1371 - val_acc: 0.8721
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1361 - acc: 0.8833 - val_loss: 0.1305 - val_acc: 0.9062
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1303 - acc: 0.9037 - val_loss: 0.1288 - val_acc: 0.9106
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1269 - acc: 0.9147 - val_loss: 0.1266 - val_acc: 0.9161
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1247 - acc: 0.9212 - val_loss: 0.1253 - val_acc: 0.9199
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1225 - acc: 0.9277 - val_loss: 0.1246 - val_acc: 0.9214
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1206 - acc: 0.9350 - val_loss: 0.1249 - val_acc: 0.9216
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1194 - acc: 0.9384 - val_loss: 0.1239 - val_acc: 0.9213
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1189 - acc: 0.9411 - val_loss: 0.1238 - val_acc: 0.9222
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1173 - acc: 0.9455 - val_loss: 0.1228 - val_acc: 0.9250
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1166 - acc: 0.9484 - val_loss: 0.1227 - val_acc: 0.9263
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1164 - acc: 0.9487 - val_loss: 0.1220 - val_acc: 0.9296
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1150 - acc: 0.9535 - val_loss: 0.1222 - val_acc: 0.9298
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1142 - acc: 0.9562 - val_loss: 0.1218 - val_acc: 0.9269
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1139 - acc: 0.9563 - val_loss: 0.1220 - val_acc: 0.9304
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1131 - acc: 0.9598 - val_loss: 0.1217 - val_acc: 0.9299
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1129 - acc: 0.9611 - val_loss: 0.1217 - val_acc: 0.9299
Epoch 18/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1120 - acc: 0.9643 - val_loss: 0.1218 - val_acc: 0.9299
Epoch 19/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1120 - acc: 0.9641 - val_loss: 0.1213 - val_acc: 0.9330
Epoch 20/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1117 - acc: 0.9623 - val_loss: 0.1215 - val_acc: 0.9324
Epoch 21/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1105 - acc: 0.9675 - val_loss: 0.1215 - val_acc: 0.9335
Epoch 22/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1110 - acc: 0.9673 - val_loss: 0.1214 - val_acc: 0.9316
Manual evaluation: (didn't understand why I made this)
True 8157
False 914
True percentage 0.899239334142
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.73      0.66      0.69       296
      B-LOC       0.71      0.78      0.74       218
      I-ORG       0.52      0.37      0.43       151
     B-MISC       0.46      0.36      0.41       141
     I-MISC       0.39      0.44      0.41       154
      B-PER       0.91      0.80      0.85       438
      I-PER       0.86      0.65      0.74       214
      I-LOC       0.66      0.83      0.74       141

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.679513785947
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1852 - acc: 0.7518 - val_loss: 0.1351 - val_acc: 0.8927
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1431 - acc: 0.8599 - val_loss: 0.1416 - val_acc: 0.8431
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1389 - acc: 0.8737 - val_loss: 0.1257 - val_acc: 0.9150
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1334 - acc: 0.8945 - val_loss: 0.1235 - val_acc: 0.9277
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1305 - acc: 0.9015 - val_loss: 0.1237 - val_acc: 0.9273
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1274 - acc: 0.9117 - val_loss: 0.1233 - val_acc: 0.9321
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1259 - acc: 0.9163 - val_loss: 0.1221 - val_acc: 0.9301
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1249 - acc: 0.9204 - val_loss: 0.1216 - val_acc: 0.9259
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1230 - acc: 0.9268 - val_loss: 0.1202 - val_acc: 0.9372
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1212 - acc: 0.9329 - val_loss: 0.1191 - val_acc: 0.9400
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1200 - acc: 0.9344 - val_loss: 0.1215 - val_acc: 0.9325
Epoch 12/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1197 - acc: 0.9389 - val_loss: 0.1200 - val_acc: 0.9386
Epoch 13/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1179 - acc: 0.9453 - val_loss: 0.1193 - val_acc: 0.9377
Manual evaluation: (didn't understand why I made this)
True 7890
False 1181
True percentage 0.869804872671
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.82      0.69      0.75       438
      B-LOC       0.65      0.70      0.67       218
      B-ORG       0.66      0.49      0.56       296
      I-ORG       0.21      0.30      0.25       151
      I-PER       0.84      0.56      0.67       214
      I-LOC       0.58      0.60      0.59       141
     B-MISC       0.35      0.21      0.27       141
     I-MISC       0.30      0.23      0.26       154

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.558224384311
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 9s 28ms/step - loss: 0.1845 - acc: 0.7482 - val_loss: 0.1488 - val_acc: 0.8264
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1404 - acc: 0.8709 - val_loss: 0.1464 - val_acc: 0.8175
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1347 - acc: 0.8894 - val_loss: 0.1361 - val_acc: 0.8693
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1308 - acc: 0.9070 - val_loss: 0.1378 - val_acc: 0.8638
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1279 - acc: 0.9129 - val_loss: 0.1334 - val_acc: 0.8818
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1255 - acc: 0.9219 - val_loss: 0.1289 - val_acc: 0.9028
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1239 - acc: 0.9280 - val_loss: 0.1302 - val_acc: 0.8931
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1225 - acc: 0.9315 - val_loss: 0.1302 - val_acc: 0.8946
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1200 - acc: 0.9362 - val_loss: 0.1284 - val_acc: 0.8986
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1198 - acc: 0.9369 - val_loss: 0.1277 - val_acc: 0.9014
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1185 - acc: 0.9445 - val_loss: 0.1282 - val_acc: 0.9043
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1170 - acc: 0.9459 - val_loss: 0.1248 - val_acc: 0.9083
Epoch 13/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1165 - acc: 0.9465 - val_loss: 0.1279 - val_acc: 0.9028
Epoch 14/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1150 - acc: 0.9541 - val_loss: 0.1238 - val_acc: 0.9168
Epoch 15/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1150 - acc: 0.9539 - val_loss: 0.1276 - val_acc: 0.9071
Epoch 16/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1145 - acc: 0.9548 - val_loss: 0.1244 - val_acc: 0.9154
Epoch 17/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1131 - acc: 0.9607 - val_loss: 0.1275 - val_acc: 0.9111
Manual evaluation: (didn't understand why I made this)
True 8022
False 1049
True percentage 0.884356741263
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-ORG       0.55      0.72      0.62       296
      B-LOC       0.71      0.69      0.70       218
      I-ORG       0.32      0.58      0.41       151
     B-MISC       0.44      0.09      0.14       141
     I-MISC       0.59      0.14      0.23       154
      B-PER       0.88      0.75      0.81       438
      I-PER       0.83      0.60      0.70       214
      I-LOC       0.74      0.76      0.75       141

avg / total       0.93      0.88      0.90      9071

F-1 Score:
0.624740433106
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.2001 - acc: 0.7156 - val_loss: 0.1394 - val_acc: 0.8743
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1468 - acc: 0.8496 - val_loss: 0.1335 - val_acc: 0.9089
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1391 - acc: 0.8784 - val_loss: 0.1292 - val_acc: 0.9107
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1355 - acc: 0.8859 - val_loss: 0.1259 - val_acc: 0.9216
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1320 - acc: 0.9014 - val_loss: 0.1248 - val_acc: 0.9230
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1297 - acc: 0.9058 - val_loss: 0.1238 - val_acc: 0.9254
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1276 - acc: 0.9158 - val_loss: 0.1230 - val_acc: 0.9339
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1253 - acc: 0.9213 - val_loss: 0.1218 - val_acc: 0.9315
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1252 - acc: 0.9224 - val_loss: 0.1216 - val_acc: 0.9297
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1230 - acc: 0.9274 - val_loss: 0.1253 - val_acc: 0.9151
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1217 - acc: 0.9317 - val_loss: 0.1198 - val_acc: 0.9329
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1214 - acc: 0.9325 - val_loss: 0.1204 - val_acc: 0.9396
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1194 - acc: 0.9401 - val_loss: 0.1202 - val_acc: 0.9349
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1184 - acc: 0.9427 - val_loss: 0.1189 - val_acc: 0.9396
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1174 - acc: 0.9460 - val_loss: 0.1189 - val_acc: 0.9410
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1170 - acc: 0.9474 - val_loss: 0.1193 - val_acc: 0.9396
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1161 - acc: 0.9483 - val_loss: 0.1198 - val_acc: 0.9377
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1159 - acc: 0.9518 - val_loss: 0.1188 - val_acc: 0.9391
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1151 - acc: 0.9517 - val_loss: 0.1186 - val_acc: 0.9424
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1140 - acc: 0.9521 - val_loss: 0.1182 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1137 - acc: 0.9572 - val_loss: 0.1183 - val_acc: 0.9396
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1138 - acc: 0.9586 - val_loss: 0.1182 - val_acc: 0.9448
Epoch 23/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1131 - acc: 0.9587 - val_loss: 0.1176 - val_acc: 0.9452
Epoch 24/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1129 - acc: 0.9617 - val_loss: 0.1176 - val_acc: 0.9495
Epoch 25/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1124 - acc: 0.9610 - val_loss: 0.1180 - val_acc: 0.9448
Epoch 26/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1119 - acc: 0.9640 - val_loss: 0.1184 - val_acc: 0.9434
Manual evaluation: (didn't understand why I made this)
True 7955
False 1116
True percentage 0.876970565539
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.87      0.70      0.78       438
      B-LOC       0.69      0.73      0.71       218
      B-ORG       0.57      0.61      0.59       296
      I-ORG       0.34      0.42      0.38       151
      I-PER       0.86      0.56      0.67       214
      I-LOC       0.63      0.72      0.67       141
     B-MISC       0.49      0.26      0.34       141
     I-MISC       0.34      0.25      0.29       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.605405405405
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.1920 - acc: 0.7328 - val_loss: 0.1473 - val_acc: 0.8198
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1423 - acc: 0.8624 - val_loss: 0.1471 - val_acc: 0.8399
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1347 - acc: 0.8918 - val_loss: 0.1387 - val_acc: 0.8652
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1310 - acc: 0.9075 - val_loss: 0.1376 - val_acc: 0.8749
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1285 - acc: 0.9103 - val_loss: 0.1337 - val_acc: 0.8822
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1261 - acc: 0.9232 - val_loss: 0.1300 - val_acc: 0.8929
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1243 - acc: 0.9226 - val_loss: 0.1321 - val_acc: 0.8917
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1228 - acc: 0.9330 - val_loss: 0.1318 - val_acc: 0.8889
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1211 - acc: 0.9341 - val_loss: 0.1324 - val_acc: 0.8861
Manual evaluation: (didn't understand why I made this)
True 7934
False 1137
True percentage 0.874655495535
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-ORG       0.50      0.72      0.59       296
      B-LOC       0.78      0.63      0.70       218
      I-ORG       0.25      0.58      0.35       151
     B-MISC       0.25      0.01      0.01       141
     I-MISC       0.53      0.06      0.11       154
      B-PER       0.85      0.73      0.78       438
      I-PER       0.80      0.56      0.66       214
      I-LOC       0.69      0.65      0.67       141

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.577252584934
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1966 - acc: 0.7278 - val_loss: 0.1437 - val_acc: 0.8610
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1459 - acc: 0.8575 - val_loss: 0.1366 - val_acc: 0.8843
Epoch 3/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1385 - acc: 0.8779 - val_loss: 0.1299 - val_acc: 0.9083
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1348 - acc: 0.8912 - val_loss: 0.1278 - val_acc: 0.9160
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1322 - acc: 0.8981 - val_loss: 0.1238 - val_acc: 0.9249
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1294 - acc: 0.9042 - val_loss: 0.1235 - val_acc: 0.9325
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1258 - acc: 0.9187 - val_loss: 0.1231 - val_acc: 0.9311
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1250 - acc: 0.9206 - val_loss: 0.1225 - val_acc: 0.9321
Epoch 9/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1243 - acc: 0.9220 - val_loss: 0.1216 - val_acc: 0.9329
Epoch 10/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1229 - acc: 0.9266 - val_loss: 0.1221 - val_acc: 0.9277
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1207 - acc: 0.9360 - val_loss: 0.1204 - val_acc: 0.9410
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1205 - acc: 0.9348 - val_loss: 0.1204 - val_acc: 0.9406
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1187 - acc: 0.9437 - val_loss: 0.1198 - val_acc: 0.9434
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1180 - acc: 0.9434 - val_loss: 0.1205 - val_acc: 0.9391
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1171 - acc: 0.9461 - val_loss: 0.1196 - val_acc: 0.9438
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1179 - acc: 0.9435 - val_loss: 0.1234 - val_acc: 0.9283
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1171 - acc: 0.9449 - val_loss: 0.1190 - val_acc: 0.9462
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1152 - acc: 0.9548 - val_loss: 0.1187 - val_acc: 0.9462
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1139 - acc: 0.9580 - val_loss: 0.1207 - val_acc: 0.9420
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1135 - acc: 0.9606 - val_loss: 0.1190 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1131 - acc: 0.9593 - val_loss: 0.1184 - val_acc: 0.9434
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1131 - acc: 0.9611 - val_loss: 0.1187 - val_acc: 0.9382
Epoch 23/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1128 - acc: 0.9611 - val_loss: 0.1185 - val_acc: 0.9434
Epoch 24/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1124 - acc: 0.9623 - val_loss: 0.1185 - val_acc: 0.9434
Manual evaluation: (didn't understand why I made this)
True 7954
False 1117
True percentage 0.87686032411
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.87      0.71      0.78       438
      B-LOC       0.67      0.68      0.68       218
      B-ORG       0.56      0.63      0.59       296
      I-ORG       0.32      0.47      0.38       151
      I-PER       0.85      0.58      0.69       214
      I-LOC       0.65      0.57      0.61       141
     B-MISC       0.48      0.21      0.29       141
     I-MISC       0.39      0.21      0.28       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.596671709531
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1864 - acc: 0.7381 - val_loss: 0.1451 - val_acc: 0.8365
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1409 - acc: 0.8677 - val_loss: 0.1387 - val_acc: 0.8553
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1348 - acc: 0.8937 - val_loss: 0.1360 - val_acc: 0.8846
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1310 - acc: 0.8999 - val_loss: 0.1319 - val_acc: 0.8910
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1285 - acc: 0.9123 - val_loss: 0.1319 - val_acc: 0.8972
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1265 - acc: 0.9176 - val_loss: 0.1296 - val_acc: 0.8917
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1238 - acc: 0.9247 - val_loss: 0.1287 - val_acc: 0.9028
Epoch 8/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1225 - acc: 0.9294 - val_loss: 0.1347 - val_acc: 0.8792
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1218 - acc: 0.9361 - val_loss: 0.1260 - val_acc: 0.9028
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1197 - acc: 0.9378 - val_loss: 0.1288 - val_acc: 0.9000
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1181 - acc: 0.9439 - val_loss: 0.1291 - val_acc: 0.8958
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1176 - acc: 0.9428 - val_loss: 0.1258 - val_acc: 0.8998
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1164 - acc: 0.9513 - val_loss: 0.1277 - val_acc: 0.8972
Epoch 14/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1155 - acc: 0.9550 - val_loss: 0.1300 - val_acc: 0.8998
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1151 - acc: 0.9535 - val_loss: 0.1267 - val_acc: 0.9069
Manual evaluation: (didn't understand why I made this)
True 8037
False 1034
True percentage 0.886010362694
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.68      0.56      0.61       296
      B-LOC       0.69      0.68      0.69       218
      I-ORG       0.40      0.46      0.43       151
     B-MISC       0.34      0.26      0.29       141
     I-MISC       0.47      0.21      0.29       154
      B-PER       0.81      0.81      0.81       438
      I-PER       0.85      0.57      0.68       214
      I-LOC       0.65      0.82      0.72       141

avg / total       0.92      0.89      0.90      9071

F-1 Score:
0.628243814122
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.1987 - acc: 0.7119 - val_loss: 0.1413 - val_acc: 0.8853
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1464 - acc: 0.8530 - val_loss: 0.1330 - val_acc: 0.9014
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1395 - acc: 0.8704 - val_loss: 0.1291 - val_acc: 0.9183
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1349 - acc: 0.8911 - val_loss: 0.1258 - val_acc: 0.9212
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1316 - acc: 0.8997 - val_loss: 0.1236 - val_acc: 0.9249
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1294 - acc: 0.9030 - val_loss: 0.1240 - val_acc: 0.9254
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1264 - acc: 0.9135 - val_loss: 0.1221 - val_acc: 0.9367
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1244 - acc: 0.9220 - val_loss: 0.1221 - val_acc: 0.9291
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1242 - acc: 0.9239 - val_loss: 0.1216 - val_acc: 0.9363
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1226 - acc: 0.9271 - val_loss: 0.1206 - val_acc: 0.9382
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1210 - acc: 0.9327 - val_loss: 0.1195 - val_acc: 0.9410
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1200 - acc: 0.9371 - val_loss: 0.1204 - val_acc: 0.9283
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1192 - acc: 0.9385 - val_loss: 0.1191 - val_acc: 0.9391
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1187 - acc: 0.9395 - val_loss: 0.1189 - val_acc: 0.9462
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1181 - acc: 0.9474 - val_loss: 0.1192 - val_acc: 0.9420
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1163 - acc: 0.9483 - val_loss: 0.1228 - val_acc: 0.9278
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1158 - acc: 0.9523 - val_loss: 0.1184 - val_acc: 0.9490
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1146 - acc: 0.9576 - val_loss: 0.1185 - val_acc: 0.9448
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1151 - acc: 0.9538 - val_loss: 0.1186 - val_acc: 0.9448
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1137 - acc: 0.9583 - val_loss: 0.1182 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1128 - acc: 0.9630 - val_loss: 0.1183 - val_acc: 0.9476
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1130 - acc: 0.9610 - val_loss: 0.1188 - val_acc: 0.9476
Epoch 23/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1126 - acc: 0.9621 - val_loss: 0.1182 - val_acc: 0.9462
Epoch 24/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1108 - acc: 0.9671 - val_loss: 0.1185 - val_acc: 0.9476
Epoch 25/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1117 - acc: 0.9632 - val_loss: 0.1189 - val_acc: 0.9448
Epoch 26/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1115 - acc: 0.9661 - val_loss: 0.1182 - val_acc: 0.9462
Manual evaluation: (didn't understand why I made this)
True 7905
False 1166
True percentage 0.871458494102
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.88      0.71      0.78       438
      B-LOC       0.66      0.66      0.66       218
      B-ORG       0.52      0.65      0.58       296
      I-ORG       0.26      0.49      0.34       151
      I-PER       0.90      0.56      0.69       214
      I-LOC       0.65      0.53      0.59       141
     B-MISC       0.39      0.16      0.23       141
     I-MISC       0.33      0.11      0.17       154

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.573057305731
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1824 - acc: 0.7374 - val_loss: 0.1442 - val_acc: 0.8574
Epoch 2/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1407 - acc: 0.8717 - val_loss: 0.1382 - val_acc: 0.8725
Epoch 3/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1348 - acc: 0.8895 - val_loss: 0.1373 - val_acc: 0.8624
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1309 - acc: 0.9064 - val_loss: 0.1364 - val_acc: 0.8780
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1275 - acc: 0.9151 - val_loss: 0.1320 - val_acc: 0.8846
Epoch 6/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1255 - acc: 0.9228 - val_loss: 0.1348 - val_acc: 0.8891
Epoch 7/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1241 - acc: 0.9278 - val_loss: 0.1337 - val_acc: 0.8846
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1222 - acc: 0.9314 - val_loss: 0.1306 - val_acc: 0.8929
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1201 - acc: 0.9385 - val_loss: 0.1318 - val_acc: 0.8901
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1195 - acc: 0.9405 - val_loss: 0.1314 - val_acc: 0.8887
Epoch 11/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1178 - acc: 0.9459 - val_loss: 0.1266 - val_acc: 0.9043
Epoch 12/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1173 - acc: 0.9452 - val_loss: 0.1266 - val_acc: 0.9123
Epoch 13/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1164 - acc: 0.9500 - val_loss: 0.1269 - val_acc: 0.9043
Epoch 14/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1160 - acc: 0.9514 - val_loss: 0.1286 - val_acc: 0.8998
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1156 - acc: 0.9506 - val_loss: 0.1275 - val_acc: 0.9085
Manual evaluation: (didn't understand why I made this)
True 8014
False 1057
True percentage 0.883474809834
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-ORG       0.57      0.66      0.62       296
      B-LOC       0.75      0.65      0.70       218
      I-ORG       0.33      0.50      0.40       151
     B-MISC       0.36      0.21      0.26       141
     I-MISC       0.38      0.24      0.29       154
      B-PER       0.87      0.76      0.81       438
      I-PER       0.79      0.61      0.69       214
      I-LOC       0.79      0.72      0.76       141

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.620178041543
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1854 - acc: 0.7356 - val_loss: 0.1376 - val_acc: 0.8909
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1433 - acc: 0.8642 - val_loss: 0.1342 - val_acc: 0.8946
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1388 - acc: 0.8730 - val_loss: 0.1286 - val_acc: 0.9192
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1331 - acc: 0.8924 - val_loss: 0.1249 - val_acc: 0.9178
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1316 - acc: 0.9020 - val_loss: 0.1235 - val_acc: 0.9249
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1283 - acc: 0.9132 - val_loss: 0.1224 - val_acc: 0.9244
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1266 - acc: 0.9160 - val_loss: 0.1226 - val_acc: 0.9277
Epoch 8/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1250 - acc: 0.9232 - val_loss: 0.1211 - val_acc: 0.9344
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1239 - acc: 0.9226 - val_loss: 0.1222 - val_acc: 0.9391
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1214 - acc: 0.9326 - val_loss: 0.1209 - val_acc: 0.9382
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1206 - acc: 0.9349 - val_loss: 0.1197 - val_acc: 0.9344
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1191 - acc: 0.9401 - val_loss: 0.1200 - val_acc: 0.9372
Epoch 13/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1188 - acc: 0.9408 - val_loss: 0.1193 - val_acc: 0.9400
Epoch 14/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1174 - acc: 0.9462 - val_loss: 0.1196 - val_acc: 0.9420
Epoch 15/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1175 - acc: 0.9445 - val_loss: 0.1188 - val_acc: 0.9462
Epoch 16/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1164 - acc: 0.9497 - val_loss: 0.1189 - val_acc: 0.9434
Epoch 17/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1157 - acc: 0.9533 - val_loss: 0.1186 - val_acc: 0.9420
Epoch 18/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1151 - acc: 0.9541 - val_loss: 0.1191 - val_acc: 0.9434
Epoch 19/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1147 - acc: 0.9550 - val_loss: 0.1191 - val_acc: 0.9434
Epoch 20/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1139 - acc: 0.9585 - val_loss: 0.1185 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1132 - acc: 0.9624 - val_loss: 0.1181 - val_acc: 0.9452
Epoch 22/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1130 - acc: 0.9574 - val_loss: 0.1187 - val_acc: 0.9448
Epoch 23/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1122 - acc: 0.9604 - val_loss: 0.1186 - val_acc: 0.9505
Epoch 24/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1117 - acc: 0.9641 - val_loss: 0.1185 - val_acc: 0.9462
Manual evaluation: (didn't understand why I made this)
True 7998
False 1073
True percentage 0.881710946974
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.88      0.71      0.78       438
      B-LOC       0.69      0.72      0.71       218
      B-ORG       0.63      0.61      0.62       296
      I-ORG       0.32      0.40      0.36       151
      I-PER       0.86      0.58      0.69       214
      I-LOC       0.66      0.65      0.65       141
     B-MISC       0.48      0.25      0.33       141
     I-MISC       0.43      0.30      0.35       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.614634146341
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1834 - acc: 0.7413 - val_loss: 0.1495 - val_acc: 0.8270
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1416 - acc: 0.8700 - val_loss: 0.1402 - val_acc: 0.8579
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1348 - acc: 0.8918 - val_loss: 0.1335 - val_acc: 0.8818
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1308 - acc: 0.9021 - val_loss: 0.1382 - val_acc: 0.8735
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1284 - acc: 0.9116 - val_loss: 0.1314 - val_acc: 0.8863
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1253 - acc: 0.9214 - val_loss: 0.1310 - val_acc: 0.8804
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1240 - acc: 0.9261 - val_loss: 0.1267 - val_acc: 0.9043
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1225 - acc: 0.9286 - val_loss: 0.1313 - val_acc: 0.8974
Epoch 9/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1206 - acc: 0.9355 - val_loss: 0.1308 - val_acc: 0.9031
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1189 - acc: 0.9409 - val_loss: 0.1307 - val_acc: 0.8972
Manual evaluation: (didn't understand why I made this)
True 7976
False 1095
True percentage 0.879285635542
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-ORG       0.50      0.74      0.60       296
      B-LOC       0.78      0.63      0.70       218
      I-ORG       0.30      0.62      0.40       151
     B-MISC       0.43      0.02      0.04       141
     I-MISC       0.57      0.08      0.14       154
      B-PER       0.86      0.74      0.80       438
      I-PER       0.80      0.58      0.68       214
      I-LOC       0.75      0.67      0.71       141

avg / total       0.92      0.88      0.89      9071

F-1 Score:
0.598873406463
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2177 - acc: 0.6406 - val_loss: 0.1544 - val_acc: 0.8015
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1494 - acc: 0.8456 - val_loss: 0.1404 - val_acc: 0.8824
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1427 - acc: 0.8614 - val_loss: 0.1366 - val_acc: 0.8922
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1378 - acc: 0.8791 - val_loss: 0.1331 - val_acc: 0.8897
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1338 - acc: 0.8937 - val_loss: 0.1325 - val_acc: 0.8946
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1314 - acc: 0.8947 - val_loss: 0.1302 - val_acc: 0.9093
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1302 - acc: 0.9031 - val_loss: 0.1299 - val_acc: 0.9020
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1278 - acc: 0.9109 - val_loss: 0.1267 - val_acc: 0.9069
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1255 - acc: 0.9149 - val_loss: 0.1260 - val_acc: 0.9167
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1248 - acc: 0.9216 - val_loss: 0.1267 - val_acc: 0.9142
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1231 - acc: 0.9230 - val_loss: 0.1249 - val_acc: 0.9216
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1220 - acc: 0.9280 - val_loss: 0.1230 - val_acc: 0.9289
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1214 - acc: 0.9293 - val_loss: 0.1234 - val_acc: 0.9191
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1199 - acc: 0.9337 - val_loss: 0.1242 - val_acc: 0.9240
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9397 - val_loss: 0.1234 - val_acc: 0.9216
Manual evaluation: (didn't understand why I made this)
True 7758
False 1313
True percentage 0.855253004079
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-PER       0.84      0.64      0.73       438
      B-LOC       0.63      0.60      0.62       218
      B-ORG       0.47      0.64      0.54       296
      I-ORG       0.22      0.54      0.31       151
      I-PER       0.82      0.55      0.66       214
      I-LOC       0.51      0.31      0.39       141
     B-MISC       0.36      0.13      0.20       141
     I-MISC       0.20      0.05      0.08       154

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.512654502649
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2281 - acc: 0.6676 - val_loss: 0.1553 - val_acc: 0.8290
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1515 - acc: 0.8425 - val_loss: 0.1464 - val_acc: 0.8432
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1429 - acc: 0.8631 - val_loss: 0.1420 - val_acc: 0.8527
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1389 - acc: 0.8734 - val_loss: 0.1393 - val_acc: 0.8432
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1339 - acc: 0.8926 - val_loss: 0.1372 - val_acc: 0.8551
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1329 - acc: 0.8947 - val_loss: 0.1359 - val_acc: 0.8646
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1302 - acc: 0.9117 - val_loss: 0.1348 - val_acc: 0.8646
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1282 - acc: 0.9146 - val_loss: 0.1325 - val_acc: 0.8789
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1261 - acc: 0.9171 - val_loss: 0.1311 - val_acc: 0.8860
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1246 - acc: 0.9253 - val_loss: 0.1305 - val_acc: 0.8812
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1228 - acc: 0.9314 - val_loss: 0.1302 - val_acc: 0.8836
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1219 - acc: 0.9336 - val_loss: 0.1299 - val_acc: 0.8812
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9359 - val_loss: 0.1289 - val_acc: 0.8836
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9421 - val_loss: 0.1292 - val_acc: 0.8812
Epoch 15/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1193 - acc: 0.9430 - val_loss: 0.1289 - val_acc: 0.8836
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1190 - acc: 0.9412 - val_loss: 0.1279 - val_acc: 0.8907
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1176 - acc: 0.9456 - val_loss: 0.1278 - val_acc: 0.9050
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1157 - acc: 0.9541 - val_loss: 0.1275 - val_acc: 0.8884
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1160 - acc: 0.9524 - val_loss: 0.1278 - val_acc: 0.8884
Epoch 20/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1153 - acc: 0.9522 - val_loss: 0.1266 - val_acc: 0.9026
Epoch 21/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1136 - acc: 0.9587 - val_loss: 0.1263 - val_acc: 0.9026
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1145 - acc: 0.9555 - val_loss: 0.1260 - val_acc: 0.8931
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1147 - acc: 0.9538 - val_loss: 0.1261 - val_acc: 0.8979
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1139 - acc: 0.9580 - val_loss: 0.1256 - val_acc: 0.9002
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1120 - acc: 0.9637 - val_loss: 0.1255 - val_acc: 0.9002
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1111 - acc: 0.9642 - val_loss: 0.1254 - val_acc: 0.9121
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1121 - acc: 0.9620 - val_loss: 0.1255 - val_acc: 0.9050
Epoch 28/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1109 - acc: 0.9664 - val_loss: 0.1251 - val_acc: 0.9097
Epoch 29/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1106 - acc: 0.9664 - val_loss: 0.1245 - val_acc: 0.9002
Epoch 30/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1109 - acc: 0.9676 - val_loss: 0.1255 - val_acc: 0.9002
Epoch 31/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1101 - acc: 0.9732 - val_loss: 0.1270 - val_acc: 0.8979
Epoch 32/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1105 - acc: 0.9691 - val_loss: 0.1257 - val_acc: 0.8979
Manual evaluation: (didn't understand why I made this)
True 7894
False 1177
True percentage 0.870245838386
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-ORG       0.53      0.57      0.55       296
      B-LOC       0.67      0.67      0.67       218
      I-ORG       0.25      0.37      0.30       151
     B-MISC       0.37      0.18      0.24       141
     I-MISC       0.45      0.34      0.39       154
      B-PER       0.83      0.71      0.77       438
      I-PER       0.76      0.51      0.61       214
      I-LOC       0.65      0.79      0.71       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.579769979357
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2087 - acc: 0.6837 - val_loss: 0.1535 - val_acc: 0.8039
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1483 - acc: 0.8435 - val_loss: 0.1380 - val_acc: 0.8775
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1419 - acc: 0.8613 - val_loss: 0.1355 - val_acc: 0.8873
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1368 - acc: 0.8782 - val_loss: 0.1318 - val_acc: 0.8971
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1339 - acc: 0.8871 - val_loss: 0.1322 - val_acc: 0.9020
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1313 - acc: 0.8936 - val_loss: 0.1307 - val_acc: 0.9020
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1278 - acc: 0.9062 - val_loss: 0.1277 - val_acc: 0.9020
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1269 - acc: 0.9109 - val_loss: 0.1283 - val_acc: 0.8995
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1265 - acc: 0.9119 - val_loss: 0.1242 - val_acc: 0.9191
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1242 - acc: 0.9235 - val_loss: 0.1243 - val_acc: 0.9118
Epoch 11/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1238 - acc: 0.9262 - val_loss: 0.1231 - val_acc: 0.9142
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1222 - acc: 0.9281 - val_loss: 0.1224 - val_acc: 0.9191
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1196 - acc: 0.9384 - val_loss: 0.1224 - val_acc: 0.9265
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1188 - acc: 0.9398 - val_loss: 0.1225 - val_acc: 0.9240
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1185 - acc: 0.9425 - val_loss: 0.1225 - val_acc: 0.9265
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1174 - acc: 0.9439 - val_loss: 0.1207 - val_acc: 0.9338
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1165 - acc: 0.9511 - val_loss: 0.1210 - val_acc: 0.9265
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1165 - acc: 0.9487 - val_loss: 0.1208 - val_acc: 0.9314
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1153 - acc: 0.9530 - val_loss: 0.1208 - val_acc: 0.9216
Manual evaluation: (didn't understand why I made this)
True 7853
False 1218
True percentage 0.865725939808
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.85      0.67      0.75       438
      B-LOC       0.63      0.62      0.63       218
      B-ORG       0.57      0.59      0.58       296
      I-ORG       0.25      0.36      0.30       151
      I-PER       0.88      0.53      0.66       214
      I-LOC       0.44      0.48      0.46       141
     B-MISC       0.42      0.18      0.26       141
     I-MISC       0.27      0.14      0.19       154

avg / total       0.91      0.87      0.88      9071

F-1 Score:
0.543838136113
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2214 - acc: 0.6227 - val_loss: 0.1588 - val_acc: 0.8100
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1499 - acc: 0.8431 - val_loss: 0.1482 - val_acc: 0.8337
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1421 - acc: 0.8614 - val_loss: 0.1432 - val_acc: 0.8432
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1372 - acc: 0.8761 - val_loss: 0.1412 - val_acc: 0.8432
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1344 - acc: 0.8894 - val_loss: 0.1380 - val_acc: 0.8741
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1318 - acc: 0.9024 - val_loss: 0.1409 - val_acc: 0.8432
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1294 - acc: 0.9086 - val_loss: 0.1377 - val_acc: 0.8622
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1268 - acc: 0.9138 - val_loss: 0.1364 - val_acc: 0.8670
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1242 - acc: 0.9271 - val_loss: 0.1356 - val_acc: 0.8599
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1250 - acc: 0.9227 - val_loss: 0.1333 - val_acc: 0.8812
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1217 - acc: 0.9331 - val_loss: 0.1357 - val_acc: 0.8646
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9336 - val_loss: 0.1319 - val_acc: 0.8789
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1201 - acc: 0.9341 - val_loss: 0.1303 - val_acc: 0.9002
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9389 - val_loss: 0.1309 - val_acc: 0.8836
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1180 - acc: 0.9454 - val_loss: 0.1306 - val_acc: 0.8884
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1179 - acc: 0.9454 - val_loss: 0.1290 - val_acc: 0.9026
Epoch 17/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1172 - acc: 0.9506 - val_loss: 0.1323 - val_acc: 0.8812
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1163 - acc: 0.9496 - val_loss: 0.1285 - val_acc: 0.9002
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9537 - val_loss: 0.1289 - val_acc: 0.8860
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1149 - acc: 0.9544 - val_loss: 0.1290 - val_acc: 0.8931
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1154 - acc: 0.9548 - val_loss: 0.1293 - val_acc: 0.8907
Manual evaluation: (didn't understand why I made this)
True 7903
False 1168
True percentage 0.871238011245
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-ORG       0.61      0.55      0.58       296
      B-LOC       0.67      0.69      0.68       218
      I-ORG       0.26      0.40      0.31       151
     B-MISC       0.40      0.25      0.31       141
     I-MISC       0.51      0.27      0.35       154
      B-PER       0.82      0.71      0.76       438
      I-PER       0.70      0.55      0.62       214
      I-LOC       0.57      0.80      0.66       141

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.584388807069
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2028 - acc: 0.7689 - val_loss: 0.1548 - val_acc: 0.8015
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1480 - acc: 0.8458 - val_loss: 0.1491 - val_acc: 0.8211
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1410 - acc: 0.8722 - val_loss: 0.1372 - val_acc: 0.8676
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1358 - acc: 0.8847 - val_loss: 0.1310 - val_acc: 0.8995
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1329 - acc: 0.8895 - val_loss: 0.1322 - val_acc: 0.8946
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1301 - acc: 0.9048 - val_loss: 0.1305 - val_acc: 0.8873
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1283 - acc: 0.9093 - val_loss: 0.1273 - val_acc: 0.8922
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1263 - acc: 0.9141 - val_loss: 0.1278 - val_acc: 0.9044
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1253 - acc: 0.9141 - val_loss: 0.1248 - val_acc: 0.9093
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1230 - acc: 0.9278 - val_loss: 0.1233 - val_acc: 0.9216
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9335 - val_loss: 0.1248 - val_acc: 0.9044
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1210 - acc: 0.9310 - val_loss: 0.1227 - val_acc: 0.9191
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1209 - acc: 0.9281 - val_loss: 0.1225 - val_acc: 0.9191
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1184 - acc: 0.9456 - val_loss: 0.1219 - val_acc: 0.9240
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1173 - acc: 0.9471 - val_loss: 0.1216 - val_acc: 0.9118
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1169 - acc: 0.9468 - val_loss: 0.1209 - val_acc: 0.9216
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1162 - acc: 0.9480 - val_loss: 0.1210 - val_acc: 0.9191
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1156 - acc: 0.9531 - val_loss: 0.1204 - val_acc: 0.9289
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1143 - acc: 0.9576 - val_loss: 0.1197 - val_acc: 0.9338
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1144 - acc: 0.9574 - val_loss: 0.1206 - val_acc: 0.9240
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1129 - acc: 0.9574 - val_loss: 0.1202 - val_acc: 0.9289
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1130 - acc: 0.9614 - val_loss: 0.1194 - val_acc: 0.9289
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1118 - acc: 0.9602 - val_loss: 0.1188 - val_acc: 0.9436
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1120 - acc: 0.9654 - val_loss: 0.1185 - val_acc: 0.9412
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1109 - acc: 0.9696 - val_loss: 0.1180 - val_acc: 0.9436
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1113 - acc: 0.9666 - val_loss: 0.1181 - val_acc: 0.9583
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1101 - acc: 0.9716 - val_loss: 0.1183 - val_acc: 0.9363
Epoch 28/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1095 - acc: 0.9733 - val_loss: 0.1181 - val_acc: 0.9436
Manual evaluation: (didn't understand why I made this)
True 7823
False 1248
True percentage 0.862418696946
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-PER       0.86      0.68      0.76       438
      B-LOC       0.61      0.62      0.62       218
      B-ORG       0.52      0.61      0.56       296
      I-ORG       0.25      0.46      0.33       151
      I-PER       0.83      0.53      0.65       214
      I-LOC       0.51      0.42      0.46       141
     B-MISC       0.39      0.28      0.32       141
     I-MISC       0.34      0.19      0.24       154

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.546046787089
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2118 - acc: 0.6491 - val_loss: 0.1527 - val_acc: 0.8242
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1476 - acc: 0.8523 - val_loss: 0.1457 - val_acc: 0.8575
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1414 - acc: 0.8685 - val_loss: 0.1428 - val_acc: 0.8527
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1364 - acc: 0.8785 - val_loss: 0.1422 - val_acc: 0.8480
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1347 - acc: 0.8866 - val_loss: 0.1366 - val_acc: 0.8646
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1297 - acc: 0.9109 - val_loss: 0.1363 - val_acc: 0.8765
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1280 - acc: 0.9157 - val_loss: 0.1360 - val_acc: 0.8694
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1260 - acc: 0.9215 - val_loss: 0.1328 - val_acc: 0.8907
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1248 - acc: 0.9212 - val_loss: 0.1321 - val_acc: 0.8812
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1239 - acc: 0.9245 - val_loss: 0.1314 - val_acc: 0.8955
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1212 - acc: 0.9339 - val_loss: 0.1312 - val_acc: 0.8860
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9384 - val_loss: 0.1293 - val_acc: 0.8955
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1193 - acc: 0.9407 - val_loss: 0.1299 - val_acc: 0.8860
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1188 - acc: 0.9427 - val_loss: 0.1302 - val_acc: 0.8812
Epoch 15/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1190 - acc: 0.9371 - val_loss: 0.1301 - val_acc: 0.9002
Manual evaluation: (didn't understand why I made this)
True 7847
False 1224
True percentage 0.865064491236
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-ORG       0.55      0.58      0.56       296
      B-LOC       0.73      0.63      0.68       218
      I-ORG       0.23      0.40      0.29       151
     B-MISC       0.25      0.02      0.04       141
     I-MISC       0.43      0.21      0.29       154
      B-PER       0.86      0.61      0.72       438
      I-PER       0.77      0.48      0.59       214
      I-LOC       0.66      0.73      0.69       141

avg / total       0.90      0.87      0.88      9071

F-1 Score:
0.547663551402
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2375 - acc: 0.6252 - val_loss: 0.1562 - val_acc: 0.7892
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1517 - acc: 0.8343 - val_loss: 0.1513 - val_acc: 0.7990
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1429 - acc: 0.8623 - val_loss: 0.1378 - val_acc: 0.8725
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1404 - acc: 0.8681 - val_loss: 0.1416 - val_acc: 0.8333
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1345 - acc: 0.8862 - val_loss: 0.1357 - val_acc: 0.8750
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1338 - acc: 0.8866 - val_loss: 0.1324 - val_acc: 0.8995
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1310 - acc: 0.8986 - val_loss: 0.1303 - val_acc: 0.9044
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1302 - acc: 0.9005 - val_loss: 0.1285 - val_acc: 0.9167
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1292 - acc: 0.9026 - val_loss: 0.1279 - val_acc: 0.9069
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1254 - acc: 0.9165 - val_loss: 0.1258 - val_acc: 0.9044
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1252 - acc: 0.9119 - val_loss: 0.1265 - val_acc: 0.9167
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1231 - acc: 0.9206 - val_loss: 0.1251 - val_acc: 0.9069
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1219 - acc: 0.9325 - val_loss: 0.1253 - val_acc: 0.9118
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1218 - acc: 0.9222 - val_loss: 0.1246 - val_acc: 0.9216
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1202 - acc: 0.9349 - val_loss: 0.1237 - val_acc: 0.9240
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9368 - val_loss: 0.1236 - val_acc: 0.9289
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1178 - acc: 0.9468 - val_loss: 0.1235 - val_acc: 0.9191
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1175 - acc: 0.9421 - val_loss: 0.1227 - val_acc: 0.9191
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1167 - acc: 0.9457 - val_loss: 0.1225 - val_acc: 0.9216
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1163 - acc: 0.9422 - val_loss: 0.1213 - val_acc: 0.9387
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1153 - acc: 0.9551 - val_loss: 0.1221 - val_acc: 0.9265
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1146 - acc: 0.9536 - val_loss: 0.1221 - val_acc: 0.9240
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1144 - acc: 0.9546 - val_loss: 0.1207 - val_acc: 0.9289
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1134 - acc: 0.9593 - val_loss: 0.1200 - val_acc: 0.9338
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1126 - acc: 0.9618 - val_loss: 0.1208 - val_acc: 0.9314
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1122 - acc: 0.9661 - val_loss: 0.1202 - val_acc: 0.9338
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1120 - acc: 0.9620 - val_loss: 0.1195 - val_acc: 0.9387
Epoch 28/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1105 - acc: 0.9698 - val_loss: 0.1193 - val_acc: 0.9338
Epoch 29/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1120 - acc: 0.9642 - val_loss: 0.1194 - val_acc: 0.9412
Epoch 30/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1098 - acc: 0.9746 - val_loss: 0.1189 - val_acc: 0.9412
Epoch 31/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1107 - acc: 0.9674 - val_loss: 0.1197 - val_acc: 0.9363
Epoch 32/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1108 - acc: 0.9664 - val_loss: 0.1205 - val_acc: 0.9314
Epoch 33/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1094 - acc: 0.9723 - val_loss: 0.1201 - val_acc: 0.9387
Manual evaluation: (didn't understand why I made this)
True 7833
False 1238
True percentage 0.863521111234
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-PER       0.86      0.64      0.74       438
      B-LOC       0.68      0.61      0.65       218
      B-ORG       0.57      0.58      0.57       296
      I-ORG       0.29      0.40      0.33       151
      I-PER       0.84      0.50      0.63       214
      I-LOC       0.58      0.45      0.51       141
     B-MISC       0.32      0.33      0.32       141
     I-MISC       0.26      0.29      0.27       154

avg / total       0.91      0.86      0.89      9071

F-1 Score:
0.544095665172
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2179 - acc: 0.6349 - val_loss: 0.1533 - val_acc: 0.8219
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1497 - acc: 0.8420 - val_loss: 0.1474 - val_acc: 0.8290
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1415 - acc: 0.8665 - val_loss: 0.1424 - val_acc: 0.8480
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1360 - acc: 0.8941 - val_loss: 0.1426 - val_acc: 0.8599
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1342 - acc: 0.8913 - val_loss: 0.1401 - val_acc: 0.8670
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1313 - acc: 0.8999 - val_loss: 0.1358 - val_acc: 0.8836
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1285 - acc: 0.9102 - val_loss: 0.1337 - val_acc: 0.8931
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1266 - acc: 0.9174 - val_loss: 0.1338 - val_acc: 0.8884
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1244 - acc: 0.9265 - val_loss: 0.1314 - val_acc: 0.8860
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1231 - acc: 0.9344 - val_loss: 0.1309 - val_acc: 0.8931
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1216 - acc: 0.9376 - val_loss: 0.1325 - val_acc: 0.8765
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9354 - val_loss: 0.1297 - val_acc: 0.8979
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1205 - acc: 0.9342 - val_loss: 0.1306 - val_acc: 0.8812
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1191 - acc: 0.9441 - val_loss: 0.1305 - val_acc: 0.8907
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1179 - acc: 0.9473 - val_loss: 0.1293 - val_acc: 0.8907
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1176 - acc: 0.9455 - val_loss: 0.1292 - val_acc: 0.8860
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1164 - acc: 0.9482 - val_loss: 0.1276 - val_acc: 0.8979
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9515 - val_loss: 0.1283 - val_acc: 0.8955
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1138 - acc: 0.9636 - val_loss: 0.1272 - val_acc: 0.8979
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1145 - acc: 0.9595 - val_loss: 0.1277 - val_acc: 0.8955
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1132 - acc: 0.9590 - val_loss: 0.1270 - val_acc: 0.8979
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1136 - acc: 0.9608 - val_loss: 0.1278 - val_acc: 0.9002
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1118 - acc: 0.9675 - val_loss: 0.1273 - val_acc: 0.8979
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1113 - acc: 0.9619 - val_loss: 0.1274 - val_acc: 0.9002
Manual evaluation: (didn't understand why I made this)
True 7892
False 1179
True percentage 0.870025355529
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.54      0.62      0.58       296
      B-LOC       0.70      0.66      0.68       218
      I-ORG       0.26      0.45      0.33       151
     B-MISC       0.48      0.11      0.18       141
     I-MISC       0.54      0.22      0.31       154
      B-PER       0.82      0.71      0.76       438
      I-PER       0.70      0.52      0.60       214
      I-LOC       0.65      0.75      0.70       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.578320428827
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2141 - acc: 0.6555 - val_loss: 0.1556 - val_acc: 0.8088
Epoch 2/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1507 - acc: 0.8361 - val_loss: 0.1446 - val_acc: 0.8211
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1421 - acc: 0.8623 - val_loss: 0.1387 - val_acc: 0.8456
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1385 - acc: 0.8737 - val_loss: 0.1373 - val_acc: 0.8627
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1362 - acc: 0.8821 - val_loss: 0.1331 - val_acc: 0.8946
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1322 - acc: 0.8932 - val_loss: 0.1324 - val_acc: 0.8873
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1298 - acc: 0.8984 - val_loss: 0.1317 - val_acc: 0.8995
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1285 - acc: 0.9075 - val_loss: 0.1283 - val_acc: 0.8971
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1267 - acc: 0.9065 - val_loss: 0.1271 - val_acc: 0.9069
Epoch 10/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1258 - acc: 0.9113 - val_loss: 0.1277 - val_acc: 0.9118
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1242 - acc: 0.9143 - val_loss: 0.1275 - val_acc: 0.9118
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1227 - acc: 0.9230 - val_loss: 0.1260 - val_acc: 0.9118
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1224 - acc: 0.9304 - val_loss: 0.1240 - val_acc: 0.9142
Epoch 14/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1205 - acc: 0.9315 - val_loss: 0.1236 - val_acc: 0.9142
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1201 - acc: 0.9365 - val_loss: 0.1230 - val_acc: 0.9191
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1188 - acc: 0.9389 - val_loss: 0.1224 - val_acc: 0.9216
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1180 - acc: 0.9410 - val_loss: 0.1232 - val_acc: 0.9191
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1178 - acc: 0.9398 - val_loss: 0.1227 - val_acc: 0.9265
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1161 - acc: 0.9483 - val_loss: 0.1217 - val_acc: 0.9265
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1153 - acc: 0.9526 - val_loss: 0.1225 - val_acc: 0.9167
Epoch 21/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1153 - acc: 0.9526 - val_loss: 0.1218 - val_acc: 0.9314
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1144 - acc: 0.9557 - val_loss: 0.1203 - val_acc: 0.9289
Epoch 23/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1140 - acc: 0.9600 - val_loss: 0.1207 - val_acc: 0.9240
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1134 - acc: 0.9603 - val_loss: 0.1205 - val_acc: 0.9314
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1125 - acc: 0.9617 - val_loss: 0.1201 - val_acc: 0.9314
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1124 - acc: 0.9597 - val_loss: 0.1198 - val_acc: 0.9338
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1111 - acc: 0.9648 - val_loss: 0.1197 - val_acc: 0.9338
Epoch 28/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1119 - acc: 0.9636 - val_loss: 0.1188 - val_acc: 0.9412
Epoch 29/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1115 - acc: 0.9669 - val_loss: 0.1186 - val_acc: 0.9510
Epoch 30/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1109 - acc: 0.9712 - val_loss: 0.1190 - val_acc: 0.9363
Epoch 31/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1110 - acc: 0.9674 - val_loss: 0.1188 - val_acc: 0.9436
Epoch 32/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1094 - acc: 0.9749 - val_loss: 0.1187 - val_acc: 0.9387
Manual evaluation: (didn't understand why I made this)
True 7791
False 1280
True percentage 0.858890971227
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-PER       0.86      0.70      0.77       438
      B-LOC       0.62      0.63      0.63       218
      B-ORG       0.49      0.60      0.54       296
      I-ORG       0.27      0.46      0.34       151
      I-PER       0.83      0.51      0.63       214
      I-LOC       0.47      0.40      0.43       141
     B-MISC       0.35      0.24      0.29       141
     I-MISC       0.32      0.27      0.29       154

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.542640186916
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2194 - acc: 0.6270 - val_loss: 0.1553 - val_acc: 0.8124
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1513 - acc: 0.8368 - val_loss: 0.1472 - val_acc: 0.8242
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1423 - acc: 0.8701 - val_loss: 0.1431 - val_acc: 0.8432
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1379 - acc: 0.8844 - val_loss: 0.1406 - val_acc: 0.8385
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1336 - acc: 0.8950 - val_loss: 0.1374 - val_acc: 0.8694
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1320 - acc: 0.8993 - val_loss: 0.1363 - val_acc: 0.8622
Epoch 7/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1295 - acc: 0.9110 - val_loss: 0.1355 - val_acc: 0.8622
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1270 - acc: 0.9197 - val_loss: 0.1342 - val_acc: 0.8670
Epoch 9/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1249 - acc: 0.9207 - val_loss: 0.1341 - val_acc: 0.8741
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1248 - acc: 0.9283 - val_loss: 0.1327 - val_acc: 0.8860
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1238 - acc: 0.9255 - val_loss: 0.1327 - val_acc: 0.8717
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1209 - acc: 0.9330 - val_loss: 0.1310 - val_acc: 0.8884
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1212 - acc: 0.9399 - val_loss: 0.1326 - val_acc: 0.8717
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1196 - acc: 0.9447 - val_loss: 0.1301 - val_acc: 0.8884
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1176 - acc: 0.9483 - val_loss: 0.1299 - val_acc: 0.8931
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1175 - acc: 0.9473 - val_loss: 0.1300 - val_acc: 0.8955
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1178 - acc: 0.9469 - val_loss: 0.1290 - val_acc: 0.8931
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9533 - val_loss: 0.1297 - val_acc: 0.8931
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9550 - val_loss: 0.1295 - val_acc: 0.8931
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1152 - acc: 0.9542 - val_loss: 0.1291 - val_acc: 0.8931
Manual evaluation: (didn't understand why I made this)
True 7869
False 1202
True percentage 0.867489802668
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.50      0.62      0.55       296
      B-LOC       0.73      0.61      0.66       218
      I-ORG       0.24      0.47      0.31       151
     B-MISC       0.59      0.07      0.13       141
     I-MISC       0.39      0.18      0.25       154
      B-PER       0.85      0.69      0.76       438
      I-PER       0.78      0.50      0.61       214
      I-LOC       0.64      0.74      0.69       141

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.561099492082
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2819 - acc: 0.4711 - val_loss: 0.2197 - val_acc: 0.6387
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1591 - acc: 0.8234 - val_loss: 0.2016 - val_acc: 0.7101
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1495 - acc: 0.8401 - val_loss: 0.1960 - val_acc: 0.7185
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1445 - acc: 0.8488 - val_loss: 0.1901 - val_acc: 0.7269
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1411 - acc: 0.8562 - val_loss: 0.1842 - val_acc: 0.7353
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1361 - acc: 0.8786 - val_loss: 0.1859 - val_acc: 0.7395
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1340 - acc: 0.8770 - val_loss: 0.1813 - val_acc: 0.7353
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1306 - acc: 0.8963 - val_loss: 0.1815 - val_acc: 0.7437
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1308 - acc: 0.8949 - val_loss: 0.1769 - val_acc: 0.7521
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1295 - acc: 0.9055 - val_loss: 0.1769 - val_acc: 0.7479
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1260 - acc: 0.9178 - val_loss: 0.1800 - val_acc: 0.7395
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1255 - acc: 0.9131 - val_loss: 0.1760 - val_acc: 0.7605
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1241 - acc: 0.9191 - val_loss: 0.1810 - val_acc: 0.7521
Epoch 14/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1226 - acc: 0.9281 - val_loss: 0.1777 - val_acc: 0.7605
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1206 - acc: 0.9428 - val_loss: 0.1704 - val_acc: 0.7731
Epoch 16/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1204 - acc: 0.9396 - val_loss: 0.1788 - val_acc: 0.7605
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1194 - acc: 0.9426 - val_loss: 0.1708 - val_acc: 0.7689
Epoch 18/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1190 - acc: 0.9370 - val_loss: 0.1743 - val_acc: 0.7647
Manual evaluation: (didn't understand why I made this)
True 7568
False 1503
True percentage 0.83430713262
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.96      7318
      B-PER       0.67      0.55      0.60       438
      B-LOC       0.56      0.60      0.58       218
      B-ORG       0.42      0.44      0.43       296
      I-ORG       0.16      0.39      0.23       151
      I-PER       0.72      0.19      0.30       214
      I-LOC       0.34      0.38      0.36       141
     B-MISC       0.57      0.03      0.05       141
     I-MISC       0.17      0.01      0.01       154

avg / total       0.88      0.83      0.85      9071

F-1 Score:
0.407145056976
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 49ms/step - loss: 0.2730 - acc: 0.4592 - val_loss: 0.1870 - val_acc: 0.7800
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1577 - acc: 0.8248 - val_loss: 0.1748 - val_acc: 0.7800
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1489 - acc: 0.8476 - val_loss: 0.1664 - val_acc: 0.7950
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1428 - acc: 0.8669 - val_loss: 0.1605 - val_acc: 0.8050
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1379 - acc: 0.8869 - val_loss: 0.1527 - val_acc: 0.8100
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1353 - acc: 0.8919 - val_loss: 0.1453 - val_acc: 0.8300
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1324 - acc: 0.8933 - val_loss: 0.1469 - val_acc: 0.8300
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1303 - acc: 0.9007 - val_loss: 0.1403 - val_acc: 0.8550
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1271 - acc: 0.9151 - val_loss: 0.1413 - val_acc: 0.8400
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1251 - acc: 0.9227 - val_loss: 0.1465 - val_acc: 0.8350
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1254 - acc: 0.9237 - val_loss: 0.1384 - val_acc: 0.8550
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1254 - acc: 0.9221 - val_loss: 0.1344 - val_acc: 0.8600
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1231 - acc: 0.9299 - val_loss: 0.1371 - val_acc: 0.8550
Epoch 14/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1231 - acc: 0.9327 - val_loss: 0.1292 - val_acc: 0.9150
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1208 - acc: 0.9341 - val_loss: 0.1381 - val_acc: 0.8550
Epoch 16/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1204 - acc: 0.9311 - val_loss: 0.1286 - val_acc: 0.9150
Epoch 17/70

74/74 [==============================] - 2s 23ms/step - loss: 0.1195 - acc: 0.9468 - val_loss: 0.1314 - val_acc: 0.8850
Epoch 18/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1199 - acc: 0.9398 - val_loss: 0.1283 - val_acc: 0.9200
Epoch 19/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1182 - acc: 0.9452 - val_loss: 0.1331 - val_acc: 0.8750
Epoch 20/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1179 - acc: 0.9457 - val_loss: 0.1318 - val_acc: 0.8750
Epoch 21/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1168 - acc: 0.9529 - val_loss: 0.1318 - val_acc: 0.8850
Manual evaluation: (didn't understand why I made this)
True 7583
False 1488
True percentage 0.835960754051
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-ORG       0.39      0.56      0.46       296
      B-LOC       0.73      0.46      0.57       218
      I-ORG       0.19      0.46      0.27       151
     B-MISC       0.19      0.06      0.10       141
     I-MISC       0.38      0.10      0.16       154
      B-PER       0.72      0.50      0.59       438
      I-PER       0.66      0.38      0.48       214
      I-LOC       0.59      0.29      0.39       141

avg / total       0.89      0.84      0.86      9071

F-1 Score:
0.431456548348
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 48ms/step - loss: 0.2555 - acc: 0.4811 - val_loss: 0.2577 - val_acc: 0.6261
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1647 - acc: 0.8092 - val_loss: 0.1986 - val_acc: 0.6849
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1461 - acc: 0.8562 - val_loss: 0.1917 - val_acc: 0.7185
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1409 - acc: 0.8649 - val_loss: 0.1972 - val_acc: 0.7185
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1370 - acc: 0.8861 - val_loss: 0.1873 - val_acc: 0.7395
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1337 - acc: 0.8916 - val_loss: 0.1781 - val_acc: 0.7395
Epoch 7/70

74/74 [==============================] - 2s 23ms/step - loss: 0.1305 - acc: 0.8967 - val_loss: 0.1777 - val_acc: 0.7437
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1286 - acc: 0.9093 - val_loss: 0.1783 - val_acc: 0.7479
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1276 - acc: 0.9115 - val_loss: 0.1811 - val_acc: 0.7269
Epoch 10/70

74/74 [==============================] - 2s 23ms/step - loss: 0.1270 - acc: 0.9062 - val_loss: 0.1771 - val_acc: 0.7437
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1258 - acc: 0.9164 - val_loss: 0.1809 - val_acc: 0.7647
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1252 - acc: 0.9151 - val_loss: 0.1695 - val_acc: 0.7689
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1233 - acc: 0.9208 - val_loss: 0.1776 - val_acc: 0.7605
Epoch 14/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1213 - acc: 0.9376 - val_loss: 0.1793 - val_acc: 0.7647
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1188 - acc: 0.9417 - val_loss: 0.1793 - val_acc: 0.7857
Manual evaluation: (didn't understand why I made this)
True 7583
False 1488
True percentage 0.835960754051
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.95      7318
      B-PER       0.62      0.58      0.60       438
      B-LOC       0.54      0.70      0.61       218
      B-ORG       0.48      0.25      0.33       296
      I-ORG       0.17      0.21      0.19       151
      I-PER       0.71      0.32      0.44       214
      I-LOC       0.31      0.50      0.38       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.86      0.84      0.84      9071

F-1 Score:
0.418962203716
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2607 - acc: 0.5400 - val_loss: 0.1951 - val_acc: 0.7850
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1597 - acc: 0.8279 - val_loss: 0.1684 - val_acc: 0.7950
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1486 - acc: 0.8458 - val_loss: 0.1605 - val_acc: 0.8000
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1432 - acc: 0.8624 - val_loss: 0.1431 - val_acc: 0.8500
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1393 - acc: 0.8849 - val_loss: 0.1512 - val_acc: 0.8100
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1354 - acc: 0.8840 - val_loss: 0.1436 - val_acc: 0.8500
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1323 - acc: 0.8979 - val_loss: 0.1428 - val_acc: 0.8500
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1314 - acc: 0.8985 - val_loss: 0.1356 - val_acc: 0.8750
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1309 - acc: 0.9078 - val_loss: 0.1360 - val_acc: 0.8650
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1285 - acc: 0.9102 - val_loss: 0.1436 - val_acc: 0.8400
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1263 - acc: 0.9209 - val_loss: 0.1409 - val_acc: 0.8650
Manual evaluation: (didn't understand why I made this)
True 7489
False 1582
True percentage 0.825598059751
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-ORG       0.40      0.43      0.41       296
      B-LOC       0.84      0.42      0.56       218
      I-ORG       0.16      0.40      0.23       151
     B-MISC       0.38      0.04      0.06       141
     I-MISC       0.38      0.17      0.23       154
      B-PER       0.52      0.55      0.53       438
      I-PER       0.42      0.37      0.39       214
      I-LOC       0.60      0.04      0.08       141

avg / total       0.88      0.83      0.84      9071

F-1 Score:
0.38554948391
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 47ms/step - loss: 0.2821 - acc: 0.4990 - val_loss: 0.2738 - val_acc: 0.6218
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1712 - acc: 0.8118 - val_loss: 0.1972 - val_acc: 0.6723
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1496 - acc: 0.8510 - val_loss: 0.1926 - val_acc: 0.7059
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1445 - acc: 0.8537 - val_loss: 0.1923 - val_acc: 0.6891
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1410 - acc: 0.8674 - val_loss: 0.1844 - val_acc: 0.7269
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1387 - acc: 0.8714 - val_loss: 0.1793 - val_acc: 0.7395
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1347 - acc: 0.8866 - val_loss: 0.1806 - val_acc: 0.7479
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1323 - acc: 0.8965 - val_loss: 0.1889 - val_acc: 0.7101
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1337 - acc: 0.8868 - val_loss: 0.1763 - val_acc: 0.7521
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1293 - acc: 0.8993 - val_loss: 0.1813 - val_acc: 0.7521
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1275 - acc: 0.9043 - val_loss: 0.1804 - val_acc: 0.7269
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1266 - acc: 0.9131 - val_loss: 0.1846 - val_acc: 0.7437
Manual evaluation: (didn't understand why I made this)
True 7451
False 1620
True percentage 0.821408885459
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.95      7318
      B-PER       0.68      0.53      0.59       438
      B-LOC       0.45      0.66      0.54       218
      B-ORG       0.39      0.43      0.41       296
      I-ORG       0.16      0.58      0.25       151
      I-PER       0.78      0.14      0.23       214
      I-LOC       0.29      0.20      0.24       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.87      0.82      0.84      9071

F-1 Score:
0.37815619495
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 47ms/step - loss: 0.2493 - acc: 0.4944 - val_loss: 0.1729 - val_acc: 0.7800
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1577 - acc: 0.8274 - val_loss: 0.1574 - val_acc: 0.8100
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1454 - acc: 0.8551 - val_loss: 0.1458 - val_acc: 0.8250
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1412 - acc: 0.8693 - val_loss: 0.1507 - val_acc: 0.7900
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1367 - acc: 0.8893 - val_loss: 0.1449 - val_acc: 0.8300
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1338 - acc: 0.8991 - val_loss: 0.1456 - val_acc: 0.8350
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1312 - acc: 0.9002 - val_loss: 0.1422 - val_acc: 0.8450
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1300 - acc: 0.9096 - val_loss: 0.1406 - val_acc: 0.8550
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1271 - acc: 0.9189 - val_loss: 0.1404 - val_acc: 0.8600
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1258 - acc: 0.9233 - val_loss: 0.1401 - val_acc: 0.8600
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1248 - acc: 0.9244 - val_loss: 0.1445 - val_acc: 0.8300
Epoch 12/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1243 - acc: 0.9260 - val_loss: 0.1386 - val_acc: 0.8650
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1218 - acc: 0.9359 - val_loss: 0.1358 - val_acc: 0.8650
Epoch 14/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1206 - acc: 0.9417 - val_loss: 0.1330 - val_acc: 0.8950
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1213 - acc: 0.9388 - val_loss: 0.1411 - val_acc: 0.8500
Epoch 16/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1186 - acc: 0.9453 - val_loss: 0.1371 - val_acc: 0.8650
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1174 - acc: 0.9504 - val_loss: 0.1331 - val_acc: 0.8800
Manual evaluation: (didn't understand why I made this)
True 7621
False 1450
True percentage 0.840149928343
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.96      7318
      B-ORG       0.46      0.49      0.48       296
      B-LOC       0.71      0.49      0.58       218
      I-ORG       0.18      0.30      0.23       151
     B-MISC       0.18      0.06      0.09       141
     I-MISC       0.36      0.16      0.22       154
      B-PER       0.70      0.53      0.61       438
      I-PER       0.49      0.46      0.47       214
      I-LOC       0.67      0.38      0.48       141

avg / total       0.88      0.84      0.86      9071

F-1 Score:
0.448340638698
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 46ms/step - loss: 0.2615 - acc: 0.4907 - val_loss: 0.2425 - val_acc: 0.6218
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1646 - acc: 0.8138 - val_loss: 0.1998 - val_acc: 0.6681
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1506 - acc: 0.8402 - val_loss: 0.1953 - val_acc: 0.6849
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1447 - acc: 0.8617 - val_loss: 0.1913 - val_acc: 0.7227
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1397 - acc: 0.8798 - val_loss: 0.1819 - val_acc: 0.7269
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1361 - acc: 0.8826 - val_loss: 0.1821 - val_acc: 0.7227
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1346 - acc: 0.8883 - val_loss: 0.1975 - val_acc: 0.7227
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1327 - acc: 0.8920 - val_loss: 0.1855 - val_acc: 0.7395
Manual evaluation: (didn't understand why I made this)
True 7469
False 1602
True percentage 0.823393231176
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-PER       0.60      0.50      0.55       438
      B-LOC       0.64      0.56      0.60       218
      B-ORG       0.34      0.46      0.39       296
      I-ORG       0.16      0.60      0.26       151
      I-PER       0.67      0.14      0.24       214
      I-LOC       0.19      0.04      0.07       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.87      0.82      0.84      9071

F-1 Score:
0.363145258103
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 46ms/step - loss: 0.2638 - acc: 0.4881 - val_loss: 0.1800 - val_acc: 0.7850
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1559 - acc: 0.8358 - val_loss: 0.1616 - val_acc: 0.7950
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1444 - acc: 0.8583 - val_loss: 0.1476 - val_acc: 0.8100
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1403 - acc: 0.8772 - val_loss: 0.1457 - val_acc: 0.8250
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1376 - acc: 0.8759 - val_loss: 0.1502 - val_acc: 0.8200
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1336 - acc: 0.8957 - val_loss: 0.1463 - val_acc: 0.8100
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1322 - acc: 0.8953 - val_loss: 0.1498 - val_acc: 0.7950
Manual evaluation: (didn't understand why I made this)
True 7248
False 1823
True percentage 0.799029875427
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.92      0.95      7318
      B-ORG       0.24      0.61      0.34       296
      B-LOC       0.80      0.04      0.07       218
      I-ORG       0.16      0.50      0.24       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.45      0.03      0.06       154
      B-PER       0.53      0.36      0.43       438
      I-PER       0.62      0.26      0.36       214
      I-LOC       0.62      0.04      0.07       141

avg / total       0.88      0.80      0.81      9071

F-1 Score:
0.285126396238
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2550 - acc: 0.5716 - val_loss: 0.2230 - val_acc: 0.6513
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1557 - acc: 0.8315 - val_loss: 0.2077 - val_acc: 0.6597
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1473 - acc: 0.8502 - val_loss: 0.2008 - val_acc: 0.6849
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1416 - acc: 0.8656 - val_loss: 0.1908 - val_acc: 0.7143
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1372 - acc: 0.8802 - val_loss: 0.1919 - val_acc: 0.7101
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1342 - acc: 0.8844 - val_loss: 0.1918 - val_acc: 0.7311
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1324 - acc: 0.8922 - val_loss: 0.2007 - val_acc: 0.7311
Manual evaluation: (didn't understand why I made this)
True 7405
False 1666
True percentage 0.816337779738
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.96      7318
      B-PER       0.67      0.49      0.56       438
      B-LOC       0.39      0.75      0.52       218
      B-ORG       0.37      0.30      0.33       296
      I-ORG       0.15      0.53      0.24       151
      I-PER       0.74      0.09      0.17       214
      I-LOC       0.27      0.32      0.29       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.87      0.82      0.83      9071

F-1 Score:
0.354408352668
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 46ms/step - loss: 0.2606 - acc: 0.4964 - val_loss: 0.1868 - val_acc: 0.7850
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1582 - acc: 0.8319 - val_loss: 0.1593 - val_acc: 0.8050
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1464 - acc: 0.8525 - val_loss: 0.1595 - val_acc: 0.7850
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1413 - acc: 0.8661 - val_loss: 0.1456 - val_acc: 0.8300
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1367 - acc: 0.8823 - val_loss: 0.1420 - val_acc: 0.8550
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1364 - acc: 0.8878 - val_loss: 0.1488 - val_acc: 0.8300
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1328 - acc: 0.8931 - val_loss: 0.1455 - val_acc: 0.8200
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1309 - acc: 0.8959 - val_loss: 0.1390 - val_acc: 0.8750
Epoch 9/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1288 - acc: 0.9129 - val_loss: 0.1376 - val_acc: 0.8600
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1269 - acc: 0.9114 - val_loss: 0.1359 - val_acc: 0.8500
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1258 - acc: 0.9262 - val_loss: 0.1382 - val_acc: 0.8450
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1249 - acc: 0.9167 - val_loss: 0.1412 - val_acc: 0.8400
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1221 - acc: 0.9325 - val_loss: 0.1337 - val_acc: 0.8650
Epoch 14/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1234 - acc: 0.9217 - val_loss: 0.1385 - val_acc: 0.8500
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1207 - acc: 0.9330 - val_loss: 0.1371 - val_acc: 0.8500
Epoch 16/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1200 - acc: 0.9430 - val_loss: 0.1362 - val_acc: 0.8600
Manual evaluation: (didn't understand why I made this)
True 7553
False 1518
True percentage 0.83265351119
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-ORG       0.39      0.58      0.46       296
      B-LOC       0.74      0.45      0.56       218
      I-ORG       0.20      0.51      0.29       151
     B-MISC       0.14      0.04      0.06       141
     I-MISC       0.29      0.03      0.06       154
      B-PER       0.69      0.47      0.56       438
      I-PER       0.50      0.41      0.45       214
      I-LOC       0.69      0.31      0.43       141

avg / total       0.89      0.83      0.85      9071

F-1 Score:
0.421307506053
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 88ms/step - loss: 0.3439 - acc: 0.0551 - val_loss: 0.2088 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2021 - acc: 0.7940 - val_loss: 0.2058 - val_acc: 0.7113
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2150 - acc: 0.6874 - val_loss: 0.1722 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1659 - acc: 0.7957 - val_loss: 0.1509 - val_acc: 0.8454
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1486 - acc: 0.8544 - val_loss: 0.1462 - val_acc: 0.8557
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1433 - acc: 0.8597 - val_loss: 0.1441 - val_acc: 0.8660
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1396 - acc: 0.8881 - val_loss: 0.1412 - val_acc: 0.8660
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1388 - acc: 0.8757 - val_loss: 0.1401 - val_acc: 0.8866
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1364 - acc: 0.8863 - val_loss: 0.1390 - val_acc: 0.8866
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1315 - acc: 0.9130 - val_loss: 0.1383 - val_acc: 0.8660
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1286 - acc: 0.9147 - val_loss: 0.1371 - val_acc: 0.8969
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1262 - acc: 0.9325 - val_loss: 0.1365 - val_acc: 0.8763
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1247 - acc: 0.9272 - val_loss: 0.1358 - val_acc: 0.8763
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1228 - acc: 0.9414 - val_loss: 0.1355 - val_acc: 0.8763
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1215 - acc: 0.9503 - val_loss: 0.1339 - val_acc: 0.8763
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1205 - acc: 0.9467 - val_loss: 0.1345 - val_acc: 0.8660
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1195 - acc: 0.9432 - val_loss: 0.1343 - val_acc: 0.8763
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1174 - acc: 0.9503 - val_loss: 0.1344 - val_acc: 0.8660
Manual evaluation: (didn't understand why I made this)
True 7351
False 1720
True percentage 0.810384742586
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.50      0.47      0.48       438
      B-LOC       0.52      0.58      0.55       218
      B-ORG       0.36      0.32      0.34       296
      I-ORG       0.15      0.40      0.21       151
      I-PER       0.94      0.07      0.13       214
      I-LOC       0.13      0.11      0.12       141
     B-MISC       0.33      0.02      0.04       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.86      0.81      0.82      9071

F-1 Score:
0.322500773754
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3619 - acc: 0.0527 - val_loss: 0.1635 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1966 - acc: 0.8122 - val_loss: 0.1531 - val_acc: 0.8675
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1669 - acc: 0.8081 - val_loss: 0.1391 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1517 - acc: 0.8419 - val_loss: 0.1359 - val_acc: 0.9157
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1447 - acc: 0.8676 - val_loss: 0.1336 - val_acc: 0.8916
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1406 - acc: 0.8784 - val_loss: 0.1329 - val_acc: 0.9277
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1383 - acc: 0.8784 - val_loss: 0.1317 - val_acc: 0.9277
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1356 - acc: 0.9027 - val_loss: 0.1306 - val_acc: 0.9398
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1347 - acc: 0.8878 - val_loss: 0.1310 - val_acc: 0.9277
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1313 - acc: 0.9081 - val_loss: 0.1301 - val_acc: 0.9398
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1298 - acc: 0.9216 - val_loss: 0.1300 - val_acc: 0.9277
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1287 - acc: 0.9162 - val_loss: 0.1300 - val_acc: 0.9398
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1264 - acc: 0.9162 - val_loss: 0.1303 - val_acc: 0.9398
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1260 - acc: 0.9230 - val_loss: 0.1309 - val_acc: 0.9398
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1232 - acc: 0.9378 - val_loss: 0.1304 - val_acc: 0.9277
Manual evaluation: (didn't understand why I made this)
True 7338
False 1733
True percentage 0.808951604013
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.95      0.95      7318
      B-ORG       0.27      0.29      0.28       296
      B-LOC       0.75      0.15      0.25       218
      I-ORG       0.17      0.42      0.25       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.39      0.08      0.14       154
      B-PER       0.56      0.34      0.43       438
      I-PER       0.46      0.30      0.37       214
      I-LOC       1.00      0.01      0.01       141

avg / total       0.85      0.81      0.81      9071

F-1 Score:
0.28096369189
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 92ms/step - loss: 0.3698 - acc: 0.0568 - val_loss: 0.1962 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1956 - acc: 0.7940 - val_loss: 0.1699 - val_acc: 0.8557
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1752 - acc: 0.7957 - val_loss: 0.1591 - val_acc: 0.8144
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1572 - acc: 0.8064 - val_loss: 0.1461 - val_acc: 0.8969
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1462 - acc: 0.8668 - val_loss: 0.1431 - val_acc: 0.8557
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1411 - acc: 0.8792 - val_loss: 0.1406 - val_acc: 0.8763
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1365 - acc: 0.8970 - val_loss: 0.1400 - val_acc: 0.8969
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1342 - acc: 0.8952 - val_loss: 0.1392 - val_acc: 0.8866
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1304 - acc: 0.9059 - val_loss: 0.1382 - val_acc: 0.8866
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1293 - acc: 0.9112 - val_loss: 0.1383 - val_acc: 0.8763
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1280 - acc: 0.9041 - val_loss: 0.1369 - val_acc: 0.8866
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1255 - acc: 0.9147 - val_loss: 0.1380 - val_acc: 0.8557
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1253 - acc: 0.9218 - val_loss: 0.1371 - val_acc: 0.8866
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1216 - acc: 0.9432 - val_loss: 0.1367 - val_acc: 0.8660
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1205 - acc: 0.9520 - val_loss: 0.1369 - val_acc: 0.8660
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1198 - acc: 0.9449 - val_loss: 0.1366 - val_acc: 0.8763
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1171 - acc: 0.9609 - val_loss: 0.1357 - val_acc: 0.8660
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1170 - acc: 0.9538 - val_loss: 0.1368 - val_acc: 0.8660
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1182 - acc: 0.9467 - val_loss: 0.1355 - val_acc: 0.8763
Epoch 20/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1153 - acc: 0.9627 - val_loss: 0.1351 - val_acc: 0.8660
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1151 - acc: 0.9627 - val_loss: 0.1367 - val_acc: 0.8660
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1155 - acc: 0.9645 - val_loss: 0.1348 - val_acc: 0.8660
Epoch 23/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1140 - acc: 0.9663 - val_loss: 0.1355 - val_acc: 0.8763
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1129 - acc: 0.9769 - val_loss: 0.1355 - val_acc: 0.8763
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1116 - acc: 0.9734 - val_loss: 0.1352 - val_acc: 0.8763
Manual evaluation: (didn't understand why I made this)
True 7283
False 1788
True percentage 0.802888325433
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.92      0.95      7318
      B-PER       0.49      0.42      0.46       438
      B-LOC       0.47      0.66      0.55       218
      B-ORG       0.29      0.33      0.31       296
      I-ORG       0.16      0.45      0.23       151
      I-PER       0.73      0.09      0.16       214
      I-LOC       0.18      0.18      0.18       141
     B-MISC       0.08      0.01      0.01       141
     I-MISC       0.50      0.01      0.01       154

avg / total       0.87      0.80      0.82      9071

F-1 Score:
0.319764011799
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 86ms/step - loss: 0.3264 - acc: 0.2149 - val_loss: 0.1560 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1956 - acc: 0.8122 - val_loss: 0.2395 - val_acc: 0.5663
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2844 - acc: 0.4297 - val_loss: 0.1492 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1750 - acc: 0.8135 - val_loss: 0.1393 - val_acc: 0.8795
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1565 - acc: 0.8311 - val_loss: 0.1351 - val_acc: 0.8554
Epoch 6/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1476 - acc: 0.8500 - val_loss: 0.1335 - val_acc: 0.8916
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1456 - acc: 0.8622 - val_loss: 0.1325 - val_acc: 0.9036
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1410 - acc: 0.8865 - val_loss: 0.1312 - val_acc: 0.9277
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1378 - acc: 0.8905 - val_loss: 0.1305 - val_acc: 0.9157
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1335 - acc: 0.8959 - val_loss: 0.1303 - val_acc: 0.9277
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1348 - acc: 0.8932 - val_loss: 0.1294 - val_acc: 0.9277
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1342 - acc: 0.8905 - val_loss: 0.1289 - val_acc: 0.9277
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1307 - acc: 0.9041 - val_loss: 0.1283 - val_acc: 0.9277
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1305 - acc: 0.9081 - val_loss: 0.1280 - val_acc: 0.9277
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1298 - acc: 0.9068 - val_loss: 0.1281 - val_acc: 0.9277
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1285 - acc: 0.9230 - val_loss: 0.1278 - val_acc: 0.9277
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1283 - acc: 0.9176 - val_loss: 0.1276 - val_acc: 0.9398
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1250 - acc: 0.9257 - val_loss: 0.1272 - val_acc: 0.9277
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1250 - acc: 0.9297 - val_loss: 0.1272 - val_acc: 0.9277
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1232 - acc: 0.9338 - val_loss: 0.1268 - val_acc: 0.9277
Epoch 21/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1229 - acc: 0.9405 - val_loss: 0.1269 - val_acc: 0.9277
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1221 - acc: 0.9419 - val_loss: 0.1268 - val_acc: 0.9277
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1212 - acc: 0.9405 - val_loss: 0.1268 - val_acc: 0.9277
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1221 - acc: 0.9324 - val_loss: 0.1274 - val_acc: 0.9277
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1185 - acc: 0.9500 - val_loss: 0.1268 - val_acc: 0.9277
Epoch 26/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1180 - acc: 0.9608 - val_loss: 0.1272 - val_acc: 0.9277
Manual evaluation: (didn't understand why I made this)
True 7284
False 1787
True percentage 0.802998566861
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.23      0.32      0.27       296
      B-LOC       0.70      0.17      0.28       218
      I-ORG       0.17      0.61      0.26       151
     B-MISC       0.10      0.04      0.05       141
     I-MISC       0.12      0.01      0.02       154
      B-PER       0.59      0.34      0.43       438
      I-PER       0.71      0.21      0.32       214
      I-LOC       0.75      0.02      0.04       141

avg / total       0.87      0.80      0.82      9071

F-1 Score:
0.272208121827
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 86ms/step - loss: 0.3440 - acc: 0.0373 - val_loss: 0.1947 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1855 - acc: 0.7940 - val_loss: 0.2414 - val_acc: 0.5979
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2436 - acc: 0.5702 - val_loss: 0.1833 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1747 - acc: 0.7940 - val_loss: 0.1579 - val_acc: 0.8247
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1560 - acc: 0.8348 - val_loss: 0.1495 - val_acc: 0.8351
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1500 - acc: 0.8348 - val_loss: 0.1467 - val_acc: 0.8454
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1421 - acc: 0.8721 - val_loss: 0.1439 - val_acc: 0.8557
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1394 - acc: 0.8828 - val_loss: 0.1424 - val_acc: 0.8557
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1366 - acc: 0.9041 - val_loss: 0.1401 - val_acc: 0.8866
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1327 - acc: 0.9112 - val_loss: 0.1395 - val_acc: 0.8866
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1311 - acc: 0.9059 - val_loss: 0.1386 - val_acc: 0.8763
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1281 - acc: 0.9290 - val_loss: 0.1378 - val_acc: 0.8763
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1263 - acc: 0.9254 - val_loss: 0.1377 - val_acc: 0.8969
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1261 - acc: 0.9307 - val_loss: 0.1362 - val_acc: 0.8866
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1242 - acc: 0.9361 - val_loss: 0.1361 - val_acc: 0.8969
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1210 - acc: 0.9414 - val_loss: 0.1359 - val_acc: 0.8763
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1215 - acc: 0.9414 - val_loss: 0.1350 - val_acc: 0.8969
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1210 - acc: 0.9414 - val_loss: 0.1355 - val_acc: 0.8969
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1180 - acc: 0.9609 - val_loss: 0.1348 - val_acc: 0.8969
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1183 - acc: 0.9556 - val_loss: 0.1348 - val_acc: 0.8969
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1185 - acc: 0.9485 - val_loss: 0.1351 - val_acc: 0.8763
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1165 - acc: 0.9716 - val_loss: 0.1346 - val_acc: 0.8866
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1153 - acc: 0.9609 - val_loss: 0.1339 - val_acc: 0.8969
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1149 - acc: 0.9680 - val_loss: 0.1343 - val_acc: 0.8866
Epoch 25/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1146 - acc: 0.9663 - val_loss: 0.1336 - val_acc: 0.8866
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1156 - acc: 0.9574 - val_loss: 0.1337 - val_acc: 0.9072
Epoch 27/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1121 - acc: 0.9716 - val_loss: 0.1333 - val_acc: 0.8969
Epoch 28/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1112 - acc: 0.9751 - val_loss: 0.1335 - val_acc: 0.8866
Epoch 29/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1123 - acc: 0.9734 - val_loss: 0.1332 - val_acc: 0.8866
Epoch 30/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1130 - acc: 0.9663 - val_loss: 0.1331 - val_acc: 0.8969
Epoch 31/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1122 - acc: 0.9751 - val_loss: 0.1329 - val_acc: 0.8969
Epoch 32/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1117 - acc: 0.9787 - val_loss: 0.1332 - val_acc: 0.8866
Epoch 33/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1099 - acc: 0.9858 - val_loss: 0.1336 - val_acc: 0.8763
Epoch 34/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1105 - acc: 0.9822 - val_loss: 0.1341 - val_acc: 0.8866
Manual evaluation: (didn't understand why I made this)
True 7341
False 1730
True percentage 0.809282328299
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.49      0.43      0.46       438
      B-LOC       0.54      0.58      0.56       218
      B-ORG       0.33      0.31      0.32       296
      I-ORG       0.16      0.44      0.23       151
      I-PER       0.71      0.08      0.14       214
      I-LOC       0.22      0.17      0.19       141
     B-MISC       0.16      0.03      0.05       141
     I-MISC       0.17      0.01      0.01       154

avg / total       0.86      0.81      0.82      9071

F-1 Score:
0.32101047443
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 88ms/step - loss: 0.3643 - acc: 0.2149 - val_loss: 0.1735 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2140 - acc: 0.8122 - val_loss: 0.1778 - val_acc: 0.8434
Epoch 3/70

29/29 [==============================] - 1s 22ms/step - loss: 0.2142 - acc: 0.7095 - val_loss: 0.1488 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1756 - acc: 0.8135 - val_loss: 0.1355 - val_acc: 0.8675
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1533 - acc: 0.8392 - val_loss: 0.1323 - val_acc: 0.8916
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1459 - acc: 0.8770 - val_loss: 0.1297 - val_acc: 0.9277
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1418 - acc: 0.8784 - val_loss: 0.1283 - val_acc: 0.9398
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1379 - acc: 0.8865 - val_loss: 0.1272 - val_acc: 0.9277
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1358 - acc: 0.8919 - val_loss: 0.1262 - val_acc: 0.9398
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1360 - acc: 0.8946 - val_loss: 0.1258 - val_acc: 0.9518
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1353 - acc: 0.8946 - val_loss: 0.1254 - val_acc: 0.9518
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1330 - acc: 0.9000 - val_loss: 0.1248 - val_acc: 0.9398
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1304 - acc: 0.9122 - val_loss: 0.1245 - val_acc: 0.9518
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1286 - acc: 0.9108 - val_loss: 0.1244 - val_acc: 0.9518
Epoch 15/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1269 - acc: 0.9243 - val_loss: 0.1241 - val_acc: 0.9518
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1268 - acc: 0.9311 - val_loss: 0.1237 - val_acc: 0.9518
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1258 - acc: 0.9257 - val_loss: 0.1238 - val_acc: 0.9518
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1234 - acc: 0.9297 - val_loss: 0.1237 - val_acc: 0.9518
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1244 - acc: 0.9284 - val_loss: 0.1239 - val_acc: 0.9518
Epoch 20/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1225 - acc: 0.9405 - val_loss: 0.1238 - val_acc: 0.9518
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1209 - acc: 0.9324 - val_loss: 0.1238 - val_acc: 0.9518
Manual evaluation: (didn't understand why I made this)
True 7327
False 1744
True percentage 0.807738948297
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-ORG       0.27      0.43      0.34       296
      B-LOC       0.62      0.19      0.29       218
      I-ORG       0.17      0.58      0.26       151
     B-MISC       0.11      0.01      0.02       141
     I-MISC       0.54      0.09      0.16       154
      B-PER       0.62      0.38      0.47       438
      I-PER       0.78      0.24      0.37       214
      I-LOC       0.67      0.01      0.03       141

avg / total       0.88      0.81      0.82      9071

F-1 Score:
0.307740520213
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3497 - acc: 0.0639 - val_loss: 0.2095 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2056 - acc: 0.7940 - val_loss: 0.2386 - val_acc: 0.5567
Epoch 3/70

29/29 [==============================] - 1s 22ms/step - loss: 0.2367 - acc: 0.5897 - val_loss: 0.1752 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1738 - acc: 0.7975 - val_loss: 0.1532 - val_acc: 0.8557
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1549 - acc: 0.8277 - val_loss: 0.1497 - val_acc: 0.8557
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1479 - acc: 0.8472 - val_loss: 0.1468 - val_acc: 0.8660
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1425 - acc: 0.8721 - val_loss: 0.1446 - val_acc: 0.8763
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1416 - acc: 0.8810 - val_loss: 0.1425 - val_acc: 0.8660
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1373 - acc: 0.8934 - val_loss: 0.1408 - val_acc: 0.8763
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1338 - acc: 0.9130 - val_loss: 0.1394 - val_acc: 0.8763
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1304 - acc: 0.9201 - val_loss: 0.1384 - val_acc: 0.8763
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1300 - acc: 0.9165 - val_loss: 0.1375 - val_acc: 0.8866
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1275 - acc: 0.9236 - val_loss: 0.1369 - val_acc: 0.8866
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1260 - acc: 0.9307 - val_loss: 0.1354 - val_acc: 0.8866
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1243 - acc: 0.9254 - val_loss: 0.1350 - val_acc: 0.8866
Epoch 16/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1234 - acc: 0.9307 - val_loss: 0.1341 - val_acc: 0.8969
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1236 - acc: 0.9361 - val_loss: 0.1348 - val_acc: 0.8866
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1212 - acc: 0.9414 - val_loss: 0.1348 - val_acc: 0.8866
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1206 - acc: 0.9378 - val_loss: 0.1339 - val_acc: 0.8866
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1170 - acc: 0.9645 - val_loss: 0.1346 - val_acc: 0.8866
Epoch 21/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1194 - acc: 0.9485 - val_loss: 0.1343 - val_acc: 0.8866
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1160 - acc: 0.9591 - val_loss: 0.1332 - val_acc: 0.8866
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1158 - acc: 0.9609 - val_loss: 0.1336 - val_acc: 0.8866
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1156 - acc: 0.9609 - val_loss: 0.1326 - val_acc: 0.8866
Epoch 25/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1139 - acc: 0.9663 - val_loss: 0.1330 - val_acc: 0.8763
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1135 - acc: 0.9680 - val_loss: 0.1332 - val_acc: 0.8763
Epoch 27/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1130 - acc: 0.9751 - val_loss: 0.1329 - val_acc: 0.8866
Manual evaluation: (didn't understand why I made this)
True 7339
False 1732
True percentage 0.809061845442
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.95      7318
      B-PER       0.53      0.48      0.51       438
      B-LOC       0.53      0.64      0.58       218
      B-ORG       0.30      0.39      0.34       296
      I-ORG       0.15      0.35      0.21       151
      I-PER       0.83      0.05      0.09       214
      I-LOC       0.19      0.21      0.20       141
     B-MISC       0.25      0.01      0.01       141
     I-MISC       0.33      0.01      0.01       154

avg / total       0.87      0.81      0.83      9071

F-1 Score:
0.338062179294
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3481 - acc: 0.0784 - val_loss: 0.1830 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.2258 - acc: 0.8122 - val_loss: 0.1977 - val_acc: 0.8072
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2213 - acc: 0.7108 - val_loss: 0.1505 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1811 - acc: 0.8135 - val_loss: 0.1376 - val_acc: 0.9036
Epoch 5/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1518 - acc: 0.8392 - val_loss: 0.1336 - val_acc: 0.9157
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1463 - acc: 0.8703 - val_loss: 0.1326 - val_acc: 0.9157
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1427 - acc: 0.8662 - val_loss: 0.1313 - val_acc: 0.9036
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1406 - acc: 0.8838 - val_loss: 0.1303 - val_acc: 0.9036
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1385 - acc: 0.8838 - val_loss: 0.1295 - val_acc: 0.9398
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1369 - acc: 0.8838 - val_loss: 0.1291 - val_acc: 0.9398
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1330 - acc: 0.9068 - val_loss: 0.1281 - val_acc: 0.9398
Epoch 12/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1321 - acc: 0.9081 - val_loss: 0.1280 - val_acc: 0.9277
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1304 - acc: 0.9068 - val_loss: 0.1271 - val_acc: 0.9398
Epoch 14/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1305 - acc: 0.9243 - val_loss: 0.1268 - val_acc: 0.9398
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1281 - acc: 0.9189 - val_loss: 0.1267 - val_acc: 0.9277
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1290 - acc: 0.9135 - val_loss: 0.1263 - val_acc: 0.9398
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1247 - acc: 0.9311 - val_loss: 0.1262 - val_acc: 0.9277
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1253 - acc: 0.9230 - val_loss: 0.1253 - val_acc: 0.9398
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1233 - acc: 0.9311 - val_loss: 0.1253 - val_acc: 0.9398
Epoch 20/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1232 - acc: 0.9392 - val_loss: 0.1249 - val_acc: 0.9277
Epoch 21/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1208 - acc: 0.9297 - val_loss: 0.1251 - val_acc: 0.9277
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1209 - acc: 0.9338 - val_loss: 0.1252 - val_acc: 0.9398
Epoch 23/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1201 - acc: 0.9446 - val_loss: 0.1246 - val_acc: 0.9398
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1217 - acc: 0.9297 - val_loss: 0.1248 - val_acc: 0.9277
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1190 - acc: 0.9446 - val_loss: 0.1253 - val_acc: 0.9277
Epoch 26/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1186 - acc: 0.9527 - val_loss: 0.1250 - val_acc: 0.9277
Manual evaluation: (didn't understand why I made this)
True 7310
False 1761
True percentage 0.805864844008
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.27      0.38      0.31       296
      B-LOC       0.69      0.17      0.27       218
      I-ORG       0.17      0.56      0.26       151
     B-MISC       0.08      0.01      0.01       141
     I-MISC       0.44      0.14      0.21       154
      B-PER       0.58      0.36      0.45       438
      I-PER       0.73      0.17      0.27       214
      I-LOC       0.75      0.02      0.04       141

avg / total       0.87      0.81      0.82      9071

F-1 Score:
0.290115532734
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3858 - acc: 0.0089 - val_loss: 0.2019 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1983 - acc: 0.7940 - val_loss: 0.2123 - val_acc: 0.7732
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2125 - acc: 0.6963 - val_loss: 0.1730 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1728 - acc: 0.8028 - val_loss: 0.1513 - val_acc: 0.8247
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1518 - acc: 0.8419 - val_loss: 0.1476 - val_acc: 0.8454
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1461 - acc: 0.8632 - val_loss: 0.1446 - val_acc: 0.8557
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1429 - acc: 0.8615 - val_loss: 0.1421 - val_acc: 0.8557
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1388 - acc: 0.8899 - val_loss: 0.1407 - val_acc: 0.8763
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1356 - acc: 0.9094 - val_loss: 0.1395 - val_acc: 0.8763
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1347 - acc: 0.9059 - val_loss: 0.1378 - val_acc: 0.8866
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1308 - acc: 0.9218 - val_loss: 0.1367 - val_acc: 0.8969
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1291 - acc: 0.9183 - val_loss: 0.1362 - val_acc: 0.8969
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1282 - acc: 0.9094 - val_loss: 0.1354 - val_acc: 0.8969
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1260 - acc: 0.9130 - val_loss: 0.1359 - val_acc: 0.8969
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1252 - acc: 0.9343 - val_loss: 0.1348 - val_acc: 0.8969
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1231 - acc: 0.9396 - val_loss: 0.1353 - val_acc: 0.8969
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1227 - acc: 0.9378 - val_loss: 0.1338 - val_acc: 0.8866
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1219 - acc: 0.9361 - val_loss: 0.1335 - val_acc: 0.8969
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1189 - acc: 0.9520 - val_loss: 0.1327 - val_acc: 0.8969
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1197 - acc: 0.9449 - val_loss: 0.1342 - val_acc: 0.8969
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1163 - acc: 0.9574 - val_loss: 0.1321 - val_acc: 0.8969
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1166 - acc: 0.9591 - val_loss: 0.1327 - val_acc: 0.8969
Epoch 23/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1178 - acc: 0.9520 - val_loss: 0.1320 - val_acc: 0.8969
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1158 - acc: 0.9663 - val_loss: 0.1315 - val_acc: 0.9072
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1148 - acc: 0.9663 - val_loss: 0.1325 - val_acc: 0.8866
Epoch 26/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1134 - acc: 0.9680 - val_loss: 0.1332 - val_acc: 0.9072
Epoch 27/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1136 - acc: 0.9680 - val_loss: 0.1334 - val_acc: 0.8763
Manual evaluation: (didn't understand why I made this)
True 7356
False 1715
True percentage 0.81093594973
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.95      7318
      B-PER       0.56      0.41      0.47       438
      B-LOC       0.52      0.52      0.52       218
      B-ORG       0.29      0.34      0.32       296
      I-ORG       0.18      0.44      0.26       151
      I-PER       1.00      0.03      0.06       214
      I-LOC       0.24      0.23      0.23       141
     B-MISC       0.20      0.03      0.05       141
     I-MISC       0.33      0.01      0.01       154

avg / total       0.87      0.81      0.82      9071

F-1 Score:
0.319269521411
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 85ms/step - loss: 0.3719 - acc: 0.0257 - val_loss: 0.1617 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1893 - acc: 0.8108 - val_loss: 0.1530 - val_acc: 0.8675
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1722 - acc: 0.8270 - val_loss: 0.1454 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1628 - acc: 0.8135 - val_loss: 0.1415 - val_acc: 0.9036
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1506 - acc: 0.8473 - val_loss: 0.1343 - val_acc: 0.8795
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1439 - acc: 0.8635 - val_loss: 0.1326 - val_acc: 0.9157
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1401 - acc: 0.8797 - val_loss: 0.1315 - val_acc: 0.9277
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1351 - acc: 0.8905 - val_loss: 0.1308 - val_acc: 0.9398
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1352 - acc: 0.8946 - val_loss: 0.1306 - val_acc: 0.9398
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1331 - acc: 0.9014 - val_loss: 0.1305 - val_acc: 0.9398
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1292 - acc: 0.9108 - val_loss: 0.1301 - val_acc: 0.9398
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1300 - acc: 0.9054 - val_loss: 0.1304 - val_acc: 0.9398
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1254 - acc: 0.9230 - val_loss: 0.1299 - val_acc: 0.9398
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1259 - acc: 0.9216 - val_loss: 0.1302 - val_acc: 0.9398
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1249 - acc: 0.9257 - val_loss: 0.1298 - val_acc: 0.9398
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1264 - acc: 0.9108 - val_loss: 0.1305 - val_acc: 0.9398
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1224 - acc: 0.9351 - val_loss: 0.1305 - val_acc: 0.9398
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1209 - acc: 0.9378 - val_loss: 0.1303 - val_acc: 0.9398
Manual evaluation: (didn't understand why I made this)
True 7278
False 1793
True percentage 0.802337118289
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-ORG       0.25      0.51      0.33       296
      B-LOC       0.75      0.15      0.25       218
      I-ORG       0.18      0.59      0.27       151
     B-MISC       0.08      0.01      0.01       141
     I-MISC       0.38      0.02      0.04       154
      B-PER       0.63      0.30      0.40       438
      I-PER       0.61      0.22      0.32       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.86      0.80      0.82      9071

F-1 Score:
0.282155091872
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 169ms/step - loss: 0.3305 - acc: 0.1352 - val_loss: 0.1319 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.2244 - acc: 0.7829 - val_loss: 0.1416 - val_acc: 0.8667
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1719 - acc: 0.7722 - val_loss: 0.1176 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1528 - acc: 0.8221 - val_loss: 0.1176 - val_acc: 0.9667
Epoch 5/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1455 - acc: 0.8719 - val_loss: 0.1157 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1402 - acc: 0.8719 - val_loss: 0.1149 - val_acc: 0.9667
Epoch 7/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1351 - acc: 0.9039 - val_loss: 0.1147 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1344 - acc: 0.9075 - val_loss: 0.1161 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1302 - acc: 0.9181 - val_loss: 0.1139 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1279 - acc: 0.9146 - val_loss: 0.1147 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1266 - acc: 0.9324 - val_loss: 0.1132 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1228 - acc: 0.9466 - val_loss: 0.1144 - val_acc: 0.9000
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1230 - acc: 0.9431 - val_loss: 0.1133 - val_acc: 0.9667
Epoch 14/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1212 - acc: 0.9395 - val_loss: 0.1121 - val_acc: 0.9667
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1168 - acc: 0.9680 - val_loss: 0.1130 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1166 - acc: 0.9680 - val_loss: 0.1108 - val_acc: 0.9667
Epoch 17/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1148 - acc: 0.9715 - val_loss: 0.1097 - val_acc: 0.9667
Epoch 18/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1151 - acc: 0.9786 - val_loss: 0.1109 - val_acc: 0.9333
Epoch 19/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1140 - acc: 0.9680 - val_loss: 0.1110 - val_acc: 0.9667
Epoch 20/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1125 - acc: 0.9822 - val_loss: 0.1100 - val_acc: 1.0000
Manual evaluation: (didn't understand why I made this)
True 7263
False 1808
True percentage 0.800683496858
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.40      0.42      0.41       438
      B-LOC       0.42      0.61      0.50       218
      B-ORG       0.29      0.15      0.20       296
      I-ORG       0.11      0.16      0.13       151
      I-PER       0.80      0.02      0.04       214
      I-LOC       0.20      0.38      0.27       141
     B-MISC       0.13      0.04      0.06       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.279676817899
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 160ms/step - loss: 0.3331 - acc: 0.0712 - val_loss: 0.1529 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1798 - acc: 0.8074 - val_loss: 0.2058 - val_acc: 0.6833
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2105 - acc: 0.6359 - val_loss: 0.1400 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1635 - acc: 0.8127 - val_loss: 0.1363 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1457 - acc: 0.8813 - val_loss: 0.1328 - val_acc: 0.9167
Epoch 6/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1417 - acc: 0.8654 - val_loss: 0.1320 - val_acc: 0.9167
Epoch 7/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1378 - acc: 0.8945 - val_loss: 0.1291 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1352 - acc: 0.8945 - val_loss: 0.1272 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1279 - acc: 0.9156 - val_loss: 0.1260 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1282 - acc: 0.9208 - val_loss: 0.1255 - val_acc: 0.9167
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1246 - acc: 0.9367 - val_loss: 0.1255 - val_acc: 0.9167
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1275 - acc: 0.9103 - val_loss: 0.1235 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1229 - acc: 0.9340 - val_loss: 0.1227 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1195 - acc: 0.9446 - val_loss: 0.1224 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1186 - acc: 0.9472 - val_loss: 0.1239 - val_acc: 0.9167
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1199 - acc: 0.9472 - val_loss: 0.1215 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1195 - acc: 0.9420 - val_loss: 0.1211 - val_acc: 0.9167
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1154 - acc: 0.9551 - val_loss: 0.1199 - val_acc: 0.9333
Epoch 19/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1149 - acc: 0.9604 - val_loss: 0.1204 - val_acc: 0.9167
Epoch 20/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1136 - acc: 0.9631 - val_loss: 0.1196 - val_acc: 0.9167
Epoch 21/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1142 - acc: 0.9657 - val_loss: 0.1193 - val_acc: 0.9500
Epoch 22/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1094 - acc: 0.9894 - val_loss: 0.1194 - val_acc: 0.9333
Epoch 23/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1120 - acc: 0.9789 - val_loss: 0.1194 - val_acc: 0.9167
Epoch 24/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1094 - acc: 0.9789 - val_loss: 0.1182 - val_acc: 0.9167
Epoch 25/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1090 - acc: 0.9842 - val_loss: 0.1178 - val_acc: 0.9500
Epoch 26/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1089 - acc: 0.9868 - val_loss: 0.1184 - val_acc: 0.9500
Epoch 27/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1102 - acc: 0.9815 - val_loss: 0.1186 - val_acc: 0.9333
Epoch 28/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1075 - acc: 0.9921 - val_loss: 0.1186 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7235
False 1836
True percentage 0.797596736854
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.19      0.24      0.21       296
      B-LOC       0.65      0.17      0.26       218
      I-ORG       0.16      0.50      0.24       151
     B-MISC       0.09      0.05      0.06       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.58      0.35      0.44       438
      I-PER       0.64      0.19      0.29       214
      I-LOC       0.64      0.05      0.09       141

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.251928020566
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 159ms/step - loss: 0.3458 - acc: 0.0427 - val_loss: 0.1415 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2252 - acc: 0.7829 - val_loss: 0.1455 - val_acc: 0.9000
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1735 - acc: 0.8078 - val_loss: 0.1219 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1554 - acc: 0.8078 - val_loss: 0.1224 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1442 - acc: 0.8577 - val_loss: 0.1221 - val_acc: 0.9000
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1387 - acc: 0.8790 - val_loss: 0.1226 - val_acc: 0.9000
Manual evaluation: (didn't understand why I made this)
True 7069
False 2002
True percentage 0.779296659685
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.91      0.94      7318
      B-PER       0.28      0.37      0.32       438
      B-LOC       0.31      0.70      0.43       218
      B-ORG       0.20      0.11      0.15       296
      I-ORG       0.12      0.14      0.13       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.18      0.38      0.25       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.82      0.78      0.80      9071

F-1 Score:
0.24449594438
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 162ms/step - loss: 0.3116 - acc: 0.2744 - val_loss: 0.1678 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2190 - acc: 0.8074 - val_loss: 0.1918 - val_acc: 0.7833
Epoch 3/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2107 - acc: 0.6992 - val_loss: 0.1422 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1721 - acc: 0.8074 - val_loss: 0.1378 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1476 - acc: 0.8443 - val_loss: 0.1353 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1431 - acc: 0.8654 - val_loss: 0.1350 - val_acc: 0.8833
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1387 - acc: 0.8945 - val_loss: 0.1326 - val_acc: 0.9167
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1353 - acc: 0.9024 - val_loss: 0.1338 - val_acc: 0.9167
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1307 - acc: 0.9156 - val_loss: 0.1311 - val_acc: 0.9167
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1307 - acc: 0.9077 - val_loss: 0.1302 - val_acc: 0.9167
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1279 - acc: 0.9340 - val_loss: 0.1284 - val_acc: 0.9167
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1242 - acc: 0.9288 - val_loss: 0.1293 - val_acc: 0.9167
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1243 - acc: 0.9367 - val_loss: 0.1281 - val_acc: 0.9167
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1222 - acc: 0.9367 - val_loss: 0.1271 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1213 - acc: 0.9446 - val_loss: 0.1256 - val_acc: 0.9167
Epoch 16/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1201 - acc: 0.9340 - val_loss: 0.1283 - val_acc: 0.9000
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1196 - acc: 0.9472 - val_loss: 0.1258 - val_acc: 0.9167
Epoch 18/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1195 - acc: 0.9367 - val_loss: 0.1253 - val_acc: 0.9167
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1161 - acc: 0.9604 - val_loss: 0.1261 - val_acc: 0.9000
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1144 - acc: 0.9657 - val_loss: 0.1261 - val_acc: 0.9000
Epoch 21/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1150 - acc: 0.9604 - val_loss: 0.1249 - val_acc: 0.9167
Epoch 22/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1156 - acc: 0.9525 - val_loss: 0.1230 - val_acc: 0.9333
Epoch 23/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1135 - acc: 0.9604 - val_loss: 0.1241 - val_acc: 0.9167
Epoch 24/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1136 - acc: 0.9631 - val_loss: 0.1237 - val_acc: 0.9167
Epoch 25/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1113 - acc: 0.9789 - val_loss: 0.1240 - val_acc: 0.9167
Manual evaluation: (didn't understand why I made this)
True 7223
False 1848
True percentage 0.796273839709
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.95      7318
      B-ORG       0.20      0.29      0.24       296
      B-LOC       0.68      0.09      0.15       218
      I-ORG       0.16      0.62      0.26       151
     B-MISC       0.07      0.02      0.03       141
     I-MISC       0.25      0.01      0.01       154
      B-PER       0.58      0.32      0.42       438
      I-PER       0.64      0.20      0.31       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.245480494767
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 163ms/step - loss: 0.3226 - acc: 0.2100 - val_loss: 0.1241 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2106 - acc: 0.7829 - val_loss: 0.1398 - val_acc: 0.9000
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1754 - acc: 0.7972 - val_loss: 0.1175 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1545 - acc: 0.8149 - val_loss: 0.1199 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1419 - acc: 0.8826 - val_loss: 0.1168 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1364 - acc: 0.8968 - val_loss: 0.1165 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1334 - acc: 0.9110 - val_loss: 0.1141 - val_acc: 0.9667
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1306 - acc: 0.9217 - val_loss: 0.1158 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1273 - acc: 0.9431 - val_loss: 0.1141 - val_acc: 0.9667
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1260 - acc: 0.9359 - val_loss: 0.1144 - val_acc: 0.9000
Manual evaluation: (didn't understand why I made this)
True 7251
False 1820
True percentage 0.799360599713
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.39      0.47      0.42       438
      B-LOC       0.39      0.67      0.49       218
      B-ORG       0.34      0.12      0.18       296
      I-ORG       0.14      0.19      0.16       151
      I-PER       1.00      0.00      0.01       214
      I-LOC       0.18      0.34      0.23       141
     B-MISC       0.10      0.01      0.01       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.285187461586
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 160ms/step - loss: 0.3569 - acc: 0.0449 - val_loss: 0.1593 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1936 - acc: 0.8074 - val_loss: 0.1732 - val_acc: 0.8333
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1963 - acc: 0.7230 - val_loss: 0.1464 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1747 - acc: 0.8074 - val_loss: 0.1408 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1527 - acc: 0.8443 - val_loss: 0.1336 - val_acc: 0.9500
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1438 - acc: 0.8602 - val_loss: 0.1321 - val_acc: 0.9500
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1402 - acc: 0.8786 - val_loss: 0.1304 - val_acc: 0.9500
Epoch 8/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1365 - acc: 0.9024 - val_loss: 0.1271 - val_acc: 0.9500
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1339 - acc: 0.8918 - val_loss: 0.1259 - val_acc: 0.9500
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1282 - acc: 0.9129 - val_loss: 0.1239 - val_acc: 0.9500
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1267 - acc: 0.9182 - val_loss: 0.1232 - val_acc: 0.9500
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1271 - acc: 0.9314 - val_loss: 0.1223 - val_acc: 0.9500
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1219 - acc: 0.9499 - val_loss: 0.1201 - val_acc: 0.9667
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1229 - acc: 0.9393 - val_loss: 0.1208 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1200 - acc: 0.9420 - val_loss: 0.1190 - val_acc: 0.9667
Epoch 16/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1172 - acc: 0.9551 - val_loss: 0.1179 - val_acc: 0.9667
Epoch 17/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1173 - acc: 0.9525 - val_loss: 0.1172 - val_acc: 0.9667
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1166 - acc: 0.9604 - val_loss: 0.1172 - val_acc: 0.9500
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1149 - acc: 0.9657 - val_loss: 0.1162 - val_acc: 0.9500
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1129 - acc: 0.9736 - val_loss: 0.1156 - val_acc: 0.9667
Epoch 21/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1133 - acc: 0.9683 - val_loss: 0.1150 - val_acc: 0.9667
Epoch 22/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1123 - acc: 0.9710 - val_loss: 0.1150 - val_acc: 0.9667
Epoch 23/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1112 - acc: 0.9710 - val_loss: 0.1138 - val_acc: 0.9833
Epoch 24/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1120 - acc: 0.9789 - val_loss: 0.1140 - val_acc: 0.9833
Epoch 25/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1111 - acc: 0.9631 - val_loss: 0.1131 - val_acc: 0.9667
Epoch 26/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1099 - acc: 0.9815 - val_loss: 0.1143 - val_acc: 0.9833
Epoch 27/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1096 - acc: 0.9815 - val_loss: 0.1132 - val_acc: 0.9833
Epoch 28/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1104 - acc: 0.9736 - val_loss: 0.1128 - val_acc: 0.9833
Epoch 29/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1081 - acc: 0.9947 - val_loss: 0.1119 - val_acc: 0.9833
Epoch 30/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1081 - acc: 0.9868 - val_loss: 0.1130 - val_acc: 0.9667
Epoch 31/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1072 - acc: 0.9894 - val_loss: 0.1124 - val_acc: 0.9667
Epoch 32/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1078 - acc: 0.9894 - val_loss: 0.1114 - val_acc: 0.9667
Epoch 33/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1073 - acc: 0.9868 - val_loss: 0.1112 - val_acc: 0.9667
Epoch 34/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1064 - acc: 0.9947 - val_loss: 0.1113 - val_acc: 0.9667
Epoch 35/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1066 - acc: 0.9921 - val_loss: 0.1108 - val_acc: 0.9667
Epoch 36/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1060 - acc: 0.9868 - val_loss: 0.1097 - val_acc: 0.9667
Epoch 37/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1057 - acc: 0.9894 - val_loss: 0.1096 - val_acc: 0.9667
Epoch 38/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1053 - acc: 0.9974 - val_loss: 0.1099 - val_acc: 0.9833
Epoch 39/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1063 - acc: 0.9894 - val_loss: 0.1102 - val_acc: 0.9833
Epoch 40/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1057 - acc: 0.9868 - val_loss: 0.1095 - val_acc: 0.9667
Epoch 41/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1038 - acc: 0.9921 - val_loss: 0.1096 - val_acc: 0.9667
Epoch 42/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1049 - acc: 0.9974 - val_loss: 0.1095 - val_acc: 0.9667
Epoch 43/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1041 - acc: 0.9947 - val_loss: 0.1097 - val_acc: 0.9667
Epoch 44/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1039 - acc: 0.9974 - val_loss: 0.1090 - val_acc: 0.9667
Epoch 45/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1036 - acc: 0.9974 - val_loss: 0.1094 - val_acc: 0.9667
Epoch 46/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1040 - acc: 0.9974 - val_loss: 0.1093 - val_acc: 0.9667
Epoch 47/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1053 - acc: 0.9842 - val_loss: 0.1086 - val_acc: 0.9667
Epoch 48/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1032 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9667
Epoch 49/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1028 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9667
Epoch 50/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1047 - acc: 0.9947 - val_loss: 0.1099 - val_acc: 0.9667
Epoch 51/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1049 - acc: 0.9868 - val_loss: 0.1101 - val_acc: 0.9667
Manual evaluation: (didn't understand why I made this)
True 7260
False 1811
True percentage 0.800352772572
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.95      7318
      B-ORG       0.23      0.31      0.26       296
      B-LOC       0.69      0.19      0.30       218
      I-ORG       0.18      0.58      0.27       151
     B-MISC       0.15      0.06      0.08       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.51      0.35      0.42       438
      I-PER       0.70      0.19      0.30       214
      I-LOC       0.90      0.06      0.12       141

avg / total       0.86      0.80      0.81      9071

F-1 Score:
0.27487244898
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 158ms/step - loss: 0.3949 - acc: 0.0320 - val_loss: 0.1393 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2208 - acc: 0.7829 - val_loss: 0.1375 - val_acc: 0.9333
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1817 - acc: 0.7829 - val_loss: 0.1233 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1631 - acc: 0.7972 - val_loss: 0.1210 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1528 - acc: 0.8256 - val_loss: 0.1184 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1437 - acc: 0.8826 - val_loss: 0.1181 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1385 - acc: 0.8897 - val_loss: 0.1173 - val_acc: 0.9000
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1364 - acc: 0.9004 - val_loss: 0.1171 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1297 - acc: 0.9146 - val_loss: 0.1168 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1285 - acc: 0.9181 - val_loss: 0.1162 - val_acc: 0.9000
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1262 - acc: 0.9466 - val_loss: 0.1165 - val_acc: 0.9000
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1231 - acc: 0.9431 - val_loss: 0.1140 - val_acc: 0.9667
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1214 - acc: 0.9537 - val_loss: 0.1155 - val_acc: 0.9000
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1201 - acc: 0.9609 - val_loss: 0.1149 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1202 - acc: 0.9466 - val_loss: 0.1153 - val_acc: 0.9000
Manual evaluation: (didn't understand why I made this)
True 7176
False 1895
True percentage 0.791092492559
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.92      0.95      7318
      B-PER       0.37      0.44      0.40       438
      B-LOC       0.39      0.59      0.47       218
      B-ORG       0.26      0.17      0.20       296
      I-ORG       0.12      0.19      0.15       151
      I-PER       0.43      0.01      0.03       214
      I-LOC       0.15      0.27      0.19       141
     B-MISC       0.11      0.04      0.05       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.79      0.81      9071

F-1 Score:
0.265830346476
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 161ms/step - loss: 0.3727 - acc: 0.0158 - val_loss: 0.1592 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2097 - acc: 0.8074 - val_loss: 0.1518 - val_acc: 0.8667
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1718 - acc: 0.8179 - val_loss: 0.1344 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1546 - acc: 0.8232 - val_loss: 0.1369 - val_acc: 0.8833
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1462 - acc: 0.8654 - val_loss: 0.1301 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1387 - acc: 0.8865 - val_loss: 0.1305 - val_acc: 0.9333
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1348 - acc: 0.8865 - val_loss: 0.1283 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1318 - acc: 0.8945 - val_loss: 0.1285 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1296 - acc: 0.9129 - val_loss: 0.1277 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1275 - acc: 0.9050 - val_loss: 0.1268 - val_acc: 0.9167
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1243 - acc: 0.9261 - val_loss: 0.1272 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1255 - acc: 0.9050 - val_loss: 0.1248 - val_acc: 0.9167
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1233 - acc: 0.9446 - val_loss: 0.1251 - val_acc: 0.9167
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1194 - acc: 0.9472 - val_loss: 0.1244 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1193 - acc: 0.9499 - val_loss: 0.1235 - val_acc: 0.9167
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1183 - acc: 0.9472 - val_loss: 0.1229 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1167 - acc: 0.9551 - val_loss: 0.1229 - val_acc: 0.9167
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1140 - acc: 0.9657 - val_loss: 0.1214 - val_acc: 0.9500
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1155 - acc: 0.9578 - val_loss: 0.1214 - val_acc: 0.9500
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1146 - acc: 0.9525 - val_loss: 0.1212 - val_acc: 0.9500
Epoch 21/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1112 - acc: 0.9736 - val_loss: 0.1214 - val_acc: 0.9333
Epoch 22/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1121 - acc: 0.9763 - val_loss: 0.1208 - val_acc: 0.9500
Epoch 23/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1117 - acc: 0.9736 - val_loss: 0.1207 - val_acc: 0.9333
Epoch 24/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1131 - acc: 0.9736 - val_loss: 0.1203 - val_acc: 0.9500
Epoch 25/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1103 - acc: 0.9815 - val_loss: 0.1207 - val_acc: 0.9333
Epoch 26/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1115 - acc: 0.9710 - val_loss: 0.1206 - val_acc: 0.9500
Epoch 27/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1099 - acc: 0.9763 - val_loss: 0.1192 - val_acc: 0.9500
Epoch 28/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1090 - acc: 0.9789 - val_loss: 0.1196 - val_acc: 0.9500
Epoch 29/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1085 - acc: 0.9789 - val_loss: 0.1202 - val_acc: 0.9333
Epoch 30/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1096 - acc: 0.9736 - val_loss: 0.1187 - val_acc: 0.9667
Epoch 31/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1088 - acc: 0.9815 - val_loss: 0.1179 - val_acc: 0.9500
Epoch 32/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1077 - acc: 0.9815 - val_loss: 0.1191 - val_acc: 0.9500
Epoch 33/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1065 - acc: 0.9947 - val_loss: 0.1179 - val_acc: 0.9500
Epoch 34/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1077 - acc: 0.9842 - val_loss: 0.1189 - val_acc: 0.9500
Manual evaluation: (didn't understand why I made this)
True 7224
False 1847
True percentage 0.796384081138
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.95      7318
      B-ORG       0.21      0.28      0.24       296
      B-LOC       0.65      0.17      0.27       218
      I-ORG       0.15      0.48      0.23       151
     B-MISC       0.10      0.04      0.06       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.51      0.35      0.42       438
      I-PER       0.52      0.20      0.28       214
      I-LOC       0.67      0.03      0.05       141

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.25452237385
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 163ms/step - loss: 0.3883 - acc: 0.0142 - val_loss: 0.1404 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1955 - acc: 0.7829 - val_loss: 0.1469 - val_acc: 0.8667
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1896 - acc: 0.7473 - val_loss: 0.1254 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1862 - acc: 0.7829 - val_loss: 0.1323 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1567 - acc: 0.8327 - val_loss: 0.1184 - val_acc: 0.9667
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1439 - acc: 0.8719 - val_loss: 0.1185 - val_acc: 0.9667
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1377 - acc: 0.8826 - val_loss: 0.1172 - val_acc: 0.9667
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1345 - acc: 0.9110 - val_loss: 0.1176 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1326 - acc: 0.8897 - val_loss: 0.1161 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1280 - acc: 0.9395 - val_loss: 0.1164 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1248 - acc: 0.9431 - val_loss: 0.1157 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1251 - acc: 0.9253 - val_loss: 0.1169 - val_acc: 0.9000
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1240 - acc: 0.9502 - val_loss: 0.1158 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1199 - acc: 0.9644 - val_loss: 0.1162 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7227
False 1844
True percentage 0.796714805424
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.94      7318
      B-PER       0.40      0.39      0.40       438
      B-LOC       0.40      0.68      0.50       218
      B-ORG       0.35      0.15      0.21       296
      I-ORG       0.14      0.19      0.16       151
      I-PER       0.75      0.03      0.05       214
      I-LOC       0.16      0.35      0.22       141
     B-MISC       0.14      0.04      0.07       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.80      0.81      9071

F-1 Score:
0.280593325093
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 157ms/step - loss: 0.3631 - acc: 0.1135 - val_loss: 0.1634 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1975 - acc: 0.8074 - val_loss: 0.1583 - val_acc: 0.8667
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1688 - acc: 0.8153 - val_loss: 0.1410 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1545 - acc: 0.8338 - val_loss: 0.1415 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1437 - acc: 0.8707 - val_loss: 0.1349 - val_acc: 0.9500
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1381 - acc: 0.8734 - val_loss: 0.1337 - val_acc: 0.9167
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1347 - acc: 0.9103 - val_loss: 0.1315 - val_acc: 0.9500
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1298 - acc: 0.9077 - val_loss: 0.1309 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1275 - acc: 0.9235 - val_loss: 0.1317 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1256 - acc: 0.9314 - val_loss: 0.1286 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1224 - acc: 0.9340 - val_loss: 0.1287 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1228 - acc: 0.9340 - val_loss: 0.1277 - val_acc: 0.9167
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1196 - acc: 0.9420 - val_loss: 0.1274 - val_acc: 0.9167
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1198 - acc: 0.9393 - val_loss: 0.1258 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1168 - acc: 0.9604 - val_loss: 0.1248 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1168 - acc: 0.9578 - val_loss: 0.1268 - val_acc: 0.9167
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1135 - acc: 0.9710 - val_loss: 0.1237 - val_acc: 0.9333
Epoch 18/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1143 - acc: 0.9578 - val_loss: 0.1245 - val_acc: 0.9167
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1156 - acc: 0.9578 - val_loss: 0.1226 - val_acc: 0.9333
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1126 - acc: 0.9683 - val_loss: 0.1222 - val_acc: 0.9500
Epoch 21/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1122 - acc: 0.9631 - val_loss: 0.1243 - val_acc: 0.9167
Epoch 22/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1134 - acc: 0.9657 - val_loss: 0.1235 - val_acc: 0.9333
Epoch 23/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1118 - acc: 0.9710 - val_loss: 0.1213 - val_acc: 0.9500
Epoch 24/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1121 - acc: 0.9683 - val_loss: 0.1223 - val_acc: 0.9667
Epoch 25/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1107 - acc: 0.9657 - val_loss: 0.1214 - val_acc: 0.9500
Epoch 26/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1076 - acc: 0.9868 - val_loss: 0.1211 - val_acc: 0.9333
Epoch 27/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1094 - acc: 0.9815 - val_loss: 0.1216 - val_acc: 0.9333
Epoch 28/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1095 - acc: 0.9763 - val_loss: 0.1212 - val_acc: 0.9333
Epoch 29/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1079 - acc: 0.9947 - val_loss: 0.1209 - val_acc: 0.9500
Epoch 30/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1072 - acc: 0.9947 - val_loss: 0.1206 - val_acc: 0.9333
Epoch 31/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1079 - acc: 0.9894 - val_loss: 0.1203 - val_acc: 0.9500
Epoch 32/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1067 - acc: 0.9894 - val_loss: 0.1208 - val_acc: 0.9500
Epoch 33/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1073 - acc: 0.9763 - val_loss: 0.1190 - val_acc: 0.9333
Epoch 34/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1056 - acc: 0.9974 - val_loss: 0.1202 - val_acc: 0.9333
Epoch 35/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1061 - acc: 0.9894 - val_loss: 0.1198 - val_acc: 0.9333
Epoch 36/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1056 - acc: 0.9894 - val_loss: 0.1198 - val_acc: 0.9500
Manual evaluation: (didn't understand why I made this)
True 7274
False 1797
True percentage 0.801896152574
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.24      0.31      0.27       296
      B-LOC       0.73      0.19      0.30       218
      I-ORG       0.17      0.59      0.26       151
     B-MISC       0.11      0.06      0.08       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.58      0.33      0.42       438
      I-PER       0.58      0.17      0.26       214
      I-LOC       0.55      0.04      0.08       141

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.267008985879
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 306ms/step - loss: 0.4014 - acc: 0.0556 - val_loss: 0.1870 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2075 - acc: 0.7778 - val_loss: 0.1748 - val_acc: 0.8966
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1757 - acc: 0.8810 - val_loss: 0.1888 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1637 - acc: 0.8333 - val_loss: 0.1711 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1470 - acc: 0.9206 - val_loss: 0.1680 - val_acc: 0.8621
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1441 - acc: 0.9206 - val_loss: 0.1756 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1661 - val_acc: 0.8621
Epoch 8/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1318 - acc: 0.9683 - val_loss: 0.1719 - val_acc: 0.8621
Epoch 9/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1353 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.8621
Epoch 10/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1313 - acc: 0.9762 - val_loss: 0.1649 - val_acc: 0.8621
Epoch 11/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1340 - acc: 0.9444 - val_loss: 0.1565 - val_acc: 0.8621
Epoch 12/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1264 - acc: 0.9762 - val_loss: 0.1578 - val_acc: 0.8621
Epoch 13/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1228 - acc: 0.9683 - val_loss: 0.1606 - val_acc: 0.8621
Epoch 14/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1231 - acc: 0.9921 - val_loss: 0.1586 - val_acc: 0.8621
Manual evaluation: (didn't understand why I made this)
True 7160
False 1757
True percentage 0.802960636986
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.92      0.94      7318
      B-PER       0.43      0.36      0.39       438
      B-LOC       0.34      0.61      0.44       218
      B-ORG       0.21      0.16      0.18       296
      I-ORG       0.14      0.42      0.21       151
      I-PER       0.26      0.05      0.08       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.80      0.81      8917

F-1 Score:
0.26588845655
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 303ms/step - loss: 0.3380 - acc: 0.1296 - val_loss: 0.2176 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2037 - acc: 0.7963 - val_loss: 0.2792 - val_acc: 0.5000
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2293 - acc: 0.5802 - val_loss: 0.1892 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1620 - acc: 0.8025 - val_loss: 0.1769 - val_acc: 0.8421
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1419 - acc: 0.8519 - val_loss: 0.1747 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1349 - acc: 0.8951 - val_loss: 0.1757 - val_acc: 0.8421
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1334 - acc: 0.9074 - val_loss: 0.1742 - val_acc: 0.8421
Epoch 8/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1258 - acc: 0.9259 - val_loss: 0.1763 - val_acc: 0.8421
Epoch 9/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1240 - acc: 0.9383 - val_loss: 0.1747 - val_acc: 0.8421
Epoch 10/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1231 - acc: 0.9198 - val_loss: 0.1780 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7123
False 1948
True percentage 0.785249696836
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.94      0.94      7318
      B-ORG       0.21      0.29      0.24       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.14      0.60      0.22       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.57      0.17      0.26       438
      I-PER       0.33      0.01      0.02       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.80      0.79      0.78      9071

F-1 Score:
0.170385395538
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 303ms/step - loss: 0.3675 - acc: 0.0873 - val_loss: 0.2189 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2368 - acc: 0.7698 - val_loss: 0.2046 - val_acc: 0.7931
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2100 - acc: 0.7540 - val_loss: 0.1847 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1736 - acc: 0.7778 - val_loss: 0.1779 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1656 - acc: 0.8333 - val_loss: 0.1803 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1484 - acc: 0.9048 - val_loss: 0.1851 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1451 - acc: 0.8889 - val_loss: 0.1834 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7245
False 1672
True percentage 0.812492990916
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.94      0.94      7318
      B-PER       0.40      0.45      0.42       438
      B-LOC       0.44      0.47      0.46       218
      B-ORG       0.28      0.12      0.17       296
      I-ORG       0.16      0.40      0.23       151
      I-PER       0.50      0.02      0.04       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.81      0.81      8917

F-1 Score:
0.281690140845
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 300ms/step - loss: 0.3394 - acc: 0.0617 - val_loss: 0.2026 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1919 - acc: 0.7963 - val_loss: 0.2309 - val_acc: 0.6842
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1797 - acc: 0.7531 - val_loss: 0.1722 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1476 - acc: 0.8148 - val_loss: 0.1797 - val_acc: 0.8158
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1342 - acc: 0.9012 - val_loss: 0.1744 - val_acc: 0.8684
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1286 - acc: 0.9074 - val_loss: 0.1771 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7188
False 1883
True percentage 0.792415389703
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.94      0.94      7318
      B-ORG       0.25      0.47      0.33       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.16      0.49      0.24       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.77      0.14      0.24       438
      I-PER       0.60      0.11      0.19       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.82      0.79      0.79      9071

F-1 Score:
0.207279029463
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 302ms/step - loss: 0.3645 - acc: 0.1984 - val_loss: 0.2135 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 35ms/step - loss: 0.2080 - acc: 0.7698 - val_loss: 0.1983 - val_acc: 0.7931
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1976 - acc: 0.7937 - val_loss: 0.2195 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1765 - acc: 0.8095 - val_loss: 0.1979 - val_acc: 0.7931
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1554 - acc: 0.8651 - val_loss: 0.1944 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1510 - acc: 0.9048 - val_loss: 0.1948 - val_acc: 0.7931
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1495 - acc: 0.8571 - val_loss: 0.1872 - val_acc: 0.8276
Epoch 8/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1401 - acc: 0.9286 - val_loss: 0.1876 - val_acc: 0.7931
Epoch 9/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1340 - acc: 0.9762 - val_loss: 0.1898 - val_acc: 0.7931
Epoch 10/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1352 - acc: 0.9524 - val_loss: 0.1870 - val_acc: 0.7931
Epoch 11/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1290 - acc: 0.9444 - val_loss: 0.1913 - val_acc: 0.7931
Epoch 12/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1289 - acc: 0.9683 - val_loss: 0.1897 - val_acc: 0.7931
Epoch 13/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1265 - acc: 0.9683 - val_loss: 0.1865 - val_acc: 0.7931
Epoch 14/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1221 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.8276
Epoch 15/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1264 - acc: 0.9683 - val_loss: 0.1901 - val_acc: 0.7931
Epoch 16/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1222 - acc: 0.9841 - val_loss: 0.1864 - val_acc: 0.8276
Epoch 17/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1214 - acc: 0.9921 - val_loss: 0.1904 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7204
False 1713
True percentage 0.807895031961
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.93      0.94      7318
      B-PER       0.38      0.32      0.35       438
      B-LOC       0.42      0.48      0.45       218
      B-ORG       0.29      0.23      0.25       296
      I-ORG       0.15      0.36      0.21       151
      I-PER       0.43      0.08      0.14       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.81      0.81      8917

F-1 Score:
0.266206896552
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 306ms/step - loss: 0.3736 - acc: 0.0185 - val_loss: 0.1951 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1992 - acc: 0.7963 - val_loss: 0.2052 - val_acc: 0.7632
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1686 - acc: 0.8148 - val_loss: 0.1769 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1543 - acc: 0.8086 - val_loss: 0.1862 - val_acc: 0.7368
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1363 - acc: 0.9012 - val_loss: 0.1680 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1309 - acc: 0.9012 - val_loss: 0.1721 - val_acc: 0.8158
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1257 - acc: 0.9383 - val_loss: 0.1709 - val_acc: 0.8158
Epoch 8/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1185 - acc: 0.9630 - val_loss: 0.1704 - val_acc: 0.8158
Manual evaluation: (didn't understand why I made this)
True 7200
False 1871
True percentage 0.793738286848
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.92      0.95      0.93      7318
      B-ORG       0.25      0.26      0.26       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.15      0.46      0.23       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.67      0.17      0.28       438
      I-PER       0.54      0.12      0.19       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.80      0.79      0.78      9071

F-1 Score:
0.184867685427
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 300ms/step - loss: 0.4023 - acc: 0.0317 - val_loss: 0.2030 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2334 - acc: 0.7698 - val_loss: 0.1825 - val_acc: 0.9310
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2379 - acc: 0.6429 - val_loss: 0.1899 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1893 - acc: 0.7778 - val_loss: 0.1769 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1590 - acc: 0.8730 - val_loss: 0.1771 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1532 - acc: 0.8889 - val_loss: 0.1761 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1510 - acc: 0.9286 - val_loss: 0.1752 - val_acc: 0.8276
Epoch 8/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1464 - acc: 0.9365 - val_loss: 0.1748 - val_acc: 0.8276
Epoch 9/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1382 - acc: 0.9365 - val_loss: 0.1760 - val_acc: 0.8276
Epoch 10/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1390 - acc: 0.9206 - val_loss: 0.1731 - val_acc: 0.8276
Epoch 11/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1325 - acc: 0.9603 - val_loss: 0.1745 - val_acc: 0.8276
Epoch 12/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1292 - acc: 0.9683 - val_loss: 0.1698 - val_acc: 0.8276
Epoch 13/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1312 - acc: 0.9921 - val_loss: 0.1720 - val_acc: 0.8276
Epoch 14/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1271 - acc: 0.9841 - val_loss: 0.1730 - val_acc: 0.8276
Epoch 15/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1271 - acc: 0.9683 - val_loss: 0.1754 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7216
False 1701
True percentage 0.809240776046
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.94      7318
      B-PER       0.37      0.40      0.39       438
      B-LOC       0.47      0.52      0.49       218
      B-ORG       0.25      0.21      0.23       296
      I-ORG       0.16      0.42      0.23       151
      I-PER       0.38      0.07      0.11       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.84      0.81      0.82      8917

F-1 Score:
0.284391534392
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 299ms/step - loss: 0.3179 - acc: 0.1543 - val_loss: 0.2063 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1887 - acc: 0.7963 - val_loss: 0.2158 - val_acc: 0.7368
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1638 - acc: 0.7963 - val_loss: 0.1786 - val_acc: 0.8158
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1416 - acc: 0.8395 - val_loss: 0.1819 - val_acc: 0.8158
Epoch 5/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1335 - acc: 0.8951 - val_loss: 0.1770 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1275 - acc: 0.9012 - val_loss: 0.1830 - val_acc: 0.8158
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1221 - acc: 0.9444 - val_loss: 0.1768 - val_acc: 0.8421
Epoch 8/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1209 - acc: 0.9259 - val_loss: 0.1779 - val_acc: 0.8158
Epoch 9/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1187 - acc: 0.9691 - val_loss: 0.1756 - val_acc: 0.8421
Epoch 10/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1166 - acc: 0.9444 - val_loss: 0.1781 - val_acc: 0.8158
Epoch 11/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1159 - acc: 0.9444 - val_loss: 0.1737 - val_acc: 0.8421
Epoch 12/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1117 - acc: 0.9691 - val_loss: 0.1801 - val_acc: 0.8158
Epoch 13/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1119 - acc: 0.9753 - val_loss: 0.1820 - val_acc: 0.8158
Epoch 14/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1125 - acc: 0.9568 - val_loss: 0.1813 - val_acc: 0.8158
Manual evaluation: (didn't understand why I made this)
True 7193
False 1878
True percentage 0.792966596847
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.94      0.94      7318
      B-ORG       0.25      0.29      0.27       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.15      0.48      0.23       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.40      0.26      0.32       438
      I-PER       0.48      0.11      0.18       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.80      0.79      0.79      9071

F-1 Score:
0.204600068658
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 301ms/step - loss: 0.3820 - acc: 0.0635 - val_loss: 0.2183 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2197 - acc: 0.7698 - val_loss: 0.1969 - val_acc: 0.8276
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1901 - acc: 0.8175 - val_loss: 0.1872 - val_acc: 0.8621
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1622 - acc: 0.8333 - val_loss: 0.1805 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1540 - acc: 0.9048 - val_loss: 0.1847 - val_acc: 0.8621
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1490 - acc: 0.8889 - val_loss: 0.1853 - val_acc: 0.7931
Epoch 7/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1417 - acc: 0.9365 - val_loss: 0.1831 - val_acc: 0.8621
Manual evaluation: (didn't understand why I made this)
True 7198
False 1719
True percentage 0.807222159919
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.92      0.94      0.93      7318
      B-PER       0.36      0.35      0.36       438
      B-LOC       0.30      0.50      0.37       218
      B-ORG       0.26      0.14      0.18       296
      I-ORG       0.17      0.06      0.09       151
      I-PER       0.47      0.07      0.11       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.80      0.81      0.80      8917

F-1 Score:
0.248213614141
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 300ms/step - loss: 0.2931 - acc: 0.3272 - val_loss: 0.2475 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2436 - acc: 0.7963 - val_loss: 0.2214 - val_acc: 0.6579
Epoch 3/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1734 - acc: 0.8025 - val_loss: 0.1830 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1607 - acc: 0.8025 - val_loss: 0.1718 - val_acc: 0.8421
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1370 - acc: 0.9074 - val_loss: 0.1780 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1319 - acc: 0.8889 - val_loss: 0.1763 - val_acc: 0.8421
Epoch 7/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1277 - acc: 0.9198 - val_loss: 0.1770 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7135
False 1936
True percentage 0.786572593981
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.95      0.94      7318
      B-ORG       0.28      0.24      0.26       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.13      0.67      0.22       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.60      0.08      0.13       438
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.79      0.79      0.78      9071

F-1 Score:
0.145428873985
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 33ms/step - loss: 0.1623 - acc: 0.8238 - val_loss: 0.1456 - val_acc: 0.8467
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1333 - acc: 0.8962 - val_loss: 0.1276 - val_acc: 0.9045
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1266 - acc: 0.9177 - val_loss: 0.1218 - val_acc: 0.9353
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1237 - acc: 0.9250 - val_loss: 0.1209 - val_acc: 0.9355
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1216 - acc: 0.9334 - val_loss: 0.1205 - val_acc: 0.9331
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1197 - acc: 0.9397 - val_loss: 0.1190 - val_acc: 0.9441
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1183 - acc: 0.9443 - val_loss: 0.1192 - val_acc: 0.9431
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1172 - acc: 0.9469 - val_loss: 0.1215 - val_acc: 0.9363
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1165 - acc: 0.9486 - val_loss: 0.1175 - val_acc: 0.9472
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1160 - acc: 0.9507 - val_loss: 0.1161 - val_acc: 0.9497
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1149 - acc: 0.9547 - val_loss: 0.1163 - val_acc: 0.9511
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1143 - acc: 0.9555 - val_loss: 0.1159 - val_acc: 0.9539
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1140 - acc: 0.9574 - val_loss: 0.1154 - val_acc: 0.9553
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1133 - acc: 0.9594 - val_loss: 0.1154 - val_acc: 0.9548
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1128 - acc: 0.9623 - val_loss: 0.1153 - val_acc: 0.9553
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1125 - acc: 0.9609 - val_loss: 0.1152 - val_acc: 0.9553
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1121 - acc: 0.9629 - val_loss: 0.1149 - val_acc: 0.9556
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1116 - acc: 0.9647 - val_loss: 0.1149 - val_acc: 0.9575
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1118 - acc: 0.9638 - val_loss: 0.1147 - val_acc: 0.9583
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1110 - acc: 0.9676 - val_loss: 0.1156 - val_acc: 0.9551
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1108 - acc: 0.9672 - val_loss: 0.1152 - val_acc: 0.9556
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1105 - acc: 0.9674 - val_loss: 0.1147 - val_acc: 0.9589
Manual evaluation: (didn't understand why I made this)
True 8244
False 827
True percentage 0.908830338441
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.92      0.84      0.88       438
      B-LOC       0.73      0.79      0.76       218
      B-ORG       0.76      0.76      0.76       296
      I-ORG       0.61      0.61      0.61       151
      I-PER       0.90      0.64      0.75       214
      I-LOC       0.68      0.81      0.74       141
     B-MISC       0.47      0.30      0.37       141
     I-MISC       0.48      0.35      0.41       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.716666666667
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1633 - acc: 0.8268 - val_loss: 0.1373 - val_acc: 0.8749
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1342 - acc: 0.8952 - val_loss: 0.1243 - val_acc: 0.9245
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1270 - acc: 0.9154 - val_loss: 0.1213 - val_acc: 0.9429
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1242 - acc: 0.9248 - val_loss: 0.1199 - val_acc: 0.9390
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1217 - acc: 0.9320 - val_loss: 0.1192 - val_acc: 0.9440
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1204 - acc: 0.9362 - val_loss: 0.1168 - val_acc: 0.9528
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1191 - acc: 0.9399 - val_loss: 0.1171 - val_acc: 0.9500
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1179 - acc: 0.9437 - val_loss: 0.1152 - val_acc: 0.9571
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1168 - acc: 0.9473 - val_loss: 0.1183 - val_acc: 0.9488
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1160 - acc: 0.9501 - val_loss: 0.1149 - val_acc: 0.9583
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1154 - acc: 0.9526 - val_loss: 0.1146 - val_acc: 0.9597
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1146 - acc: 0.9544 - val_loss: 0.1143 - val_acc: 0.9593
Epoch 13/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1141 - acc: 0.9564 - val_loss: 0.1145 - val_acc: 0.9577
Epoch 14/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1134 - acc: 0.9587 - val_loss: 0.1167 - val_acc: 0.9502
Epoch 15/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1135 - acc: 0.9596 - val_loss: 0.1146 - val_acc: 0.9600
Manual evaluation: (didn't understand why I made this)
True 8243
False 828
True percentage 0.908720097012
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.78      0.72      0.75       296
      B-LOC       0.80      0.70      0.75       218
      I-ORG       0.66      0.52      0.58       151
     B-MISC       0.39      0.36      0.37       141
     I-MISC       0.44      0.51      0.47       154
      B-PER       0.92      0.85      0.88       438
      I-PER       0.93      0.63      0.75       214
      I-LOC       0.79      0.74      0.76       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.711925503154
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1583 - acc: 0.8346 - val_loss: 0.1324 - val_acc: 0.9000
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1309 - acc: 0.9031 - val_loss: 0.1234 - val_acc: 0.9250
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1260 - acc: 0.9178 - val_loss: 0.1210 - val_acc: 0.9359
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1228 - acc: 0.9290 - val_loss: 0.1210 - val_acc: 0.9319
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1208 - acc: 0.9339 - val_loss: 0.1210 - val_acc: 0.9313
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1195 - acc: 0.9405 - val_loss: 0.1183 - val_acc: 0.9423
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1181 - acc: 0.9447 - val_loss: 0.1178 - val_acc: 0.9381
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1170 - acc: 0.9477 - val_loss: 0.1164 - val_acc: 0.9483
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1161 - acc: 0.9495 - val_loss: 0.1185 - val_acc: 0.9395
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1154 - acc: 0.9528 - val_loss: 0.1161 - val_acc: 0.9493
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1146 - acc: 0.9547 - val_loss: 0.1157 - val_acc: 0.9530
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1140 - acc: 0.9572 - val_loss: 0.1156 - val_acc: 0.9522
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1138 - acc: 0.9582 - val_loss: 0.1193 - val_acc: 0.9340
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1130 - acc: 0.9598 - val_loss: 0.1154 - val_acc: 0.9517
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9618 - val_loss: 0.1151 - val_acc: 0.9540
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1122 - acc: 0.9624 - val_loss: 0.1146 - val_acc: 0.9539
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1117 - acc: 0.9640 - val_loss: 0.1148 - val_acc: 0.9544
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1110 - acc: 0.9661 - val_loss: 0.1150 - val_acc: 0.9556
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1110 - acc: 0.9649 - val_loss: 0.1144 - val_acc: 0.9560
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1108 - acc: 0.9684 - val_loss: 0.1153 - val_acc: 0.9530
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1105 - acc: 0.9675 - val_loss: 0.1144 - val_acc: 0.9561
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9690 - val_loss: 0.1155 - val_acc: 0.9534
Manual evaluation: (didn't understand why I made this)
True 8228
False 843
True percentage 0.907066475582
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.91      0.85      0.88       438
      B-LOC       0.74      0.74      0.74       218
      B-ORG       0.70      0.75      0.72       296
      I-ORG       0.49      0.70      0.58       151
      I-PER       0.92      0.66      0.77       214
      I-LOC       0.75      0.74      0.75       141
     B-MISC       0.61      0.21      0.32       141
     I-MISC       0.51      0.23      0.32       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.705811502559
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1617 - acc: 0.8313 - val_loss: 0.1332 - val_acc: 0.8955
Epoch 2/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1317 - acc: 0.9018 - val_loss: 0.1232 - val_acc: 0.9288
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1265 - acc: 0.9173 - val_loss: 0.1193 - val_acc: 0.9443
Epoch 4/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1232 - acc: 0.9271 - val_loss: 0.1259 - val_acc: 0.9149
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1218 - acc: 0.9310 - val_loss: 0.1169 - val_acc: 0.9508
Epoch 6/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1195 - acc: 0.9398 - val_loss: 0.1167 - val_acc: 0.9494
Epoch 7/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1188 - acc: 0.9410 - val_loss: 0.1159 - val_acc: 0.9551
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1175 - acc: 0.9443 - val_loss: 0.1148 - val_acc: 0.9571
Epoch 9/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1167 - acc: 0.9469 - val_loss: 0.1146 - val_acc: 0.9591
Epoch 10/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1154 - acc: 0.9518 - val_loss: 0.1146 - val_acc: 0.9553
Epoch 11/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1149 - acc: 0.9539 - val_loss: 0.1149 - val_acc: 0.9568
Epoch 12/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1137 - acc: 0.9575 - val_loss: 0.1139 - val_acc: 0.9608
Epoch 13/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1135 - acc: 0.9584 - val_loss: 0.1140 - val_acc: 0.9602
Epoch 14/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1132 - acc: 0.9601 - val_loss: 0.1141 - val_acc: 0.9596
Epoch 15/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1127 - acc: 0.9611 - val_loss: 0.1153 - val_acc: 0.9513
Manual evaluation: (didn't understand why I made this)
True 8162
False 909
True percentage 0.899790541285
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.86      0.56      0.68       296
      B-LOC       0.78      0.72      0.75       218
      I-ORG       0.74      0.28      0.40       151
     B-MISC       0.28      0.48      0.35       141
     I-MISC       0.37      0.60      0.46       154
      B-PER       0.93      0.81      0.87       438
      I-PER       0.88      0.65      0.75       214
      I-LOC       0.73      0.74      0.74       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.664495114007
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1614 - acc: 0.8299 - val_loss: 0.1439 - val_acc: 0.8792
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1326 - acc: 0.8992 - val_loss: 0.1258 - val_acc: 0.9157
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1269 - acc: 0.9154 - val_loss: 0.1248 - val_acc: 0.9121
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1242 - acc: 0.9250 - val_loss: 0.1205 - val_acc: 0.9339
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1220 - acc: 0.9307 - val_loss: 0.1204 - val_acc: 0.9325
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1200 - acc: 0.9372 - val_loss: 0.1191 - val_acc: 0.9392
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1189 - acc: 0.9414 - val_loss: 0.1173 - val_acc: 0.9474
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1179 - acc: 0.9453 - val_loss: 0.1180 - val_acc: 0.9412
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1166 - acc: 0.9477 - val_loss: 0.1178 - val_acc: 0.9443
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1160 - acc: 0.9514 - val_loss: 0.1171 - val_acc: 0.9478
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1150 - acc: 0.9544 - val_loss: 0.1163 - val_acc: 0.9520
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1146 - acc: 0.9547 - val_loss: 0.1171 - val_acc: 0.9458
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1138 - acc: 0.9584 - val_loss: 0.1193 - val_acc: 0.9365
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1133 - acc: 0.9603 - val_loss: 0.1155 - val_acc: 0.9531
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1127 - acc: 0.9618 - val_loss: 0.1151 - val_acc: 0.9556
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1122 - acc: 0.9639 - val_loss: 0.1152 - val_acc: 0.9548
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1119 - acc: 0.9643 - val_loss: 0.1170 - val_acc: 0.9506
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1118 - acc: 0.9633 - val_loss: 0.1148 - val_acc: 0.9565
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1117 - acc: 0.9654 - val_loss: 0.1146 - val_acc: 0.9579
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1109 - acc: 0.9675 - val_loss: 0.1155 - val_acc: 0.9532
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1106 - acc: 0.9678 - val_loss: 0.1152 - val_acc: 0.9559
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1103 - acc: 0.9685 - val_loss: 0.1150 - val_acc: 0.9578
Manual evaluation: (didn't understand why I made this)
True 8260
False 811
True percentage 0.910594201301
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.90      0.85      0.87       438
      B-LOC       0.73      0.81      0.77       218
      B-ORG       0.74      0.76      0.75       296
      I-ORG       0.63      0.62      0.62       151
      I-PER       0.91      0.65      0.76       214
      I-LOC       0.69      0.81      0.75       141
     B-MISC       0.58      0.26      0.36       141
     I-MISC       0.54      0.33      0.41       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.724220623501
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 33ms/step - loss: 0.1608 - acc: 0.8298 - val_loss: 0.1338 - val_acc: 0.8837
Epoch 2/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1327 - acc: 0.8975 - val_loss: 0.1238 - val_acc: 0.9317
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1270 - acc: 0.9153 - val_loss: 0.1207 - val_acc: 0.9382
Epoch 4/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1237 - acc: 0.9262 - val_loss: 0.1227 - val_acc: 0.9269
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1215 - acc: 0.9324 - val_loss: 0.1182 - val_acc: 0.9434
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1203 - acc: 0.9369 - val_loss: 0.1170 - val_acc: 0.9474
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1186 - acc: 0.9435 - val_loss: 0.1162 - val_acc: 0.9530
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1176 - acc: 0.9445 - val_loss: 0.1158 - val_acc: 0.9522
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1164 - acc: 0.9488 - val_loss: 0.1154 - val_acc: 0.9537
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1163 - acc: 0.9493 - val_loss: 0.1172 - val_acc: 0.9448
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1154 - acc: 0.9534 - val_loss: 0.1158 - val_acc: 0.9508
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1142 - acc: 0.9557 - val_loss: 0.1148 - val_acc: 0.9548
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1136 - acc: 0.9571 - val_loss: 0.1140 - val_acc: 0.9571
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1135 - acc: 0.9583 - val_loss: 0.1143 - val_acc: 0.9562
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1128 - acc: 0.9595 - val_loss: 0.1144 - val_acc: 0.9550
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1126 - acc: 0.9622 - val_loss: 0.1139 - val_acc: 0.9576
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1124 - acc: 0.9622 - val_loss: 0.1148 - val_acc: 0.9524
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1112 - acc: 0.9668 - val_loss: 0.1139 - val_acc: 0.9576
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1113 - acc: 0.9651 - val_loss: 0.1137 - val_acc: 0.9599
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1109 - acc: 0.9661 - val_loss: 0.1135 - val_acc: 0.9591
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1108 - acc: 0.9666 - val_loss: 0.1143 - val_acc: 0.9579
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1102 - acc: 0.9691 - val_loss: 0.1135 - val_acc: 0.9582
Epoch 23/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9699 - val_loss: 0.1137 - val_acc: 0.9593
Epoch 24/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9690 - val_loss: 0.1137 - val_acc: 0.9585
Epoch 25/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1097 - acc: 0.9710 - val_loss: 0.1144 - val_acc: 0.9579
Manual evaluation: (didn't understand why I made this)
True 8238
False 833
True percentage 0.908168889869
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.74      0.77      0.75       296
      B-LOC       0.74      0.77      0.75       218
      I-ORG       0.47      0.75      0.58       151
     B-MISC       0.55      0.26      0.35       141
     I-MISC       0.47      0.30      0.37       154
      B-PER       0.92      0.84      0.88       438
      I-PER       0.94      0.63      0.75       214
      I-LOC       0.75      0.75      0.75       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.710308056872
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 33ms/step - loss: 0.1510 - acc: 0.8417 - val_loss: 0.1316 - val_acc: 0.8948
Epoch 2/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1298 - acc: 0.9045 - val_loss: 0.1240 - val_acc: 0.9210
Epoch 3/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1248 - acc: 0.9202 - val_loss: 0.1199 - val_acc: 0.9361
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1218 - acc: 0.9315 - val_loss: 0.1201 - val_acc: 0.9337
Epoch 5/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1200 - acc: 0.9361 - val_loss: 0.1195 - val_acc: 0.9415
Epoch 6/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1188 - acc: 0.9402 - val_loss: 0.1180 - val_acc: 0.9429
Epoch 7/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1173 - acc: 0.9475 - val_loss: 0.1170 - val_acc: 0.9431
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1162 - acc: 0.9495 - val_loss: 0.1161 - val_acc: 0.9470
Epoch 9/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1156 - acc: 0.9521 - val_loss: 0.1169 - val_acc: 0.9393
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1148 - acc: 0.9542 - val_loss: 0.1157 - val_acc: 0.9504
Epoch 11/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1142 - acc: 0.9554 - val_loss: 0.1157 - val_acc: 0.9500
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1135 - acc: 0.9580 - val_loss: 0.1154 - val_acc: 0.9510
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1129 - acc: 0.9599 - val_loss: 0.1143 - val_acc: 0.9553
Epoch 14/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1122 - acc: 0.9622 - val_loss: 0.1147 - val_acc: 0.9529
Epoch 15/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1117 - acc: 0.9634 - val_loss: 0.1144 - val_acc: 0.9555
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1117 - acc: 0.9636 - val_loss: 0.1142 - val_acc: 0.9569
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9642 - val_loss: 0.1139 - val_acc: 0.9567
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1107 - acc: 0.9669 - val_loss: 0.1138 - val_acc: 0.9581
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1106 - acc: 0.9675 - val_loss: 0.1139 - val_acc: 0.9572
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9690 - val_loss: 0.1140 - val_acc: 0.9577
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9690 - val_loss: 0.1137 - val_acc: 0.9572
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9696 - val_loss: 0.1143 - val_acc: 0.9591
Epoch 23/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1095 - acc: 0.9710 - val_loss: 0.1138 - val_acc: 0.9572
Epoch 24/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1095 - acc: 0.9710 - val_loss: 0.1149 - val_acc: 0.9531
Manual evaluation: (didn't understand why I made this)
True 8244
False 827
True percentage 0.908830338441
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.92      0.84      0.88       438
      B-LOC       0.72      0.81      0.76       218
      B-ORG       0.67      0.77      0.72       296
      I-ORG       0.51      0.70      0.59       151
      I-PER       0.91      0.66      0.76       214
      I-LOC       0.67      0.80      0.73       141
     B-MISC       0.70      0.23      0.35       141
     I-MISC       0.62      0.23      0.34       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.712759643917
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1531 - acc: 0.8356 - val_loss: 0.1317 - val_acc: 0.8869
Epoch 2/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1302 - acc: 0.9033 - val_loss: 0.1283 - val_acc: 0.9080
Epoch 3/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1256 - acc: 0.9191 - val_loss: 0.1195 - val_acc: 0.9374
Epoch 4/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1223 - acc: 0.9286 - val_loss: 0.1181 - val_acc: 0.9445
Epoch 5/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1202 - acc: 0.9349 - val_loss: 0.1179 - val_acc: 0.9403
Epoch 6/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1192 - acc: 0.9402 - val_loss: 0.1153 - val_acc: 0.9528
Epoch 7/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1173 - acc: 0.9463 - val_loss: 0.1159 - val_acc: 0.9482
Epoch 8/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1167 - acc: 0.9470 - val_loss: 0.1188 - val_acc: 0.9362
Epoch 9/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1159 - acc: 0.9500 - val_loss: 0.1151 - val_acc: 0.9521
Epoch 10/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1146 - acc: 0.9537 - val_loss: 0.1144 - val_acc: 0.9542
Epoch 11/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1143 - acc: 0.9541 - val_loss: 0.1135 - val_acc: 0.9568
Epoch 12/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1136 - acc: 0.9585 - val_loss: 0.1136 - val_acc: 0.9588
Epoch 13/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1135 - acc: 0.9567 - val_loss: 0.1135 - val_acc: 0.9573
Epoch 14/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1127 - acc: 0.9606 - val_loss: 0.1139 - val_acc: 0.9542
Epoch 15/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1119 - acc: 0.9618 - val_loss: 0.1131 - val_acc: 0.9576
Epoch 16/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1119 - acc: 0.9631 - val_loss: 0.1130 - val_acc: 0.9599
Epoch 17/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1111 - acc: 0.9663 - val_loss: 0.1132 - val_acc: 0.9585
Epoch 18/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1108 - acc: 0.9662 - val_loss: 0.1127 - val_acc: 0.9602
Epoch 19/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1107 - acc: 0.9668 - val_loss: 0.1129 - val_acc: 0.9594
Epoch 20/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1100 - acc: 0.9685 - val_loss: 0.1124 - val_acc: 0.9608
Epoch 21/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1100 - acc: 0.9680 - val_loss: 0.1125 - val_acc: 0.9611
Epoch 22/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1095 - acc: 0.9699 - val_loss: 0.1124 - val_acc: 0.9617
Epoch 23/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1098 - acc: 0.9695 - val_loss: 0.1133 - val_acc: 0.9614
Epoch 24/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1091 - acc: 0.9705 - val_loss: 0.1125 - val_acc: 0.9614
Epoch 25/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1089 - acc: 0.9730 - val_loss: 0.1126 - val_acc: 0.9597
Manual evaluation: (didn't understand why I made this)
True 8267
False 804
True percentage 0.911365891302
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.97      0.98      7318
      B-ORG       0.75      0.75      0.75       296
      B-LOC       0.75      0.73      0.74       218
      I-ORG       0.69      0.60      0.64       151
     B-MISC       0.48      0.32      0.38       141
     I-MISC       0.43      0.56      0.49       154
      B-PER       0.96      0.83      0.89       438
      I-PER       0.97      0.59      0.74       214
      I-LOC       0.77      0.74      0.75       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.71951951952
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1469 - acc: 0.8493 - val_loss: 0.1388 - val_acc: 0.8508
Epoch 2/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1291 - acc: 0.9075 - val_loss: 0.1253 - val_acc: 0.9133
Epoch 3/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1245 - acc: 0.9234 - val_loss: 0.1227 - val_acc: 0.9251
Epoch 4/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1220 - acc: 0.9305 - val_loss: 0.1184 - val_acc: 0.9409
Epoch 5/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1202 - acc: 0.9368 - val_loss: 0.1203 - val_acc: 0.9350
Epoch 6/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1188 - acc: 0.9413 - val_loss: 0.1168 - val_acc: 0.9470
Epoch 7/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1169 - acc: 0.9468 - val_loss: 0.1167 - val_acc: 0.9444
Epoch 8/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1164 - acc: 0.9506 - val_loss: 0.1175 - val_acc: 0.9447
Epoch 9/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1155 - acc: 0.9517 - val_loss: 0.1173 - val_acc: 0.9455
Epoch 10/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1148 - acc: 0.9538 - val_loss: 0.1158 - val_acc: 0.9507
Epoch 11/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1142 - acc: 0.9552 - val_loss: 0.1155 - val_acc: 0.9499
Epoch 12/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1134 - acc: 0.9584 - val_loss: 0.1148 - val_acc: 0.9540
Epoch 13/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1131 - acc: 0.9584 - val_loss: 0.1157 - val_acc: 0.9512
Epoch 14/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1126 - acc: 0.9620 - val_loss: 0.1143 - val_acc: 0.9574
Epoch 15/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1120 - acc: 0.9620 - val_loss: 0.1145 - val_acc: 0.9562
Epoch 16/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1118 - acc: 0.9629 - val_loss: 0.1148 - val_acc: 0.9556
Epoch 17/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1113 - acc: 0.9645 - val_loss: 0.1140 - val_acc: 0.9556
Epoch 18/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1108 - acc: 0.9670 - val_loss: 0.1140 - val_acc: 0.9562
Epoch 19/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1103 - acc: 0.9688 - val_loss: 0.1141 - val_acc: 0.9572
Epoch 20/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1101 - acc: 0.9693 - val_loss: 0.1142 - val_acc: 0.9572
Manual evaluation: (didn't understand why I made this)
True 8265
False 806
True percentage 0.911145408444
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.92      0.85      0.89       438
      B-LOC       0.71      0.83      0.76       218
      B-ORG       0.72      0.75      0.73       296
      I-ORG       0.63      0.57      0.60       151
      I-PER       0.94      0.65      0.77       214
      I-LOC       0.61      0.84      0.71       141
     B-MISC       0.71      0.29      0.41       141
     I-MISC       0.56      0.36      0.44       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.724732461356
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 32ms/step - loss: 0.1454 - acc: 0.8517 - val_loss: 0.1326 - val_acc: 0.8998
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1285 - acc: 0.9102 - val_loss: 0.1199 - val_acc: 0.9468
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1244 - acc: 0.9223 - val_loss: 0.1187 - val_acc: 0.9434
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1215 - acc: 0.9309 - val_loss: 0.1190 - val_acc: 0.9383
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1194 - acc: 0.9387 - val_loss: 0.1158 - val_acc: 0.9531
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1183 - acc: 0.9417 - val_loss: 0.1179 - val_acc: 0.9439
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1171 - acc: 0.9462 - val_loss: 0.1146 - val_acc: 0.9588
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1160 - acc: 0.9487 - val_loss: 0.1145 - val_acc: 0.9556
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1153 - acc: 0.9529 - val_loss: 0.1140 - val_acc: 0.9584
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1145 - acc: 0.9541 - val_loss: 0.1148 - val_acc: 0.9574
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1141 - acc: 0.9565 - val_loss: 0.1132 - val_acc: 0.9588
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1133 - acc: 0.9574 - val_loss: 0.1136 - val_acc: 0.9562
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1130 - acc: 0.9583 - val_loss: 0.1129 - val_acc: 0.9602
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1126 - acc: 0.9601 - val_loss: 0.1130 - val_acc: 0.9602
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1116 - acc: 0.9629 - val_loss: 0.1129 - val_acc: 0.9610
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1114 - acc: 0.9648 - val_loss: 0.1125 - val_acc: 0.9599
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1111 - acc: 0.9653 - val_loss: 0.1131 - val_acc: 0.9610
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1102 - acc: 0.9682 - val_loss: 0.1125 - val_acc: 0.9605
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1104 - acc: 0.9680 - val_loss: 0.1127 - val_acc: 0.9608
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1102 - acc: 0.9675 - val_loss: 0.1131 - val_acc: 0.9619
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9687 - val_loss: 0.1125 - val_acc: 0.9605
Manual evaluation: (didn't understand why I made this)
True 8278
False 793
True percentage 0.912578547018
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.74      0.75      0.75       296
      B-LOC       0.74      0.78      0.76       218
      I-ORG       0.59      0.60      0.60       151
     B-MISC       0.52      0.38      0.44       141
     I-MISC       0.54      0.48      0.51       154
      B-PER       0.93      0.85      0.89       438
      I-PER       0.94      0.66      0.78       214
      I-LOC       0.71      0.82      0.76       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.73215339233
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1787 - acc: 0.7806 - val_loss: 0.1438 - val_acc: 0.8652
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1421 - acc: 0.8728 - val_loss: 0.1315 - val_acc: 0.8938
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1332 - acc: 0.8980 - val_loss: 0.1278 - val_acc: 0.9049
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1286 - acc: 0.9112 - val_loss: 0.1265 - val_acc: 0.9160
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1254 - acc: 0.9191 - val_loss: 0.1240 - val_acc: 0.9222
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1238 - acc: 0.9253 - val_loss: 0.1230 - val_acc: 0.9233
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1221 - acc: 0.9316 - val_loss: 0.1211 - val_acc: 0.9317
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1209 - acc: 0.9349 - val_loss: 0.1209 - val_acc: 0.9318
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1199 - acc: 0.9380 - val_loss: 0.1202 - val_acc: 0.9338
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1184 - acc: 0.9427 - val_loss: 0.1203 - val_acc: 0.9337
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1177 - acc: 0.9459 - val_loss: 0.1202 - val_acc: 0.9349
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1168 - acc: 0.9489 - val_loss: 0.1194 - val_acc: 0.9345
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1161 - acc: 0.9514 - val_loss: 0.1198 - val_acc: 0.9355
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1157 - acc: 0.9519 - val_loss: 0.1202 - val_acc: 0.9344
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1152 - acc: 0.9527 - val_loss: 0.1188 - val_acc: 0.9364
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1141 - acc: 0.9571 - val_loss: 0.1183 - val_acc: 0.9384
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1138 - acc: 0.9577 - val_loss: 0.1185 - val_acc: 0.9393
Epoch 18/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1131 - acc: 0.9615 - val_loss: 0.1186 - val_acc: 0.9408
Epoch 19/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1129 - acc: 0.9627 - val_loss: 0.1188 - val_acc: 0.9370
Manual evaluation: (didn't understand why I made this)
True 8094
False 977
True percentage 0.892294124132
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.88      0.76      0.82       438
      B-LOC       0.69      0.77      0.73       218
      B-ORG       0.69      0.71      0.70       296
      I-ORG       0.47      0.49      0.48       151
      I-PER       0.89      0.63      0.73       214
      I-LOC       0.59      0.82      0.68       141
     B-MISC       0.42      0.11      0.18       141
     I-MISC       0.41      0.22      0.29       154

avg / total       0.92      0.89      0.90      9071

F-1 Score:
0.656553398058
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1815 - acc: 0.7789 - val_loss: 0.1476 - val_acc: 0.8489
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1429 - acc: 0.8721 - val_loss: 0.1350 - val_acc: 0.8959
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1336 - acc: 0.8952 - val_loss: 0.1326 - val_acc: 0.9058
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1293 - acc: 0.9109 - val_loss: 0.1283 - val_acc: 0.9047
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1264 - acc: 0.9169 - val_loss: 0.1262 - val_acc: 0.9162
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1232 - acc: 0.9279 - val_loss: 0.1248 - val_acc: 0.9240
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1225 - acc: 0.9282 - val_loss: 0.1243 - val_acc: 0.9222
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1210 - acc: 0.9347 - val_loss: 0.1239 - val_acc: 0.9233
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1200 - acc: 0.9387 - val_loss: 0.1236 - val_acc: 0.9244
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1186 - acc: 0.9430 - val_loss: 0.1229 - val_acc: 0.9311
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1178 - acc: 0.9450 - val_loss: 0.1233 - val_acc: 0.9256
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1168 - acc: 0.9486 - val_loss: 0.1227 - val_acc: 0.9275
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1155 - acc: 0.9530 - val_loss: 0.1226 - val_acc: 0.9300
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1152 - acc: 0.9522 - val_loss: 0.1227 - val_acc: 0.9294
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1148 - acc: 0.9554 - val_loss: 0.1220 - val_acc: 0.9315
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1137 - acc: 0.9582 - val_loss: 0.1221 - val_acc: 0.9309
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1134 - acc: 0.9595 - val_loss: 0.1224 - val_acc: 0.9294
Epoch 18/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1126 - acc: 0.9625 - val_loss: 0.1221 - val_acc: 0.9309
Manual evaluation: (didn't understand why I made this)
True 8129
False 942
True percentage 0.896152574137
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.72      0.68      0.70       296
      B-LOC       0.73      0.73      0.73       218
      I-ORG       0.49      0.49      0.49       151
     B-MISC       0.33      0.18      0.23       141
     I-MISC       0.39      0.32      0.35       154
      B-PER       0.92      0.80      0.86       438
      I-PER       0.88      0.62      0.73       214
      I-LOC       0.69      0.77      0.73       141

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.66889632107
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1731 - acc: 0.8082 - val_loss: 0.1436 - val_acc: 0.8878
Epoch 2/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1399 - acc: 0.8785 - val_loss: 0.1302 - val_acc: 0.9204
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1322 - acc: 0.8971 - val_loss: 0.1260 - val_acc: 0.9127
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1279 - acc: 0.9144 - val_loss: 0.1248 - val_acc: 0.9157
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1254 - acc: 0.9201 - val_loss: 0.1224 - val_acc: 0.9254
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1228 - acc: 0.9288 - val_loss: 0.1227 - val_acc: 0.9305
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1218 - acc: 0.9314 - val_loss: 0.1214 - val_acc: 0.9236
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1205 - acc: 0.9346 - val_loss: 0.1207 - val_acc: 0.9328
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1191 - acc: 0.9410 - val_loss: 0.1192 - val_acc: 0.9379
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1176 - acc: 0.9453 - val_loss: 0.1187 - val_acc: 0.9406
Epoch 11/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1167 - acc: 0.9479 - val_loss: 0.1200 - val_acc: 0.9320
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1161 - acc: 0.9509 - val_loss: 0.1190 - val_acc: 0.9409
Epoch 13/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1155 - acc: 0.9510 - val_loss: 0.1178 - val_acc: 0.9442
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1149 - acc: 0.9548 - val_loss: 0.1188 - val_acc: 0.9408
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1147 - acc: 0.9564 - val_loss: 0.1191 - val_acc: 0.9430
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1140 - acc: 0.9578 - val_loss: 0.1191 - val_acc: 0.9402
Manual evaluation: (didn't understand why I made this)
True 8109
False 962
True percentage 0.893947745563
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.90      0.76      0.83       438
      B-LOC       0.73      0.68      0.70       218
      B-ORG       0.65      0.70      0.68       296
      I-ORG       0.45      0.60      0.51       151
      I-PER       0.88      0.63      0.73       214
      I-LOC       0.78      0.74      0.76       141
     B-MISC       0.42      0.19      0.26       141
     I-MISC       0.45      0.22      0.30       154

avg / total       0.93      0.89      0.91      9071

F-1 Score:
0.660561660562
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1746 - acc: 0.7913 - val_loss: 0.1439 - val_acc: 0.8650
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1404 - acc: 0.8749 - val_loss: 0.1325 - val_acc: 0.9002
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1327 - acc: 0.8996 - val_loss: 0.1290 - val_acc: 0.9049
Epoch 4/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1276 - acc: 0.9136 - val_loss: 0.1260 - val_acc: 0.9177
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1253 - acc: 0.9211 - val_loss: 0.1243 - val_acc: 0.9196
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1227 - acc: 0.9288 - val_loss: 0.1238 - val_acc: 0.9248
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1217 - acc: 0.9335 - val_loss: 0.1232 - val_acc: 0.9263
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1204 - acc: 0.9389 - val_loss: 0.1235 - val_acc: 0.9233
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1189 - acc: 0.9406 - val_loss: 0.1231 - val_acc: 0.9263
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1181 - acc: 0.9433 - val_loss: 0.1226 - val_acc: 0.9289
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1168 - acc: 0.9475 - val_loss: 0.1223 - val_acc: 0.9304
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1158 - acc: 0.9506 - val_loss: 0.1220 - val_acc: 0.9310
Epoch 13/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1150 - acc: 0.9532 - val_loss: 0.1221 - val_acc: 0.9295
Epoch 14/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1148 - acc: 0.9545 - val_loss: 0.1218 - val_acc: 0.9330
Epoch 15/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1141 - acc: 0.9553 - val_loss: 0.1221 - val_acc: 0.9316
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1136 - acc: 0.9581 - val_loss: 0.1218 - val_acc: 0.9325
Epoch 17/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1130 - acc: 0.9604 - val_loss: 0.1221 - val_acc: 0.9310
Manual evaluation: (didn't understand why I made this)
True 8148
False 923
True percentage 0.898247161283
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.75      0.65      0.69       296
      B-LOC       0.72      0.78      0.75       218
      I-ORG       0.66      0.36      0.47       151
     B-MISC       0.30      0.23      0.26       141
     I-MISC       0.40      0.47      0.43       154
      B-PER       0.92      0.80      0.86       438
      I-PER       0.89      0.63      0.74       214
      I-LOC       0.67      0.83      0.74       141

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.676895306859
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1778 - acc: 0.7865 - val_loss: 0.1454 - val_acc: 0.8587
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1414 - acc: 0.8731 - val_loss: 0.1331 - val_acc: 0.8954
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1332 - acc: 0.8972 - val_loss: 0.1275 - val_acc: 0.9076
Epoch 4/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1285 - acc: 0.9094 - val_loss: 0.1274 - val_acc: 0.9028
Epoch 5/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1260 - acc: 0.9182 - val_loss: 0.1235 - val_acc: 0.9219
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1240 - acc: 0.9237 - val_loss: 0.1241 - val_acc: 0.9216
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1226 - acc: 0.9291 - val_loss: 0.1219 - val_acc: 0.9300
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1212 - acc: 0.9342 - val_loss: 0.1235 - val_acc: 0.9163
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1196 - acc: 0.9370 - val_loss: 0.1224 - val_acc: 0.9279
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1178 - acc: 0.9446 - val_loss: 0.1213 - val_acc: 0.9316
Epoch 11/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1174 - acc: 0.9471 - val_loss: 0.1204 - val_acc: 0.9352
Epoch 12/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1166 - acc: 0.9497 - val_loss: 0.1197 - val_acc: 0.9365
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1154 - acc: 0.9528 - val_loss: 0.1202 - val_acc: 0.9331
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1151 - acc: 0.9534 - val_loss: 0.1205 - val_acc: 0.9357
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1145 - acc: 0.9566 - val_loss: 0.1205 - val_acc: 0.9365
Manual evaluation: (didn't understand why I made this)
True 8089
False 982
True percentage 0.891742916988
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.91      0.74      0.82       438
      B-LOC       0.68      0.74      0.71       218
      B-ORG       0.67      0.72      0.69       296
      I-ORG       0.47      0.58      0.52       151
      I-PER       0.90      0.59      0.71       214
      I-LOC       0.64      0.78      0.70       141
     B-MISC       0.41      0.13      0.19       141
     I-MISC       0.38      0.18      0.24       154

avg / total       0.92      0.89      0.90      9071

F-1 Score:
0.651842826683
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1746 - acc: 0.7974 - val_loss: 0.1521 - val_acc: 0.8268
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1415 - acc: 0.8737 - val_loss: 0.1351 - val_acc: 0.8818
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1330 - acc: 0.8970 - val_loss: 0.1294 - val_acc: 0.9083
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1293 - acc: 0.9077 - val_loss: 0.1278 - val_acc: 0.9116
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1264 - acc: 0.9162 - val_loss: 0.1263 - val_acc: 0.9147
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1236 - acc: 0.9267 - val_loss: 0.1249 - val_acc: 0.9201
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1223 - acc: 0.9304 - val_loss: 0.1247 - val_acc: 0.9149
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1207 - acc: 0.9337 - val_loss: 0.1237 - val_acc: 0.9274
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1193 - acc: 0.9411 - val_loss: 0.1233 - val_acc: 0.9264
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1185 - acc: 0.9411 - val_loss: 0.1233 - val_acc: 0.9289
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1177 - acc: 0.9444 - val_loss: 0.1226 - val_acc: 0.9315
Epoch 12/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1167 - acc: 0.9463 - val_loss: 0.1227 - val_acc: 0.9268
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1155 - acc: 0.9516 - val_loss: 0.1224 - val_acc: 0.9283
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1154 - acc: 0.9520 - val_loss: 0.1222 - val_acc: 0.9341
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1144 - acc: 0.9563 - val_loss: 0.1220 - val_acc: 0.9299
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1145 - acc: 0.9542 - val_loss: 0.1220 - val_acc: 0.9340
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1136 - acc: 0.9592 - val_loss: 0.1219 - val_acc: 0.9319
Epoch 18/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1130 - acc: 0.9602 - val_loss: 0.1214 - val_acc: 0.9330
Epoch 19/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1127 - acc: 0.9613 - val_loss: 0.1214 - val_acc: 0.9346
Epoch 20/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1116 - acc: 0.9629 - val_loss: 0.1214 - val_acc: 0.9330
Epoch 21/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1116 - acc: 0.9647 - val_loss: 0.1217 - val_acc: 0.9356
Epoch 22/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1112 - acc: 0.9662 - val_loss: 0.1217 - val_acc: 0.9315
Epoch 23/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1107 - acc: 0.9668 - val_loss: 0.1218 - val_acc: 0.9357
Manual evaluation: (didn't understand why I made this)
True 8179
False 892
True percentage 0.901664645574
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.71      0.72      0.71       296
      B-LOC       0.74      0.75      0.74       218
      I-ORG       0.53      0.52      0.53       151
     B-MISC       0.47      0.30      0.36       141
     I-MISC       0.44      0.36      0.40       154
      B-PER       0.90      0.82      0.86       438
      I-PER       0.89      0.62      0.73       214
      I-LOC       0.72      0.79      0.75       141

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.692053973013
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1670 - acc: 0.8063 - val_loss: 0.1402 - val_acc: 0.8756
Epoch 2/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1384 - acc: 0.8777 - val_loss: 0.1308 - val_acc: 0.8964
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1322 - acc: 0.8993 - val_loss: 0.1264 - val_acc: 0.9093
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1281 - acc: 0.9116 - val_loss: 0.1235 - val_acc: 0.9185
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1249 - acc: 0.9213 - val_loss: 0.1233 - val_acc: 0.9221
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1227 - acc: 0.9289 - val_loss: 0.1213 - val_acc: 0.9316
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1214 - acc: 0.9325 - val_loss: 0.1219 - val_acc: 0.9222
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1198 - acc: 0.9388 - val_loss: 0.1201 - val_acc: 0.9316
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1187 - acc: 0.9407 - val_loss: 0.1205 - val_acc: 0.9338
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1172 - acc: 0.9448 - val_loss: 0.1197 - val_acc: 0.9312
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1167 - acc: 0.9477 - val_loss: 0.1194 - val_acc: 0.9352
Epoch 12/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1157 - acc: 0.9526 - val_loss: 0.1184 - val_acc: 0.9388
Epoch 13/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1149 - acc: 0.9549 - val_loss: 0.1187 - val_acc: 0.9359
Epoch 14/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1148 - acc: 0.9547 - val_loss: 0.1189 - val_acc: 0.9358
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1142 - acc: 0.9576 - val_loss: 0.1182 - val_acc: 0.9368
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1130 - acc: 0.9605 - val_loss: 0.1190 - val_acc: 0.9404
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1126 - acc: 0.9607 - val_loss: 0.1192 - val_acc: 0.9388
Epoch 18/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1124 - acc: 0.9626 - val_loss: 0.1189 - val_acc: 0.9401
Manual evaluation: (didn't understand why I made this)
True 8139
False 932
True percentage 0.897254988425
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.87      0.78      0.82       438
      B-LOC       0.75      0.70      0.72       218
      B-ORG       0.67      0.72      0.69       296
      I-ORG       0.46      0.64      0.53       151
      I-PER       0.92      0.62      0.74       214
      I-LOC       0.75      0.72      0.73       141
     B-MISC       0.49      0.26      0.34       141
     I-MISC       0.50      0.28      0.36       154

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.672496984318
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1663 - acc: 0.7918 - val_loss: 0.1380 - val_acc: 0.8847
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1376 - acc: 0.8810 - val_loss: 0.1341 - val_acc: 0.8853
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1311 - acc: 0.9003 - val_loss: 0.1276 - val_acc: 0.9147
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1268 - acc: 0.9142 - val_loss: 0.1255 - val_acc: 0.9186
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1246 - acc: 0.9197 - val_loss: 0.1247 - val_acc: 0.9236
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1221 - acc: 0.9299 - val_loss: 0.1241 - val_acc: 0.9172
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1210 - acc: 0.9348 - val_loss: 0.1227 - val_acc: 0.9265
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1196 - acc: 0.9361 - val_loss: 0.1229 - val_acc: 0.9293
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1187 - acc: 0.9399 - val_loss: 0.1220 - val_acc: 0.9309
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1178 - acc: 0.9439 - val_loss: 0.1216 - val_acc: 0.9254
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1166 - acc: 0.9488 - val_loss: 0.1218 - val_acc: 0.9247
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1154 - acc: 0.9501 - val_loss: 0.1218 - val_acc: 0.9257
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1141 - acc: 0.9557 - val_loss: 0.1214 - val_acc: 0.9283
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1143 - acc: 0.9543 - val_loss: 0.1214 - val_acc: 0.9294
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1139 - acc: 0.9570 - val_loss: 0.1216 - val_acc: 0.9295
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1132 - acc: 0.9592 - val_loss: 0.1214 - val_acc: 0.9306
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1126 - acc: 0.9610 - val_loss: 0.1215 - val_acc: 0.9300
Manual evaluation: (didn't understand why I made this)
True 8171
False 900
True percentage 0.900782714144
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.78      0.68      0.73       296
      B-LOC       0.73      0.80      0.76       218
      I-ORG       0.52      0.43      0.47       151
     B-MISC       0.41      0.28      0.33       141
     I-MISC       0.43      0.39      0.41       154
      B-PER       0.91      0.80      0.85       438
      I-PER       0.86      0.63      0.73       214
      I-LOC       0.69      0.83      0.75       141

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.686953901778
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1590 - acc: 0.8147 - val_loss: 0.1327 - val_acc: 0.8959
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1339 - acc: 0.8913 - val_loss: 0.1271 - val_acc: 0.9099
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1292 - acc: 0.9078 - val_loss: 0.1257 - val_acc: 0.9213
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1255 - acc: 0.9188 - val_loss: 0.1246 - val_acc: 0.9148
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1236 - acc: 0.9253 - val_loss: 0.1226 - val_acc: 0.9227
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1220 - acc: 0.9323 - val_loss: 0.1222 - val_acc: 0.9231
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1200 - acc: 0.9375 - val_loss: 0.1209 - val_acc: 0.9260
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1188 - acc: 0.9423 - val_loss: 0.1214 - val_acc: 0.9242
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1182 - acc: 0.9445 - val_loss: 0.1210 - val_acc: 0.9262
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1178 - acc: 0.9456 - val_loss: 0.1209 - val_acc: 0.9296
Manual evaluation: (didn't understand why I made this)
True 8051
False 1020
True percentage 0.887553742697
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.86      0.74      0.80       438
      B-LOC       0.74      0.74      0.74       218
      B-ORG       0.61      0.70      0.65       296
      I-ORG       0.33      0.54      0.41       151
      I-PER       0.83      0.65      0.73       214
      I-LOC       0.71      0.58      0.64       141
     B-MISC       0.45      0.18      0.25       141
     I-MISC       0.41      0.18      0.25       154

avg / total       0.92      0.89      0.90      9071

F-1 Score:
0.628776548011
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1575 - acc: 0.8168 - val_loss: 0.1370 - val_acc: 0.8843
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1344 - acc: 0.8886 - val_loss: 0.1297 - val_acc: 0.9057
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1288 - acc: 0.9095 - val_loss: 0.1277 - val_acc: 0.9146
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1257 - acc: 0.9184 - val_loss: 0.1256 - val_acc: 0.9141
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1233 - acc: 0.9282 - val_loss: 0.1245 - val_acc: 0.9194
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1213 - acc: 0.9328 - val_loss: 0.1232 - val_acc: 0.9247
Epoch 7/70

753/753 [==============================] - 23s 30ms/step - loss: 0.1202 - acc: 0.9370 - val_loss: 0.1227 - val_acc: 0.9263
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1188 - acc: 0.9419 - val_loss: 0.1229 - val_acc: 0.9278
Epoch 9/70

753/753 [==============================] - 23s 30ms/step - loss: 0.1177 - acc: 0.9444 - val_loss: 0.1229 - val_acc: 0.9235
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1168 - acc: 0.9497 - val_loss: 0.1215 - val_acc: 0.9283
Epoch 11/70

753/753 [==============================] - 23s 30ms/step - loss: 0.1156 - acc: 0.9508 - val_loss: 0.1222 - val_acc: 0.9296
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1156 - acc: 0.9515 - val_loss: 0.1213 - val_acc: 0.9294
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1143 - acc: 0.9557 - val_loss: 0.1211 - val_acc: 0.9304
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1136 - acc: 0.9578 - val_loss: 0.1211 - val_acc: 0.9329
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1129 - acc: 0.9612 - val_loss: 0.1211 - val_acc: 0.9334
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1126 - acc: 0.9616 - val_loss: 0.1206 - val_acc: 0.9335
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1120 - acc: 0.9645 - val_loss: 0.1209 - val_acc: 0.9313
Epoch 18/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1111 - acc: 0.9643 - val_loss: 0.1203 - val_acc: 0.9335
Epoch 19/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1112 - acc: 0.9654 - val_loss: 0.1201 - val_acc: 0.9345
Epoch 20/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1112 - acc: 0.9647 - val_loss: 0.1206 - val_acc: 0.9360
Epoch 21/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1106 - acc: 0.9676 - val_loss: 0.1206 - val_acc: 0.9354
Epoch 22/70

753/753 [==============================] - 23s 30ms/step - loss: 0.1102 - acc: 0.9688 - val_loss: 0.1203 - val_acc: 0.9382
Manual evaluation: (didn't understand why I made this)
True 8199
False 872
True percentage 0.903869474148
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.73      0.71      0.72       296
      B-LOC       0.74      0.76      0.75       218
      I-ORG       0.52      0.46      0.49       151
     B-MISC       0.49      0.32      0.39       141
     I-MISC       0.44      0.48      0.46       154
      B-PER       0.91      0.82      0.86       438
      I-PER       0.91      0.64      0.75       214
      I-LOC       0.81      0.77      0.79       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.698860227954
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.2049 - acc: 0.7112 - val_loss: 0.1576 - val_acc: 0.8247
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1607 - acc: 0.8179 - val_loss: 0.1431 - val_acc: 0.8810
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1475 - acc: 0.8574 - val_loss: 0.1359 - val_acc: 0.8866
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1433 - acc: 0.8670 - val_loss: 0.1316 - val_acc: 0.9089
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1350 - acc: 0.8929 - val_loss: 0.1285 - val_acc: 0.9046
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1334 - acc: 0.8959 - val_loss: 0.1252 - val_acc: 0.9206
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1297 - acc: 0.9052 - val_loss: 0.1249 - val_acc: 0.9273
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1274 - acc: 0.9137 - val_loss: 0.1243 - val_acc: 0.9297
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1262 - acc: 0.9183 - val_loss: 0.1246 - val_acc: 0.9335
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1245 - acc: 0.9214 - val_loss: 0.1226 - val_acc: 0.9297
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1232 - acc: 0.9273 - val_loss: 0.1216 - val_acc: 0.9321
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1226 - acc: 0.9307 - val_loss: 0.1213 - val_acc: 0.9349
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1206 - acc: 0.9343 - val_loss: 0.1213 - val_acc: 0.9335
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1196 - acc: 0.9395 - val_loss: 0.1228 - val_acc: 0.9311
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1201 - acc: 0.9363 - val_loss: 0.1225 - val_acc: 0.9292
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1181 - acc: 0.9442 - val_loss: 0.1205 - val_acc: 0.9420
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1176 - acc: 0.9462 - val_loss: 0.1204 - val_acc: 0.9349
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1169 - acc: 0.9475 - val_loss: 0.1203 - val_acc: 0.9377
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1161 - acc: 0.9505 - val_loss: 0.1195 - val_acc: 0.9420
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1158 - acc: 0.9491 - val_loss: 0.1195 - val_acc: 0.9420
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1151 - acc: 0.9543 - val_loss: 0.1194 - val_acc: 0.9434
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1151 - acc: 0.9538 - val_loss: 0.1197 - val_acc: 0.9391
Epoch 23/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1145 - acc: 0.9538 - val_loss: 0.1202 - val_acc: 0.9434
Epoch 24/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1133 - acc: 0.9601 - val_loss: 0.1200 - val_acc: 0.9420
Manual evaluation: (didn't understand why I made this)
True 7924
False 1147
True percentage 0.873553081248
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.86      0.72      0.78       438
      B-LOC       0.65      0.67      0.66       218
      B-ORG       0.55      0.64      0.59       296
      I-ORG       0.33      0.37      0.35       151
      I-PER       0.84      0.56      0.67       214
      I-LOC       0.73      0.60      0.66       141
     B-MISC       0.41      0.17      0.24       141
     I-MISC       0.30      0.27      0.29       154

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.588341890667
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.2058 - acc: 0.7413 - val_loss: 0.1698 - val_acc: 0.7985
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1607 - acc: 0.8207 - val_loss: 0.1569 - val_acc: 0.8389
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1483 - acc: 0.8591 - val_loss: 0.1454 - val_acc: 0.8460
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1402 - acc: 0.8765 - val_loss: 0.1428 - val_acc: 0.8773
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1346 - acc: 0.8992 - val_loss: 0.1412 - val_acc: 0.8873
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1304 - acc: 0.9097 - val_loss: 0.1349 - val_acc: 0.8915
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1283 - acc: 0.9130 - val_loss: 0.1319 - val_acc: 0.8929
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1258 - acc: 0.9188 - val_loss: 0.1304 - val_acc: 0.9026
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1236 - acc: 0.9268 - val_loss: 0.1350 - val_acc: 0.8899
Epoch 10/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1237 - acc: 0.9280 - val_loss: 0.1331 - val_acc: 0.8923
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1217 - acc: 0.9345 - val_loss: 0.1322 - val_acc: 0.8958
Manual evaluation: (didn't understand why I made this)
True 7930
False 1141
True percentage 0.87421452982
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-ORG       0.53      0.71      0.61       296
      B-LOC       0.86      0.52      0.65       218
      I-ORG       0.35      0.62      0.45       151
     B-MISC       0.14      0.01      0.01       141
     I-MISC       0.30      0.21      0.25       154
      B-PER       0.85      0.73      0.79       438
      I-PER       0.79      0.53      0.64       214
      I-LOC       0.81      0.62      0.70       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.591600730371
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.2111 - acc: 0.7138 - val_loss: 0.1594 - val_acc: 0.8327
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1588 - acc: 0.8238 - val_loss: 0.1434 - val_acc: 0.8720
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1494 - acc: 0.8536 - val_loss: 0.1380 - val_acc: 0.8800
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1409 - acc: 0.8780 - val_loss: 0.1307 - val_acc: 0.9027
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1371 - acc: 0.8862 - val_loss: 0.1305 - val_acc: 0.9207
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1334 - acc: 0.9013 - val_loss: 0.1261 - val_acc: 0.9188
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1296 - acc: 0.9076 - val_loss: 0.1260 - val_acc: 0.9198
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1288 - acc: 0.9104 - val_loss: 0.1240 - val_acc: 0.9297
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1269 - acc: 0.9157 - val_loss: 0.1224 - val_acc: 0.9297
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1249 - acc: 0.9196 - val_loss: 0.1219 - val_acc: 0.9287
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1226 - acc: 0.9291 - val_loss: 0.1218 - val_acc: 0.9335
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1212 - acc: 0.9344 - val_loss: 0.1224 - val_acc: 0.9278
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1196 - acc: 0.9364 - val_loss: 0.1205 - val_acc: 0.9424
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1198 - acc: 0.9361 - val_loss: 0.1201 - val_acc: 0.9382
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1194 - acc: 0.9397 - val_loss: 0.1207 - val_acc: 0.9410
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1184 - acc: 0.9404 - val_loss: 0.1199 - val_acc: 0.9420
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1170 - acc: 0.9468 - val_loss: 0.1196 - val_acc: 0.9420
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1166 - acc: 0.9483 - val_loss: 0.1189 - val_acc: 0.9490
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1154 - acc: 0.9512 - val_loss: 0.1201 - val_acc: 0.9420
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1160 - acc: 0.9509 - val_loss: 0.1193 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1150 - acc: 0.9538 - val_loss: 0.1186 - val_acc: 0.9481
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1142 - acc: 0.9547 - val_loss: 0.1189 - val_acc: 0.9448
Epoch 23/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1145 - acc: 0.9541 - val_loss: 0.1184 - val_acc: 0.9490
Epoch 24/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1126 - acc: 0.9591 - val_loss: 0.1188 - val_acc: 0.9476
Epoch 25/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1121 - acc: 0.9649 - val_loss: 0.1182 - val_acc: 0.9462
Epoch 26/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1115 - acc: 0.9669 - val_loss: 0.1183 - val_acc: 0.9434
Epoch 27/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1125 - acc: 0.9606 - val_loss: 0.1180 - val_acc: 0.9462
Epoch 28/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1114 - acc: 0.9658 - val_loss: 0.1190 - val_acc: 0.9481
Epoch 29/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1114 - acc: 0.9644 - val_loss: 0.1179 - val_acc: 0.9462
Epoch 30/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1107 - acc: 0.9680 - val_loss: 0.1179 - val_acc: 0.9462
Epoch 31/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1110 - acc: 0.9668 - val_loss: 0.1180 - val_acc: 0.9476
Epoch 32/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1107 - acc: 0.9686 - val_loss: 0.1192 - val_acc: 0.9490
Epoch 33/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1109 - acc: 0.9676 - val_loss: 0.1184 - val_acc: 0.9490
Manual evaluation: (didn't understand why I made this)
True 7967
False 1104
True percentage 0.878293462683
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.87      0.73      0.79       438
      B-LOC       0.68      0.70      0.69       218
      B-ORG       0.60      0.65      0.62       296
      I-ORG       0.40      0.50      0.45       151
      I-PER       0.88      0.57      0.69       214
      I-LOC       0.68      0.67      0.68       141
     B-MISC       0.41      0.17      0.24       141
     I-MISC       0.30      0.20      0.24       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.613843351548
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.2240 - acc: 0.7254 - val_loss: 0.1683 - val_acc: 0.8084
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1582 - acc: 0.8329 - val_loss: 0.1571 - val_acc: 0.8295
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1453 - acc: 0.8627 - val_loss: 0.1476 - val_acc: 0.8460
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1379 - acc: 0.8843 - val_loss: 0.1430 - val_acc: 0.8622
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1348 - acc: 0.8964 - val_loss: 0.1367 - val_acc: 0.8749
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1307 - acc: 0.9049 - val_loss: 0.1346 - val_acc: 0.8735
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1279 - acc: 0.9153 - val_loss: 0.1357 - val_acc: 0.8754
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1242 - acc: 0.9254 - val_loss: 0.1296 - val_acc: 0.9095
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1235 - acc: 0.9302 - val_loss: 0.1296 - val_acc: 0.8955
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1217 - acc: 0.9335 - val_loss: 0.1305 - val_acc: 0.9010
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1204 - acc: 0.9391 - val_loss: 0.1308 - val_acc: 0.9010
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1193 - acc: 0.9418 - val_loss: 0.1328 - val_acc: 0.8868
Manual evaluation: (didn't understand why I made this)
True 7918
False 1153
True percentage 0.872891632676
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-ORG       0.54      0.68      0.61       296
      B-LOC       0.78      0.56      0.65       218
      I-ORG       0.28      0.74      0.41       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.25      0.01      0.01       154
      B-PER       0.89      0.70      0.78       438
      I-PER       0.88      0.53      0.66       214
      I-LOC       0.83      0.58      0.68       141

avg / total       0.91      0.87      0.88      9071

F-1 Score:
0.576604237028
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.2130 - acc: 0.6981 - val_loss: 0.1535 - val_acc: 0.8328
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1581 - acc: 0.8233 - val_loss: 0.1414 - val_acc: 0.8851
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1480 - acc: 0.8535 - val_loss: 0.1345 - val_acc: 0.8956
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1407 - acc: 0.8718 - val_loss: 0.1301 - val_acc: 0.9055
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1368 - acc: 0.8813 - val_loss: 0.1292 - val_acc: 0.9174
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1338 - acc: 0.8930 - val_loss: 0.1253 - val_acc: 0.9249
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1298 - acc: 0.9068 - val_loss: 0.1249 - val_acc: 0.9230
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1292 - acc: 0.9052 - val_loss: 0.1241 - val_acc: 0.9307
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1263 - acc: 0.9202 - val_loss: 0.1233 - val_acc: 0.9254
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1260 - acc: 0.9180 - val_loss: 0.1217 - val_acc: 0.9301
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1228 - acc: 0.9256 - val_loss: 0.1235 - val_acc: 0.9325
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1236 - acc: 0.9229 - val_loss: 0.1214 - val_acc: 0.9311
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1214 - acc: 0.9318 - val_loss: 0.1206 - val_acc: 0.9344
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1212 - acc: 0.9309 - val_loss: 0.1205 - val_acc: 0.9367
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1195 - acc: 0.9381 - val_loss: 0.1211 - val_acc: 0.9406
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1191 - acc: 0.9409 - val_loss: 0.1202 - val_acc: 0.9438
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1190 - acc: 0.9410 - val_loss: 0.1195 - val_acc: 0.9410
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1171 - acc: 0.9484 - val_loss: 0.1195 - val_acc: 0.9448
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1157 - acc: 0.9496 - val_loss: 0.1191 - val_acc: 0.9462
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1165 - acc: 0.9479 - val_loss: 0.1188 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1157 - acc: 0.9524 - val_loss: 0.1188 - val_acc: 0.9420
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1155 - acc: 0.9530 - val_loss: 0.1188 - val_acc: 0.9434
Epoch 23/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1145 - acc: 0.9569 - val_loss: 0.1186 - val_acc: 0.9434
Epoch 24/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1141 - acc: 0.9576 - val_loss: 0.1187 - val_acc: 0.9434
Epoch 25/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1142 - acc: 0.9528 - val_loss: 0.1187 - val_acc: 0.9434
Epoch 26/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1122 - acc: 0.9609 - val_loss: 0.1187 - val_acc: 0.9420
Manual evaluation: (didn't understand why I made this)
True 7925
False 1146
True percentage 0.873663322677
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.85      0.73      0.79       438
      B-LOC       0.70      0.67      0.68       218
      B-ORG       0.53      0.66      0.59       296
      I-ORG       0.33      0.45      0.38       151
      I-PER       0.87      0.52      0.65       214
      I-LOC       0.72      0.57      0.64       141
     B-MISC       0.35      0.08      0.13       141
     I-MISC       0.31      0.23      0.26       154

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.586666666667
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1996 - acc: 0.7127 - val_loss: 0.1598 - val_acc: 0.8143
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1524 - acc: 0.8438 - val_loss: 0.1551 - val_acc: 0.8422
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1421 - acc: 0.8725 - val_loss: 0.1402 - val_acc: 0.8562
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1373 - acc: 0.8808 - val_loss: 0.1364 - val_acc: 0.8701
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1336 - acc: 0.8964 - val_loss: 0.1393 - val_acc: 0.8666
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1293 - acc: 0.9100 - val_loss: 0.1317 - val_acc: 0.8891
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1273 - acc: 0.9168 - val_loss: 0.1319 - val_acc: 0.8899
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1247 - acc: 0.9234 - val_loss: 0.1308 - val_acc: 0.8986
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1234 - acc: 0.9268 - val_loss: 0.1311 - val_acc: 0.8941
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1226 - acc: 0.9326 - val_loss: 0.1285 - val_acc: 0.8972
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1206 - acc: 0.9358 - val_loss: 0.1311 - val_acc: 0.9012
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1198 - acc: 0.9399 - val_loss: 0.1287 - val_acc: 0.9010
Epoch 13/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1185 - acc: 0.9434 - val_loss: 0.1284 - val_acc: 0.9043
Epoch 14/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1185 - acc: 0.9425 - val_loss: 0.1288 - val_acc: 0.9012
Epoch 15/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1174 - acc: 0.9491 - val_loss: 0.1299 - val_acc: 0.9014
Epoch 16/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1175 - acc: 0.9463 - val_loss: 0.1290 - val_acc: 0.9055
Manual evaluation: (didn't understand why I made this)
True 7974
False 1097
True percentage 0.879065152684
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-ORG       0.51      0.72      0.60       296
      B-LOC       0.74      0.65      0.69       218
      I-ORG       0.33      0.55      0.41       151
     B-MISC       0.33      0.01      0.03       141
     I-MISC       0.33      0.14      0.20       154
      B-PER       0.86      0.77      0.81       438
      I-PER       0.86      0.57      0.68       214
      I-LOC       0.74      0.72      0.73       141

avg / total       0.92      0.88      0.89      9071

F-1 Score:
0.608928571429
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.1976 - acc: 0.7142 - val_loss: 0.1434 - val_acc: 0.8553
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1516 - acc: 0.8295 - val_loss: 0.1372 - val_acc: 0.8932
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1444 - acc: 0.8590 - val_loss: 0.1299 - val_acc: 0.9083
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1389 - acc: 0.8764 - val_loss: 0.1401 - val_acc: 0.8617
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1343 - acc: 0.8921 - val_loss: 0.1252 - val_acc: 0.9287
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1320 - acc: 0.8954 - val_loss: 0.1251 - val_acc: 0.9249
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1296 - acc: 0.9103 - val_loss: 0.1220 - val_acc: 0.9362
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1274 - acc: 0.9102 - val_loss: 0.1223 - val_acc: 0.9339
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1248 - acc: 0.9215 - val_loss: 0.1209 - val_acc: 0.9362
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1237 - acc: 0.9269 - val_loss: 0.1213 - val_acc: 0.9363
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1231 - acc: 0.9277 - val_loss: 0.1206 - val_acc: 0.9424
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1211 - acc: 0.9342 - val_loss: 0.1208 - val_acc: 0.9391
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1195 - acc: 0.9403 - val_loss: 0.1196 - val_acc: 0.9481
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1184 - acc: 0.9441 - val_loss: 0.1195 - val_acc: 0.9438
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1185 - acc: 0.9446 - val_loss: 0.1180 - val_acc: 0.9481
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1175 - acc: 0.9464 - val_loss: 0.1184 - val_acc: 0.9476
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1169 - acc: 0.9453 - val_loss: 0.1188 - val_acc: 0.9448
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1156 - acc: 0.9530 - val_loss: 0.1209 - val_acc: 0.9396
Manual evaluation: (didn't understand why I made this)
True 7936
False 1135
True percentage 0.874875978393
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.93      0.71      0.80       438
      B-LOC       0.71      0.63      0.67       218
      B-ORG       0.64      0.52      0.57       296
      I-ORG       0.38      0.19      0.25       151
      I-PER       0.94      0.46      0.62       214
      I-LOC       0.72      0.60      0.65       141
     B-MISC       0.33      0.40      0.36       141
     I-MISC       0.29      0.59      0.39       154

avg / total       0.93      0.87      0.90      9071

F-1 Score:
0.581487101669
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.2138 - acc: 0.7183 - val_loss: 0.1587 - val_acc: 0.8143
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1503 - acc: 0.8419 - val_loss: 0.1514 - val_acc: 0.8385
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1424 - acc: 0.8675 - val_loss: 0.1478 - val_acc: 0.8264
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1361 - acc: 0.8838 - val_loss: 0.1419 - val_acc: 0.8460
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1329 - acc: 0.8927 - val_loss: 0.1346 - val_acc: 0.8794
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1299 - acc: 0.9058 - val_loss: 0.1353 - val_acc: 0.8749
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1271 - acc: 0.9138 - val_loss: 0.1403 - val_acc: 0.8666
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1257 - acc: 0.9223 - val_loss: 0.1317 - val_acc: 0.8899
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1236 - acc: 0.9279 - val_loss: 0.1289 - val_acc: 0.9012
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1223 - acc: 0.9336 - val_loss: 0.1315 - val_acc: 0.8941
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1213 - acc: 0.9346 - val_loss: 0.1301 - val_acc: 0.8955
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1203 - acc: 0.9391 - val_loss: 0.1308 - val_acc: 0.8984
Manual evaluation: (didn't understand why I made this)
True 7976
False 1095
True percentage 0.879285635542
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-ORG       0.66      0.65      0.65       296
      B-LOC       0.65      0.76      0.70       218
      I-ORG       0.32      0.68      0.44       151
     B-MISC       0.67      0.01      0.03       141
     I-MISC       0.29      0.01      0.02       154
      B-PER       0.77      0.76      0.76       438
      I-PER       0.74      0.58      0.65       214
      I-LOC       0.68      0.72      0.70       141

avg / total       0.92      0.88      0.89      9071

F-1 Score:
0.605037037037
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.1894 - acc: 0.7281 - val_loss: 0.1373 - val_acc: 0.8856
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1450 - acc: 0.8550 - val_loss: 0.1324 - val_acc: 0.8923
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1376 - acc: 0.8807 - val_loss: 0.1280 - val_acc: 0.9206
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1334 - acc: 0.8968 - val_loss: 0.1283 - val_acc: 0.9131
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1300 - acc: 0.9065 - val_loss: 0.1232 - val_acc: 0.9291
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1280 - acc: 0.9097 - val_loss: 0.1225 - val_acc: 0.9277
Epoch 7/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1263 - acc: 0.9177 - val_loss: 0.1251 - val_acc: 0.9292
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1245 - acc: 0.9223 - val_loss: 0.1219 - val_acc: 0.9406
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1229 - acc: 0.9288 - val_loss: 0.1215 - val_acc: 0.9382
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1219 - acc: 0.9309 - val_loss: 0.1200 - val_acc: 0.9391
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1215 - acc: 0.9335 - val_loss: 0.1194 - val_acc: 0.9386
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1200 - acc: 0.9352 - val_loss: 0.1194 - val_acc: 0.9438
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1190 - acc: 0.9390 - val_loss: 0.1189 - val_acc: 0.9410
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1181 - acc: 0.9433 - val_loss: 0.1188 - val_acc: 0.9406
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1169 - acc: 0.9464 - val_loss: 0.1194 - val_acc: 0.9420
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1163 - acc: 0.9478 - val_loss: 0.1183 - val_acc: 0.9434
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1155 - acc: 0.9518 - val_loss: 0.1187 - val_acc: 0.9462
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1149 - acc: 0.9553 - val_loss: 0.1177 - val_acc: 0.9452
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1143 - acc: 0.9587 - val_loss: 0.1181 - val_acc: 0.9434
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1138 - acc: 0.9579 - val_loss: 0.1184 - val_acc: 0.9391
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1132 - acc: 0.9608 - val_loss: 0.1178 - val_acc: 0.9467
Manual evaluation: (didn't understand why I made this)
True 7894
False 1177
True percentage 0.870245838386
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-PER       0.87      0.71      0.78       438
      B-LOC       0.67      0.62      0.65       218
      B-ORG       0.52      0.64      0.57       296
      I-ORG       0.27      0.54      0.36       151
      I-PER       0.89      0.58      0.71       214
      I-LOC       0.71      0.43      0.53       141
     B-MISC       0.35      0.16      0.22       141
     I-MISC       0.34      0.17      0.23       154

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.56793072559
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1848 - acc: 0.7361 - val_loss: 0.1446 - val_acc: 0.8353
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1395 - acc: 0.8798 - val_loss: 0.1389 - val_acc: 0.8537
Epoch 3/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1352 - acc: 0.8846 - val_loss: 0.1354 - val_acc: 0.8764
Epoch 4/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1305 - acc: 0.9067 - val_loss: 0.1369 - val_acc: 0.8650
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1274 - acc: 0.9144 - val_loss: 0.1335 - val_acc: 0.8881
Epoch 6/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1250 - acc: 0.9200 - val_loss: 0.1298 - val_acc: 0.9000
Epoch 7/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1236 - acc: 0.9289 - val_loss: 0.1316 - val_acc: 0.8976
Epoch 8/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1216 - acc: 0.9332 - val_loss: 0.1322 - val_acc: 0.8875
Epoch 9/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1206 - acc: 0.9389 - val_loss: 0.1263 - val_acc: 0.9028
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1195 - acc: 0.9386 - val_loss: 0.1303 - val_acc: 0.9085
Epoch 11/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1183 - acc: 0.9414 - val_loss: 0.1277 - val_acc: 0.9097
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1172 - acc: 0.9478 - val_loss: 0.1287 - val_acc: 0.8943
Manual evaluation: (didn't understand why I made this)
True 7988
False 1083
True percentage 0.880608532687
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.60      0.65      0.62       296
      B-LOC       0.74      0.66      0.70       218
      I-ORG       0.30      0.58      0.39       151
     B-MISC       0.43      0.07      0.12       141
     I-MISC       0.65      0.08      0.15       154
      B-PER       0.84      0.74      0.79       438
      I-PER       0.78      0.59      0.67       214
      I-LOC       0.76      0.58      0.66       141

avg / total       0.92      0.88      0.89      9071

F-1 Score:
0.600429316161
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 35ms/step - loss: 0.2530 - acc: 0.6425 - val_loss: 0.1863 - val_acc: 0.7819
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1749 - acc: 0.7941 - val_loss: 0.1717 - val_acc: 0.7819
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1616 - acc: 0.8140 - val_loss: 0.1655 - val_acc: 0.7843
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1531 - acc: 0.8364 - val_loss: 0.1535 - val_acc: 0.8235
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1498 - acc: 0.8506 - val_loss: 0.1508 - val_acc: 0.8162
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1435 - acc: 0.8651 - val_loss: 0.1446 - val_acc: 0.8333
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1382 - acc: 0.8792 - val_loss: 0.1396 - val_acc: 0.8799
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1351 - acc: 0.8941 - val_loss: 0.1383 - val_acc: 0.8701
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1326 - acc: 0.8896 - val_loss: 0.1353 - val_acc: 0.8750
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1316 - acc: 0.9043 - val_loss: 0.1365 - val_acc: 0.8824
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1290 - acc: 0.9047 - val_loss: 0.1326 - val_acc: 0.8995
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1270 - acc: 0.9172 - val_loss: 0.1311 - val_acc: 0.8971
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1247 - acc: 0.9200 - val_loss: 0.1295 - val_acc: 0.9142
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1244 - acc: 0.9181 - val_loss: 0.1299 - val_acc: 0.9020
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1222 - acc: 0.9316 - val_loss: 0.1287 - val_acc: 0.9044
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1236 - acc: 0.9228 - val_loss: 0.1282 - val_acc: 0.9142
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1202 - acc: 0.9385 - val_loss: 0.1271 - val_acc: 0.9142
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1211 - acc: 0.9331 - val_loss: 0.1268 - val_acc: 0.9142
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9408 - val_loss: 0.1259 - val_acc: 0.9118
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1177 - acc: 0.9453 - val_loss: 0.1254 - val_acc: 0.9216
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1166 - acc: 0.9483 - val_loss: 0.1259 - val_acc: 0.9167
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1169 - acc: 0.9449 - val_loss: 0.1247 - val_acc: 0.9191
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1164 - acc: 0.9508 - val_loss: 0.1255 - val_acc: 0.9167
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1156 - acc: 0.9540 - val_loss: 0.1246 - val_acc: 0.9240
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1151 - acc: 0.9541 - val_loss: 0.1250 - val_acc: 0.9167
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1150 - acc: 0.9501 - val_loss: 0.1243 - val_acc: 0.9240
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1137 - acc: 0.9602 - val_loss: 0.1252 - val_acc: 0.9191
Epoch 28/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1136 - acc: 0.9561 - val_loss: 0.1234 - val_acc: 0.9265
Epoch 29/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1137 - acc: 0.9569 - val_loss: 0.1242 - val_acc: 0.9240
Epoch 30/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1128 - acc: 0.9601 - val_loss: 0.1250 - val_acc: 0.9216
Epoch 31/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1129 - acc: 0.9600 - val_loss: 0.1252 - val_acc: 0.9289
Manual evaluation: (didn't understand why I made this)
True 7857
False 1214
True percentage 0.866166905523
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.96      7318
      B-PER       0.85      0.62      0.72       438
      B-LOC       0.73      0.56      0.64       218
      B-ORG       0.70      0.59      0.64       296
      I-ORG       0.39      0.29      0.33       151
      I-PER       0.81      0.51      0.63       214
      I-LOC       0.69      0.42      0.52       141
     B-MISC       0.31      0.17      0.22       141
     I-MISC       0.31      0.42      0.36       154

avg / total       0.90      0.87      0.88      9071

F-1 Score:
0.560591449695
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2368 - acc: 0.6047 - val_loss: 0.1787 - val_acc: 0.7933
Epoch 2/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1731 - acc: 0.8010 - val_loss: 0.1657 - val_acc: 0.8029
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1623 - acc: 0.8154 - val_loss: 0.1577 - val_acc: 0.8052
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1536 - acc: 0.8346 - val_loss: 0.1537 - val_acc: 0.8100
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1466 - acc: 0.8560 - val_loss: 0.1489 - val_acc: 0.8527
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1418 - acc: 0.8684 - val_loss: 0.1461 - val_acc: 0.8646
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1388 - acc: 0.8816 - val_loss: 0.1415 - val_acc: 0.8646
Epoch 8/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1352 - acc: 0.8924 - val_loss: 0.1427 - val_acc: 0.8622
Epoch 9/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1329 - acc: 0.8997 - val_loss: 0.1377 - val_acc: 0.8836
Epoch 10/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1299 - acc: 0.9050 - val_loss: 0.1358 - val_acc: 0.8907
Epoch 11/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1275 - acc: 0.9165 - val_loss: 0.1346 - val_acc: 0.8884
Epoch 12/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1259 - acc: 0.9265 - val_loss: 0.1344 - val_acc: 0.8836
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1277 - acc: 0.9160 - val_loss: 0.1353 - val_acc: 0.8836
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1236 - acc: 0.9259 - val_loss: 0.1337 - val_acc: 0.8979
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1227 - acc: 0.9323 - val_loss: 0.1326 - val_acc: 0.8931
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1224 - acc: 0.9292 - val_loss: 0.1311 - val_acc: 0.8955
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1214 - acc: 0.9336 - val_loss: 0.1347 - val_acc: 0.8789
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1203 - acc: 0.9421 - val_loss: 0.1303 - val_acc: 0.8979
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1187 - acc: 0.9403 - val_loss: 0.1308 - val_acc: 0.8955
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1177 - acc: 0.9439 - val_loss: 0.1316 - val_acc: 0.8884
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1172 - acc: 0.9490 - val_loss: 0.1313 - val_acc: 0.8955
Manual evaluation: (didn't understand why I made this)
True 7825
False 1246
True percentage 0.862639179804
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.96      7318
      B-ORG       0.50      0.64      0.56       296
      B-LOC       0.75      0.61      0.67       218
      I-ORG       0.26      0.38      0.31       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.23      0.14      0.18       154
      B-PER       0.86      0.61      0.72       438
      I-PER       0.79      0.43      0.56       214
      I-LOC       0.77      0.64      0.70       141

avg / total       0.89      0.86      0.87      9071

F-1 Score:
0.538291837378
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2429 - acc: 0.6308 - val_loss: 0.1810 - val_acc: 0.7819
Epoch 2/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1696 - acc: 0.8030 - val_loss: 0.1676 - val_acc: 0.7794
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1573 - acc: 0.8245 - val_loss: 0.1577 - val_acc: 0.8088
Epoch 4/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1494 - acc: 0.8513 - val_loss: 0.1497 - val_acc: 0.8186
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1445 - acc: 0.8599 - val_loss: 0.1458 - val_acc: 0.8235
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1408 - acc: 0.8751 - val_loss: 0.1440 - val_acc: 0.8382
Epoch 7/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1364 - acc: 0.8859 - val_loss: 0.1374 - val_acc: 0.8775
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1337 - acc: 0.8952 - val_loss: 0.1354 - val_acc: 0.8848
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1319 - acc: 0.8998 - val_loss: 0.1355 - val_acc: 0.8750
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1304 - acc: 0.9013 - val_loss: 0.1306 - val_acc: 0.9093
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1280 - acc: 0.9104 - val_loss: 0.1294 - val_acc: 0.9093
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1254 - acc: 0.9157 - val_loss: 0.1298 - val_acc: 0.9044
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1248 - acc: 0.9196 - val_loss: 0.1285 - val_acc: 0.9118
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1233 - acc: 0.9195 - val_loss: 0.1275 - val_acc: 0.9118
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1214 - acc: 0.9337 - val_loss: 0.1290 - val_acc: 0.9069
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9259 - val_loss: 0.1287 - val_acc: 0.9118
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1204 - acc: 0.9360 - val_loss: 0.1245 - val_acc: 0.9265
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1203 - acc: 0.9303 - val_loss: 0.1248 - val_acc: 0.9167
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1182 - acc: 0.9414 - val_loss: 0.1249 - val_acc: 0.9289
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1189 - acc: 0.9391 - val_loss: 0.1238 - val_acc: 0.9314
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1173 - acc: 0.9416 - val_loss: 0.1248 - val_acc: 0.9314
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9464 - val_loss: 0.1243 - val_acc: 0.9314
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1152 - acc: 0.9481 - val_loss: 0.1239 - val_acc: 0.9314
Manual evaluation: (didn't understand why I made this)
True 7903
False 1168
True percentage 0.871238011245
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-PER       0.90      0.69      0.78       438
      B-LOC       0.62      0.67      0.64       218
      B-ORG       0.62      0.60      0.61       296
      I-ORG       0.35      0.47      0.40       151
      I-PER       0.80      0.55      0.65       214
      I-LOC       0.53      0.51      0.52       141
     B-MISC       0.47      0.11      0.17       141
     I-MISC       0.34      0.17      0.23       154

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.578455790785
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2489 - acc: 0.6520 - val_loss: 0.1745 - val_acc: 0.7933
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1690 - acc: 0.8094 - val_loss: 0.1602 - val_acc: 0.8076
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1572 - acc: 0.8282 - val_loss: 0.1579 - val_acc: 0.8385
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1515 - acc: 0.8447 - val_loss: 0.1499 - val_acc: 0.8290
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1461 - acc: 0.8607 - val_loss: 0.1459 - val_acc: 0.8409
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1403 - acc: 0.8727 - val_loss: 0.1427 - val_acc: 0.8812
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1382 - acc: 0.8903 - val_loss: 0.1397 - val_acc: 0.8741
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1341 - acc: 0.8963 - val_loss: 0.1379 - val_acc: 0.8765
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1300 - acc: 0.9113 - val_loss: 0.1369 - val_acc: 0.8884
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1303 - acc: 0.9132 - val_loss: 0.1334 - val_acc: 0.9074
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1268 - acc: 0.9211 - val_loss: 0.1329 - val_acc: 0.9050
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1260 - acc: 0.9208 - val_loss: 0.1326 - val_acc: 0.8955
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1241 - acc: 0.9286 - val_loss: 0.1319 - val_acc: 0.9097
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1225 - acc: 0.9317 - val_loss: 0.1307 - val_acc: 0.8979
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1205 - acc: 0.9398 - val_loss: 0.1300 - val_acc: 0.9121
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1203 - acc: 0.9347 - val_loss: 0.1292 - val_acc: 0.9121
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1194 - acc: 0.9386 - val_loss: 0.1288 - val_acc: 0.9002
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1188 - acc: 0.9405 - val_loss: 0.1291 - val_acc: 0.9050
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1180 - acc: 0.9470 - val_loss: 0.1280 - val_acc: 0.9026
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1177 - acc: 0.9430 - val_loss: 0.1286 - val_acc: 0.8979
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1165 - acc: 0.9472 - val_loss: 0.1276 - val_acc: 0.9050
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1156 - acc: 0.9543 - val_loss: 0.1270 - val_acc: 0.9002
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1158 - acc: 0.9540 - val_loss: 0.1272 - val_acc: 0.9026
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1141 - acc: 0.9546 - val_loss: 0.1277 - val_acc: 0.9026
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1151 - acc: 0.9538 - val_loss: 0.1275 - val_acc: 0.9026
Manual evaluation: (didn't understand why I made this)
True 7865
False 1206
True percentage 0.867048836953
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.55      0.65      0.59       296
      B-LOC       0.68      0.71      0.70       218
      I-ORG       0.32      0.44      0.37       151
     B-MISC       0.20      0.02      0.04       141
     I-MISC       0.15      0.02      0.03       154
      B-PER       0.82      0.68      0.74       438
      I-PER       0.72      0.56      0.63       214
      I-LOC       0.53      0.79      0.64       141

avg / total       0.90      0.87      0.88      9071

F-1 Score:
0.571773949834
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2229 - acc: 0.6928 - val_loss: 0.1763 - val_acc: 0.7819
Epoch 2/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1675 - acc: 0.8050 - val_loss: 0.1620 - val_acc: 0.7843
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1577 - acc: 0.8311 - val_loss: 0.1536 - val_acc: 0.8137
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1483 - acc: 0.8544 - val_loss: 0.1490 - val_acc: 0.8456
Epoch 5/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1425 - acc: 0.8653 - val_loss: 0.1441 - val_acc: 0.8456
Epoch 6/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1384 - acc: 0.8744 - val_loss: 0.1409 - val_acc: 0.8652
Epoch 7/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1375 - acc: 0.8813 - val_loss: 0.1378 - val_acc: 0.8824
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1321 - acc: 0.8990 - val_loss: 0.1337 - val_acc: 0.8922
Epoch 9/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1324 - acc: 0.8947 - val_loss: 0.1323 - val_acc: 0.9020
Epoch 10/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1291 - acc: 0.9067 - val_loss: 0.1290 - val_acc: 0.9020
Epoch 11/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1276 - acc: 0.9075 - val_loss: 0.1283 - val_acc: 0.9118
Epoch 12/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1267 - acc: 0.9086 - val_loss: 0.1304 - val_acc: 0.9069
Epoch 13/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1245 - acc: 0.9162 - val_loss: 0.1296 - val_acc: 0.8995
Epoch 14/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1250 - acc: 0.9151 - val_loss: 0.1266 - val_acc: 0.9142
Epoch 15/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1230 - acc: 0.9255 - val_loss: 0.1279 - val_acc: 0.9093
Epoch 16/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1207 - acc: 0.9340 - val_loss: 0.1266 - val_acc: 0.9118
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1210 - acc: 0.9274 - val_loss: 0.1268 - val_acc: 0.9118
Epoch 18/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1214 - acc: 0.9272 - val_loss: 0.1247 - val_acc: 0.9118
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1184 - acc: 0.9403 - val_loss: 0.1245 - val_acc: 0.9118
Epoch 20/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1183 - acc: 0.9384 - val_loss: 0.1249 - val_acc: 0.9142
Epoch 21/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1184 - acc: 0.9386 - val_loss: 0.1241 - val_acc: 0.9191
Epoch 22/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1166 - acc: 0.9454 - val_loss: 0.1223 - val_acc: 0.9216
Epoch 23/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1160 - acc: 0.9470 - val_loss: 0.1228 - val_acc: 0.9191
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1156 - acc: 0.9469 - val_loss: 0.1235 - val_acc: 0.9118
Epoch 25/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1152 - acc: 0.9541 - val_loss: 0.1232 - val_acc: 0.9191
Manual evaluation: (didn't understand why I made this)
True 7828
False 1243
True percentage 0.86296990409
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-PER       0.83      0.66      0.74       438
      B-LOC       0.64      0.66      0.65       218
      B-ORG       0.53      0.63      0.57       296
      I-ORG       0.25      0.34      0.29       151
      I-PER       0.79      0.49      0.60       214
      I-LOC       0.54      0.53      0.54       141
     B-MISC       0.50      0.11      0.18       141
     I-MISC       0.25      0.17      0.20       154

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.543465045593
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2351 - acc: 0.6400 - val_loss: 0.1758 - val_acc: 0.7933
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1690 - acc: 0.8046 - val_loss: 0.1629 - val_acc: 0.8029
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1566 - acc: 0.8216 - val_loss: 0.1559 - val_acc: 0.8171
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1490 - acc: 0.8458 - val_loss: 0.1509 - val_acc: 0.8480
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1446 - acc: 0.8698 - val_loss: 0.1465 - val_acc: 0.8290
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1412 - acc: 0.8730 - val_loss: 0.1437 - val_acc: 0.8456
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1370 - acc: 0.8881 - val_loss: 0.1404 - val_acc: 0.8741
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1342 - acc: 0.8956 - val_loss: 0.1375 - val_acc: 0.8789
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1321 - acc: 0.9031 - val_loss: 0.1358 - val_acc: 0.8717
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1300 - acc: 0.9102 - val_loss: 0.1334 - val_acc: 0.8907
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1286 - acc: 0.9157 - val_loss: 0.1356 - val_acc: 0.8741
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1279 - acc: 0.9172 - val_loss: 0.1328 - val_acc: 0.8955
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1247 - acc: 0.9255 - val_loss: 0.1308 - val_acc: 0.9002
Epoch 14/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1242 - acc: 0.9245 - val_loss: 0.1305 - val_acc: 0.9074
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1231 - acc: 0.9321 - val_loss: 0.1290 - val_acc: 0.9050
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1219 - acc: 0.9353 - val_loss: 0.1307 - val_acc: 0.9002
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1207 - acc: 0.9362 - val_loss: 0.1291 - val_acc: 0.9050
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1203 - acc: 0.9354 - val_loss: 0.1290 - val_acc: 0.9074
Manual evaluation: (didn't understand why I made this)
True 7840
False 1231
True percentage 0.864292801235
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-ORG       0.59      0.55      0.57       296
      B-LOC       0.64      0.68      0.66       218
      I-ORG       0.32      0.20      0.24       151
     B-MISC       0.17      0.02      0.04       141
     I-MISC       0.31      0.15      0.20       154
      B-PER       0.77      0.67      0.71       438
      I-PER       0.68      0.50      0.57       214
      I-LOC       0.54      0.79      0.64       141

avg / total       0.89      0.86      0.87      9071

F-1 Score:
0.549953022236
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2298 - acc: 0.6635 - val_loss: 0.1625 - val_acc: 0.7819
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1591 - acc: 0.8165 - val_loss: 0.1533 - val_acc: 0.8039
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1522 - acc: 0.8329 - val_loss: 0.1478 - val_acc: 0.8186
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1469 - acc: 0.8537 - val_loss: 0.1419 - val_acc: 0.8456
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1424 - acc: 0.8620 - val_loss: 0.1425 - val_acc: 0.8309
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1383 - acc: 0.8732 - val_loss: 0.1383 - val_acc: 0.8701
Epoch 7/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1378 - acc: 0.8794 - val_loss: 0.1378 - val_acc: 0.8775
Epoch 8/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1337 - acc: 0.8873 - val_loss: 0.1317 - val_acc: 0.8971
Epoch 9/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1317 - acc: 0.8955 - val_loss: 0.1316 - val_acc: 0.8995
Epoch 10/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1286 - acc: 0.9045 - val_loss: 0.1291 - val_acc: 0.9069
Epoch 11/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1276 - acc: 0.9159 - val_loss: 0.1287 - val_acc: 0.9069
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1252 - acc: 0.9182 - val_loss: 0.1283 - val_acc: 0.9069
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1248 - acc: 0.9208 - val_loss: 0.1288 - val_acc: 0.8971
Epoch 14/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1244 - acc: 0.9184 - val_loss: 0.1256 - val_acc: 0.9240
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9319 - val_loss: 0.1234 - val_acc: 0.9240
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1210 - acc: 0.9340 - val_loss: 0.1232 - val_acc: 0.9216
Epoch 17/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1210 - acc: 0.9366 - val_loss: 0.1229 - val_acc: 0.9265
Epoch 18/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1186 - acc: 0.9403 - val_loss: 0.1225 - val_acc: 0.9265
Epoch 19/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1185 - acc: 0.9450 - val_loss: 0.1245 - val_acc: 0.9167
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1177 - acc: 0.9421 - val_loss: 0.1210 - val_acc: 0.9289
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1171 - acc: 0.9427 - val_loss: 0.1213 - val_acc: 0.9191
Epoch 22/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1169 - acc: 0.9456 - val_loss: 0.1203 - val_acc: 0.9314
Epoch 23/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1143 - acc: 0.9585 - val_loss: 0.1217 - val_acc: 0.9265
Epoch 24/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1155 - acc: 0.9482 - val_loss: 0.1213 - val_acc: 0.9240
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1140 - acc: 0.9590 - val_loss: 0.1205 - val_acc: 0.9338
Manual evaluation: (didn't understand why I made this)
True 7844
False 1227
True percentage 0.86473376695
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.83      0.69      0.75       438
      B-LOC       0.69      0.61      0.65       218
      B-ORG       0.61      0.57      0.59       296
      I-ORG       0.23      0.34      0.28       151
      I-PER       0.80      0.49      0.60       214
      I-LOC       0.61      0.38      0.46       141
     B-MISC       0.36      0.28      0.31       141
     I-MISC       0.26      0.27      0.26       154

avg / total       0.91      0.86      0.89      9071

F-1 Score:
0.542146755609
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2263 - acc: 0.6670 - val_loss: 0.1704 - val_acc: 0.7981
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1596 - acc: 0.8219 - val_loss: 0.1548 - val_acc: 0.8100
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1511 - acc: 0.8279 - val_loss: 0.1519 - val_acc: 0.8124
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1433 - acc: 0.8647 - val_loss: 0.1466 - val_acc: 0.8290
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1405 - acc: 0.8707 - val_loss: 0.1429 - val_acc: 0.8314
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1373 - acc: 0.8778 - val_loss: 0.1403 - val_acc: 0.8409
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1336 - acc: 0.8883 - val_loss: 0.1382 - val_acc: 0.8741
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1296 - acc: 0.9111 - val_loss: 0.1369 - val_acc: 0.8361
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1295 - acc: 0.9066 - val_loss: 0.1345 - val_acc: 0.8836
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1284 - acc: 0.9104 - val_loss: 0.1323 - val_acc: 0.8789
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1252 - acc: 0.9253 - val_loss: 0.1317 - val_acc: 0.8931
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1238 - acc: 0.9293 - val_loss: 0.1307 - val_acc: 0.8836
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1225 - acc: 0.9292 - val_loss: 0.1313 - val_acc: 0.8955
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1206 - acc: 0.9382 - val_loss: 0.1329 - val_acc: 0.8694
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1203 - acc: 0.9339 - val_loss: 0.1298 - val_acc: 0.8860
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1183 - acc: 0.9398 - val_loss: 0.1299 - val_acc: 0.8812
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1177 - acc: 0.9422 - val_loss: 0.1281 - val_acc: 0.8979
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1160 - acc: 0.9528 - val_loss: 0.1295 - val_acc: 0.8884
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1162 - acc: 0.9505 - val_loss: 0.1270 - val_acc: 0.9026
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1149 - acc: 0.9521 - val_loss: 0.1269 - val_acc: 0.9097
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1145 - acc: 0.9533 - val_loss: 0.1269 - val_acc: 0.9097
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1142 - acc: 0.9551 - val_loss: 0.1275 - val_acc: 0.9002
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1140 - acc: 0.9540 - val_loss: 0.1271 - val_acc: 0.9002
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1135 - acc: 0.9583 - val_loss: 0.1292 - val_acc: 0.8955
Manual evaluation: (didn't understand why I made this)
True 7834
False 1237
True percentage 0.863631352662
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-ORG       0.50      0.65      0.57       296
      B-LOC       0.72      0.58      0.64       218
      I-ORG       0.25      0.58      0.35       151
     B-MISC       0.33      0.03      0.05       141
     I-MISC       0.46      0.12      0.19       154
      B-PER       0.78      0.70      0.73       438
      I-PER       0.71      0.50      0.58       214
      I-LOC       0.63      0.69      0.66       141

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.549779735683
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2371 - acc: 0.5955 - val_loss: 0.1624 - val_acc: 0.7966
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1543 - acc: 0.8308 - val_loss: 0.1453 - val_acc: 0.8407
Epoch 3/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1449 - acc: 0.8536 - val_loss: 0.1426 - val_acc: 0.8382
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1405 - acc: 0.8704 - val_loss: 0.1348 - val_acc: 0.8799
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1373 - acc: 0.8738 - val_loss: 0.1325 - val_acc: 0.8897
Epoch 6/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1342 - acc: 0.8823 - val_loss: 0.1298 - val_acc: 0.8946
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1319 - acc: 0.8949 - val_loss: 0.1303 - val_acc: 0.8995
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1303 - acc: 0.8981 - val_loss: 0.1297 - val_acc: 0.8971
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1276 - acc: 0.9100 - val_loss: 0.1289 - val_acc: 0.8995
Epoch 10/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1262 - acc: 0.9091 - val_loss: 0.1245 - val_acc: 0.9069
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1245 - acc: 0.9203 - val_loss: 0.1255 - val_acc: 0.9167
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1228 - acc: 0.9248 - val_loss: 0.1250 - val_acc: 0.9191
Epoch 13/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1226 - acc: 0.9286 - val_loss: 0.1249 - val_acc: 0.9142
Manual evaluation: (didn't understand why I made this)
True 7748
False 1323
True percentage 0.854150589792
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-PER       0.78      0.66      0.72       438
      B-LOC       0.65      0.56      0.60       218
      B-ORG       0.47      0.60      0.53       296
      I-ORG       0.21      0.45      0.29       151
      I-PER       0.66      0.58      0.62       214
      I-LOC       0.51      0.33      0.40       141
     B-MISC       0.37      0.12      0.18       141
     I-MISC       0.36      0.09      0.15       154

avg / total       0.90      0.85      0.87      9071

F-1 Score:
0.509780675756
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2091 - acc: 0.6512 - val_loss: 0.1509 - val_acc: 0.8266
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1470 - acc: 0.8491 - val_loss: 0.1445 - val_acc: 0.8385
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1403 - acc: 0.8690 - val_loss: 0.1401 - val_acc: 0.8599
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1351 - acc: 0.8833 - val_loss: 0.1368 - val_acc: 0.8717
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1316 - acc: 0.9037 - val_loss: 0.1356 - val_acc: 0.8836
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1288 - acc: 0.9104 - val_loss: 0.1340 - val_acc: 0.8765
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1288 - acc: 0.9080 - val_loss: 0.1335 - val_acc: 0.8884
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1258 - acc: 0.9200 - val_loss: 0.1335 - val_acc: 0.8717
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1238 - acc: 0.9263 - val_loss: 0.1318 - val_acc: 0.8860
Epoch 10/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1224 - acc: 0.9312 - val_loss: 0.1303 - val_acc: 0.8955
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1218 - acc: 0.9336 - val_loss: 0.1308 - val_acc: 0.8884
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1199 - acc: 0.9402 - val_loss: 0.1299 - val_acc: 0.8884
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1187 - acc: 0.9430 - val_loss: 0.1292 - val_acc: 0.8979
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1183 - acc: 0.9414 - val_loss: 0.1284 - val_acc: 0.9026
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1184 - acc: 0.9450 - val_loss: 0.1288 - val_acc: 0.9050
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1164 - acc: 0.9513 - val_loss: 0.1289 - val_acc: 0.8979
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1161 - acc: 0.9501 - val_loss: 0.1290 - val_acc: 0.8884
Manual evaluation: (didn't understand why I made this)
True 7884
False 1187
True percentage 0.869143424099
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-ORG       0.51      0.65      0.57       296
      B-LOC       0.71      0.64      0.67       218
      I-ORG       0.26      0.40      0.32       151
     B-MISC       0.61      0.10      0.17       141
     I-MISC       0.55      0.23      0.33       154
      B-PER       0.78      0.72      0.75       438
      I-PER       0.77      0.51      0.61       214
      I-LOC       0.56      0.82      0.66       141

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.577058823529
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2527 - acc: 0.4916 - val_loss: 0.2584 - val_acc: 0.6261
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1993 - acc: 0.7989 - val_loss: 0.2340 - val_acc: 0.6218
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1714 - acc: 0.8033 - val_loss: 0.2270 - val_acc: 0.6176
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1635 - acc: 0.8101 - val_loss: 0.2228 - val_acc: 0.6429
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1576 - acc: 0.8254 - val_loss: 0.2068 - val_acc: 0.7017
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1526 - acc: 0.8417 - val_loss: 0.2099 - val_acc: 0.7017
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1441 - acc: 0.8640 - val_loss: 0.1996 - val_acc: 0.7311
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1415 - acc: 0.8798 - val_loss: 0.2027 - val_acc: 0.7143
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1381 - acc: 0.8768 - val_loss: 0.1951 - val_acc: 0.7437
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1349 - acc: 0.8887 - val_loss: 0.2006 - val_acc: 0.7185
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1348 - acc: 0.8872 - val_loss: 0.1949 - val_acc: 0.7311
Epoch 12/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1324 - acc: 0.8982 - val_loss: 0.1912 - val_acc: 0.7143
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1310 - acc: 0.9042 - val_loss: 0.1885 - val_acc: 0.7647
Epoch 14/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1282 - acc: 0.9127 - val_loss: 0.1878 - val_acc: 0.7437
Epoch 15/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1265 - acc: 0.9134 - val_loss: 0.1810 - val_acc: 0.7605
Epoch 16/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1245 - acc: 0.9220 - val_loss: 0.1876 - val_acc: 0.7605
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1234 - acc: 0.9292 - val_loss: 0.1874 - val_acc: 0.7479
Epoch 18/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1222 - acc: 0.9260 - val_loss: 0.1885 - val_acc: 0.7647
Manual evaluation: (didn't understand why I made this)
True 7617
False 1454
True percentage 0.839708962628
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.95      0.95      7318
      B-PER       0.60      0.60      0.60       438
      B-LOC       0.62      0.54      0.57       218
      B-ORG       0.49      0.43      0.46       296
      I-ORG       0.27      0.33      0.30       151
      I-PER       0.56      0.12      0.19       214
      I-LOC       0.55      0.51      0.53       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.84      0.84      9071

F-1 Score:
0.434753661784
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 47ms/step - loss: 0.2603 - acc: 0.4751 - val_loss: 0.2272 - val_acc: 0.7800
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1936 - acc: 0.8078 - val_loss: 0.2005 - val_acc: 0.7800
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1701 - acc: 0.8126 - val_loss: 0.1864 - val_acc: 0.7800
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1634 - acc: 0.8094 - val_loss: 0.1822 - val_acc: 0.7900
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1574 - acc: 0.8215 - val_loss: 0.1752 - val_acc: 0.7850
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1523 - acc: 0.8332 - val_loss: 0.1732 - val_acc: 0.7850
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1481 - acc: 0.8479 - val_loss: 0.1710 - val_acc: 0.7950
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1440 - acc: 0.8657 - val_loss: 0.1602 - val_acc: 0.8050
Epoch 9/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1427 - acc: 0.8688 - val_loss: 0.1567 - val_acc: 0.8400
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1428 - acc: 0.8701 - val_loss: 0.1523 - val_acc: 0.8150
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1367 - acc: 0.8824 - val_loss: 0.1575 - val_acc: 0.8150
Epoch 12/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1344 - acc: 0.8967 - val_loss: 0.1523 - val_acc: 0.8250
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1333 - acc: 0.8959 - val_loss: 0.1602 - val_acc: 0.8150
Epoch 14/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1306 - acc: 0.9044 - val_loss: 0.1570 - val_acc: 0.8200
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1303 - acc: 0.9100 - val_loss: 0.1491 - val_acc: 0.8300
Epoch 16/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1262 - acc: 0.9217 - val_loss: 0.1477 - val_acc: 0.8300
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1263 - acc: 0.9122 - val_loss: 0.1475 - val_acc: 0.8350
Epoch 18/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1246 - acc: 0.9219 - val_loss: 0.1442 - val_acc: 0.8550
Epoch 19/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1250 - acc: 0.9256 - val_loss: 0.1497 - val_acc: 0.8350
Epoch 20/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1242 - acc: 0.9237 - val_loss: 0.1395 - val_acc: 0.8850
Epoch 21/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1217 - acc: 0.9434 - val_loss: 0.1473 - val_acc: 0.8500
Epoch 22/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1211 - acc: 0.9371 - val_loss: 0.1407 - val_acc: 0.8750
Epoch 23/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1213 - acc: 0.9375 - val_loss: 0.1437 - val_acc: 0.8750
Manual evaluation: (didn't understand why I made this)
True 7547
False 1524
True percentage 0.831992062617
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.91      0.96      0.93      7318
      B-ORG       0.58      0.50      0.54       296
      B-LOC       0.77      0.44      0.56       218
      I-ORG       0.35      0.13      0.18       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.31      0.12      0.18       154
      B-PER       0.75      0.34      0.47       438
      I-PER       0.57      0.20      0.30       214
      I-LOC       0.78      0.35      0.48       141

avg / total       0.84      0.83      0.83      9071

F-1 Score:
0.404789494013
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2760 - acc: 0.4599 - val_loss: 0.2679 - val_acc: 0.6008
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.2040 - acc: 0.7674 - val_loss: 0.2306 - val_acc: 0.6176
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1721 - acc: 0.8049 - val_loss: 0.2234 - val_acc: 0.6471
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1620 - acc: 0.8184 - val_loss: 0.2155 - val_acc: 0.6681
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1545 - acc: 0.8322 - val_loss: 0.2153 - val_acc: 0.6765
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1536 - acc: 0.8459 - val_loss: 0.2079 - val_acc: 0.7101
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1474 - acc: 0.8640 - val_loss: 0.2100 - val_acc: 0.6765
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1468 - acc: 0.8566 - val_loss: 0.2008 - val_acc: 0.7311
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1400 - acc: 0.8776 - val_loss: 0.1982 - val_acc: 0.7227
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1386 - acc: 0.8742 - val_loss: 0.1954 - val_acc: 0.7185
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1357 - acc: 0.8812 - val_loss: 0.1861 - val_acc: 0.7353
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1332 - acc: 0.8963 - val_loss: 0.1843 - val_acc: 0.7311
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1310 - acc: 0.9077 - val_loss: 0.1813 - val_acc: 0.7437
Epoch 14/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1318 - acc: 0.8923 - val_loss: 0.1857 - val_acc: 0.7395
Epoch 15/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1266 - acc: 0.9110 - val_loss: 0.1815 - val_acc: 0.7689
Epoch 16/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1257 - acc: 0.9176 - val_loss: 0.1753 - val_acc: 0.7605
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1277 - acc: 0.9130 - val_loss: 0.1879 - val_acc: 0.7815
Epoch 18/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1237 - acc: 0.9244 - val_loss: 0.1937 - val_acc: 0.7479
Epoch 19/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1231 - acc: 0.9208 - val_loss: 0.1853 - val_acc: 0.7899
Manual evaluation: (didn't understand why I made this)
True 7577
False 1494
True percentage 0.835299305479
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.95      0.95      7318
      B-PER       0.72      0.50      0.59       438
      B-LOC       0.59      0.60      0.59       218
      B-ORG       0.49      0.40      0.44       296
      I-ORG       0.20      0.38      0.26       151
      I-PER       0.79      0.18      0.29       214
      I-LOC       0.36      0.29      0.32       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.84      0.84      9071

F-1 Score:
0.404994937563
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 47ms/step - loss: 0.2989 - acc: 0.4683 - val_loss: 0.2168 - val_acc: 0.7800
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1836 - acc: 0.8091 - val_loss: 0.2362 - val_acc: 0.7800
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1872 - acc: 0.8170 - val_loss: 0.1885 - val_acc: 0.7850
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1591 - acc: 0.8216 - val_loss: 0.1766 - val_acc: 0.7900
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1535 - acc: 0.8388 - val_loss: 0.1786 - val_acc: 0.7950
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1505 - acc: 0.8525 - val_loss: 0.1752 - val_acc: 0.7950
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1450 - acc: 0.8564 - val_loss: 0.1692 - val_acc: 0.8050
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1418 - acc: 0.8674 - val_loss: 0.1606 - val_acc: 0.8150
Epoch 9/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1406 - acc: 0.8684 - val_loss: 0.1615 - val_acc: 0.8100
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1369 - acc: 0.8852 - val_loss: 0.1477 - val_acc: 0.8550
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1351 - acc: 0.8954 - val_loss: 0.1492 - val_acc: 0.8400
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1342 - acc: 0.8942 - val_loss: 0.1532 - val_acc: 0.8300
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1317 - acc: 0.8978 - val_loss: 0.1506 - val_acc: 0.8350
Manual evaluation: (didn't understand why I made this)
True 7462
False 1609
True percentage 0.822621541175
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.95      0.94      7318
      B-ORG       0.40      0.36      0.38       296
      B-LOC       0.98      0.21      0.35       218
      I-ORG       0.24      0.29      0.26       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.52      0.58      0.55       438
      I-PER       0.55      0.18      0.27       214
      I-LOC       1.00      0.04      0.08       141

avg / total       0.84      0.82      0.82      9071

F-1 Score:
0.352899324084
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2511 - acc: 0.4720 - val_loss: 0.2352 - val_acc: 0.6429
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.2205 - acc: 0.8058 - val_loss: 0.2190 - val_acc: 0.6303
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1643 - acc: 0.8138 - val_loss: 0.2130 - val_acc: 0.6555
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1561 - acc: 0.8286 - val_loss: 0.2044 - val_acc: 0.7101
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1483 - acc: 0.8514 - val_loss: 0.1999 - val_acc: 0.7269
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1457 - acc: 0.8576 - val_loss: 0.2018 - val_acc: 0.7185
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1435 - acc: 0.8723 - val_loss: 0.1971 - val_acc: 0.7101
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1420 - acc: 0.8585 - val_loss: 0.1925 - val_acc: 0.7185
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1351 - acc: 0.8830 - val_loss: 0.1936 - val_acc: 0.7395
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1332 - acc: 0.9030 - val_loss: 0.1908 - val_acc: 0.7353
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1338 - acc: 0.8909 - val_loss: 0.1841 - val_acc: 0.7563
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1292 - acc: 0.9054 - val_loss: 0.1888 - val_acc: 0.7479
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1272 - acc: 0.9118 - val_loss: 0.1907 - val_acc: 0.7563
Epoch 14/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1288 - acc: 0.9052 - val_loss: 0.1822 - val_acc: 0.7563
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1253 - acc: 0.9177 - val_loss: 0.1826 - val_acc: 0.7689
Epoch 16/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1239 - acc: 0.9203 - val_loss: 0.1863 - val_acc: 0.7563
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1221 - acc: 0.9248 - val_loss: 0.1863 - val_acc: 0.7689
Manual evaluation: (didn't understand why I made this)
True 7539
False 1532
True percentage 0.831110131187
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.95      0.95      7318
      B-PER       0.69      0.45      0.54       438
      B-LOC       0.46      0.77      0.57       218
      B-ORG       0.47      0.40      0.43       296
      I-ORG       0.18      0.22      0.20       151
      I-PER       0.72      0.11      0.19       214
      I-LOC       0.40      0.44      0.42       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.83      0.83      9071

F-1 Score:
0.395908940944
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2757 - acc: 0.4780 - val_loss: 0.1967 - val_acc: 0.7850
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1912 - acc: 0.8116 - val_loss: 0.1894 - val_acc: 0.7800
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1676 - acc: 0.8161 - val_loss: 0.1770 - val_acc: 0.7850
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1567 - acc: 0.8290 - val_loss: 0.1782 - val_acc: 0.7950
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1524 - acc: 0.8361 - val_loss: 0.1657 - val_acc: 0.8050
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1490 - acc: 0.8478 - val_loss: 0.1653 - val_acc: 0.8050
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1439 - acc: 0.8747 - val_loss: 0.1671 - val_acc: 0.8050
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1430 - acc: 0.8713 - val_loss: 0.1568 - val_acc: 0.8150
Epoch 9/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1378 - acc: 0.8759 - val_loss: 0.1587 - val_acc: 0.7950
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1362 - acc: 0.8827 - val_loss: 0.1552 - val_acc: 0.8200
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1353 - acc: 0.8860 - val_loss: 0.1525 - val_acc: 0.8200
Epoch 12/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1326 - acc: 0.8952 - val_loss: 0.1487 - val_acc: 0.8350
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1331 - acc: 0.8979 - val_loss: 0.1484 - val_acc: 0.8300
Epoch 14/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1280 - acc: 0.9141 - val_loss: 0.1514 - val_acc: 0.8200
Epoch 15/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1280 - acc: 0.9053 - val_loss: 0.1417 - val_acc: 0.8600
Epoch 16/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1271 - acc: 0.9122 - val_loss: 0.1373 - val_acc: 0.8900
Epoch 17/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1258 - acc: 0.9249 - val_loss: 0.1417 - val_acc: 0.8500
Epoch 18/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1236 - acc: 0.9304 - val_loss: 0.1382 - val_acc: 0.8850
Epoch 19/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1230 - acc: 0.9323 - val_loss: 0.1383 - val_acc: 0.9000
Manual evaluation: (didn't understand why I made this)
True 7588
False 1483
True percentage 0.836511961195
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.92      0.96      0.94      7318
      B-ORG       0.52      0.55      0.53       296
      B-LOC       0.84      0.44      0.58       218
      I-ORG       0.29      0.07      0.11       151
     B-MISC       0.50      0.01      0.01       141
     I-MISC       0.34      0.25      0.29       154
      B-PER       0.73      0.35      0.48       438
      I-PER       0.62      0.25      0.35       214
      I-LOC       0.72      0.48      0.57       141

avg / total       0.86      0.84      0.84      9071

F-1 Score:
0.428938670584
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2704 - acc: 0.4526 - val_loss: 0.2637 - val_acc: 0.5252
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.2348 - acc: 0.7278 - val_loss: 0.2134 - val_acc: 0.6345
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1601 - acc: 0.8181 - val_loss: 0.2142 - val_acc: 0.6639
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1524 - acc: 0.8366 - val_loss: 0.2114 - val_acc: 0.6849
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1483 - acc: 0.8503 - val_loss: 0.2062 - val_acc: 0.6849
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1451 - acc: 0.8625 - val_loss: 0.2008 - val_acc: 0.7059
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1409 - acc: 0.8695 - val_loss: 0.1947 - val_acc: 0.7059
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1392 - acc: 0.8768 - val_loss: 0.1928 - val_acc: 0.7017
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1374 - acc: 0.8719 - val_loss: 0.1886 - val_acc: 0.7227
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1356 - acc: 0.8844 - val_loss: 0.1773 - val_acc: 0.7437
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1322 - acc: 0.8973 - val_loss: 0.1868 - val_acc: 0.7437
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1298 - acc: 0.9043 - val_loss: 0.1843 - val_acc: 0.7479
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1299 - acc: 0.9008 - val_loss: 0.1813 - val_acc: 0.7605
Manual evaluation: (didn't understand why I made this)
True 7524
False 1547
True percentage 0.829456509756
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.95      7318
      B-PER       0.53      0.58      0.55       438
      B-LOC       0.64      0.60      0.62       218
      B-ORG       0.43      0.28      0.34       296
      I-ORG       0.20      0.38      0.27       151
      I-PER       0.56      0.15      0.24       214
      I-LOC       0.34      0.33      0.33       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.83      0.83      9071

F-1 Score:
0.387906079125
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 46ms/step - loss: 0.2737 - acc: 0.4610 - val_loss: 0.2018 - val_acc: 0.7800
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1776 - acc: 0.8136 - val_loss: 0.1732 - val_acc: 0.7700
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1545 - acc: 0.8275 - val_loss: 0.1638 - val_acc: 0.7900
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1485 - acc: 0.8431 - val_loss: 0.1591 - val_acc: 0.7800
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1443 - acc: 0.8500 - val_loss: 0.1601 - val_acc: 0.7850
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1422 - acc: 0.8574 - val_loss: 0.1619 - val_acc: 0.7850
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1397 - acc: 0.8722 - val_loss: 0.1618 - val_acc: 0.7700
Manual evaluation: (didn't understand why I made this)
True 7043
False 2028
True percentage 0.776430382538
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.92      0.95      7318
      B-ORG       0.19      0.70      0.30       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.12      0.35      0.18       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.88      0.02      0.03       438
      I-PER       0.89      0.04      0.07       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.85      0.78      0.78      9071

F-1 Score:
0.16575922565
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2817 - acc: 0.4688 - val_loss: 0.2090 - val_acc: 0.6807
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1546 - acc: 0.8259 - val_loss: 0.2043 - val_acc: 0.6933
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1494 - acc: 0.8448 - val_loss: 0.2090 - val_acc: 0.6765
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1428 - acc: 0.8713 - val_loss: 0.2319 - val_acc: 0.6555
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1427 - acc: 0.8629 - val_loss: 0.2005 - val_acc: 0.6933
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1359 - acc: 0.8791 - val_loss: 0.1833 - val_acc: 0.7227
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1340 - acc: 0.8883 - val_loss: 0.2002 - val_acc: 0.6975
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1311 - acc: 0.8972 - val_loss: 0.1842 - val_acc: 0.7395
Epoch 9/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1294 - acc: 0.9062 - val_loss: 0.1814 - val_acc: 0.7311
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1277 - acc: 0.9095 - val_loss: 0.1865 - val_acc: 0.7395
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1260 - acc: 0.9171 - val_loss: 0.1853 - val_acc: 0.7311
Epoch 12/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1255 - acc: 0.9185 - val_loss: 0.1822 - val_acc: 0.7479
Manual evaluation: (didn't understand why I made this)
True 7554
False 1517
True percentage 0.832763752618
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-PER       0.64      0.58      0.61       438
      B-LOC       0.61      0.62      0.61       218
      B-ORG       0.41      0.41      0.41       296
      I-ORG       0.17      0.55      0.26       151
      I-PER       0.77      0.25      0.37       214
      I-LOC       0.29      0.14      0.19       141
     B-MISC       0.08      0.01      0.01       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.87      0.83      0.85      9071

F-1 Score:
0.404364959079
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2618 - acc: 0.4989 - val_loss: 0.1844 - val_acc: 0.7850
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1573 - acc: 0.8315 - val_loss: 0.1545 - val_acc: 0.8100
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1456 - acc: 0.8632 - val_loss: 0.1505 - val_acc: 0.8050
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1400 - acc: 0.8737 - val_loss: 0.1569 - val_acc: 0.8150
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1374 - acc: 0.8829 - val_loss: 0.1432 - val_acc: 0.8600
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1349 - acc: 0.8968 - val_loss: 0.1417 - val_acc: 0.8600
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1339 - acc: 0.8956 - val_loss: 0.1462 - val_acc: 0.8200
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1311 - acc: 0.8926 - val_loss: 0.1456 - val_acc: 0.8350
Epoch 9/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1293 - acc: 0.9070 - val_loss: 0.1467 - val_acc: 0.8400
Manual evaluation: (didn't understand why I made this)
True 7452
False 1619
True percentage 0.821519126888
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.96      7318
      B-ORG       0.39      0.53      0.45       296
      B-LOC       0.86      0.28      0.43       218
      I-ORG       0.16      0.68      0.26       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.70      0.46      0.56       438
      I-PER       0.83      0.09      0.17       214
      I-LOC       1.00      0.01      0.01       141

avg / total       0.89      0.82      0.83      9071

F-1 Score:
0.343415248897
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 93ms/step - loss: 0.3145 - acc: 0.2558 - val_loss: 0.1951 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1951 - acc: 0.7940 - val_loss: 0.1820 - val_acc: 0.7938
Epoch 3/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1818 - acc: 0.7940 - val_loss: 0.1759 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1715 - acc: 0.7940 - val_loss: 0.1880 - val_acc: 0.8454
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1882 - acc: 0.8046 - val_loss: 0.3082 - val_acc: 0.7938
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.3056 - acc: 0.7940 - val_loss: 0.1816 - val_acc: 0.8351
Manual evaluation: (didn't understand why I made this)
True 7132
False 1939
True percentage 0.786241869695
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.85      0.97      0.90      7318
      B-PER       0.49      0.12      0.19       438
      B-LOC       1.00      0.00      0.01       218
      B-ORG       0.00      0.00      0.00       296
      I-ORG       0.12      0.07      0.09       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.74      0.79      0.74      9071

F-1 Score:
0.064681724846
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3322 - acc: 0.0703 - val_loss: 0.1660 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1883 - acc: 0.8095 - val_loss: 0.1804 - val_acc: 0.8795
Epoch 3/70

29/29 [==============================] - 1s 22ms/step - loss: 0.2203 - acc: 0.8122 - val_loss: 0.2247 - val_acc: 0.8313
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2327 - acc: 0.7959 - val_loss: 0.1546 - val_acc: 0.8795
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1715 - acc: 0.8108 - val_loss: 0.1504 - val_acc: 0.8795
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1680 - acc: 0.8122 - val_loss: 0.1498 - val_acc: 0.8795
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1645 - acc: 0.8176 - val_loss: 0.1472 - val_acc: 0.8795
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1628 - acc: 0.8189 - val_loss: 0.1461 - val_acc: 0.8795
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1581 - acc: 0.8297 - val_loss: 0.1447 - val_acc: 0.8795
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1563 - acc: 0.8311 - val_loss: 0.1439 - val_acc: 0.8795
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1538 - acc: 0.8459 - val_loss: 0.1421 - val_acc: 0.8795
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1498 - acc: 0.8419 - val_loss: 0.1413 - val_acc: 0.8795
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1494 - acc: 0.8514 - val_loss: 0.1397 - val_acc: 0.8795
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1455 - acc: 0.8473 - val_loss: 0.1386 - val_acc: 0.8795
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1444 - acc: 0.8730 - val_loss: 0.1382 - val_acc: 0.8795
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1418 - acc: 0.8676 - val_loss: 0.1363 - val_acc: 0.8916
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1404 - acc: 0.8851 - val_loss: 0.1380 - val_acc: 0.8795
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1390 - acc: 0.8595 - val_loss: 0.1368 - val_acc: 0.8916
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1385 - acc: 0.9000 - val_loss: 0.1356 - val_acc: 0.8795
Epoch 20/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1342 - acc: 0.8946 - val_loss: 0.1335 - val_acc: 0.9036
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1340 - acc: 0.8919 - val_loss: 0.1328 - val_acc: 0.8916
Epoch 22/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1323 - acc: 0.9041 - val_loss: 0.1330 - val_acc: 0.9036
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1291 - acc: 0.9068 - val_loss: 0.1323 - val_acc: 0.9157
Epoch 24/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1305 - acc: 0.9230 - val_loss: 0.1340 - val_acc: 0.8916
Epoch 25/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1268 - acc: 0.9162 - val_loss: 0.1317 - val_acc: 0.9036
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1275 - acc: 0.9216 - val_loss: 0.1333 - val_acc: 0.8916
Epoch 27/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1249 - acc: 0.9230 - val_loss: 0.1322 - val_acc: 0.9157
Epoch 28/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1251 - acc: 0.9365 - val_loss: 0.1338 - val_acc: 0.8795
Manual evaluation: (didn't understand why I made this)
True 7302
False 1769
True percentage 0.804982912579
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.89      0.96      0.92      7318
      B-ORG       0.38      0.31      0.34       296
      B-LOC       1.00      0.00      0.01       218
      I-ORG       0.33      0.22      0.26       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.20      0.01      0.01       154
      B-PER       0.59      0.27      0.37       438
      I-PER       0.69      0.13      0.21       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.81      0.80      0.78      9071

F-1 Score:
0.232219365895
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3398 - acc: 0.0444 - val_loss: 0.1989 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1982 - acc: 0.7940 - val_loss: 0.2867 - val_acc: 0.7938
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2732 - acc: 0.7940 - val_loss: 0.2377 - val_acc: 0.7629
Epoch 4/70

29/29 [==============================] - 1s 20ms/step - loss: 0.2346 - acc: 0.7069 - val_loss: 0.1798 - val_acc: 0.7938
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1764 - acc: 0.7957 - val_loss: 0.1753 - val_acc: 0.7938
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1721 - acc: 0.7957 - val_loss: 0.1705 - val_acc: 0.7938
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1653 - acc: 0.7993 - val_loss: 0.1662 - val_acc: 0.8041
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1607 - acc: 0.8099 - val_loss: 0.1619 - val_acc: 0.8247
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1567 - acc: 0.8313 - val_loss: 0.1576 - val_acc: 0.8247
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1534 - acc: 0.8224 - val_loss: 0.1526 - val_acc: 0.8351
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1475 - acc: 0.8490 - val_loss: 0.1515 - val_acc: 0.8351
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1467 - acc: 0.8490 - val_loss: 0.1503 - val_acc: 0.8660
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1435 - acc: 0.8863 - val_loss: 0.1544 - val_acc: 0.8144
Epoch 14/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1442 - acc: 0.8561 - val_loss: 0.1512 - val_acc: 0.8866
Epoch 15/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1464 - acc: 0.8917 - val_loss: 0.1501 - val_acc: 0.8454
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1406 - acc: 0.8561 - val_loss: 0.1436 - val_acc: 0.8763
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1371 - acc: 0.9005 - val_loss: 0.1433 - val_acc: 0.8763
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1342 - acc: 0.9005 - val_loss: 0.1391 - val_acc: 0.8969
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1319 - acc: 0.9147 - val_loss: 0.1397 - val_acc: 0.8866
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1295 - acc: 0.8970 - val_loss: 0.1372 - val_acc: 0.8969
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1285 - acc: 0.9165 - val_loss: 0.1385 - val_acc: 0.8969
Epoch 22/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1253 - acc: 0.9272 - val_loss: 0.1345 - val_acc: 0.9072
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1237 - acc: 0.9343 - val_loss: 0.1354 - val_acc: 0.8866
Epoch 24/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1263 - acc: 0.9307 - val_loss: 0.1344 - val_acc: 0.8969
Epoch 25/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1255 - acc: 0.9325 - val_loss: 0.1411 - val_acc: 0.8969
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1223 - acc: 0.9272 - val_loss: 0.1320 - val_acc: 0.9072
Epoch 27/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1216 - acc: 0.9449 - val_loss: 0.1361 - val_acc: 0.8969
Epoch 28/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1205 - acc: 0.9272 - val_loss: 0.1300 - val_acc: 0.9175
Epoch 29/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1191 - acc: 0.9591 - val_loss: 0.1345 - val_acc: 0.8866
Epoch 30/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1183 - acc: 0.9432 - val_loss: 0.1281 - val_acc: 0.9175
Epoch 31/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1175 - acc: 0.9503 - val_loss: 0.1332 - val_acc: 0.8969
Epoch 32/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1183 - acc: 0.9414 - val_loss: 0.1270 - val_acc: 0.9175
Epoch 33/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1179 - acc: 0.9574 - val_loss: 0.1303 - val_acc: 0.8969
Epoch 34/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1170 - acc: 0.9538 - val_loss: 0.1288 - val_acc: 0.9175
Epoch 35/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1140 - acc: 0.9591 - val_loss: 0.1293 - val_acc: 0.9072
Manual evaluation: (didn't understand why I made this)
True 7416
False 1655
True percentage 0.817550435454
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.95      0.94      7318
      B-PER       0.56      0.48      0.51       438
      B-LOC       0.59      0.40      0.48       218
      B-ORG       0.39      0.36      0.38       296
      I-ORG       0.19      0.23      0.21       151
      I-PER       0.53      0.04      0.07       214
      I-LOC       0.26      0.21      0.23       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.83      0.82      0.82      9071

F-1 Score:
0.332518337408
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 85ms/step - loss: 0.3263 - acc: 0.0216 - val_loss: 0.1674 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1910 - acc: 0.8122 - val_loss: 0.1857 - val_acc: 0.8795
Epoch 3/70

29/29 [==============================] - 1s 20ms/step - loss: 0.2450 - acc: 0.8122 - val_loss: 0.2158 - val_acc: 0.8554
Epoch 4/70

29/29 [==============================] - 1s 20ms/step - loss: 0.2249 - acc: 0.7973 - val_loss: 0.1521 - val_acc: 0.8795
Epoch 5/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1720 - acc: 0.8122 - val_loss: 0.1467 - val_acc: 0.8795
Epoch 6/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1674 - acc: 0.8122 - val_loss: 0.1451 - val_acc: 0.8795
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1633 - acc: 0.8176 - val_loss: 0.1434 - val_acc: 0.8795
Epoch 8/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1584 - acc: 0.8230 - val_loss: 0.1407 - val_acc: 0.8795
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1539 - acc: 0.8311 - val_loss: 0.1395 - val_acc: 0.8795
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1517 - acc: 0.8392 - val_loss: 0.1373 - val_acc: 0.8675
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1486 - acc: 0.8554 - val_loss: 0.1350 - val_acc: 0.8675
Epoch 12/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1479 - acc: 0.8486 - val_loss: 0.1418 - val_acc: 0.9277
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1471 - acc: 0.8932 - val_loss: 0.1353 - val_acc: 0.8675
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1415 - acc: 0.8595 - val_loss: 0.1348 - val_acc: 0.9036
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1395 - acc: 0.8959 - val_loss: 0.1335 - val_acc: 0.8795
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1375 - acc: 0.8770 - val_loss: 0.1336 - val_acc: 0.9036
Epoch 17/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1364 - acc: 0.9081 - val_loss: 0.1327 - val_acc: 0.8916
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1369 - acc: 0.8824 - val_loss: 0.1335 - val_acc: 0.9157
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1348 - acc: 0.9081 - val_loss: 0.1315 - val_acc: 0.9036
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1309 - acc: 0.9122 - val_loss: 0.1316 - val_acc: 0.9036
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1305 - acc: 0.9081 - val_loss: 0.1311 - val_acc: 0.9036
Epoch 22/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1285 - acc: 0.9135 - val_loss: 0.1317 - val_acc: 0.9277
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1275 - acc: 0.9230 - val_loss: 0.1303 - val_acc: 0.9157
Epoch 24/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1260 - acc: 0.9324 - val_loss: 0.1301 - val_acc: 0.9157
Epoch 25/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1263 - acc: 0.9257 - val_loss: 0.1306 - val_acc: 0.9277
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1260 - acc: 0.9311 - val_loss: 0.1303 - val_acc: 0.9036
Epoch 27/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1242 - acc: 0.9351 - val_loss: 0.1304 - val_acc: 0.9277
Manual evaluation: (didn't understand why I made this)
True 7339
False 1732
True percentage 0.809061845442
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.95      0.94      7318
      B-ORG       0.38      0.39      0.38       296
      B-LOC       0.88      0.07      0.13       218
      I-ORG       0.20      0.54      0.30       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.14      0.01      0.01       154
      B-PER       0.56      0.37      0.44       438
      I-PER       0.67      0.16      0.26       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.83      0.81      0.81      9071

F-1 Score:
0.288249911253
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 85ms/step - loss: 0.3468 - acc: 0.0266 - val_loss: 0.2052 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2063 - acc: 0.7940 - val_loss: 0.3672 - val_acc: 0.7938
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.3514 - acc: 0.7940 - val_loss: 0.1970 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1959 - acc: 0.7975 - val_loss: 0.1828 - val_acc: 0.7938
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1805 - acc: 0.7940 - val_loss: 0.1755 - val_acc: 0.7938
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1744 - acc: 0.7957 - val_loss: 0.1712 - val_acc: 0.7938
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1658 - acc: 0.7957 - val_loss: 0.1643 - val_acc: 0.8351
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1610 - acc: 0.8171 - val_loss: 0.1611 - val_acc: 0.8351
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1561 - acc: 0.8188 - val_loss: 0.1545 - val_acc: 0.8351
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1493 - acc: 0.8348 - val_loss: 0.1520 - val_acc: 0.8247
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1509 - acc: 0.8384 - val_loss: 0.1568 - val_acc: 0.8763
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1525 - acc: 0.8899 - val_loss: 0.1549 - val_acc: 0.8247
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1451 - acc: 0.8508 - val_loss: 0.1475 - val_acc: 0.8866
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1399 - acc: 0.8810 - val_loss: 0.1471 - val_acc: 0.8763
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1430 - acc: 0.8668 - val_loss: 0.1442 - val_acc: 0.8866
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1388 - acc: 0.8917 - val_loss: 0.1450 - val_acc: 0.8660
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1348 - acc: 0.9059 - val_loss: 0.1401 - val_acc: 0.8763
Epoch 18/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1329 - acc: 0.9076 - val_loss: 0.1422 - val_acc: 0.8763
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1304 - acc: 0.9094 - val_loss: 0.1382 - val_acc: 0.8763
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1302 - acc: 0.9201 - val_loss: 0.1401 - val_acc: 0.8866
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1269 - acc: 0.9218 - val_loss: 0.1400 - val_acc: 0.8763
Epoch 22/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1260 - acc: 0.9272 - val_loss: 0.1371 - val_acc: 0.8763
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1262 - acc: 0.9343 - val_loss: 0.1388 - val_acc: 0.8763
Epoch 24/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1256 - acc: 0.9254 - val_loss: 0.1350 - val_acc: 0.8866
Epoch 25/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1245 - acc: 0.9325 - val_loss: 0.1352 - val_acc: 0.8866
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1215 - acc: 0.9343 - val_loss: 0.1353 - val_acc: 0.8763
Epoch 27/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1197 - acc: 0.9467 - val_loss: 0.1332 - val_acc: 0.8866
Epoch 28/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1208 - acc: 0.9432 - val_loss: 0.1381 - val_acc: 0.8866
Epoch 29/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1201 - acc: 0.9449 - val_loss: 0.1348 - val_acc: 0.8866
Epoch 30/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1197 - acc: 0.9503 - val_loss: 0.1379 - val_acc: 0.8866
Manual evaluation: (didn't understand why I made this)
True 7322
False 1749
True percentage 0.807187741153
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.92      0.95      0.93      7318
      B-PER       0.60      0.39      0.48       438
      B-LOC       0.56      0.27      0.36       218
      B-ORG       0.34      0.34      0.34       296
      I-ORG       0.16      0.23      0.18       151
      I-PER       0.44      0.02      0.04       214
      I-LOC       0.09      0.02      0.03       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.81      0.81      0.80      9071

F-1 Score:
0.275378368402
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 86ms/step - loss: 0.3397 - acc: 0.0419 - val_loss: 0.1632 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1839 - acc: 0.8122 - val_loss: 0.1611 - val_acc: 0.8795
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1897 - acc: 0.8122 - val_loss: 0.2496 - val_acc: 0.7952
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2558 - acc: 0.6486 - val_loss: 0.1553 - val_acc: 0.8795
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1699 - acc: 0.8176 - val_loss: 0.1478 - val_acc: 0.8795
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1654 - acc: 0.8176 - val_loss: 0.1482 - val_acc: 0.8795
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1607 - acc: 0.8392 - val_loss: 0.1427 - val_acc: 0.8795
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1557 - acc: 0.8243 - val_loss: 0.1412 - val_acc: 0.8795
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1513 - acc: 0.8541 - val_loss: 0.1387 - val_acc: 0.8795
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1504 - acc: 0.8378 - val_loss: 0.1376 - val_acc: 0.8554
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1478 - acc: 0.8743 - val_loss: 0.1360 - val_acc: 0.8554
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1441 - acc: 0.8635 - val_loss: 0.1371 - val_acc: 0.8916
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1452 - acc: 0.8865 - val_loss: 0.1353 - val_acc: 0.8554
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1399 - acc: 0.8770 - val_loss: 0.1339 - val_acc: 0.8916
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1390 - acc: 0.8919 - val_loss: 0.1339 - val_acc: 0.8795
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1356 - acc: 0.8770 - val_loss: 0.1329 - val_acc: 0.9157
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1365 - acc: 0.8986 - val_loss: 0.1332 - val_acc: 0.9036
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1341 - acc: 0.9041 - val_loss: 0.1335 - val_acc: 0.9277
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1328 - acc: 0.9149 - val_loss: 0.1335 - val_acc: 0.9036
Manual evaluation: (didn't understand why I made this)
True 7246
False 1825
True percentage 0.79880939257
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.89      0.96      0.92      7318
      B-ORG       0.35      0.21      0.26       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.21      0.26      0.23       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.44      0.31      0.36       438
      I-PER       0.62      0.04      0.07       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.77      0.80      0.78      9071

F-1 Score:
0.199180327869
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 86ms/step - loss: 0.3328 - acc: 0.0515 - val_loss: 0.2091 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2017 - acc: 0.7940 - val_loss: 0.2385 - val_acc: 0.7835
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2386 - acc: 0.7851 - val_loss: 0.1635 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1618 - acc: 0.8028 - val_loss: 0.1539 - val_acc: 0.8454
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1538 - acc: 0.8171 - val_loss: 0.1509 - val_acc: 0.8763
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1513 - acc: 0.8455 - val_loss: 0.1502 - val_acc: 0.8866
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1472 - acc: 0.8668 - val_loss: 0.1483 - val_acc: 0.8660
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1468 - acc: 0.8366 - val_loss: 0.1471 - val_acc: 0.9072
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1413 - acc: 0.8863 - val_loss: 0.1453 - val_acc: 0.8866
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1406 - acc: 0.8828 - val_loss: 0.1434 - val_acc: 0.8969
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1379 - acc: 0.8721 - val_loss: 0.1451 - val_acc: 0.8763
Epoch 12/70

29/29 [==============================] - 1s 20ms/step - loss: 0.1387 - acc: 0.8650 - val_loss: 0.1415 - val_acc: 0.9175
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1353 - acc: 0.8970 - val_loss: 0.1427 - val_acc: 0.8969
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1335 - acc: 0.8952 - val_loss: 0.1391 - val_acc: 0.9175
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1298 - acc: 0.9183 - val_loss: 0.1401 - val_acc: 0.8866
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1298 - acc: 0.9094 - val_loss: 0.1374 - val_acc: 0.9072
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1273 - acc: 0.9094 - val_loss: 0.1399 - val_acc: 0.8866
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1271 - acc: 0.9236 - val_loss: 0.1360 - val_acc: 0.8969
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1254 - acc: 0.9272 - val_loss: 0.1386 - val_acc: 0.9072
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1249 - acc: 0.9254 - val_loss: 0.1360 - val_acc: 0.8969
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1231 - acc: 0.9183 - val_loss: 0.1364 - val_acc: 0.9072
Epoch 22/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1205 - acc: 0.9378 - val_loss: 0.1338 - val_acc: 0.9278
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1206 - acc: 0.9414 - val_loss: 0.1343 - val_acc: 0.9072
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1200 - acc: 0.9414 - val_loss: 0.1341 - val_acc: 0.9072
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1181 - acc: 0.9485 - val_loss: 0.1334 - val_acc: 0.9278
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1198 - acc: 0.9396 - val_loss: 0.1353 - val_acc: 0.8969
Epoch 27/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1184 - acc: 0.9503 - val_loss: 0.1352 - val_acc: 0.8969
Epoch 28/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1187 - acc: 0.9396 - val_loss: 0.1387 - val_acc: 0.8866
Manual evaluation: (didn't understand why I made this)
True 7202
False 1869
True percentage 0.793958769706
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.92      0.95      7318
      B-PER       0.44      0.43      0.43       438
      B-LOC       0.31      0.70      0.43       218
      B-ORG       0.19      0.03      0.06       296
      I-ORG       0.14      0.25      0.18       151
      I-PER       0.48      0.05      0.09       214
      I-LOC       0.14      0.32      0.19       141
     B-MISC       0.19      0.04      0.06       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.79      0.81      9071

F-1 Score:
0.265045953157
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 86ms/step - loss: 0.3013 - acc: 0.5014 - val_loss: 0.1682 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2032 - acc: 0.8122 - val_loss: 0.2571 - val_acc: 0.6988
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2715 - acc: 0.5838 - val_loss: 0.1514 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1668 - acc: 0.8122 - val_loss: 0.1445 - val_acc: 0.8795
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1634 - acc: 0.8149 - val_loss: 0.1417 - val_acc: 0.8554
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1564 - acc: 0.8203 - val_loss: 0.1388 - val_acc: 0.8554
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1536 - acc: 0.8270 - val_loss: 0.1367 - val_acc: 0.8675
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1482 - acc: 0.8500 - val_loss: 0.1346 - val_acc: 0.8795
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1467 - acc: 0.8527 - val_loss: 0.1337 - val_acc: 0.9157
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1434 - acc: 0.8554 - val_loss: 0.1325 - val_acc: 0.9277
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1423 - acc: 0.8676 - val_loss: 0.1314 - val_acc: 0.9157
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1400 - acc: 0.8770 - val_loss: 0.1302 - val_acc: 0.9157
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1390 - acc: 0.8770 - val_loss: 0.1295 - val_acc: 0.9157
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1380 - acc: 0.8838 - val_loss: 0.1294 - val_acc: 0.9157
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1351 - acc: 0.8986 - val_loss: 0.1285 - val_acc: 0.9157
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1354 - acc: 0.8824 - val_loss: 0.1293 - val_acc: 0.9157
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1317 - acc: 0.8865 - val_loss: 0.1286 - val_acc: 0.9157
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1305 - acc: 0.9081 - val_loss: 0.1279 - val_acc: 0.9398
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1300 - acc: 0.9095 - val_loss: 0.1280 - val_acc: 0.9157
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1276 - acc: 0.9068 - val_loss: 0.1273 - val_acc: 0.9398
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1294 - acc: 0.9041 - val_loss: 0.1287 - val_acc: 0.9157
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1277 - acc: 0.9108 - val_loss: 0.1274 - val_acc: 0.9036
Epoch 23/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1269 - acc: 0.9081 - val_loss: 0.1277 - val_acc: 0.9277
Manual evaluation: (didn't understand why I made this)
True 7233
False 1838
True percentage 0.797376253996
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.25      0.52      0.34       296
      B-LOC       0.86      0.06      0.10       218
      I-ORG       0.16      0.58      0.25       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.17      0.04      0.06       154
      B-PER       0.70      0.18      0.28       438
      I-PER       0.49      0.24      0.32       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.86      0.80      0.81      9071

F-1 Score:
0.244241085516
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 86ms/step - loss: 0.4308 - acc: 0.0124 - val_loss: 0.1962 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1892 - acc: 0.7940 - val_loss: 0.1762 - val_acc: 0.8144
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1744 - acc: 0.8064 - val_loss: 0.1657 - val_acc: 0.8041
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1604 - acc: 0.8082 - val_loss: 0.1505 - val_acc: 0.8557
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1466 - acc: 0.8686 - val_loss: 0.1462 - val_acc: 0.8660
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1404 - acc: 0.8668 - val_loss: 0.1434 - val_acc: 0.8557
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1370 - acc: 0.8988 - val_loss: 0.1414 - val_acc: 0.8557
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1355 - acc: 0.8970 - val_loss: 0.1405 - val_acc: 0.8660
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1306 - acc: 0.9183 - val_loss: 0.1393 - val_acc: 0.8557
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1296 - acc: 0.9094 - val_loss: 0.1384 - val_acc: 0.8557
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1275 - acc: 0.9325 - val_loss: 0.1383 - val_acc: 0.8763
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1259 - acc: 0.9236 - val_loss: 0.1375 - val_acc: 0.8866
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1214 - acc: 0.9503 - val_loss: 0.1376 - val_acc: 0.8763
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1213 - acc: 0.9361 - val_loss: 0.1366 - val_acc: 0.8969
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1193 - acc: 0.9609 - val_loss: 0.1374 - val_acc: 0.8660
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1183 - acc: 0.9538 - val_loss: 0.1364 - val_acc: 0.8763
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1174 - acc: 0.9591 - val_loss: 0.1369 - val_acc: 0.8557
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1161 - acc: 0.9609 - val_loss: 0.1371 - val_acc: 0.8763
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1171 - acc: 0.9645 - val_loss: 0.1358 - val_acc: 0.8866
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1173 - acc: 0.9591 - val_loss: 0.1371 - val_acc: 0.8763
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1145 - acc: 0.9663 - val_loss: 0.1365 - val_acc: 0.8763
Epoch 22/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1115 - acc: 0.9751 - val_loss: 0.1365 - val_acc: 0.8763
Manual evaluation: (didn't understand why I made this)
True 7346
False 1725
True percentage 0.809833535443
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.52      0.43      0.48       438
      B-LOC       0.51      0.55      0.53       218
      B-ORG       0.32      0.35      0.34       296
      I-ORG       0.16      0.40      0.23       151
      I-PER       0.88      0.14      0.24       214
      I-LOC       0.22      0.25      0.23       141
     B-MISC       0.16      0.02      0.04       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.86      0.81      0.83      9071

F-1 Score:
0.331698344574
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 86ms/step - loss: 0.4238 - acc: 0.0122 - val_loss: 0.1555 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1873 - acc: 0.8122 - val_loss: 0.1758 - val_acc: 0.8675
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1947 - acc: 0.7459 - val_loss: 0.1536 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1739 - acc: 0.8122 - val_loss: 0.1395 - val_acc: 0.8675
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1518 - acc: 0.8595 - val_loss: 0.1339 - val_acc: 0.8795
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1431 - acc: 0.8757 - val_loss: 0.1318 - val_acc: 0.8795
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1396 - acc: 0.8865 - val_loss: 0.1301 - val_acc: 0.9157
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1364 - acc: 0.8932 - val_loss: 0.1293 - val_acc: 0.9157
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1356 - acc: 0.8932 - val_loss: 0.1283 - val_acc: 0.9398
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1311 - acc: 0.9041 - val_loss: 0.1282 - val_acc: 0.9277
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1313 - acc: 0.9081 - val_loss: 0.1271 - val_acc: 0.9398
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1293 - acc: 0.9203 - val_loss: 0.1270 - val_acc: 0.9277
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1283 - acc: 0.9122 - val_loss: 0.1269 - val_acc: 0.9398
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1246 - acc: 0.9365 - val_loss: 0.1266 - val_acc: 0.9398
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1221 - acc: 0.9419 - val_loss: 0.1261 - val_acc: 0.9398
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1233 - acc: 0.9405 - val_loss: 0.1263 - val_acc: 0.9398
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1217 - acc: 0.9378 - val_loss: 0.1265 - val_acc: 0.9398
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1198 - acc: 0.9486 - val_loss: 0.1269 - val_acc: 0.9398
Manual evaluation: (didn't understand why I made this)
True 7368
False 1703
True percentage 0.812258846875
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.94      0.95      7318
      B-ORG       0.29      0.38      0.33       296
      B-LOC       0.76      0.19      0.30       218
      I-ORG       0.17      0.48      0.25       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.42      0.03      0.06       154
      B-PER       0.67      0.35      0.46       438
      I-PER       0.72      0.32      0.45       214
      I-LOC       0.50      0.04      0.08       141

avg / total       0.86      0.81      0.82      9071

F-1 Score:
0.307537012113
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 164ms/step - loss: 0.3310 - acc: 0.0747 - val_loss: 0.1506 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2015 - acc: 0.7829 - val_loss: 0.1341 - val_acc: 0.9333
Epoch 3/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1997 - acc: 0.7829 - val_loss: 0.2161 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2379 - acc: 0.7580 - val_loss: 0.1352 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1822 - acc: 0.7829 - val_loss: 0.1367 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7089
False 1982
True percentage 0.781501488259
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.83      0.97      0.90      7318
      B-PER       0.00      0.00      0.00       438
      B-LOC       0.00      0.00      0.00       218
      B-ORG       0.00      0.00      0.00       296
      I-ORG       0.00      0.00      0.00       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.67      0.78      0.72      9071

F-1 Score:
0.0
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 163ms/step - loss: 0.3371 - acc: 0.0211 - val_loss: 0.1568 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1953 - acc: 0.8047 - val_loss: 0.1951 - val_acc: 0.9000
Epoch 3/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2488 - acc: 0.8074 - val_loss: 0.2244 - val_acc: 0.8667
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2402 - acc: 0.7678 - val_loss: 0.1490 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1771 - acc: 0.8074 - val_loss: 0.1470 - val_acc: 0.9000
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1704 - acc: 0.8074 - val_loss: 0.1457 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1650 - acc: 0.8074 - val_loss: 0.1450 - val_acc: 0.9000
Epoch 8/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1649 - acc: 0.8074 - val_loss: 0.1439 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1610 - acc: 0.8179 - val_loss: 0.1437 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1578 - acc: 0.8127 - val_loss: 0.1421 - val_acc: 0.9000
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1545 - acc: 0.8206 - val_loss: 0.1409 - val_acc: 0.9000
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1514 - acc: 0.8417 - val_loss: 0.1395 - val_acc: 0.9000
Epoch 13/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1481 - acc: 0.8390 - val_loss: 0.1385 - val_acc: 0.9000
Epoch 14/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1449 - acc: 0.8549 - val_loss: 0.1382 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1457 - acc: 0.8575 - val_loss: 0.1379 - val_acc: 0.9000
Epoch 16/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1409 - acc: 0.8654 - val_loss: 0.1359 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1391 - acc: 0.8813 - val_loss: 0.1351 - val_acc: 0.9333
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1359 - acc: 0.8918 - val_loss: 0.1346 - val_acc: 0.9333
Epoch 19/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1358 - acc: 0.8945 - val_loss: 0.1334 - val_acc: 0.9333
Epoch 20/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1342 - acc: 0.9050 - val_loss: 0.1320 - val_acc: 0.9333
Epoch 21/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1318 - acc: 0.9050 - val_loss: 0.1327 - val_acc: 0.9333
Epoch 22/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1318 - acc: 0.9077 - val_loss: 0.1305 - val_acc: 0.9500
Epoch 23/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1278 - acc: 0.9393 - val_loss: 0.1321 - val_acc: 0.9333
Epoch 24/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1290 - acc: 0.9077 - val_loss: 0.1302 - val_acc: 0.9500
Epoch 25/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1250 - acc: 0.9420 - val_loss: 0.1293 - val_acc: 0.9333
Epoch 26/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1230 - acc: 0.9235 - val_loss: 0.1283 - val_acc: 0.9500
Epoch 27/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1250 - acc: 0.9393 - val_loss: 0.1295 - val_acc: 0.9333
Epoch 28/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1212 - acc: 0.9420 - val_loss: 0.1265 - val_acc: 0.9500
Epoch 29/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1229 - acc: 0.9420 - val_loss: 0.1277 - val_acc: 0.9333
Epoch 30/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1203 - acc: 0.9314 - val_loss: 0.1272 - val_acc: 0.9333
Epoch 31/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1220 - acc: 0.9340 - val_loss: 0.1304 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7201
False 1870
True percentage 0.793848528277
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.94      0.94      7318
      B-ORG       0.25      0.45      0.32       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.21      0.55      0.30       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.53      0.14      0.22       438
      I-PER       0.62      0.14      0.23       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.80      0.79      0.79      9071

F-1 Score:
0.215341308937
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 160ms/step - loss: 0.3313 - acc: 0.0534 - val_loss: 0.1422 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2029 - acc: 0.7829 - val_loss: 0.1392 - val_acc: 0.9333
Epoch 3/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1850 - acc: 0.7829 - val_loss: 0.1296 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1876 - acc: 0.7829 - val_loss: 0.2409 - val_acc: 0.6333
Epoch 5/70

14/14 [==============================] - 0s 23ms/step - loss: 0.2572 - acc: 0.5480 - val_loss: 0.1292 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1778 - acc: 0.7865 - val_loss: 0.1236 - val_acc: 0.9333
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1706 - acc: 0.7829 - val_loss: 0.1283 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1642 - acc: 0.7972 - val_loss: 0.1201 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1581 - acc: 0.7972 - val_loss: 0.1258 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1562 - acc: 0.8399 - val_loss: 0.1165 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1603 - acc: 0.7900 - val_loss: 0.1353 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1612 - acc: 0.8648 - val_loss: 0.1161 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1492 - acc: 0.8221 - val_loss: 0.1165 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1424 - acc: 0.8754 - val_loss: 0.1170 - val_acc: 0.9667
Epoch 15/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1392 - acc: 0.9110 - val_loss: 0.1156 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1388 - acc: 0.8897 - val_loss: 0.1146 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1353 - acc: 0.9004 - val_loss: 0.1158 - val_acc: 0.9667
Epoch 18/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1318 - acc: 0.9181 - val_loss: 0.1157 - val_acc: 0.9667
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1308 - acc: 0.9324 - val_loss: 0.1135 - val_acc: 0.9333
Epoch 20/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1312 - acc: 0.9039 - val_loss: 0.1164 - val_acc: 0.9333
Epoch 21/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1327 - acc: 0.9181 - val_loss: 0.1146 - val_acc: 0.9333
Epoch 22/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1285 - acc: 0.9217 - val_loss: 0.1148 - val_acc: 0.9667
Manual evaluation: (didn't understand why I made this)
True 7284
False 1787
True percentage 0.802998566861
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.94      0.94      7318
      B-PER       0.66      0.31      0.42       438
      B-LOC       0.36      0.57      0.44       218
      B-ORG       0.24      0.28      0.26       296
      I-ORG       0.11      0.09      0.10       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.25      0.53      0.34       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.82      0.80      0.81      9071

F-1 Score:
0.281229561805
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 160ms/step - loss: 0.3287 - acc: 0.0633 - val_loss: 0.1668 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1955 - acc: 0.8074 - val_loss: 0.2334 - val_acc: 0.9000
Epoch 3/70

14/14 [==============================] - 0s 24ms/step - loss: 0.3220 - acc: 0.8074 - val_loss: 0.1881 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2057 - acc: 0.8285 - val_loss: 0.1470 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1694 - acc: 0.8074 - val_loss: 0.1462 - val_acc: 0.9000
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1633 - acc: 0.8074 - val_loss: 0.1440 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1601 - acc: 0.8259 - val_loss: 0.1416 - val_acc: 0.9000
Epoch 8/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1583 - acc: 0.8179 - val_loss: 0.1435 - val_acc: 0.9167
Epoch 9/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1532 - acc: 0.8654 - val_loss: 0.1384 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1501 - acc: 0.8390 - val_loss: 0.1390 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1465 - acc: 0.8760 - val_loss: 0.1340 - val_acc: 0.9167
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1452 - acc: 0.8575 - val_loss: 0.1336 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1377 - acc: 0.8892 - val_loss: 0.1312 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1389 - acc: 0.8839 - val_loss: 0.1307 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1346 - acc: 0.9024 - val_loss: 0.1296 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1331 - acc: 0.9050 - val_loss: 0.1287 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1315 - acc: 0.9103 - val_loss: 0.1279 - val_acc: 0.9500
Epoch 18/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1297 - acc: 0.9182 - val_loss: 0.1265 - val_acc: 0.9333
Epoch 19/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1285 - acc: 0.9182 - val_loss: 0.1250 - val_acc: 0.9500
Epoch 20/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1251 - acc: 0.9367 - val_loss: 0.1244 - val_acc: 0.9333
Epoch 21/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1264 - acc: 0.9156 - val_loss: 0.1230 - val_acc: 0.9500
Epoch 22/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1233 - acc: 0.9367 - val_loss: 0.1234 - val_acc: 0.9500
Epoch 23/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1201 - acc: 0.9446 - val_loss: 0.1229 - val_acc: 0.9333
Epoch 24/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1204 - acc: 0.9340 - val_loss: 0.1214 - val_acc: 0.9500
Epoch 25/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1215 - acc: 0.9499 - val_loss: 0.1212 - val_acc: 0.9500
Epoch 26/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1196 - acc: 0.9446 - val_loss: 0.1207 - val_acc: 0.9500
Epoch 27/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1178 - acc: 0.9499 - val_loss: 0.1198 - val_acc: 0.9500
Epoch 28/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1146 - acc: 0.9657 - val_loss: 0.1197 - val_acc: 0.9500
Epoch 29/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1155 - acc: 0.9551 - val_loss: 0.1196 - val_acc: 0.9333
Epoch 30/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1160 - acc: 0.9472 - val_loss: 0.1171 - val_acc: 0.9667
Epoch 31/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1151 - acc: 0.9683 - val_loss: 0.1200 - val_acc: 0.9333
Epoch 32/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1156 - acc: 0.9604 - val_loss: 0.1193 - val_acc: 0.9500
Epoch 33/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1132 - acc: 0.9657 - val_loss: 0.1185 - val_acc: 0.9500
Manual evaluation: (didn't understand why I made this)
True 7243
False 1828
True percentage 0.798478668284
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.89      0.96      0.92      7318
      B-ORG       0.39      0.34      0.36       296
      B-LOC       0.73      0.05      0.09       218
      I-ORG       0.25      0.27      0.26       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.51      0.16      0.24       438
      I-PER       0.50      0.09      0.15       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.79      0.80      0.78      9071

F-1 Score:
0.20328975116
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 158ms/step - loss: 0.3362 - acc: 0.0534 - val_loss: 0.1669 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2101 - acc: 0.7829 - val_loss: 0.1599 - val_acc: 0.9333
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2744 - acc: 0.7829 - val_loss: 0.1954 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2263 - acc: 0.7936 - val_loss: 0.1367 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1766 - acc: 0.7829 - val_loss: 0.1314 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1751 - acc: 0.7829 - val_loss: 0.1295 - val_acc: 0.9333
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1676 - acc: 0.7865 - val_loss: 0.1278 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1661 - acc: 0.7936 - val_loss: 0.1268 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1595 - acc: 0.8043 - val_loss: 0.1235 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1553 - acc: 0.7972 - val_loss: 0.1214 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1503 - acc: 0.8327 - val_loss: 0.1203 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1479 - acc: 0.8292 - val_loss: 0.1164 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1434 - acc: 0.8434 - val_loss: 0.1165 - val_acc: 0.9667
Epoch 14/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1405 - acc: 0.8790 - val_loss: 0.1163 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1412 - acc: 0.8577 - val_loss: 0.1183 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1410 - acc: 0.9039 - val_loss: 0.1178 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1441 - acc: 0.8505 - val_loss: 0.1203 - val_acc: 0.9667
Manual evaluation: (didn't understand why I made this)
True 7125
False 1946
True percentage 0.785470179694
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.93      0.94      7318
      B-PER       0.71      0.11      0.19       438
      B-LOC       0.23      0.75      0.35       218
      B-ORG       0.24      0.27      0.25       296
      I-ORG       0.12      0.11      0.12       151
      I-PER       1.00      0.01      0.03       214
      I-LOC       0.13      0.10      0.11       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.79      0.79      9071

F-1 Score:
0.208974358974
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 159ms/step - loss: 0.3209 - acc: 0.1346 - val_loss: 0.1536 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1885 - acc: 0.8074 - val_loss: 0.1990 - val_acc: 0.9000
Epoch 3/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2475 - acc: 0.8074 - val_loss: 0.2179 - val_acc: 0.8167
Epoch 4/70

14/14 [==============================] - 0s 23ms/step - loss: 0.2310 - acc: 0.7757 - val_loss: 0.1504 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1715 - acc: 0.8153 - val_loss: 0.1432 - val_acc: 0.9000
Epoch 6/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1640 - acc: 0.8074 - val_loss: 0.1425 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1569 - acc: 0.8179 - val_loss: 0.1401 - val_acc: 0.9000
Epoch 8/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1538 - acc: 0.8338 - val_loss: 0.1398 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1509 - acc: 0.8602 - val_loss: 0.1368 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1452 - acc: 0.8628 - val_loss: 0.1352 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1420 - acc: 0.8892 - val_loss: 0.1333 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1400 - acc: 0.8971 - val_loss: 0.1322 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1400 - acc: 0.8839 - val_loss: 0.1315 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1383 - acc: 0.8945 - val_loss: 0.1335 - val_acc: 0.9500
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1349 - acc: 0.9050 - val_loss: 0.1294 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1302 - acc: 0.9077 - val_loss: 0.1287 - val_acc: 0.9500
Epoch 17/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1317 - acc: 0.9182 - val_loss: 0.1285 - val_acc: 0.9500
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1282 - acc: 0.9182 - val_loss: 0.1268 - val_acc: 0.9500
Epoch 19/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1264 - acc: 0.9103 - val_loss: 0.1269 - val_acc: 0.9500
Epoch 20/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1238 - acc: 0.9367 - val_loss: 0.1250 - val_acc: 0.9500
Epoch 21/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1218 - acc: 0.9499 - val_loss: 0.1257 - val_acc: 0.9500
Epoch 22/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1223 - acc: 0.9288 - val_loss: 0.1234 - val_acc: 0.9500
Epoch 23/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1202 - acc: 0.9446 - val_loss: 0.1248 - val_acc: 0.9500
Epoch 24/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1193 - acc: 0.9340 - val_loss: 0.1223 - val_acc: 0.9500
Epoch 25/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1196 - acc: 0.9499 - val_loss: 0.1228 - val_acc: 0.9500
Epoch 26/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1183 - acc: 0.9367 - val_loss: 0.1207 - val_acc: 0.9667
Epoch 27/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1156 - acc: 0.9578 - val_loss: 0.1211 - val_acc: 0.9500
Epoch 28/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1154 - acc: 0.9631 - val_loss: 0.1200 - val_acc: 0.9500
Epoch 29/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1146 - acc: 0.9578 - val_loss: 0.1191 - val_acc: 0.9667
Epoch 30/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1149 - acc: 0.9710 - val_loss: 0.1213 - val_acc: 0.9500
Epoch 31/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1124 - acc: 0.9763 - val_loss: 0.1208 - val_acc: 0.9500
Epoch 32/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1137 - acc: 0.9578 - val_loss: 0.1202 - val_acc: 0.9500
Manual evaluation: (didn't understand why I made this)
True 7232
False 1839
True percentage 0.797266012568
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.91      0.95      0.93      7318
      B-ORG       0.25      0.08      0.12       296
      B-LOC       0.76      0.17      0.28       218
      I-ORG       0.22      0.24      0.23       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.04      0.01      0.01       154
      B-PER       0.29      0.29      0.29       438
      I-PER       0.40      0.10      0.16       214
      I-LOC       0.90      0.06      0.12       141

avg / total       0.80      0.80      0.79      9071

F-1 Score:
0.196607555898
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 157ms/step - loss: 0.3370 - acc: 0.0498 - val_loss: 0.1389 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2000 - acc: 0.7829 - val_loss: 0.2068 - val_acc: 0.9333
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2286 - acc: 0.7651 - val_loss: 0.1260 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1781 - acc: 0.7865 - val_loss: 0.1392 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1686 - acc: 0.8221 - val_loss: 0.1203 - val_acc: 0.9667
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1523 - acc: 0.8399 - val_loss: 0.1203 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1463 - acc: 0.8470 - val_loss: 0.1199 - val_acc: 0.9000
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1451 - acc: 0.8434 - val_loss: 0.1208 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1417 - acc: 0.8719 - val_loss: 0.1196 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1402 - acc: 0.8790 - val_loss: 0.1201 - val_acc: 0.9000
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1388 - acc: 0.8790 - val_loss: 0.1171 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1347 - acc: 0.8790 - val_loss: 0.1199 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1366 - acc: 0.8790 - val_loss: 0.1167 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1336 - acc: 0.9075 - val_loss: 0.1198 - val_acc: 0.9000
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1304 - acc: 0.9039 - val_loss: 0.1148 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1308 - acc: 0.9039 - val_loss: 0.1161 - val_acc: 0.9667
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1291 - acc: 0.9075 - val_loss: 0.1156 - val_acc: 0.9333
Epoch 18/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1250 - acc: 0.9288 - val_loss: 0.1155 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7171
False 1900
True percentage 0.790541285415
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.92      0.94      7318
      B-PER       0.34      0.47      0.40       438
      B-LOC       0.40      0.52      0.45       218
      B-ORG       0.21      0.12      0.15       296
      I-ORG       0.10      0.10      0.10       151
      I-PER       1.00      0.00      0.01       214
      I-LOC       0.17      0.37      0.24       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.79      0.80      9071

F-1 Score:
0.258988421694
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 158ms/step - loss: 0.3324 - acc: 0.0580 - val_loss: 0.1616 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1957 - acc: 0.8074 - val_loss: 0.2541 - val_acc: 0.6333
Epoch 3/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2580 - acc: 0.5778 - val_loss: 0.1497 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1688 - acc: 0.8074 - val_loss: 0.1472 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1677 - acc: 0.8074 - val_loss: 0.1557 - val_acc: 0.9000
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1671 - acc: 0.8522 - val_loss: 0.1370 - val_acc: 0.9167
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1474 - acc: 0.8443 - val_loss: 0.1370 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1423 - acc: 0.8654 - val_loss: 0.1338 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1418 - acc: 0.8654 - val_loss: 0.1330 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1385 - acc: 0.8707 - val_loss: 0.1335 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1353 - acc: 0.8839 - val_loss: 0.1364 - val_acc: 0.8833
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1354 - acc: 0.8839 - val_loss: 0.1307 - val_acc: 0.9167
Epoch 13/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1331 - acc: 0.8971 - val_loss: 0.1337 - val_acc: 0.8833
Epoch 14/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1298 - acc: 0.9103 - val_loss: 0.1286 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1265 - acc: 0.9077 - val_loss: 0.1344 - val_acc: 0.8833
Epoch 16/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1263 - acc: 0.9261 - val_loss: 0.1286 - val_acc: 0.9167
Epoch 17/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1235 - acc: 0.9420 - val_loss: 0.1303 - val_acc: 0.9167
Manual evaluation: (didn't understand why I made this)
True 7183
False 1888
True percentage 0.79186418256
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.95      0.94      7318
      B-ORG       0.25      0.39      0.31       296
      B-LOC       0.50      0.00      0.01       218
      I-ORG       0.15      0.54      0.23       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.63      0.14      0.23       438
      I-PER       0.57      0.04      0.07       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.82      0.79      0.79      9071

F-1 Score:
0.184850590688
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 158ms/step - loss: 0.3609 - acc: 0.0783 - val_loss: 0.1203 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1948 - acc: 0.7900 - val_loss: 0.1343 - val_acc: 0.9000
Epoch 3/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1680 - acc: 0.8221 - val_loss: 0.1191 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1501 - acc: 0.8292 - val_loss: 0.1199 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1425 - acc: 0.8790 - val_loss: 0.1175 - val_acc: 0.9000
Epoch 6/70

14/14 [==============================] - 0s 23ms/step - loss: 0.1349 - acc: 0.9075 - val_loss: 0.1199 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1345 - acc: 0.9004 - val_loss: 0.1164 - val_acc: 0.9000
Epoch 8/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1297 - acc: 0.9253 - val_loss: 0.1183 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1292 - acc: 0.9324 - val_loss: 0.1156 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1219 - acc: 0.9644 - val_loss: 0.1150 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1199 - acc: 0.9573 - val_loss: 0.1148 - val_acc: 0.9000
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1193 - acc: 0.9609 - val_loss: 0.1143 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1169 - acc: 0.9751 - val_loss: 0.1166 - val_acc: 0.9000
Epoch 14/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1184 - acc: 0.9466 - val_loss: 0.1164 - val_acc: 0.9000
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1162 - acc: 0.9644 - val_loss: 0.1157 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7148
False 1923
True percentage 0.788005732554
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.92      0.94      7318
      B-PER       0.38      0.40      0.39       438
      B-LOC       0.35      0.66      0.46       218
      B-ORG       0.28      0.15      0.19       296
      I-ORG       0.13      0.30      0.18       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.16      0.23      0.19       141
     B-MISC       0.10      0.03      0.04       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.83      0.79      0.80      9071

F-1 Score:
0.262178919398
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 159ms/step - loss: 0.3253 - acc: 0.1583 - val_loss: 0.1589 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2153 - acc: 0.8074 - val_loss: 0.1801 - val_acc: 0.7833
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2115 - acc: 0.6755 - val_loss: 0.1414 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1751 - acc: 0.8074 - val_loss: 0.1366 - val_acc: 0.9167
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1478 - acc: 0.8602 - val_loss: 0.1357 - val_acc: 0.9167
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1415 - acc: 0.8786 - val_loss: 0.1339 - val_acc: 0.9333
Epoch 7/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1385 - acc: 0.8892 - val_loss: 0.1333 - val_acc: 0.9167
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1363 - acc: 0.8971 - val_loss: 0.1309 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1349 - acc: 0.8918 - val_loss: 0.1303 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1315 - acc: 0.9129 - val_loss: 0.1294 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1296 - acc: 0.9235 - val_loss: 0.1270 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1286 - acc: 0.9103 - val_loss: 0.1271 - val_acc: 0.9167
Epoch 13/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1239 - acc: 0.9446 - val_loss: 0.1257 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1228 - acc: 0.9340 - val_loss: 0.1258 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1204 - acc: 0.9525 - val_loss: 0.1241 - val_acc: 0.9167
Epoch 16/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1193 - acc: 0.9499 - val_loss: 0.1219 - val_acc: 0.9500
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1200 - acc: 0.9420 - val_loss: 0.1225 - val_acc: 0.9333
Epoch 18/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1154 - acc: 0.9736 - val_loss: 0.1219 - val_acc: 0.9167
Epoch 19/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1185 - acc: 0.9472 - val_loss: 0.1209 - val_acc: 0.9333
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1150 - acc: 0.9710 - val_loss: 0.1202 - val_acc: 0.9500
Epoch 21/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1173 - acc: 0.9525 - val_loss: 0.1195 - val_acc: 0.9500
Epoch 22/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1134 - acc: 0.9683 - val_loss: 0.1193 - val_acc: 0.9500
Epoch 23/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1123 - acc: 0.9815 - val_loss: 0.1191 - val_acc: 0.9500
Epoch 24/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1132 - acc: 0.9710 - val_loss: 0.1183 - val_acc: 0.9500
Epoch 25/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1155 - acc: 0.9472 - val_loss: 0.1203 - val_acc: 0.9167
Epoch 26/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1127 - acc: 0.9789 - val_loss: 0.1181 - val_acc: 0.9500
Epoch 27/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1105 - acc: 0.9868 - val_loss: 0.1180 - val_acc: 0.9333
Epoch 28/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1096 - acc: 0.9921 - val_loss: 0.1170 - val_acc: 0.9333
Epoch 29/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1093 - acc: 0.9789 - val_loss: 0.1170 - val_acc: 0.9333
Epoch 30/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1096 - acc: 0.9842 - val_loss: 0.1171 - val_acc: 0.9500
Epoch 31/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1082 - acc: 0.9868 - val_loss: 0.1161 - val_acc: 0.9500
Epoch 32/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1090 - acc: 0.9894 - val_loss: 0.1165 - val_acc: 0.9500
Epoch 33/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1066 - acc: 0.9921 - val_loss: 0.1158 - val_acc: 0.9500
Epoch 34/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1085 - acc: 0.9842 - val_loss: 0.1155 - val_acc: 0.9500
Epoch 35/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1075 - acc: 0.9921 - val_loss: 0.1157 - val_acc: 0.9500
Epoch 36/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1052 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9333
Epoch 37/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1067 - acc: 0.9894 - val_loss: 0.1167 - val_acc: 0.9500
Manual evaluation: (didn't understand why I made this)
True 7231
False 1840
True percentage 0.797155771139
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.94      0.95      7318
      B-ORG       0.22      0.26      0.24       296
      B-LOC       0.87      0.12      0.22       218
      I-ORG       0.15      0.57      0.24       151
     B-MISC       0.06      0.04      0.04       141
     I-MISC       0.33      0.01      0.01       154
      B-PER       0.63      0.28      0.38       438
      I-PER       0.92      0.15      0.26       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.86      0.80      0.81      9071

F-1 Score:
0.23275862069
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 308ms/step - loss: 0.3507 - acc: 0.0794 - val_loss: 0.2101 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2317 - acc: 0.7698 - val_loss: 0.2686 - val_acc: 0.8276
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2561 - acc: 0.7698 - val_loss: 0.2286 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2359 - acc: 0.7937 - val_loss: 0.1931 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1945 - acc: 0.7698 - val_loss: 0.1925 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1922 - acc: 0.7698 - val_loss: 0.1884 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1856 - acc: 0.7937 - val_loss: 0.1935 - val_acc: 0.8276
Epoch 8/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1814 - acc: 0.7698 - val_loss: 0.1864 - val_acc: 0.8276
Epoch 9/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1806 - acc: 0.8413 - val_loss: 0.1965 - val_acc: 0.8276
Epoch 10/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1728 - acc: 0.7698 - val_loss: 0.1876 - val_acc: 0.8276
Epoch 11/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1692 - acc: 0.8095 - val_loss: 0.1856 - val_acc: 0.8276
Epoch 12/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1631 - acc: 0.8651 - val_loss: 0.1990 - val_acc: 0.8276
Epoch 13/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1618 - acc: 0.8413 - val_loss: 0.1862 - val_acc: 0.8276
Epoch 14/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1608 - acc: 0.8730 - val_loss: 0.1865 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7162
False 1755
True percentage 0.803184927666
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.85      0.97      0.90      7318
      B-PER       0.53      0.14      0.22       438
      B-LOC       0.46      0.08      0.13       218
      B-ORG       1.00      0.00      0.01       296
      I-ORG       0.33      0.01      0.01       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.77      0.80      0.76      8917

F-1 Score:
0.0911680911681
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 312ms/step - loss: 0.3117 - acc: 0.3086 - val_loss: 0.1719 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 31ms/step - loss: 0.1970 - acc: 0.7963 - val_loss: 0.1796 - val_acc: 0.8421
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1735 - acc: 0.8025 - val_loss: 0.2297 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2054 - acc: 0.7963 - val_loss: 0.2585 - val_acc: 0.5263
Manual evaluation: (didn't understand why I made this)
True 5189
False 3882
True percentage 0.572042773674
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.67      0.79      7318
      B-ORG       0.07      0.61      0.13       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.10      0.53      0.16       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.00      0.00      0.00       438
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.78      0.57      0.65      9071

F-1 Score:
0.100872938894
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 309ms/step - loss: 0.3801 - acc: 0.0714 - val_loss: 0.2018 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2196 - acc: 0.7698 - val_loss: 0.2472 - val_acc: 0.8276
Epoch 3/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2573 - acc: 0.7698 - val_loss: 0.2999 - val_acc: 0.3448
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2803 - acc: 0.5714 - val_loss: 0.1953 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1979 - acc: 0.7698 - val_loss: 0.1907 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1883 - acc: 0.7698 - val_loss: 0.1889 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1872 - acc: 0.8095 - val_loss: 0.1890 - val_acc: 0.8276
Epoch 8/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1839 - acc: 0.7698 - val_loss: 0.1877 - val_acc: 0.8276
Epoch 9/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1819 - acc: 0.8016 - val_loss: 0.1911 - val_acc: 0.8276
Epoch 10/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1768 - acc: 0.7937 - val_loss: 0.1827 - val_acc: 0.8276
Epoch 11/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1700 - acc: 0.8016 - val_loss: 0.1818 - val_acc: 0.8276
Epoch 12/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1642 - acc: 0.8413 - val_loss: 0.1821 - val_acc: 0.8276
Epoch 13/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1630 - acc: 0.8333 - val_loss: 0.1757 - val_acc: 0.8276
Epoch 14/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1521 - acc: 0.8730 - val_loss: 0.1761 - val_acc: 0.8276
Epoch 15/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1529 - acc: 0.8810 - val_loss: 0.1842 - val_acc: 0.8276
Epoch 16/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1512 - acc: 0.8889 - val_loss: 0.1802 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7162
False 1755
True percentage 0.803184927666
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.86      0.96      0.91      7318
      B-PER       0.32      0.18      0.23       438
      B-LOC       0.40      0.10      0.16       218
      B-ORG       0.32      0.03      0.06       296
      I-ORG       1.00      0.01      0.01       151
      I-PER       1.00      0.00      0.01       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.79      0.80      0.77      8917

F-1 Score:
0.114610221993
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 295ms/step - loss: 0.3163 - acc: 0.2284 - val_loss: 0.1756 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1933 - acc: 0.7963 - val_loss: 0.2210 - val_acc: 0.8421
Epoch 3/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1862 - acc: 0.7963 - val_loss: 0.2497 - val_acc: 0.6053
Epoch 4/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2235 - acc: 0.6296 - val_loss: 0.1780 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7084
False 1987
True percentage 0.780950281116
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.83      0.97      0.90      7318
      B-ORG       0.00      0.00      0.00       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.10      0.01      0.01       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.00      0.00      0.00       438
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.67      0.78      0.72      9071

F-1 Score:
0.00155279503106
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 299ms/step - loss: 0.3435 - acc: 0.1825 - val_loss: 0.2083 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2280 - acc: 0.7698 - val_loss: 0.2218 - val_acc: 0.8276
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2243 - acc: 0.7460 - val_loss: 0.2706 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2570 - acc: 0.7698 - val_loss: 0.2120 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7095
False 1822
True percentage 0.795671189862
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.85      0.96      0.90      7318
      B-PER       0.59      0.08      0.14       438
      B-LOC       0.00      0.00      0.00       218
      B-ORG       0.00      0.00      0.00       296
      I-ORG       0.09      0.09      0.09       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.73      0.80      0.75      8917

F-1 Score:
0.0526315789474
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 300ms/step - loss: 0.3421 - acc: 0.0185 - val_loss: 0.1816 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1914 - acc: 0.7963 - val_loss: 0.2723 - val_acc: 0.8421
Epoch 3/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2459 - acc: 0.7963 - val_loss: 0.2485 - val_acc: 0.6579
Epoch 4/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2410 - acc: 0.5864 - val_loss: 0.1715 - val_acc: 0.8421
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1692 - acc: 0.7963 - val_loss: 0.1737 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1623 - acc: 0.8395 - val_loss: 0.1763 - val_acc: 0.8421
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1525 - acc: 0.8457 - val_loss: 0.1816 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7073
False 1998
True percentage 0.7797376254
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.84      0.97      0.90      7318
      B-ORG       0.00      0.00      0.00       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.05      0.03      0.04       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.00      0.00      0.00       438
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.68      0.78      0.73      9071

F-1 Score:
0.00539665407447
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 298ms/step - loss: 0.3925 - acc: 0.0397 - val_loss: 0.2204 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2345 - acc: 0.7698 - val_loss: 0.1893 - val_acc: 0.8276
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1893 - acc: 0.7619 - val_loss: 0.1868 - val_acc: 0.7931
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1805 - acc: 0.7540 - val_loss: 0.1715 - val_acc: 0.7931
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1830 - acc: 0.7857 - val_loss: 0.2831 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2232 - acc: 0.7698 - val_loss: 0.2030 - val_acc: 0.7931
Epoch 7/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2001 - acc: 0.8095 - val_loss: 0.1740 - val_acc: 0.7931
Manual evaluation: (didn't understand why I made this)
True 7054
False 1863
True percentage 0.791073230907
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.92      0.93      7318
      B-PER       0.39      0.18      0.25       438
      B-LOC       0.24      0.55      0.33       218
      B-ORG       0.20      0.26      0.23       296
      I-ORG       0.12      0.20      0.15       151
      I-PER       0.75      0.01      0.03       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.79      0.80      8917

F-1 Score:
0.209427609428
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 301ms/step - loss: 0.3380 - acc: 0.0617 - val_loss: 0.1973 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1879 - acc: 0.7963 - val_loss: 0.2555 - val_acc: 0.5263
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2214 - acc: 0.6420 - val_loss: 0.1785 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1727 - acc: 0.7963 - val_loss: 0.1844 - val_acc: 0.7895
Epoch 5/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1605 - acc: 0.8642 - val_loss: 0.1752 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1488 - acc: 0.8457 - val_loss: 0.1761 - val_acc: 0.8158
Epoch 7/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1381 - acc: 0.8889 - val_loss: 0.1761 - val_acc: 0.8158
Epoch 8/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1394 - acc: 0.8827 - val_loss: 0.1768 - val_acc: 0.8158
Manual evaluation: (didn't understand why I made this)
True 7126
False 1945
True percentage 0.785580421122
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.89      0.95      0.92      7318
      B-ORG       0.25      0.28      0.26       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.12      0.19      0.15       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.41      0.06      0.10       438
      I-PER       0.28      0.02      0.04       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.75      0.79      0.76      9071

F-1 Score:
0.117598343685
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 299ms/step - loss: 0.3537 - acc: 0.0556 - val_loss: 0.2319 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2336 - acc: 0.7698 - val_loss: 0.1929 - val_acc: 0.7931
Epoch 3/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2013 - acc: 0.8175 - val_loss: 0.1815 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1701 - acc: 0.7857 - val_loss: 0.1689 - val_acc: 0.8621
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1563 - acc: 0.9127 - val_loss: 0.1712 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1446 - acc: 0.9206 - val_loss: 0.1761 - val_acc: 0.8621
Epoch 7/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1409 - acc: 0.9524 - val_loss: 0.1745 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7219
False 1698
True percentage 0.809577212067
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.93      0.93      7318
      B-PER       0.43      0.37      0.40       438
      B-LOC       0.34      0.57      0.43       218
      B-ORG       0.26      0.13      0.17       296
      I-ORG       0.18      0.35      0.24       151
      I-PER       0.73      0.04      0.07       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.81      0.81      8917

F-1 Score:
0.274481772695
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 302ms/step - loss: 0.3469 - acc: 0.0864 - val_loss: 0.2020 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1902 - acc: 0.7963 - val_loss: 0.2294 - val_acc: 0.6842
Epoch 3/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1843 - acc: 0.7284 - val_loss: 0.1841 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1579 - acc: 0.7963 - val_loss: 0.1827 - val_acc: 0.7895
Epoch 5/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1378 - acc: 0.9074 - val_loss: 0.1805 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1337 - acc: 0.8889 - val_loss: 0.1837 - val_acc: 0.8158
Epoch 7/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1273 - acc: 0.9383 - val_loss: 0.1845 - val_acc: 0.8158
Epoch 8/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1233 - acc: 0.9383 - val_loss: 0.1861 - val_acc: 0.8158
Manual evaluation: (didn't understand why I made this)
True 7171
False 1900
True percentage 0.790541285415
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.92      0.95      0.93      7318
      B-ORG       0.30      0.30      0.30       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.16      0.49      0.24       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.57      0.09      0.15       438
      I-PER       0.19      0.07      0.10       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.78      0.79      0.78      9071

F-1 Score:
0.162528216704
