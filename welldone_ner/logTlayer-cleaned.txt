Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 32ms/step - loss: 0.1462 - acc: 0.8590 - val_loss: 0.1291 - val_acc: 0.9022
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1283 - acc: 0.9087 - val_loss: 0.1222 - val_acc: 0.9342
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1237 - acc: 0.9246 - val_loss: 0.1201 - val_acc: 0.9380
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1211 - acc: 0.9328 - val_loss: 0.1183 - val_acc: 0.9449
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1193 - acc: 0.9381 - val_loss: 0.1186 - val_acc: 0.9407
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1180 - acc: 0.9429 - val_loss: 0.1188 - val_acc: 0.9417
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1169 - acc: 0.9466 - val_loss: 0.1161 - val_acc: 0.9492
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1157 - acc: 0.9509 - val_loss: 0.1175 - val_acc: 0.9448
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1150 - acc: 0.9517 - val_loss: 0.1159 - val_acc: 0.9478
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1142 - acc: 0.9563 - val_loss: 0.1156 - val_acc: 0.9488
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1137 - acc: 0.9571 - val_loss: 0.1151 - val_acc: 0.9532
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1130 - acc: 0.9596 - val_loss: 0.1150 - val_acc: 0.9521
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1126 - acc: 0.9607 - val_loss: 0.1150 - val_acc: 0.9505
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9613 - val_loss: 0.1145 - val_acc: 0.9548
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1117 - acc: 0.9638 - val_loss: 0.1144 - val_acc: 0.9556
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1109 - acc: 0.9662 - val_loss: 0.1143 - val_acc: 0.9545
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1105 - acc: 0.9669 - val_loss: 0.1142 - val_acc: 0.9554
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1104 - acc: 0.9679 - val_loss: 0.1140 - val_acc: 0.9560
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9695 - val_loss: 0.1141 - val_acc: 0.9559
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9684 - val_loss: 0.1138 - val_acc: 0.9564
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1099 - acc: 0.9695 - val_loss: 0.1139 - val_acc: 0.9581
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1094 - acc: 0.9710 - val_loss: 0.1139 - val_acc: 0.9570
Epoch 23/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1095 - acc: 0.9714 - val_loss: 0.1146 - val_acc: 0.9557
Manual evaluation: (didn't understand why I made this)
True 8261
False 810
True percentage 0.91070444273
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.93      0.85      0.88       438
      B-LOC       0.74      0.78      0.76       218
      B-ORG       0.74      0.76      0.75       296
      I-ORG       0.50      0.71      0.59       151
      I-PER       0.93      0.66      0.78       214
      I-LOC       0.69      0.80      0.74       141
     B-MISC       0.60      0.31      0.41       141
     I-MISC       0.57      0.23      0.33       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.720715350224
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1481 - acc: 0.8469 - val_loss: 0.1292 - val_acc: 0.9030
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1287 - acc: 0.9086 - val_loss: 0.1209 - val_acc: 0.9373
Epoch 3/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1244 - acc: 0.9203 - val_loss: 0.1192 - val_acc: 0.9391
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1212 - acc: 0.9327 - val_loss: 0.1171 - val_acc: 0.9491
Epoch 5/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1201 - acc: 0.9360 - val_loss: 0.1165 - val_acc: 0.9491
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1186 - acc: 0.9422 - val_loss: 0.1150 - val_acc: 0.9568
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1174 - acc: 0.9466 - val_loss: 0.1147 - val_acc: 0.9582
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1163 - acc: 0.9498 - val_loss: 0.1144 - val_acc: 0.9582
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1153 - acc: 0.9522 - val_loss: 0.1151 - val_acc: 0.9542
Epoch 10/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1148 - acc: 0.9529 - val_loss: 0.1137 - val_acc: 0.9591
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1139 - acc: 0.9567 - val_loss: 0.1146 - val_acc: 0.9576
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1130 - acc: 0.9593 - val_loss: 0.1135 - val_acc: 0.9590
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1134 - acc: 0.9576 - val_loss: 0.1133 - val_acc: 0.9605
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1124 - acc: 0.9615 - val_loss: 0.1133 - val_acc: 0.9599
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9614 - val_loss: 0.1128 - val_acc: 0.9604
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1116 - acc: 0.9633 - val_loss: 0.1128 - val_acc: 0.9594
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9640 - val_loss: 0.1132 - val_acc: 0.9590
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1105 - acc: 0.9680 - val_loss: 0.1128 - val_acc: 0.9599
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1102 - acc: 0.9690 - val_loss: 0.1128 - val_acc: 0.9602
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9689 - val_loss: 0.1126 - val_acc: 0.9596
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9694 - val_loss: 0.1130 - val_acc: 0.9593
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1101 - acc: 0.9688 - val_loss: 0.1127 - val_acc: 0.9601
Epoch 23/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1096 - acc: 0.9690 - val_loss: 0.1127 - val_acc: 0.9584
Manual evaluation: (didn't understand why I made this)
True 8271
False 800
True percentage 0.911806857017
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.98      7318
      B-ORG       0.75      0.74      0.74       296
      B-LOC       0.76      0.74      0.75       218
      I-ORG       0.65      0.55      0.60       151
     B-MISC       0.50      0.43      0.46       141
     I-MISC       0.46      0.49      0.48       154
      B-PER       0.93      0.84      0.88       438
      I-PER       0.93      0.66      0.77       214
      I-LOC       0.75      0.77      0.76       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.724465558195
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1525 - acc: 0.8357 - val_loss: 0.1318 - val_acc: 0.8966
Epoch 2/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1301 - acc: 0.9030 - val_loss: 0.1307 - val_acc: 0.9063
Epoch 3/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1257 - acc: 0.9185 - val_loss: 0.1228 - val_acc: 0.9255
Epoch 4/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1228 - acc: 0.9289 - val_loss: 0.1207 - val_acc: 0.9331
Epoch 5/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1207 - acc: 0.9353 - val_loss: 0.1236 - val_acc: 0.9263
Epoch 6/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1190 - acc: 0.9395 - val_loss: 0.1183 - val_acc: 0.9441
Epoch 7/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1179 - acc: 0.9445 - val_loss: 0.1183 - val_acc: 0.9440
Epoch 8/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1168 - acc: 0.9485 - val_loss: 0.1174 - val_acc: 0.9446
Epoch 9/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1161 - acc: 0.9501 - val_loss: 0.1165 - val_acc: 0.9478
Epoch 10/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1148 - acc: 0.9539 - val_loss: 0.1157 - val_acc: 0.9515
Epoch 11/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1145 - acc: 0.9548 - val_loss: 0.1183 - val_acc: 0.9406
Epoch 12/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1137 - acc: 0.9571 - val_loss: 0.1153 - val_acc: 0.9514
Epoch 13/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1130 - acc: 0.9597 - val_loss: 0.1155 - val_acc: 0.9514
Epoch 14/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1128 - acc: 0.9604 - val_loss: 0.1152 - val_acc: 0.9522
Epoch 15/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1124 - acc: 0.9617 - val_loss: 0.1165 - val_acc: 0.9524
Epoch 16/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1120 - acc: 0.9631 - val_loss: 0.1146 - val_acc: 0.9552
Epoch 17/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1117 - acc: 0.9640 - val_loss: 0.1149 - val_acc: 0.9545
Epoch 18/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1114 - acc: 0.9652 - val_loss: 0.1149 - val_acc: 0.9551
Epoch 19/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1110 - acc: 0.9659 - val_loss: 0.1146 - val_acc: 0.9557
Manual evaluation: (didn't understand why I made this)
True 8247
False 824
True percentage 0.909161062727
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.91      0.84      0.88       438
      B-LOC       0.72      0.78      0.74       218
      B-ORG       0.71      0.76      0.73       296
      I-ORG       0.56      0.60      0.58       151
      I-PER       0.91      0.66      0.76       214
      I-LOC       0.64      0.79      0.70       141
     B-MISC       0.62      0.32      0.42       141
     I-MISC       0.59      0.34      0.43       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.714243235207
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 50s 33ms/step - loss: 0.1535 - acc: 0.8341 - val_loss: 0.1324 - val_acc: 0.8820
Epoch 2/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1303 - acc: 0.9025 - val_loss: 0.1260 - val_acc: 0.9107
Epoch 3/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1257 - acc: 0.9184 - val_loss: 0.1202 - val_acc: 0.9399
Epoch 4/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1231 - acc: 0.9278 - val_loss: 0.1182 - val_acc: 0.9451
Epoch 5/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1205 - acc: 0.9366 - val_loss: 0.1185 - val_acc: 0.9436
Epoch 6/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1189 - acc: 0.9416 - val_loss: 0.1173 - val_acc: 0.9455
Epoch 7/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1181 - acc: 0.9429 - val_loss: 0.1170 - val_acc: 0.9448
Epoch 8/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1169 - acc: 0.9462 - val_loss: 0.1148 - val_acc: 0.9539
Epoch 9/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1159 - acc: 0.9511 - val_loss: 0.1146 - val_acc: 0.9545
Epoch 10/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1149 - acc: 0.9539 - val_loss: 0.1144 - val_acc: 0.9544
Epoch 11/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1144 - acc: 0.9553 - val_loss: 0.1136 - val_acc: 0.9582
Epoch 12/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1139 - acc: 0.9562 - val_loss: 0.1141 - val_acc: 0.9559
Epoch 13/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1133 - acc: 0.9579 - val_loss: 0.1133 - val_acc: 0.9599
Epoch 14/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1130 - acc: 0.9592 - val_loss: 0.1134 - val_acc: 0.9584
Epoch 15/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1122 - acc: 0.9629 - val_loss: 0.1131 - val_acc: 0.9590
Epoch 16/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1120 - acc: 0.9621 - val_loss: 0.1128 - val_acc: 0.9613
Epoch 17/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1117 - acc: 0.9636 - val_loss: 0.1131 - val_acc: 0.9599
Epoch 18/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1112 - acc: 0.9662 - val_loss: 0.1128 - val_acc: 0.9616
Epoch 19/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1106 - acc: 0.9681 - val_loss: 0.1126 - val_acc: 0.9605
Epoch 20/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1106 - acc: 0.9667 - val_loss: 0.1126 - val_acc: 0.9616
Epoch 21/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1104 - acc: 0.9680 - val_loss: 0.1126 - val_acc: 0.9610
Epoch 22/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1100 - acc: 0.9694 - val_loss: 0.1126 - val_acc: 0.9624
Epoch 23/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1096 - acc: 0.9696 - val_loss: 0.1125 - val_acc: 0.9630
Epoch 24/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1095 - acc: 0.9702 - val_loss: 0.1128 - val_acc: 0.9624
Epoch 25/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1092 - acc: 0.9716 - val_loss: 0.1126 - val_acc: 0.9602
Epoch 26/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1089 - acc: 0.9725 - val_loss: 0.1128 - val_acc: 0.9604
Manual evaluation: (didn't understand why I made this)
True 8246
False 825
True percentage 0.909050821299
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.79      0.72      0.75       296
      B-LOC       0.73      0.78      0.76       218
      I-ORG       0.56      0.57      0.56       151
     B-MISC       0.50      0.41      0.45       141
     I-MISC       0.44      0.49      0.47       154
      B-PER       0.91      0.84      0.87       438
      I-PER       0.91      0.66      0.77       214
      I-LOC       0.72      0.77      0.74       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.71701439906
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 50s 33ms/step - loss: 0.1461 - acc: 0.8521 - val_loss: 0.1273 - val_acc: 0.9125
Epoch 2/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1284 - acc: 0.9098 - val_loss: 0.1217 - val_acc: 0.9317
Epoch 3/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1242 - acc: 0.9234 - val_loss: 0.1261 - val_acc: 0.9179
Epoch 4/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1217 - acc: 0.9296 - val_loss: 0.1192 - val_acc: 0.9377
Epoch 5/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1198 - acc: 0.9357 - val_loss: 0.1195 - val_acc: 0.9352
Epoch 6/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1181 - acc: 0.9428 - val_loss: 0.1182 - val_acc: 0.9376
Epoch 7/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1170 - acc: 0.9477 - val_loss: 0.1158 - val_acc: 0.9515
Epoch 8/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1164 - acc: 0.9490 - val_loss: 0.1169 - val_acc: 0.9452
Epoch 9/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1150 - acc: 0.9534 - val_loss: 0.1156 - val_acc: 0.9492
Epoch 10/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1146 - acc: 0.9542 - val_loss: 0.1150 - val_acc: 0.9538
Epoch 11/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1138 - acc: 0.9566 - val_loss: 0.1157 - val_acc: 0.9496
Epoch 12/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1133 - acc: 0.9578 - val_loss: 0.1157 - val_acc: 0.9524
Epoch 13/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1131 - acc: 0.9599 - val_loss: 0.1156 - val_acc: 0.9510
Manual evaluation: (didn't understand why I made this)
True 8194
False 877
True percentage 0.903318267005
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.92      0.84      0.88       438
      B-LOC       0.71      0.78      0.75       218
      B-ORG       0.63      0.77      0.69       296
      I-ORG       0.41      0.67      0.51       151
      I-PER       0.93      0.66      0.77       214
      I-LOC       0.67      0.78      0.72       141
     B-MISC       0.68      0.18      0.28       141
     I-MISC       0.58      0.14      0.23       154

avg / total       0.94      0.90      0.91      9071

F-1 Score:
0.688089622642
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 32ms/step - loss: 0.1498 - acc: 0.8445 - val_loss: 0.1377 - val_acc: 0.8731
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1295 - acc: 0.9070 - val_loss: 0.1217 - val_acc: 0.9336
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1245 - acc: 0.9226 - val_loss: 0.1197 - val_acc: 0.9357
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1221 - acc: 0.9304 - val_loss: 0.1177 - val_acc: 0.9494
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1201 - acc: 0.9361 - val_loss: 0.1180 - val_acc: 0.9448
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1188 - acc: 0.9409 - val_loss: 0.1165 - val_acc: 0.9517
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1177 - acc: 0.9441 - val_loss: 0.1156 - val_acc: 0.9496
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1168 - acc: 0.9476 - val_loss: 0.1148 - val_acc: 0.9522
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1157 - acc: 0.9505 - val_loss: 0.1188 - val_acc: 0.9343
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1152 - acc: 0.9522 - val_loss: 0.1139 - val_acc: 0.9574
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1139 - acc: 0.9572 - val_loss: 0.1135 - val_acc: 0.9576
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1135 - acc: 0.9583 - val_loss: 0.1134 - val_acc: 0.9596
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1129 - acc: 0.9596 - val_loss: 0.1143 - val_acc: 0.9559
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9621 - val_loss: 0.1133 - val_acc: 0.9579
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1117 - acc: 0.9637 - val_loss: 0.1129 - val_acc: 0.9599
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9652 - val_loss: 0.1131 - val_acc: 0.9601
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1110 - acc: 0.9660 - val_loss: 0.1131 - val_acc: 0.9584
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1108 - acc: 0.9665 - val_loss: 0.1131 - val_acc: 0.9604
Manual evaluation: (didn't understand why I made this)
True 8253
False 818
True percentage 0.9098225113
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.97      0.97      7318
      B-ORG       0.74      0.76      0.75       296
      B-LOC       0.74      0.76      0.75       218
      I-ORG       0.55      0.61      0.58       151
     B-MISC       0.55      0.24      0.33       141
     I-MISC       0.61      0.28      0.38       154
      B-PER       0.90      0.84      0.87       438
      I-PER       0.91      0.66      0.76       214
      I-LOC       0.69      0.82      0.75       141

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.715104009647
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 50s 33ms/step - loss: 0.1480 - acc: 0.8524 - val_loss: 0.1287 - val_acc: 0.9095
Epoch 2/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1289 - acc: 0.9081 - val_loss: 0.1276 - val_acc: 0.8986
Epoch 3/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1246 - acc: 0.9212 - val_loss: 0.1220 - val_acc: 0.9270
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1218 - acc: 0.9322 - val_loss: 0.1189 - val_acc: 0.9391
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1201 - acc: 0.9374 - val_loss: 0.1178 - val_acc: 0.9462
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1183 - acc: 0.9434 - val_loss: 0.1175 - val_acc: 0.9440
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1173 - acc: 0.9468 - val_loss: 0.1167 - val_acc: 0.9490
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1159 - acc: 0.9515 - val_loss: 0.1161 - val_acc: 0.9490
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1157 - acc: 0.9520 - val_loss: 0.1156 - val_acc: 0.9517
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1147 - acc: 0.9552 - val_loss: 0.1157 - val_acc: 0.9512
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1141 - acc: 0.9570 - val_loss: 0.1152 - val_acc: 0.9545
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1135 - acc: 0.9580 - val_loss: 0.1145 - val_acc: 0.9565
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1128 - acc: 0.9609 - val_loss: 0.1146 - val_acc: 0.9557
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9631 - val_loss: 0.1141 - val_acc: 0.9562
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1119 - acc: 0.9645 - val_loss: 0.1144 - val_acc: 0.9576
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9648 - val_loss: 0.1146 - val_acc: 0.9573
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1109 - acc: 0.9662 - val_loss: 0.1145 - val_acc: 0.9576
Manual evaluation: (didn't understand why I made this)
True 8235
False 836
True percentage 0.907838165583
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.97      0.97      7318
      B-PER       0.91      0.84      0.87       438
      B-LOC       0.70      0.78      0.74       218
      B-ORG       0.73      0.75      0.74       296
      I-ORG       0.58      0.56      0.57       151
      I-PER       0.91      0.65      0.76       214
      I-LOC       0.63      0.84      0.72       141
     B-MISC       0.70      0.21      0.33       141
     I-MISC       0.60      0.24      0.34       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.709305850258
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 33ms/step - loss: 0.1463 - acc: 0.8498 - val_loss: 0.1275 - val_acc: 0.9092
Epoch 2/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1283 - acc: 0.9088 - val_loss: 0.1216 - val_acc: 0.9321
Epoch 3/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1242 - acc: 0.9230 - val_loss: 0.1186 - val_acc: 0.9448
Epoch 4/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1219 - acc: 0.9310 - val_loss: 0.1180 - val_acc: 0.9443
Epoch 5/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1198 - acc: 0.9372 - val_loss: 0.1164 - val_acc: 0.9503
Epoch 6/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1186 - acc: 0.9410 - val_loss: 0.1182 - val_acc: 0.9362
Epoch 7/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1174 - acc: 0.9446 - val_loss: 0.1151 - val_acc: 0.9545
Epoch 8/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1165 - acc: 0.9486 - val_loss: 0.1152 - val_acc: 0.9513
Epoch 9/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1153 - acc: 0.9516 - val_loss: 0.1146 - val_acc: 0.9545
Epoch 10/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1145 - acc: 0.9548 - val_loss: 0.1151 - val_acc: 0.9514
Epoch 11/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1139 - acc: 0.9575 - val_loss: 0.1130 - val_acc: 0.9585
Epoch 12/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1131 - acc: 0.9595 - val_loss: 0.1133 - val_acc: 0.9571
Epoch 13/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1127 - acc: 0.9601 - val_loss: 0.1145 - val_acc: 0.9539
Epoch 14/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1123 - acc: 0.9615 - val_loss: 0.1128 - val_acc: 0.9594
Epoch 15/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1113 - acc: 0.9653 - val_loss: 0.1127 - val_acc: 0.9596
Epoch 16/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1115 - acc: 0.9632 - val_loss: 0.1127 - val_acc: 0.9613
Epoch 17/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1110 - acc: 0.9652 - val_loss: 0.1128 - val_acc: 0.9602
Epoch 18/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1108 - acc: 0.9666 - val_loss: 0.1124 - val_acc: 0.9610
Epoch 19/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1106 - acc: 0.9666 - val_loss: 0.1125 - val_acc: 0.9610
Epoch 20/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1100 - acc: 0.9690 - val_loss: 0.1123 - val_acc: 0.9613
Epoch 21/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1097 - acc: 0.9697 - val_loss: 0.1123 - val_acc: 0.9616
Epoch 22/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1092 - acc: 0.9718 - val_loss: 0.1123 - val_acc: 0.9610
Epoch 23/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1092 - acc: 0.9722 - val_loss: 0.1125 - val_acc: 0.9622
Epoch 24/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1089 - acc: 0.9724 - val_loss: 0.1126 - val_acc: 0.9613
Epoch 25/70

1506/1506 [==============================] - 47s 31ms/step - loss: 0.1090 - acc: 0.9726 - val_loss: 0.1124 - val_acc: 0.9616
Manual evaluation: (didn't understand why I made this)
True 8284
False 787
True percentage 0.91323999559
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.97      0.97      7318
      B-ORG       0.77      0.76      0.76       296
      B-LOC       0.71      0.82      0.76       218
      I-ORG       0.64      0.56      0.60       151
     B-MISC       0.58      0.30      0.39       141
     I-MISC       0.54      0.38      0.44       154
      B-PER       0.93      0.84      0.89       438
      I-PER       0.92      0.66      0.77       214
      I-LOC       0.70      0.82      0.76       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.730445246691
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1482 - acc: 0.8517 - val_loss: 0.1289 - val_acc: 0.9061
Epoch 2/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1286 - acc: 0.9100 - val_loss: 0.1252 - val_acc: 0.9161
Epoch 3/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1249 - acc: 0.9207 - val_loss: 0.1265 - val_acc: 0.9092
Epoch 4/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1217 - acc: 0.9331 - val_loss: 0.1194 - val_acc: 0.9407
Epoch 5/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1201 - acc: 0.9373 - val_loss: 0.1178 - val_acc: 0.9456
Epoch 6/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1180 - acc: 0.9433 - val_loss: 0.1164 - val_acc: 0.9501
Epoch 7/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1173 - acc: 0.9451 - val_loss: 0.1235 - val_acc: 0.9189
Epoch 8/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1165 - acc: 0.9485 - val_loss: 0.1182 - val_acc: 0.9392
Epoch 9/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1155 - acc: 0.9519 - val_loss: 0.1157 - val_acc: 0.9533
Epoch 10/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1148 - acc: 0.9539 - val_loss: 0.1155 - val_acc: 0.9531
Epoch 11/70

1506/1506 [==============================] - 46s 30ms/step - loss: 0.1140 - acc: 0.9564 - val_loss: 0.1153 - val_acc: 0.9538
Epoch 12/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1132 - acc: 0.9594 - val_loss: 0.1153 - val_acc: 0.9532
Epoch 13/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1127 - acc: 0.9607 - val_loss: 0.1148 - val_acc: 0.9564
Epoch 14/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1122 - acc: 0.9624 - val_loss: 0.1146 - val_acc: 0.9554
Epoch 15/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1117 - acc: 0.9658 - val_loss: 0.1146 - val_acc: 0.9562
Epoch 16/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1119 - acc: 0.9639 - val_loss: 0.1140 - val_acc: 0.9559
Epoch 17/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1112 - acc: 0.9651 - val_loss: 0.1142 - val_acc: 0.9562
Epoch 18/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1111 - acc: 0.9648 - val_loss: 0.1143 - val_acc: 0.9571
Epoch 19/70

1506/1506 [==============================] - 46s 31ms/step - loss: 0.1102 - acc: 0.9683 - val_loss: 0.1141 - val_acc: 0.9581
Manual evaluation: (didn't understand why I made this)
True 8263
False 808
True percentage 0.910924925587
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.92      0.84      0.88       438
      B-LOC       0.72      0.80      0.76       218
      B-ORG       0.74      0.74      0.74       296
      I-ORG       0.60      0.57      0.59       151
      I-PER       0.90      0.66      0.76       214
      I-LOC       0.63      0.82      0.72       141
     B-MISC       0.58      0.33      0.42       141
     I-MISC       0.56      0.37      0.45       154

avg / total       0.94      0.91      0.92      9071

F-1 Score:
0.720930232558
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 1.0 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104845 unique words.
4841 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 230
OOV word occurences: 314
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6710144     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,218,818
Trainable params: 7,218,818
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 1506 samples, validate on 168 samples
Epoch 1/70

1506/1506 [==============================] - 49s 33ms/step - loss: 0.1501 - acc: 0.8431 - val_loss: 0.1293 - val_acc: 0.9028
Epoch 2/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1294 - acc: 0.9076 - val_loss: 0.1213 - val_acc: 0.9363
Epoch 3/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1252 - acc: 0.9177 - val_loss: 0.1225 - val_acc: 0.9186
Epoch 4/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1222 - acc: 0.9296 - val_loss: 0.1178 - val_acc: 0.9459
Epoch 5/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1201 - acc: 0.9353 - val_loss: 0.1190 - val_acc: 0.9380
Epoch 6/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1191 - acc: 0.9405 - val_loss: 0.1215 - val_acc: 0.9300
Epoch 7/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1179 - acc: 0.9447 - val_loss: 0.1152 - val_acc: 0.9545
Epoch 8/70

1506/1506 [==============================] - 47s 32ms/step - loss: 0.1164 - acc: 0.9483 - val_loss: 0.1147 - val_acc: 0.9573
Epoch 9/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1154 - acc: 0.9518 - val_loss: 0.1145 - val_acc: 0.9576
Epoch 10/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1147 - acc: 0.9527 - val_loss: 0.1141 - val_acc: 0.9570
Epoch 11/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1144 - acc: 0.9558 - val_loss: 0.1143 - val_acc: 0.9585
Epoch 12/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1135 - acc: 0.9572 - val_loss: 0.1145 - val_acc: 0.9588
Epoch 13/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1135 - acc: 0.9567 - val_loss: 0.1135 - val_acc: 0.9613
Epoch 14/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1123 - acc: 0.9611 - val_loss: 0.1133 - val_acc: 0.9616
Epoch 15/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1123 - acc: 0.9611 - val_loss: 0.1133 - val_acc: 0.9599
Epoch 16/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1119 - acc: 0.9628 - val_loss: 0.1131 - val_acc: 0.9613
Epoch 17/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1114 - acc: 0.9641 - val_loss: 0.1132 - val_acc: 0.9616
Epoch 18/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1112 - acc: 0.9650 - val_loss: 0.1129 - val_acc: 0.9621
Epoch 19/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1107 - acc: 0.9677 - val_loss: 0.1134 - val_acc: 0.9621
Epoch 20/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1105 - acc: 0.9679 - val_loss: 0.1132 - val_acc: 0.9601
Epoch 21/70

1506/1506 [==============================] - 48s 32ms/step - loss: 0.1099 - acc: 0.9691 - val_loss: 0.1132 - val_acc: 0.9590
Manual evaluation: (didn't understand why I made this)
True 8263
False 808
True percentage 0.910924925587
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.81      0.73      0.77       296
      B-LOC       0.71      0.81      0.76       218
      I-ORG       0.60      0.55      0.57       151
     B-MISC       0.45      0.40      0.42       141
     I-MISC       0.52      0.45      0.48       154
      B-PER       0.92      0.84      0.88       438
      I-PER       0.93      0.67      0.78       214
      I-LOC       0.66      0.82      0.73       141

avg / total       0.94      0.91      0.93      9071

F-1 Score:
0.724970553592
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1653 - acc: 0.8036 - val_loss: 0.1343 - val_acc: 0.8816
Epoch 2/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1348 - acc: 0.8878 - val_loss: 0.1279 - val_acc: 0.9126
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1298 - acc: 0.9058 - val_loss: 0.1295 - val_acc: 0.8975
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1269 - acc: 0.9156 - val_loss: 0.1266 - val_acc: 0.9096
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1238 - acc: 0.9258 - val_loss: 0.1227 - val_acc: 0.9222
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1222 - acc: 0.9313 - val_loss: 0.1223 - val_acc: 0.9271
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1210 - acc: 0.9343 - val_loss: 0.1218 - val_acc: 0.9297
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1194 - acc: 0.9413 - val_loss: 0.1206 - val_acc: 0.9279
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1185 - acc: 0.9429 - val_loss: 0.1210 - val_acc: 0.9310
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1175 - acc: 0.9466 - val_loss: 0.1198 - val_acc: 0.9316
Epoch 11/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1166 - acc: 0.9496 - val_loss: 0.1200 - val_acc: 0.9330
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1162 - acc: 0.9510 - val_loss: 0.1191 - val_acc: 0.9354
Epoch 13/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1149 - acc: 0.9536 - val_loss: 0.1187 - val_acc: 0.9367
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1143 - acc: 0.9571 - val_loss: 0.1207 - val_acc: 0.9338
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1136 - acc: 0.9596 - val_loss: 0.1194 - val_acc: 0.9381
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1130 - acc: 0.9600 - val_loss: 0.1208 - val_acc: 0.9343
Manual evaluation: (didn't understand why I made this)
True 8093
False 978
True percentage 0.892183882703
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-PER       0.88      0.76      0.81       438
      B-LOC       0.73      0.72      0.73       218
      B-ORG       0.58      0.76      0.66       296
      I-ORG       0.38      0.62      0.47       151
      I-PER       0.89      0.65      0.75       214
      I-LOC       0.67      0.79      0.73       141
     B-MISC       0.65      0.17      0.27       141
     I-MISC       0.60      0.16      0.25       154

avg / total       0.93      0.89      0.91      9071

F-1 Score:
0.655008891523
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1635 - acc: 0.8077 - val_loss: 0.1372 - val_acc: 0.8854
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1346 - acc: 0.8927 - val_loss: 0.1313 - val_acc: 0.9019
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1295 - acc: 0.9075 - val_loss: 0.1282 - val_acc: 0.9110
Epoch 4/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1255 - acc: 0.9183 - val_loss: 0.1260 - val_acc: 0.9141
Epoch 5/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1239 - acc: 0.9226 - val_loss: 0.1245 - val_acc: 0.9250
Epoch 6/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1227 - acc: 0.9317 - val_loss: 0.1244 - val_acc: 0.9240
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1205 - acc: 0.9347 - val_loss: 0.1240 - val_acc: 0.9193
Epoch 8/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1189 - acc: 0.9410 - val_loss: 0.1228 - val_acc: 0.9260
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1184 - acc: 0.9422 - val_loss: 0.1231 - val_acc: 0.9264
Epoch 10/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1171 - acc: 0.9463 - val_loss: 0.1228 - val_acc: 0.9253
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1162 - acc: 0.9494 - val_loss: 0.1223 - val_acc: 0.9242
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1157 - acc: 0.9515 - val_loss: 0.1214 - val_acc: 0.9307
Epoch 13/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1147 - acc: 0.9544 - val_loss: 0.1215 - val_acc: 0.9290
Epoch 14/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1145 - acc: 0.9560 - val_loss: 0.1215 - val_acc: 0.9326
Epoch 15/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1135 - acc: 0.9601 - val_loss: 0.1217 - val_acc: 0.9309
Manual evaluation: (didn't understand why I made this)
True 8153
False 918
True percentage 0.898798368427
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.69      0.71      0.70       296
      B-LOC       0.73      0.73      0.73       218
      I-ORG       0.46      0.48      0.47       151
     B-MISC       0.45      0.35      0.40       141
     I-MISC       0.42      0.47      0.44       154
      B-PER       0.91      0.80      0.85       438
      I-PER       0.92      0.61      0.74       214
      I-LOC       0.72      0.76      0.74       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.679245283019
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1588 - acc: 0.8172 - val_loss: 0.1329 - val_acc: 0.8957
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1338 - acc: 0.8937 - val_loss: 0.1269 - val_acc: 0.9103
Epoch 3/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1289 - acc: 0.9106 - val_loss: 0.1243 - val_acc: 0.9230
Epoch 4/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1260 - acc: 0.9183 - val_loss: 0.1237 - val_acc: 0.9188
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1229 - acc: 0.9288 - val_loss: 0.1232 - val_acc: 0.9187
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1217 - acc: 0.9311 - val_loss: 0.1221 - val_acc: 0.9217
Epoch 7/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1205 - acc: 0.9363 - val_loss: 0.1210 - val_acc: 0.9244
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1186 - acc: 0.9429 - val_loss: 0.1216 - val_acc: 0.9266
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1173 - acc: 0.9469 - val_loss: 0.1206 - val_acc: 0.9273
Epoch 10/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1171 - acc: 0.9469 - val_loss: 0.1202 - val_acc: 0.9296
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1158 - acc: 0.9525 - val_loss: 0.1202 - val_acc: 0.9292
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1151 - acc: 0.9548 - val_loss: 0.1207 - val_acc: 0.9292
Epoch 13/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1144 - acc: 0.9564 - val_loss: 0.1198 - val_acc: 0.9319
Epoch 14/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1140 - acc: 0.9563 - val_loss: 0.1192 - val_acc: 0.9321
Epoch 15/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1132 - acc: 0.9590 - val_loss: 0.1200 - val_acc: 0.9326
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1125 - acc: 0.9613 - val_loss: 0.1192 - val_acc: 0.9383
Epoch 17/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1125 - acc: 0.9608 - val_loss: 0.1187 - val_acc: 0.9404
Epoch 18/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1119 - acc: 0.9639 - val_loss: 0.1198 - val_acc: 0.9360
Epoch 19/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1117 - acc: 0.9645 - val_loss: 0.1200 - val_acc: 0.9351
Epoch 20/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1112 - acc: 0.9666 - val_loss: 0.1190 - val_acc: 0.9363
Manual evaluation: (didn't understand why I made this)
True 8147
False 924
True percentage 0.898136919854
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.90      0.76      0.82       438
      B-LOC       0.71      0.76      0.73       218
      B-ORG       0.66      0.71      0.69       296
      I-ORG       0.54      0.46      0.50       151
      I-PER       0.92      0.64      0.75       214
      I-LOC       0.66      0.77      0.71       141
     B-MISC       0.51      0.26      0.35       141
     I-MISC       0.50      0.39      0.44       154

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.677341389728
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1616 - acc: 0.8073 - val_loss: 0.1369 - val_acc: 0.8892
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1349 - acc: 0.8880 - val_loss: 0.1315 - val_acc: 0.9039
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1291 - acc: 0.9063 - val_loss: 0.1301 - val_acc: 0.9080
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1260 - acc: 0.9164 - val_loss: 0.1273 - val_acc: 0.9205
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1238 - acc: 0.9259 - val_loss: 0.1253 - val_acc: 0.9227
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1224 - acc: 0.9279 - val_loss: 0.1245 - val_acc: 0.9204
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1205 - acc: 0.9365 - val_loss: 0.1239 - val_acc: 0.9207
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1190 - acc: 0.9408 - val_loss: 0.1230 - val_acc: 0.9238
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1184 - acc: 0.9406 - val_loss: 0.1234 - val_acc: 0.9237
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1170 - acc: 0.9470 - val_loss: 0.1225 - val_acc: 0.9259
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1160 - acc: 0.9496 - val_loss: 0.1225 - val_acc: 0.9269
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1154 - acc: 0.9529 - val_loss: 0.1225 - val_acc: 0.9278
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1145 - acc: 0.9547 - val_loss: 0.1215 - val_acc: 0.9270
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1136 - acc: 0.9595 - val_loss: 0.1212 - val_acc: 0.9280
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1131 - acc: 0.9581 - val_loss: 0.1219 - val_acc: 0.9288
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1127 - acc: 0.9600 - val_loss: 0.1213 - val_acc: 0.9294
Epoch 17/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1122 - acc: 0.9633 - val_loss: 0.1208 - val_acc: 0.9301
Epoch 18/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1125 - acc: 0.9605 - val_loss: 0.1210 - val_acc: 0.9316
Epoch 19/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1115 - acc: 0.9640 - val_loss: 0.1210 - val_acc: 0.9337
Epoch 20/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1108 - acc: 0.9664 - val_loss: 0.1211 - val_acc: 0.9310
Manual evaluation: (didn't understand why I made this)
True 8183
False 888
True percentage 0.902105611289
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.69      0.70      0.70       296
      B-LOC       0.72      0.75      0.74       218
      I-ORG       0.49      0.52      0.50       151
     B-MISC       0.55      0.34      0.42       141
     I-MISC       0.50      0.40      0.44       154
      B-PER       0.89      0.81      0.85       438
      I-PER       0.87      0.65      0.74       214
      I-LOC       0.72      0.79      0.76       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.693452380952
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1672 - acc: 0.7959 - val_loss: 0.1361 - val_acc: 0.8851
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1349 - acc: 0.8887 - val_loss: 0.1301 - val_acc: 0.8997
Epoch 3/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1309 - acc: 0.9023 - val_loss: 0.1274 - val_acc: 0.9077
Epoch 4/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1269 - acc: 0.9124 - val_loss: 0.1253 - val_acc: 0.9126
Epoch 5/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1252 - acc: 0.9201 - val_loss: 0.1232 - val_acc: 0.9187
Epoch 6/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1225 - acc: 0.9292 - val_loss: 0.1224 - val_acc: 0.9235
Epoch 7/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1210 - acc: 0.9357 - val_loss: 0.1214 - val_acc: 0.9307
Epoch 8/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1200 - acc: 0.9370 - val_loss: 0.1211 - val_acc: 0.9289
Epoch 9/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1185 - acc: 0.9435 - val_loss: 0.1213 - val_acc: 0.9315
Epoch 10/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1178 - acc: 0.9436 - val_loss: 0.1200 - val_acc: 0.9331
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1168 - acc: 0.9480 - val_loss: 0.1196 - val_acc: 0.9350
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1169 - acc: 0.9473 - val_loss: 0.1202 - val_acc: 0.9348
Epoch 13/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1153 - acc: 0.9535 - val_loss: 0.1202 - val_acc: 0.9340
Epoch 14/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1145 - acc: 0.9543 - val_loss: 0.1196 - val_acc: 0.9360
Epoch 15/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1135 - acc: 0.9598 - val_loss: 0.1209 - val_acc: 0.9361
Epoch 16/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1133 - acc: 0.9595 - val_loss: 0.1205 - val_acc: 0.9378
Epoch 17/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1133 - acc: 0.9602 - val_loss: 0.1197 - val_acc: 0.9382
Manual evaluation: (didn't understand why I made this)
True 8095
False 976
True percentage 0.892404365561
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.88      0.76      0.82       438
      B-LOC       0.71      0.76      0.74       218
      B-ORG       0.62      0.73      0.67       296
      I-ORG       0.39      0.40      0.39       151
      I-PER       0.89      0.65      0.75       214
      I-LOC       0.64      0.80      0.71       141
     B-MISC       0.43      0.14      0.21       141
     I-MISC       0.45      0.22      0.30       154

avg / total       0.93      0.89      0.91      9071

F-1 Score:
0.65100873231
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1658 - acc: 0.8020 - val_loss: 0.1368 - val_acc: 0.8883
Epoch 2/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1359 - acc: 0.8834 - val_loss: 0.1323 - val_acc: 0.9034
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1301 - acc: 0.9004 - val_loss: 0.1284 - val_acc: 0.9153
Epoch 4/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1270 - acc: 0.9151 - val_loss: 0.1262 - val_acc: 0.9189
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1244 - acc: 0.9236 - val_loss: 0.1252 - val_acc: 0.9186
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1226 - acc: 0.9288 - val_loss: 0.1244 - val_acc: 0.9210
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1210 - acc: 0.9339 - val_loss: 0.1233 - val_acc: 0.9223
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1199 - acc: 0.9376 - val_loss: 0.1232 - val_acc: 0.9219
Epoch 9/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1180 - acc: 0.9440 - val_loss: 0.1228 - val_acc: 0.9230
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1178 - acc: 0.9439 - val_loss: 0.1225 - val_acc: 0.9262
Epoch 11/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1168 - acc: 0.9474 - val_loss: 0.1219 - val_acc: 0.9310
Epoch 12/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1161 - acc: 0.9500 - val_loss: 0.1216 - val_acc: 0.9284
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1145 - acc: 0.9543 - val_loss: 0.1211 - val_acc: 0.9275
Epoch 14/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1140 - acc: 0.9563 - val_loss: 0.1210 - val_acc: 0.9317
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1137 - acc: 0.9579 - val_loss: 0.1212 - val_acc: 0.9275
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1132 - acc: 0.9600 - val_loss: 0.1212 - val_acc: 0.9325
Epoch 17/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1127 - acc: 0.9620 - val_loss: 0.1209 - val_acc: 0.9304
Epoch 18/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1122 - acc: 0.9616 - val_loss: 0.1209 - val_acc: 0.9329
Epoch 19/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1117 - acc: 0.9625 - val_loss: 0.1211 - val_acc: 0.9322
Epoch 20/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1113 - acc: 0.9661 - val_loss: 0.1208 - val_acc: 0.9325
Epoch 21/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1103 - acc: 0.9686 - val_loss: 0.1208 - val_acc: 0.9341
Epoch 22/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1105 - acc: 0.9679 - val_loss: 0.1211 - val_acc: 0.9344
Epoch 23/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1099 - acc: 0.9703 - val_loss: 0.1211 - val_acc: 0.9328
Epoch 24/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1099 - acc: 0.9681 - val_loss: 0.1209 - val_acc: 0.9329
Manual evaluation: (didn't understand why I made this)
True 8188
False 883
True percentage 0.902656818432
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.72      0.69      0.70       296
      B-LOC       0.71      0.79      0.75       218
      I-ORG       0.53      0.44      0.48       151
     B-MISC       0.52      0.32      0.39       141
     I-MISC       0.43      0.46      0.44       154
      B-PER       0.91      0.83      0.87       438
      I-PER       0.92      0.64      0.76       214
      I-LOC       0.69      0.79      0.74       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.695755417038
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1618 - acc: 0.8167 - val_loss: 0.1331 - val_acc: 0.8867
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1347 - acc: 0.8884 - val_loss: 0.1284 - val_acc: 0.9074
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1296 - acc: 0.9054 - val_loss: 0.1258 - val_acc: 0.9097
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1261 - acc: 0.9159 - val_loss: 0.1246 - val_acc: 0.9122
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1237 - acc: 0.9274 - val_loss: 0.1234 - val_acc: 0.9200
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1219 - acc: 0.9304 - val_loss: 0.1230 - val_acc: 0.9185
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1210 - acc: 0.9357 - val_loss: 0.1213 - val_acc: 0.9234
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1195 - acc: 0.9378 - val_loss: 0.1211 - val_acc: 0.9251
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1180 - acc: 0.9438 - val_loss: 0.1213 - val_acc: 0.9281
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1175 - acc: 0.9449 - val_loss: 0.1202 - val_acc: 0.9291
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1167 - acc: 0.9489 - val_loss: 0.1201 - val_acc: 0.9305
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1158 - acc: 0.9518 - val_loss: 0.1197 - val_acc: 0.9327
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1149 - acc: 0.9539 - val_loss: 0.1205 - val_acc: 0.9310
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1143 - acc: 0.9560 - val_loss: 0.1197 - val_acc: 0.9326
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1137 - acc: 0.9579 - val_loss: 0.1188 - val_acc: 0.9360
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1135 - acc: 0.9585 - val_loss: 0.1195 - val_acc: 0.9347
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1127 - acc: 0.9628 - val_loss: 0.1196 - val_acc: 0.9373
Epoch 18/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1127 - acc: 0.9600 - val_loss: 0.1197 - val_acc: 0.9376
Manual evaluation: (didn't understand why I made this)
True 8128
False 943
True percentage 0.896042332709
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.89      0.77      0.83       438
      B-LOC       0.70      0.76      0.73       218
      B-ORG       0.68      0.72      0.70       296
      I-ORG       0.42      0.50      0.45       151
      I-PER       0.90      0.64      0.75       214
      I-LOC       0.66      0.79      0.72       141
     B-MISC       0.52      0.23      0.32       141
     I-MISC       0.53      0.25      0.34       154

avg / total       0.93      0.90      0.91      9071

F-1 Score:
0.66968053044
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 26s 34ms/step - loss: 0.1620 - acc: 0.8132 - val_loss: 0.1364 - val_acc: 0.8889
Epoch 2/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1350 - acc: 0.8879 - val_loss: 0.1316 - val_acc: 0.8978
Epoch 3/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1297 - acc: 0.9031 - val_loss: 0.1283 - val_acc: 0.9059
Epoch 4/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1268 - acc: 0.9148 - val_loss: 0.1264 - val_acc: 0.9152
Epoch 5/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1244 - acc: 0.9220 - val_loss: 0.1247 - val_acc: 0.9209
Epoch 6/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1224 - acc: 0.9288 - val_loss: 0.1241 - val_acc: 0.9165
Epoch 7/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1208 - acc: 0.9338 - val_loss: 0.1231 - val_acc: 0.9239
Epoch 8/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1196 - acc: 0.9384 - val_loss: 0.1231 - val_acc: 0.9238
Epoch 9/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1180 - acc: 0.9441 - val_loss: 0.1221 - val_acc: 0.9219
Epoch 10/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1170 - acc: 0.9447 - val_loss: 0.1220 - val_acc: 0.9198
Epoch 11/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1166 - acc: 0.9482 - val_loss: 0.1224 - val_acc: 0.9267
Epoch 12/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1152 - acc: 0.9553 - val_loss: 0.1217 - val_acc: 0.9252
Epoch 13/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1147 - acc: 0.9528 - val_loss: 0.1212 - val_acc: 0.9289
Epoch 14/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1141 - acc: 0.9555 - val_loss: 0.1207 - val_acc: 0.9263
Epoch 15/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1135 - acc: 0.9562 - val_loss: 0.1209 - val_acc: 0.9278
Epoch 16/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1129 - acc: 0.9600 - val_loss: 0.1207 - val_acc: 0.9283
Epoch 17/70

753/753 [==============================] - 24s 32ms/step - loss: 0.1126 - acc: 0.9607 - val_loss: 0.1208 - val_acc: 0.9316
Manual evaluation: (didn't understand why I made this)
True 8190
False 881
True percentage 0.90287730129
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.73      0.71      0.72       296
      B-LOC       0.74      0.76      0.75       218
      I-ORG       0.49      0.45      0.47       151
     B-MISC       0.49      0.28      0.36       141
     I-MISC       0.48      0.36      0.41       154
      B-PER       0.91      0.81      0.86       438
      I-PER       0.90      0.65      0.75       214
      I-LOC       0.68      0.83      0.75       141

avg / total       0.94      0.90      0.92      9071

F-1 Score:
0.692747517304
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104328 unique words.
4324 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 247
OOV word occurences: 371
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6677056     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,730
Trainable params: 7,185,730
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 34ms/step - loss: 0.1668 - acc: 0.7917 - val_loss: 0.1342 - val_acc: 0.8907
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1368 - acc: 0.8805 - val_loss: 0.1291 - val_acc: 0.9043
Epoch 3/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1305 - acc: 0.9025 - val_loss: 0.1267 - val_acc: 0.9094
Epoch 4/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1272 - acc: 0.9151 - val_loss: 0.1239 - val_acc: 0.9229
Epoch 5/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1248 - acc: 0.9219 - val_loss: 0.1241 - val_acc: 0.9188
Epoch 6/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1226 - acc: 0.9302 - val_loss: 0.1237 - val_acc: 0.9196
Epoch 7/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1212 - acc: 0.9321 - val_loss: 0.1224 - val_acc: 0.9259
Epoch 8/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1200 - acc: 0.9377 - val_loss: 0.1205 - val_acc: 0.9309
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1189 - acc: 0.9413 - val_loss: 0.1214 - val_acc: 0.9283
Epoch 10/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1179 - acc: 0.9462 - val_loss: 0.1210 - val_acc: 0.9290
Epoch 11/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1173 - acc: 0.9476 - val_loss: 0.1192 - val_acc: 0.9323
Epoch 12/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1165 - acc: 0.9503 - val_loss: 0.1202 - val_acc: 0.9318
Epoch 13/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1155 - acc: 0.9529 - val_loss: 0.1192 - val_acc: 0.9316
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1148 - acc: 0.9562 - val_loss: 0.1199 - val_acc: 0.9333
Epoch 15/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1142 - acc: 0.9579 - val_loss: 0.1199 - val_acc: 0.9364
Epoch 16/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1139 - acc: 0.9591 - val_loss: 0.1192 - val_acc: 0.9346
Manual evaluation: (didn't understand why I made this)
True 8111
False 960
True percentage 0.89416822842
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-PER       0.86      0.74      0.80       438
      B-LOC       0.73      0.74      0.74       218
      B-ORG       0.66      0.72      0.69       296
      I-ORG       0.44      0.49      0.46       151
      I-PER       0.84      0.66      0.74       214
      I-LOC       0.68      0.77      0.72       141
     B-MISC       0.52      0.26      0.35       141
     I-MISC       0.43      0.32      0.37       154

avg / total       0.93      0.89      0.91      9071

F-1 Score:
0.660895522388
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.5 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 104325 unique words.
4321 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 244
OOV word occurences: 351
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Padded until 24 chars.
Padded until 83 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 83, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 83)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 83, 64)       6676864     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 83, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 83, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 83, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 83, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,185,538
Trainable params: 7,185,538
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 753 samples, validate on 84 samples
Epoch 1/70

753/753 [==============================] - 25s 33ms/step - loss: 0.1660 - acc: 0.7977 - val_loss: 0.1371 - val_acc: 0.8721
Epoch 2/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1361 - acc: 0.8833 - val_loss: 0.1305 - val_acc: 0.9062
Epoch 3/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1303 - acc: 0.9037 - val_loss: 0.1288 - val_acc: 0.9106
Epoch 4/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1269 - acc: 0.9147 - val_loss: 0.1266 - val_acc: 0.9161
Epoch 5/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1247 - acc: 0.9212 - val_loss: 0.1253 - val_acc: 0.9199
Epoch 6/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1225 - acc: 0.9277 - val_loss: 0.1246 - val_acc: 0.9214
Epoch 7/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1206 - acc: 0.9350 - val_loss: 0.1249 - val_acc: 0.9216
Epoch 8/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1194 - acc: 0.9384 - val_loss: 0.1239 - val_acc: 0.9213
Epoch 9/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1189 - acc: 0.9411 - val_loss: 0.1238 - val_acc: 0.9222
Epoch 10/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1173 - acc: 0.9455 - val_loss: 0.1228 - val_acc: 0.9250
Epoch 11/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1166 - acc: 0.9484 - val_loss: 0.1227 - val_acc: 0.9263
Epoch 12/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1164 - acc: 0.9487 - val_loss: 0.1220 - val_acc: 0.9296
Epoch 13/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1150 - acc: 0.9535 - val_loss: 0.1222 - val_acc: 0.9298
Epoch 14/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1142 - acc: 0.9562 - val_loss: 0.1218 - val_acc: 0.9269
Epoch 15/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1139 - acc: 0.9563 - val_loss: 0.1220 - val_acc: 0.9304
Epoch 16/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1131 - acc: 0.9598 - val_loss: 0.1217 - val_acc: 0.9299
Epoch 17/70

753/753 [==============================] - 23s 31ms/step - loss: 0.1129 - acc: 0.9611 - val_loss: 0.1217 - val_acc: 0.9299
Epoch 18/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1120 - acc: 0.9643 - val_loss: 0.1218 - val_acc: 0.9299
Epoch 19/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1120 - acc: 0.9641 - val_loss: 0.1213 - val_acc: 0.9330
Epoch 20/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1117 - acc: 0.9623 - val_loss: 0.1215 - val_acc: 0.9324
Epoch 21/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1105 - acc: 0.9675 - val_loss: 0.1215 - val_acc: 0.9335
Epoch 22/70

753/753 [==============================] - 24s 31ms/step - loss: 0.1110 - acc: 0.9673 - val_loss: 0.1214 - val_acc: 0.9316
Manual evaluation: (didn't understand why I made this)
True 8157
False 914
True percentage 0.899239334142
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.96      0.97      7318
      B-ORG       0.73      0.66      0.69       296
      B-LOC       0.71      0.78      0.74       218
      I-ORG       0.52      0.37      0.43       151
     B-MISC       0.46      0.36      0.41       141
     I-MISC       0.39      0.44      0.41       154
      B-PER       0.91      0.80      0.85       438
      I-PER       0.86      0.65      0.74       214
      I-LOC       0.66      0.83      0.74       141

avg / total       0.93      0.90      0.92      9071

F-1 Score:
0.679513785947
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1852 - acc: 0.7518 - val_loss: 0.1351 - val_acc: 0.8927
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1431 - acc: 0.8599 - val_loss: 0.1416 - val_acc: 0.8431
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1389 - acc: 0.8737 - val_loss: 0.1257 - val_acc: 0.9150
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1334 - acc: 0.8945 - val_loss: 0.1235 - val_acc: 0.9277
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1305 - acc: 0.9015 - val_loss: 0.1237 - val_acc: 0.9273
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1274 - acc: 0.9117 - val_loss: 0.1233 - val_acc: 0.9321
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1259 - acc: 0.9163 - val_loss: 0.1221 - val_acc: 0.9301
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1249 - acc: 0.9204 - val_loss: 0.1216 - val_acc: 0.9259
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1230 - acc: 0.9268 - val_loss: 0.1202 - val_acc: 0.9372
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1212 - acc: 0.9329 - val_loss: 0.1191 - val_acc: 0.9400
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1200 - acc: 0.9344 - val_loss: 0.1215 - val_acc: 0.9325
Epoch 12/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1197 - acc: 0.9389 - val_loss: 0.1200 - val_acc: 0.9386
Epoch 13/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1179 - acc: 0.9453 - val_loss: 0.1193 - val_acc: 0.9377
Manual evaluation: (didn't understand why I made this)
True 7890
False 1181
True percentage 0.869804872671
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.82      0.69      0.75       438
      B-LOC       0.65      0.70      0.67       218
      B-ORG       0.66      0.49      0.56       296
      I-ORG       0.21      0.30      0.25       151
      I-PER       0.84      0.56      0.67       214
      I-LOC       0.58      0.60      0.59       141
     B-MISC       0.35      0.21      0.27       141
     I-MISC       0.30      0.23      0.26       154

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.558224384311
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 9s 28ms/step - loss: 0.1845 - acc: 0.7482 - val_loss: 0.1488 - val_acc: 0.8264
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1404 - acc: 0.8709 - val_loss: 0.1464 - val_acc: 0.8175
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1347 - acc: 0.8894 - val_loss: 0.1361 - val_acc: 0.8693
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1308 - acc: 0.9070 - val_loss: 0.1378 - val_acc: 0.8638
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1279 - acc: 0.9129 - val_loss: 0.1334 - val_acc: 0.8818
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1255 - acc: 0.9219 - val_loss: 0.1289 - val_acc: 0.9028
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1239 - acc: 0.9280 - val_loss: 0.1302 - val_acc: 0.8931
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1225 - acc: 0.9315 - val_loss: 0.1302 - val_acc: 0.8946
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1200 - acc: 0.9362 - val_loss: 0.1284 - val_acc: 0.8986
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1198 - acc: 0.9369 - val_loss: 0.1277 - val_acc: 0.9014
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1185 - acc: 0.9445 - val_loss: 0.1282 - val_acc: 0.9043
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1170 - acc: 0.9459 - val_loss: 0.1248 - val_acc: 0.9083
Epoch 13/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1165 - acc: 0.9465 - val_loss: 0.1279 - val_acc: 0.9028
Epoch 14/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1150 - acc: 0.9541 - val_loss: 0.1238 - val_acc: 0.9168
Epoch 15/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1150 - acc: 0.9539 - val_loss: 0.1276 - val_acc: 0.9071
Epoch 16/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1145 - acc: 0.9548 - val_loss: 0.1244 - val_acc: 0.9154
Epoch 17/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1131 - acc: 0.9607 - val_loss: 0.1275 - val_acc: 0.9111
Manual evaluation: (didn't understand why I made this)
True 8022
False 1049
True percentage 0.884356741263
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-ORG       0.55      0.72      0.62       296
      B-LOC       0.71      0.69      0.70       218
      I-ORG       0.32      0.58      0.41       151
     B-MISC       0.44      0.09      0.14       141
     I-MISC       0.59      0.14      0.23       154
      B-PER       0.88      0.75      0.81       438
      I-PER       0.83      0.60      0.70       214
      I-LOC       0.74      0.76      0.75       141

avg / total       0.93      0.88      0.90      9071

F-1 Score:
0.624740433106
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.2001 - acc: 0.7156 - val_loss: 0.1394 - val_acc: 0.8743
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1468 - acc: 0.8496 - val_loss: 0.1335 - val_acc: 0.9089
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1391 - acc: 0.8784 - val_loss: 0.1292 - val_acc: 0.9107
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1355 - acc: 0.8859 - val_loss: 0.1259 - val_acc: 0.9216
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1320 - acc: 0.9014 - val_loss: 0.1248 - val_acc: 0.9230
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1297 - acc: 0.9058 - val_loss: 0.1238 - val_acc: 0.9254
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1276 - acc: 0.9158 - val_loss: 0.1230 - val_acc: 0.9339
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1253 - acc: 0.9213 - val_loss: 0.1218 - val_acc: 0.9315
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1252 - acc: 0.9224 - val_loss: 0.1216 - val_acc: 0.9297
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1230 - acc: 0.9274 - val_loss: 0.1253 - val_acc: 0.9151
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1217 - acc: 0.9317 - val_loss: 0.1198 - val_acc: 0.9329
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1214 - acc: 0.9325 - val_loss: 0.1204 - val_acc: 0.9396
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1194 - acc: 0.9401 - val_loss: 0.1202 - val_acc: 0.9349
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1184 - acc: 0.9427 - val_loss: 0.1189 - val_acc: 0.9396
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1174 - acc: 0.9460 - val_loss: 0.1189 - val_acc: 0.9410
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1170 - acc: 0.9474 - val_loss: 0.1193 - val_acc: 0.9396
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1161 - acc: 0.9483 - val_loss: 0.1198 - val_acc: 0.9377
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1159 - acc: 0.9518 - val_loss: 0.1188 - val_acc: 0.9391
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1151 - acc: 0.9517 - val_loss: 0.1186 - val_acc: 0.9424
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1140 - acc: 0.9521 - val_loss: 0.1182 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1137 - acc: 0.9572 - val_loss: 0.1183 - val_acc: 0.9396
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1138 - acc: 0.9586 - val_loss: 0.1182 - val_acc: 0.9448
Epoch 23/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1131 - acc: 0.9587 - val_loss: 0.1176 - val_acc: 0.9452
Epoch 24/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1129 - acc: 0.9617 - val_loss: 0.1176 - val_acc: 0.9495
Epoch 25/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1124 - acc: 0.9610 - val_loss: 0.1180 - val_acc: 0.9448
Epoch 26/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1119 - acc: 0.9640 - val_loss: 0.1184 - val_acc: 0.9434
Manual evaluation: (didn't understand why I made this)
True 7955
False 1116
True percentage 0.876970565539
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.87      0.70      0.78       438
      B-LOC       0.69      0.73      0.71       218
      B-ORG       0.57      0.61      0.59       296
      I-ORG       0.34      0.42      0.38       151
      I-PER       0.86      0.56      0.67       214
      I-LOC       0.63      0.72      0.67       141
     B-MISC       0.49      0.26      0.34       141
     I-MISC       0.34      0.25      0.29       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.605405405405
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.1920 - acc: 0.7328 - val_loss: 0.1473 - val_acc: 0.8198
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1423 - acc: 0.8624 - val_loss: 0.1471 - val_acc: 0.8399
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1347 - acc: 0.8918 - val_loss: 0.1387 - val_acc: 0.8652
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1310 - acc: 0.9075 - val_loss: 0.1376 - val_acc: 0.8749
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1285 - acc: 0.9103 - val_loss: 0.1337 - val_acc: 0.8822
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1261 - acc: 0.9232 - val_loss: 0.1300 - val_acc: 0.8929
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1243 - acc: 0.9226 - val_loss: 0.1321 - val_acc: 0.8917
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1228 - acc: 0.9330 - val_loss: 0.1318 - val_acc: 0.8889
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1211 - acc: 0.9341 - val_loss: 0.1324 - val_acc: 0.8861
Manual evaluation: (didn't understand why I made this)
True 7934
False 1137
True percentage 0.874655495535
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-ORG       0.50      0.72      0.59       296
      B-LOC       0.78      0.63      0.70       218
      I-ORG       0.25      0.58      0.35       151
     B-MISC       0.25      0.01      0.01       141
     I-MISC       0.53      0.06      0.11       154
      B-PER       0.85      0.73      0.78       438
      I-PER       0.80      0.56      0.66       214
      I-LOC       0.69      0.65      0.67       141

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.577252584934
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1966 - acc: 0.7278 - val_loss: 0.1437 - val_acc: 0.8610
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1459 - acc: 0.8575 - val_loss: 0.1366 - val_acc: 0.8843
Epoch 3/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1385 - acc: 0.8779 - val_loss: 0.1299 - val_acc: 0.9083
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1348 - acc: 0.8912 - val_loss: 0.1278 - val_acc: 0.9160
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1322 - acc: 0.8981 - val_loss: 0.1238 - val_acc: 0.9249
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1294 - acc: 0.9042 - val_loss: 0.1235 - val_acc: 0.9325
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1258 - acc: 0.9187 - val_loss: 0.1231 - val_acc: 0.9311
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1250 - acc: 0.9206 - val_loss: 0.1225 - val_acc: 0.9321
Epoch 9/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1243 - acc: 0.9220 - val_loss: 0.1216 - val_acc: 0.9329
Epoch 10/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1229 - acc: 0.9266 - val_loss: 0.1221 - val_acc: 0.9277
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1207 - acc: 0.9360 - val_loss: 0.1204 - val_acc: 0.9410
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1205 - acc: 0.9348 - val_loss: 0.1204 - val_acc: 0.9406
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1187 - acc: 0.9437 - val_loss: 0.1198 - val_acc: 0.9434
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1180 - acc: 0.9434 - val_loss: 0.1205 - val_acc: 0.9391
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1171 - acc: 0.9461 - val_loss: 0.1196 - val_acc: 0.9438
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1179 - acc: 0.9435 - val_loss: 0.1234 - val_acc: 0.9283
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1171 - acc: 0.9449 - val_loss: 0.1190 - val_acc: 0.9462
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1152 - acc: 0.9548 - val_loss: 0.1187 - val_acc: 0.9462
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1139 - acc: 0.9580 - val_loss: 0.1207 - val_acc: 0.9420
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1135 - acc: 0.9606 - val_loss: 0.1190 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1131 - acc: 0.9593 - val_loss: 0.1184 - val_acc: 0.9434
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1131 - acc: 0.9611 - val_loss: 0.1187 - val_acc: 0.9382
Epoch 23/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1128 - acc: 0.9611 - val_loss: 0.1185 - val_acc: 0.9434
Epoch 24/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1124 - acc: 0.9623 - val_loss: 0.1185 - val_acc: 0.9434
Manual evaluation: (didn't understand why I made this)
True 7954
False 1117
True percentage 0.87686032411
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.87      0.71      0.78       438
      B-LOC       0.67      0.68      0.68       218
      B-ORG       0.56      0.63      0.59       296
      I-ORG       0.32      0.47      0.38       151
      I-PER       0.85      0.58      0.69       214
      I-LOC       0.65      0.57      0.61       141
     B-MISC       0.48      0.21      0.29       141
     I-MISC       0.39      0.21      0.28       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.596671709531
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1864 - acc: 0.7381 - val_loss: 0.1451 - val_acc: 0.8365
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1409 - acc: 0.8677 - val_loss: 0.1387 - val_acc: 0.8553
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1348 - acc: 0.8937 - val_loss: 0.1360 - val_acc: 0.8846
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1310 - acc: 0.8999 - val_loss: 0.1319 - val_acc: 0.8910
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1285 - acc: 0.9123 - val_loss: 0.1319 - val_acc: 0.8972
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1265 - acc: 0.9176 - val_loss: 0.1296 - val_acc: 0.8917
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1238 - acc: 0.9247 - val_loss: 0.1287 - val_acc: 0.9028
Epoch 8/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1225 - acc: 0.9294 - val_loss: 0.1347 - val_acc: 0.8792
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1218 - acc: 0.9361 - val_loss: 0.1260 - val_acc: 0.9028
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1197 - acc: 0.9378 - val_loss: 0.1288 - val_acc: 0.9000
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1181 - acc: 0.9439 - val_loss: 0.1291 - val_acc: 0.8958
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1176 - acc: 0.9428 - val_loss: 0.1258 - val_acc: 0.8998
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1164 - acc: 0.9513 - val_loss: 0.1277 - val_acc: 0.8972
Epoch 14/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1155 - acc: 0.9550 - val_loss: 0.1300 - val_acc: 0.8998
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1151 - acc: 0.9535 - val_loss: 0.1267 - val_acc: 0.9069
Manual evaluation: (didn't understand why I made this)
True 8037
False 1034
True percentage 0.886010362694
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-ORG       0.68      0.56      0.61       296
      B-LOC       0.69      0.68      0.69       218
      I-ORG       0.40      0.46      0.43       151
     B-MISC       0.34      0.26      0.29       141
     I-MISC       0.47      0.21      0.29       154
      B-PER       0.81      0.81      0.81       438
      I-PER       0.85      0.57      0.68       214
      I-LOC       0.65      0.82      0.72       141

avg / total       0.92      0.89      0.90      9071

F-1 Score:
0.628243814122
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 27ms/step - loss: 0.1987 - acc: 0.7119 - val_loss: 0.1413 - val_acc: 0.8853
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1464 - acc: 0.8530 - val_loss: 0.1330 - val_acc: 0.9014
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1395 - acc: 0.8704 - val_loss: 0.1291 - val_acc: 0.9183
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1349 - acc: 0.8911 - val_loss: 0.1258 - val_acc: 0.9212
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1316 - acc: 0.8997 - val_loss: 0.1236 - val_acc: 0.9249
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1294 - acc: 0.9030 - val_loss: 0.1240 - val_acc: 0.9254
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1264 - acc: 0.9135 - val_loss: 0.1221 - val_acc: 0.9367
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1244 - acc: 0.9220 - val_loss: 0.1221 - val_acc: 0.9291
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1242 - acc: 0.9239 - val_loss: 0.1216 - val_acc: 0.9363
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1226 - acc: 0.9271 - val_loss: 0.1206 - val_acc: 0.9382
Epoch 11/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1210 - acc: 0.9327 - val_loss: 0.1195 - val_acc: 0.9410
Epoch 12/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1200 - acc: 0.9371 - val_loss: 0.1204 - val_acc: 0.9283
Epoch 13/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1192 - acc: 0.9385 - val_loss: 0.1191 - val_acc: 0.9391
Epoch 14/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1187 - acc: 0.9395 - val_loss: 0.1189 - val_acc: 0.9462
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1181 - acc: 0.9474 - val_loss: 0.1192 - val_acc: 0.9420
Epoch 16/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1163 - acc: 0.9483 - val_loss: 0.1228 - val_acc: 0.9278
Epoch 17/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1158 - acc: 0.9523 - val_loss: 0.1184 - val_acc: 0.9490
Epoch 18/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1146 - acc: 0.9576 - val_loss: 0.1185 - val_acc: 0.9448
Epoch 19/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1151 - acc: 0.9538 - val_loss: 0.1186 - val_acc: 0.9448
Epoch 20/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1137 - acc: 0.9583 - val_loss: 0.1182 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1128 - acc: 0.9630 - val_loss: 0.1183 - val_acc: 0.9476
Epoch 22/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1130 - acc: 0.9610 - val_loss: 0.1188 - val_acc: 0.9476
Epoch 23/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1126 - acc: 0.9621 - val_loss: 0.1182 - val_acc: 0.9462
Epoch 24/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1108 - acc: 0.9671 - val_loss: 0.1185 - val_acc: 0.9476
Epoch 25/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1117 - acc: 0.9632 - val_loss: 0.1189 - val_acc: 0.9448
Epoch 26/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1115 - acc: 0.9661 - val_loss: 0.1182 - val_acc: 0.9462
Manual evaluation: (didn't understand why I made this)
True 7905
False 1166
True percentage 0.871458494102
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.88      0.71      0.78       438
      B-LOC       0.66      0.66      0.66       218
      B-ORG       0.52      0.65      0.58       296
      I-ORG       0.26      0.49      0.34       151
      I-PER       0.90      0.56      0.69       214
      I-LOC       0.65      0.53      0.59       141
     B-MISC       0.39      0.16      0.23       141
     I-MISC       0.33      0.11      0.17       154

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.573057305731
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1824 - acc: 0.7374 - val_loss: 0.1442 - val_acc: 0.8574
Epoch 2/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1407 - acc: 0.8717 - val_loss: 0.1382 - val_acc: 0.8725
Epoch 3/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1348 - acc: 0.8895 - val_loss: 0.1373 - val_acc: 0.8624
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1309 - acc: 0.9064 - val_loss: 0.1364 - val_acc: 0.8780
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1275 - acc: 0.9151 - val_loss: 0.1320 - val_acc: 0.8846
Epoch 6/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1255 - acc: 0.9228 - val_loss: 0.1348 - val_acc: 0.8891
Epoch 7/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1241 - acc: 0.9278 - val_loss: 0.1337 - val_acc: 0.8846
Epoch 8/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1222 - acc: 0.9314 - val_loss: 0.1306 - val_acc: 0.8929
Epoch 9/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1201 - acc: 0.9385 - val_loss: 0.1318 - val_acc: 0.8901
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1195 - acc: 0.9405 - val_loss: 0.1314 - val_acc: 0.8887
Epoch 11/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1178 - acc: 0.9459 - val_loss: 0.1266 - val_acc: 0.9043
Epoch 12/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1173 - acc: 0.9452 - val_loss: 0.1266 - val_acc: 0.9123
Epoch 13/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1164 - acc: 0.9500 - val_loss: 0.1269 - val_acc: 0.9043
Epoch 14/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1160 - acc: 0.9514 - val_loss: 0.1286 - val_acc: 0.8998
Epoch 15/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1156 - acc: 0.9506 - val_loss: 0.1275 - val_acc: 0.9085
Manual evaluation: (didn't understand why I made this)
True 8014
False 1057
True percentage 0.883474809834
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-ORG       0.57      0.66      0.62       296
      B-LOC       0.75      0.65      0.70       218
      I-ORG       0.33      0.50      0.40       151
     B-MISC       0.36      0.21      0.26       141
     I-MISC       0.38      0.24      0.29       154
      B-PER       0.87      0.76      0.81       438
      I-PER       0.79      0.61      0.69       214
      I-LOC       0.79      0.72      0.76       141

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.620178041543
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103885 unique words.
3881 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 267
OOV word occurences: 434
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6648704     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,157,378
Trainable params: 7,157,378
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1854 - acc: 0.7356 - val_loss: 0.1376 - val_acc: 0.8909
Epoch 2/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1433 - acc: 0.8642 - val_loss: 0.1342 - val_acc: 0.8946
Epoch 3/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1388 - acc: 0.8730 - val_loss: 0.1286 - val_acc: 0.9192
Epoch 4/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1331 - acc: 0.8924 - val_loss: 0.1249 - val_acc: 0.9178
Epoch 5/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1316 - acc: 0.9020 - val_loss: 0.1235 - val_acc: 0.9249
Epoch 6/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1283 - acc: 0.9132 - val_loss: 0.1224 - val_acc: 0.9244
Epoch 7/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1266 - acc: 0.9160 - val_loss: 0.1226 - val_acc: 0.9277
Epoch 8/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1250 - acc: 0.9232 - val_loss: 0.1211 - val_acc: 0.9344
Epoch 9/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1239 - acc: 0.9226 - val_loss: 0.1222 - val_acc: 0.9391
Epoch 10/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1214 - acc: 0.9326 - val_loss: 0.1209 - val_acc: 0.9382
Epoch 11/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1206 - acc: 0.9349 - val_loss: 0.1197 - val_acc: 0.9344
Epoch 12/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1191 - acc: 0.9401 - val_loss: 0.1200 - val_acc: 0.9372
Epoch 13/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1188 - acc: 0.9408 - val_loss: 0.1193 - val_acc: 0.9400
Epoch 14/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1174 - acc: 0.9462 - val_loss: 0.1196 - val_acc: 0.9420
Epoch 15/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1175 - acc: 0.9445 - val_loss: 0.1188 - val_acc: 0.9462
Epoch 16/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1164 - acc: 0.9497 - val_loss: 0.1189 - val_acc: 0.9434
Epoch 17/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1157 - acc: 0.9533 - val_loss: 0.1186 - val_acc: 0.9420
Epoch 18/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1151 - acc: 0.9541 - val_loss: 0.1191 - val_acc: 0.9434
Epoch 19/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1147 - acc: 0.9550 - val_loss: 0.1191 - val_acc: 0.9434
Epoch 20/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1139 - acc: 0.9585 - val_loss: 0.1185 - val_acc: 0.9434
Epoch 21/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1132 - acc: 0.9624 - val_loss: 0.1181 - val_acc: 0.9452
Epoch 22/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1130 - acc: 0.9574 - val_loss: 0.1187 - val_acc: 0.9448
Epoch 23/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1122 - acc: 0.9604 - val_loss: 0.1186 - val_acc: 0.9505
Epoch 24/70

300/300 [==============================] - 7s 22ms/step - loss: 0.1117 - acc: 0.9641 - val_loss: 0.1185 - val_acc: 0.9462
Manual evaluation: (didn't understand why I made this)
True 7998
False 1073
True percentage 0.881710946974
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.96      0.97      7318
      B-PER       0.88      0.71      0.78       438
      B-LOC       0.69      0.72      0.71       218
      B-ORG       0.63      0.61      0.62       296
      I-ORG       0.32      0.40      0.36       151
      I-PER       0.86      0.58      0.69       214
      I-LOC       0.66      0.65      0.65       141
     B-MISC       0.48      0.25      0.33       141
     I-MISC       0.43      0.30      0.35       154

avg / total       0.92      0.88      0.90      9071

F-1 Score:
0.614634146341
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.2 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103920 unique words.
3916 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 261
OOV word occurences: 380
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Padded until 24 chars.
Padded until 58 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 58, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 58)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 58, 64)       6650944     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 58, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 58, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 58, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,159,618
Trainable params: 7,159,618
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 300 samples, validate on 34 samples
Epoch 1/70

300/300 [==============================] - 8s 28ms/step - loss: 0.1834 - acc: 0.7413 - val_loss: 0.1495 - val_acc: 0.8270
Epoch 2/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1416 - acc: 0.8700 - val_loss: 0.1402 - val_acc: 0.8579
Epoch 3/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1348 - acc: 0.8918 - val_loss: 0.1335 - val_acc: 0.8818
Epoch 4/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1308 - acc: 0.9021 - val_loss: 0.1382 - val_acc: 0.8735
Epoch 5/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1284 - acc: 0.9116 - val_loss: 0.1314 - val_acc: 0.8863
Epoch 6/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1253 - acc: 0.9214 - val_loss: 0.1310 - val_acc: 0.8804
Epoch 7/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1240 - acc: 0.9261 - val_loss: 0.1267 - val_acc: 0.9043
Epoch 8/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1225 - acc: 0.9286 - val_loss: 0.1313 - val_acc: 0.8974
Epoch 9/70

300/300 [==============================] - 6s 22ms/step - loss: 0.1206 - acc: 0.9355 - val_loss: 0.1308 - val_acc: 0.9031
Epoch 10/70

300/300 [==============================] - 6s 21ms/step - loss: 0.1189 - acc: 0.9409 - val_loss: 0.1307 - val_acc: 0.8972
Manual evaluation: (didn't understand why I made this)
True 7976
False 1095
True percentage 0.879285635542
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-ORG       0.50      0.74      0.60       296
      B-LOC       0.78      0.63      0.70       218
      I-ORG       0.30      0.62      0.40       151
     B-MISC       0.43      0.02      0.04       141
     I-MISC       0.57      0.08      0.14       154
      B-PER       0.86      0.74      0.80       438
      I-PER       0.80      0.58      0.68       214
      I-LOC       0.75      0.67      0.71       141

avg / total       0.92      0.88      0.89      9071

F-1 Score:
0.598873406463
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2177 - acc: 0.6406 - val_loss: 0.1544 - val_acc: 0.8015
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1494 - acc: 0.8456 - val_loss: 0.1404 - val_acc: 0.8824
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1427 - acc: 0.8614 - val_loss: 0.1366 - val_acc: 0.8922
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1378 - acc: 0.8791 - val_loss: 0.1331 - val_acc: 0.8897
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1338 - acc: 0.8937 - val_loss: 0.1325 - val_acc: 0.8946
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1314 - acc: 0.8947 - val_loss: 0.1302 - val_acc: 0.9093
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1302 - acc: 0.9031 - val_loss: 0.1299 - val_acc: 0.9020
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1278 - acc: 0.9109 - val_loss: 0.1267 - val_acc: 0.9069
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1255 - acc: 0.9149 - val_loss: 0.1260 - val_acc: 0.9167
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1248 - acc: 0.9216 - val_loss: 0.1267 - val_acc: 0.9142
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1231 - acc: 0.9230 - val_loss: 0.1249 - val_acc: 0.9216
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1220 - acc: 0.9280 - val_loss: 0.1230 - val_acc: 0.9289
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1214 - acc: 0.9293 - val_loss: 0.1234 - val_acc: 0.9191
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1199 - acc: 0.9337 - val_loss: 0.1242 - val_acc: 0.9240
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9397 - val_loss: 0.1234 - val_acc: 0.9216
Manual evaluation: (didn't understand why I made this)
True 7758
False 1313
True percentage 0.855253004079
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-PER       0.84      0.64      0.73       438
      B-LOC       0.63      0.60      0.62       218
      B-ORG       0.47      0.64      0.54       296
      I-ORG       0.22      0.54      0.31       151
      I-PER       0.82      0.55      0.66       214
      I-LOC       0.51      0.31      0.39       141
     B-MISC       0.36      0.13      0.20       141
     I-MISC       0.20      0.05      0.08       154

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.512654502649
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2281 - acc: 0.6676 - val_loss: 0.1553 - val_acc: 0.8290
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1515 - acc: 0.8425 - val_loss: 0.1464 - val_acc: 0.8432
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1429 - acc: 0.8631 - val_loss: 0.1420 - val_acc: 0.8527
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1389 - acc: 0.8734 - val_loss: 0.1393 - val_acc: 0.8432
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1339 - acc: 0.8926 - val_loss: 0.1372 - val_acc: 0.8551
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1329 - acc: 0.8947 - val_loss: 0.1359 - val_acc: 0.8646
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1302 - acc: 0.9117 - val_loss: 0.1348 - val_acc: 0.8646
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1282 - acc: 0.9146 - val_loss: 0.1325 - val_acc: 0.8789
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1261 - acc: 0.9171 - val_loss: 0.1311 - val_acc: 0.8860
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1246 - acc: 0.9253 - val_loss: 0.1305 - val_acc: 0.8812
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1228 - acc: 0.9314 - val_loss: 0.1302 - val_acc: 0.8836
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1219 - acc: 0.9336 - val_loss: 0.1299 - val_acc: 0.8812
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9359 - val_loss: 0.1289 - val_acc: 0.8836
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9421 - val_loss: 0.1292 - val_acc: 0.8812
Epoch 15/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1193 - acc: 0.9430 - val_loss: 0.1289 - val_acc: 0.8836
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1190 - acc: 0.9412 - val_loss: 0.1279 - val_acc: 0.8907
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1176 - acc: 0.9456 - val_loss: 0.1278 - val_acc: 0.9050
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1157 - acc: 0.9541 - val_loss: 0.1275 - val_acc: 0.8884
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1160 - acc: 0.9524 - val_loss: 0.1278 - val_acc: 0.8884
Epoch 20/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1153 - acc: 0.9522 - val_loss: 0.1266 - val_acc: 0.9026
Epoch 21/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1136 - acc: 0.9587 - val_loss: 0.1263 - val_acc: 0.9026
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1145 - acc: 0.9555 - val_loss: 0.1260 - val_acc: 0.8931
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1147 - acc: 0.9538 - val_loss: 0.1261 - val_acc: 0.8979
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1139 - acc: 0.9580 - val_loss: 0.1256 - val_acc: 0.9002
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1120 - acc: 0.9637 - val_loss: 0.1255 - val_acc: 0.9002
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1111 - acc: 0.9642 - val_loss: 0.1254 - val_acc: 0.9121
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1121 - acc: 0.9620 - val_loss: 0.1255 - val_acc: 0.9050
Epoch 28/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1109 - acc: 0.9664 - val_loss: 0.1251 - val_acc: 0.9097
Epoch 29/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1106 - acc: 0.9664 - val_loss: 0.1245 - val_acc: 0.9002
Epoch 30/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1109 - acc: 0.9676 - val_loss: 0.1255 - val_acc: 0.9002
Epoch 31/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1101 - acc: 0.9732 - val_loss: 0.1270 - val_acc: 0.8979
Epoch 32/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1105 - acc: 0.9691 - val_loss: 0.1257 - val_acc: 0.8979
Manual evaluation: (didn't understand why I made this)
True 7894
False 1177
True percentage 0.870245838386
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-ORG       0.53      0.57      0.55       296
      B-LOC       0.67      0.67      0.67       218
      I-ORG       0.25      0.37      0.30       151
     B-MISC       0.37      0.18      0.24       141
     I-MISC       0.45      0.34      0.39       154
      B-PER       0.83      0.71      0.77       438
      I-PER       0.76      0.51      0.61       214
      I-LOC       0.65      0.79      0.71       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.579769979357
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2087 - acc: 0.6837 - val_loss: 0.1535 - val_acc: 0.8039
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1483 - acc: 0.8435 - val_loss: 0.1380 - val_acc: 0.8775
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1419 - acc: 0.8613 - val_loss: 0.1355 - val_acc: 0.8873
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1368 - acc: 0.8782 - val_loss: 0.1318 - val_acc: 0.8971
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1339 - acc: 0.8871 - val_loss: 0.1322 - val_acc: 0.9020
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1313 - acc: 0.8936 - val_loss: 0.1307 - val_acc: 0.9020
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1278 - acc: 0.9062 - val_loss: 0.1277 - val_acc: 0.9020
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1269 - acc: 0.9109 - val_loss: 0.1283 - val_acc: 0.8995
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1265 - acc: 0.9119 - val_loss: 0.1242 - val_acc: 0.9191
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1242 - acc: 0.9235 - val_loss: 0.1243 - val_acc: 0.9118
Epoch 11/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1238 - acc: 0.9262 - val_loss: 0.1231 - val_acc: 0.9142
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1222 - acc: 0.9281 - val_loss: 0.1224 - val_acc: 0.9191
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1196 - acc: 0.9384 - val_loss: 0.1224 - val_acc: 0.9265
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1188 - acc: 0.9398 - val_loss: 0.1225 - val_acc: 0.9240
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1185 - acc: 0.9425 - val_loss: 0.1225 - val_acc: 0.9265
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1174 - acc: 0.9439 - val_loss: 0.1207 - val_acc: 0.9338
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1165 - acc: 0.9511 - val_loss: 0.1210 - val_acc: 0.9265
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1165 - acc: 0.9487 - val_loss: 0.1208 - val_acc: 0.9314
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1153 - acc: 0.9530 - val_loss: 0.1208 - val_acc: 0.9216
Manual evaluation: (didn't understand why I made this)
True 7853
False 1218
True percentage 0.865725939808
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.97      7318
      B-PER       0.85      0.67      0.75       438
      B-LOC       0.63      0.62      0.63       218
      B-ORG       0.57      0.59      0.58       296
      I-ORG       0.25      0.36      0.30       151
      I-PER       0.88      0.53      0.66       214
      I-LOC       0.44      0.48      0.46       141
     B-MISC       0.42      0.18      0.26       141
     I-MISC       0.27      0.14      0.19       154

avg / total       0.91      0.87      0.88      9071

F-1 Score:
0.543838136113
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2214 - acc: 0.6227 - val_loss: 0.1588 - val_acc: 0.8100
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1499 - acc: 0.8431 - val_loss: 0.1482 - val_acc: 0.8337
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1421 - acc: 0.8614 - val_loss: 0.1432 - val_acc: 0.8432
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1372 - acc: 0.8761 - val_loss: 0.1412 - val_acc: 0.8432
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1344 - acc: 0.8894 - val_loss: 0.1380 - val_acc: 0.8741
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1318 - acc: 0.9024 - val_loss: 0.1409 - val_acc: 0.8432
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1294 - acc: 0.9086 - val_loss: 0.1377 - val_acc: 0.8622
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1268 - acc: 0.9138 - val_loss: 0.1364 - val_acc: 0.8670
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1242 - acc: 0.9271 - val_loss: 0.1356 - val_acc: 0.8599
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1250 - acc: 0.9227 - val_loss: 0.1333 - val_acc: 0.8812
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1217 - acc: 0.9331 - val_loss: 0.1357 - val_acc: 0.8646
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9336 - val_loss: 0.1319 - val_acc: 0.8789
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1201 - acc: 0.9341 - val_loss: 0.1303 - val_acc: 0.9002
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9389 - val_loss: 0.1309 - val_acc: 0.8836
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1180 - acc: 0.9454 - val_loss: 0.1306 - val_acc: 0.8884
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1179 - acc: 0.9454 - val_loss: 0.1290 - val_acc: 0.9026
Epoch 17/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1172 - acc: 0.9506 - val_loss: 0.1323 - val_acc: 0.8812
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1163 - acc: 0.9496 - val_loss: 0.1285 - val_acc: 0.9002
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9537 - val_loss: 0.1289 - val_acc: 0.8860
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1149 - acc: 0.9544 - val_loss: 0.1290 - val_acc: 0.8931
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1154 - acc: 0.9548 - val_loss: 0.1293 - val_acc: 0.8907
Manual evaluation: (didn't understand why I made this)
True 7903
False 1168
True percentage 0.871238011245
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-ORG       0.61      0.55      0.58       296
      B-LOC       0.67      0.69      0.68       218
      I-ORG       0.26      0.40      0.31       151
     B-MISC       0.40      0.25      0.31       141
     I-MISC       0.51      0.27      0.35       154
      B-PER       0.82      0.71      0.76       438
      I-PER       0.70      0.55      0.62       214
      I-LOC       0.57      0.80      0.66       141

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.584388807069
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2028 - acc: 0.7689 - val_loss: 0.1548 - val_acc: 0.8015
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1480 - acc: 0.8458 - val_loss: 0.1491 - val_acc: 0.8211
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1410 - acc: 0.8722 - val_loss: 0.1372 - val_acc: 0.8676
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1358 - acc: 0.8847 - val_loss: 0.1310 - val_acc: 0.8995
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1329 - acc: 0.8895 - val_loss: 0.1322 - val_acc: 0.8946
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1301 - acc: 0.9048 - val_loss: 0.1305 - val_acc: 0.8873
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1283 - acc: 0.9093 - val_loss: 0.1273 - val_acc: 0.8922
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1263 - acc: 0.9141 - val_loss: 0.1278 - val_acc: 0.9044
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1253 - acc: 0.9141 - val_loss: 0.1248 - val_acc: 0.9093
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1230 - acc: 0.9278 - val_loss: 0.1233 - val_acc: 0.9216
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9335 - val_loss: 0.1248 - val_acc: 0.9044
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1210 - acc: 0.9310 - val_loss: 0.1227 - val_acc: 0.9191
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1209 - acc: 0.9281 - val_loss: 0.1225 - val_acc: 0.9191
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1184 - acc: 0.9456 - val_loss: 0.1219 - val_acc: 0.9240
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1173 - acc: 0.9471 - val_loss: 0.1216 - val_acc: 0.9118
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1169 - acc: 0.9468 - val_loss: 0.1209 - val_acc: 0.9216
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1162 - acc: 0.9480 - val_loss: 0.1210 - val_acc: 0.9191
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1156 - acc: 0.9531 - val_loss: 0.1204 - val_acc: 0.9289
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1143 - acc: 0.9576 - val_loss: 0.1197 - val_acc: 0.9338
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1144 - acc: 0.9574 - val_loss: 0.1206 - val_acc: 0.9240
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1129 - acc: 0.9574 - val_loss: 0.1202 - val_acc: 0.9289
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1130 - acc: 0.9614 - val_loss: 0.1194 - val_acc: 0.9289
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1118 - acc: 0.9602 - val_loss: 0.1188 - val_acc: 0.9436
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1120 - acc: 0.9654 - val_loss: 0.1185 - val_acc: 0.9412
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1109 - acc: 0.9696 - val_loss: 0.1180 - val_acc: 0.9436
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1113 - acc: 0.9666 - val_loss: 0.1181 - val_acc: 0.9583
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1101 - acc: 0.9716 - val_loss: 0.1183 - val_acc: 0.9363
Epoch 28/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1095 - acc: 0.9733 - val_loss: 0.1181 - val_acc: 0.9436
Manual evaluation: (didn't understand why I made this)
True 7823
False 1248
True percentage 0.862418696946
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-PER       0.86      0.68      0.76       438
      B-LOC       0.61      0.62      0.62       218
      B-ORG       0.52      0.61      0.56       296
      I-ORG       0.25      0.46      0.33       151
      I-PER       0.83      0.53      0.65       214
      I-LOC       0.51      0.42      0.46       141
     B-MISC       0.39      0.28      0.32       141
     I-MISC       0.34      0.19      0.24       154

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.546046787089
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2118 - acc: 0.6491 - val_loss: 0.1527 - val_acc: 0.8242
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1476 - acc: 0.8523 - val_loss: 0.1457 - val_acc: 0.8575
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1414 - acc: 0.8685 - val_loss: 0.1428 - val_acc: 0.8527
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1364 - acc: 0.8785 - val_loss: 0.1422 - val_acc: 0.8480
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1347 - acc: 0.8866 - val_loss: 0.1366 - val_acc: 0.8646
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1297 - acc: 0.9109 - val_loss: 0.1363 - val_acc: 0.8765
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1280 - acc: 0.9157 - val_loss: 0.1360 - val_acc: 0.8694
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1260 - acc: 0.9215 - val_loss: 0.1328 - val_acc: 0.8907
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1248 - acc: 0.9212 - val_loss: 0.1321 - val_acc: 0.8812
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1239 - acc: 0.9245 - val_loss: 0.1314 - val_acc: 0.8955
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1212 - acc: 0.9339 - val_loss: 0.1312 - val_acc: 0.8860
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9384 - val_loss: 0.1293 - val_acc: 0.8955
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1193 - acc: 0.9407 - val_loss: 0.1299 - val_acc: 0.8860
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1188 - acc: 0.9427 - val_loss: 0.1302 - val_acc: 0.8812
Epoch 15/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1190 - acc: 0.9371 - val_loss: 0.1301 - val_acc: 0.9002
Manual evaluation: (didn't understand why I made this)
True 7847
False 1224
True percentage 0.865064491236
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.95      0.96      7318
      B-ORG       0.55      0.58      0.56       296
      B-LOC       0.73      0.63      0.68       218
      I-ORG       0.23      0.40      0.29       151
     B-MISC       0.25      0.02      0.04       141
     I-MISC       0.43      0.21      0.29       154
      B-PER       0.86      0.61      0.72       438
      I-PER       0.77      0.48      0.59       214
      I-LOC       0.66      0.73      0.69       141

avg / total       0.90      0.87      0.88      9071

F-1 Score:
0.547663551402
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2375 - acc: 0.6252 - val_loss: 0.1562 - val_acc: 0.7892
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1517 - acc: 0.8343 - val_loss: 0.1513 - val_acc: 0.7990
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1429 - acc: 0.8623 - val_loss: 0.1378 - val_acc: 0.8725
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1404 - acc: 0.8681 - val_loss: 0.1416 - val_acc: 0.8333
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1345 - acc: 0.8862 - val_loss: 0.1357 - val_acc: 0.8750
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1338 - acc: 0.8866 - val_loss: 0.1324 - val_acc: 0.8995
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1310 - acc: 0.8986 - val_loss: 0.1303 - val_acc: 0.9044
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1302 - acc: 0.9005 - val_loss: 0.1285 - val_acc: 0.9167
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1292 - acc: 0.9026 - val_loss: 0.1279 - val_acc: 0.9069
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1254 - acc: 0.9165 - val_loss: 0.1258 - val_acc: 0.9044
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1252 - acc: 0.9119 - val_loss: 0.1265 - val_acc: 0.9167
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1231 - acc: 0.9206 - val_loss: 0.1251 - val_acc: 0.9069
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1219 - acc: 0.9325 - val_loss: 0.1253 - val_acc: 0.9118
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1218 - acc: 0.9222 - val_loss: 0.1246 - val_acc: 0.9216
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1202 - acc: 0.9349 - val_loss: 0.1237 - val_acc: 0.9240
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1195 - acc: 0.9368 - val_loss: 0.1236 - val_acc: 0.9289
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1178 - acc: 0.9468 - val_loss: 0.1235 - val_acc: 0.9191
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1175 - acc: 0.9421 - val_loss: 0.1227 - val_acc: 0.9191
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1167 - acc: 0.9457 - val_loss: 0.1225 - val_acc: 0.9216
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1163 - acc: 0.9422 - val_loss: 0.1213 - val_acc: 0.9387
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1153 - acc: 0.9551 - val_loss: 0.1221 - val_acc: 0.9265
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1146 - acc: 0.9536 - val_loss: 0.1221 - val_acc: 0.9240
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1144 - acc: 0.9546 - val_loss: 0.1207 - val_acc: 0.9289
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1134 - acc: 0.9593 - val_loss: 0.1200 - val_acc: 0.9338
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1126 - acc: 0.9618 - val_loss: 0.1208 - val_acc: 0.9314
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1122 - acc: 0.9661 - val_loss: 0.1202 - val_acc: 0.9338
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1120 - acc: 0.9620 - val_loss: 0.1195 - val_acc: 0.9387
Epoch 28/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1105 - acc: 0.9698 - val_loss: 0.1193 - val_acc: 0.9338
Epoch 29/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1120 - acc: 0.9642 - val_loss: 0.1194 - val_acc: 0.9412
Epoch 30/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1098 - acc: 0.9746 - val_loss: 0.1189 - val_acc: 0.9412
Epoch 31/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1107 - acc: 0.9674 - val_loss: 0.1197 - val_acc: 0.9363
Epoch 32/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1108 - acc: 0.9664 - val_loss: 0.1205 - val_acc: 0.9314
Epoch 33/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1094 - acc: 0.9723 - val_loss: 0.1201 - val_acc: 0.9387
Manual evaluation: (didn't understand why I made this)
True 7833
False 1238
True percentage 0.863521111234
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.95      0.97      7318
      B-PER       0.86      0.64      0.74       438
      B-LOC       0.68      0.61      0.65       218
      B-ORG       0.57      0.58      0.57       296
      I-ORG       0.29      0.40      0.33       151
      I-PER       0.84      0.50      0.63       214
      I-LOC       0.58      0.45      0.51       141
     B-MISC       0.32      0.33      0.32       141
     I-MISC       0.26      0.29      0.27       154

avg / total       0.91      0.86      0.89      9071

F-1 Score:
0.544095665172
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2179 - acc: 0.6349 - val_loss: 0.1533 - val_acc: 0.8219
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1497 - acc: 0.8420 - val_loss: 0.1474 - val_acc: 0.8290
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1415 - acc: 0.8665 - val_loss: 0.1424 - val_acc: 0.8480
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1360 - acc: 0.8941 - val_loss: 0.1426 - val_acc: 0.8599
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1342 - acc: 0.8913 - val_loss: 0.1401 - val_acc: 0.8670
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1313 - acc: 0.8999 - val_loss: 0.1358 - val_acc: 0.8836
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1285 - acc: 0.9102 - val_loss: 0.1337 - val_acc: 0.8931
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1266 - acc: 0.9174 - val_loss: 0.1338 - val_acc: 0.8884
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1244 - acc: 0.9265 - val_loss: 0.1314 - val_acc: 0.8860
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1231 - acc: 0.9344 - val_loss: 0.1309 - val_acc: 0.8931
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1216 - acc: 0.9376 - val_loss: 0.1325 - val_acc: 0.8765
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1215 - acc: 0.9354 - val_loss: 0.1297 - val_acc: 0.8979
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1205 - acc: 0.9342 - val_loss: 0.1306 - val_acc: 0.8812
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1191 - acc: 0.9441 - val_loss: 0.1305 - val_acc: 0.8907
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1179 - acc: 0.9473 - val_loss: 0.1293 - val_acc: 0.8907
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1176 - acc: 0.9455 - val_loss: 0.1292 - val_acc: 0.8860
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1164 - acc: 0.9482 - val_loss: 0.1276 - val_acc: 0.8979
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9515 - val_loss: 0.1283 - val_acc: 0.8955
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1138 - acc: 0.9636 - val_loss: 0.1272 - val_acc: 0.8979
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1145 - acc: 0.9595 - val_loss: 0.1277 - val_acc: 0.8955
Epoch 21/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1132 - acc: 0.9590 - val_loss: 0.1270 - val_acc: 0.8979
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1136 - acc: 0.9608 - val_loss: 0.1278 - val_acc: 0.9002
Epoch 23/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1118 - acc: 0.9675 - val_loss: 0.1273 - val_acc: 0.8979
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1113 - acc: 0.9619 - val_loss: 0.1274 - val_acc: 0.9002
Manual evaluation: (didn't understand why I made this)
True 7892
False 1179
True percentage 0.870025355529
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.54      0.62      0.58       296
      B-LOC       0.70      0.66      0.68       218
      I-ORG       0.26      0.45      0.33       151
     B-MISC       0.48      0.11      0.18       141
     I-MISC       0.54      0.22      0.31       154
      B-PER       0.82      0.71      0.76       438
      I-PER       0.70      0.52      0.60       214
      I-LOC       0.65      0.75      0.70       141

avg / total       0.91      0.87      0.89      9071

F-1 Score:
0.578320428827
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103739 unique words.
3735 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 272
OOV word occurences: 452
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6639360     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,148,034
Trainable params: 7,148,034
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 34ms/step - loss: 0.2141 - acc: 0.6555 - val_loss: 0.1556 - val_acc: 0.8088
Epoch 2/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1507 - acc: 0.8361 - val_loss: 0.1446 - val_acc: 0.8211
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1421 - acc: 0.8623 - val_loss: 0.1387 - val_acc: 0.8456
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1385 - acc: 0.8737 - val_loss: 0.1373 - val_acc: 0.8627
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1362 - acc: 0.8821 - val_loss: 0.1331 - val_acc: 0.8946
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1322 - acc: 0.8932 - val_loss: 0.1324 - val_acc: 0.8873
Epoch 7/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1298 - acc: 0.8984 - val_loss: 0.1317 - val_acc: 0.8995
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1285 - acc: 0.9075 - val_loss: 0.1283 - val_acc: 0.8971
Epoch 9/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1267 - acc: 0.9065 - val_loss: 0.1271 - val_acc: 0.9069
Epoch 10/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1258 - acc: 0.9113 - val_loss: 0.1277 - val_acc: 0.9118
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1242 - acc: 0.9143 - val_loss: 0.1275 - val_acc: 0.9118
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1227 - acc: 0.9230 - val_loss: 0.1260 - val_acc: 0.9118
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1224 - acc: 0.9304 - val_loss: 0.1240 - val_acc: 0.9142
Epoch 14/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1205 - acc: 0.9315 - val_loss: 0.1236 - val_acc: 0.9142
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1201 - acc: 0.9365 - val_loss: 0.1230 - val_acc: 0.9191
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1188 - acc: 0.9389 - val_loss: 0.1224 - val_acc: 0.9216
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1180 - acc: 0.9410 - val_loss: 0.1232 - val_acc: 0.9191
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1178 - acc: 0.9398 - val_loss: 0.1227 - val_acc: 0.9265
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1161 - acc: 0.9483 - val_loss: 0.1217 - val_acc: 0.9265
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1153 - acc: 0.9526 - val_loss: 0.1225 - val_acc: 0.9167
Epoch 21/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1153 - acc: 0.9526 - val_loss: 0.1218 - val_acc: 0.9314
Epoch 22/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1144 - acc: 0.9557 - val_loss: 0.1203 - val_acc: 0.9289
Epoch 23/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1140 - acc: 0.9600 - val_loss: 0.1207 - val_acc: 0.9240
Epoch 24/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1134 - acc: 0.9603 - val_loss: 0.1205 - val_acc: 0.9314
Epoch 25/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1125 - acc: 0.9617 - val_loss: 0.1201 - val_acc: 0.9314
Epoch 26/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1124 - acc: 0.9597 - val_loss: 0.1198 - val_acc: 0.9338
Epoch 27/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1111 - acc: 0.9648 - val_loss: 0.1197 - val_acc: 0.9338
Epoch 28/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1119 - acc: 0.9636 - val_loss: 0.1188 - val_acc: 0.9412
Epoch 29/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1115 - acc: 0.9669 - val_loss: 0.1186 - val_acc: 0.9510
Epoch 30/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1109 - acc: 0.9712 - val_loss: 0.1190 - val_acc: 0.9363
Epoch 31/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1110 - acc: 0.9674 - val_loss: 0.1188 - val_acc: 0.9436
Epoch 32/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1094 - acc: 0.9749 - val_loss: 0.1187 - val_acc: 0.9387
Manual evaluation: (didn't understand why I made this)
True 7791
False 1280
True percentage 0.858890971227
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.99      0.94      0.96      7318
      B-PER       0.86      0.70      0.77       438
      B-LOC       0.62      0.63      0.63       218
      B-ORG       0.49      0.60      0.54       296
      I-ORG       0.27      0.46      0.34       151
      I-PER       0.83      0.51      0.63       214
      I-LOC       0.47      0.40      0.43       141
     B-MISC       0.35      0.24      0.29       141
     I-MISC       0.32      0.27      0.29       154

avg / total       0.91      0.86      0.88      9071

F-1 Score:
0.542640186916
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.1 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103772 unique words.
3768 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 271
OOV word occurences: 423
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6641472     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,150,146
Trainable params: 7,150,146
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 150 samples, validate on 17 samples
Epoch 1/70

150/150 [==============================] - 5s 33ms/step - loss: 0.2194 - acc: 0.6270 - val_loss: 0.1553 - val_acc: 0.8124
Epoch 2/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1513 - acc: 0.8368 - val_loss: 0.1472 - val_acc: 0.8242
Epoch 3/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1423 - acc: 0.8701 - val_loss: 0.1431 - val_acc: 0.8432
Epoch 4/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1379 - acc: 0.8844 - val_loss: 0.1406 - val_acc: 0.8385
Epoch 5/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1336 - acc: 0.8950 - val_loss: 0.1374 - val_acc: 0.8694
Epoch 6/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1320 - acc: 0.8993 - val_loss: 0.1363 - val_acc: 0.8622
Epoch 7/70

150/150 [==============================] - 3s 20ms/step - loss: 0.1295 - acc: 0.9110 - val_loss: 0.1355 - val_acc: 0.8622
Epoch 8/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1270 - acc: 0.9197 - val_loss: 0.1342 - val_acc: 0.8670
Epoch 9/70

150/150 [==============================] - 3s 22ms/step - loss: 0.1249 - acc: 0.9207 - val_loss: 0.1341 - val_acc: 0.8741
Epoch 10/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1248 - acc: 0.9283 - val_loss: 0.1327 - val_acc: 0.8860
Epoch 11/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1238 - acc: 0.9255 - val_loss: 0.1327 - val_acc: 0.8717
Epoch 12/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1209 - acc: 0.9330 - val_loss: 0.1310 - val_acc: 0.8884
Epoch 13/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1212 - acc: 0.9399 - val_loss: 0.1326 - val_acc: 0.8717
Epoch 14/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1196 - acc: 0.9447 - val_loss: 0.1301 - val_acc: 0.8884
Epoch 15/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1176 - acc: 0.9483 - val_loss: 0.1299 - val_acc: 0.8931
Epoch 16/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1175 - acc: 0.9473 - val_loss: 0.1300 - val_acc: 0.8955
Epoch 17/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1178 - acc: 0.9469 - val_loss: 0.1290 - val_acc: 0.8931
Epoch 18/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9533 - val_loss: 0.1297 - val_acc: 0.8931
Epoch 19/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1155 - acc: 0.9550 - val_loss: 0.1295 - val_acc: 0.8931
Epoch 20/70

150/150 [==============================] - 3s 21ms/step - loss: 0.1152 - acc: 0.9542 - val_loss: 0.1291 - val_acc: 0.8931
Manual evaluation: (didn't understand why I made this)
True 7869
False 1202
True percentage 0.867489802668
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.95      0.96      7318
      B-ORG       0.50      0.62      0.55       296
      B-LOC       0.73      0.61      0.66       218
      I-ORG       0.24      0.47      0.31       151
     B-MISC       0.59      0.07      0.13       141
     I-MISC       0.39      0.18      0.25       154
      B-PER       0.85      0.69      0.76       438
      I-PER       0.78      0.50      0.61       214
      I-LOC       0.64      0.74      0.69       141

avg / total       0.92      0.87      0.89      9071

F-1 Score:
0.561099492082
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2819 - acc: 0.4711 - val_loss: 0.2197 - val_acc: 0.6387
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1591 - acc: 0.8234 - val_loss: 0.2016 - val_acc: 0.7101
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1495 - acc: 0.8401 - val_loss: 0.1960 - val_acc: 0.7185
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1445 - acc: 0.8488 - val_loss: 0.1901 - val_acc: 0.7269
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1411 - acc: 0.8562 - val_loss: 0.1842 - val_acc: 0.7353
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1361 - acc: 0.8786 - val_loss: 0.1859 - val_acc: 0.7395
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1340 - acc: 0.8770 - val_loss: 0.1813 - val_acc: 0.7353
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1306 - acc: 0.8963 - val_loss: 0.1815 - val_acc: 0.7437
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1308 - acc: 0.8949 - val_loss: 0.1769 - val_acc: 0.7521
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1295 - acc: 0.9055 - val_loss: 0.1769 - val_acc: 0.7479
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1260 - acc: 0.9178 - val_loss: 0.1800 - val_acc: 0.7395
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1255 - acc: 0.9131 - val_loss: 0.1760 - val_acc: 0.7605
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1241 - acc: 0.9191 - val_loss: 0.1810 - val_acc: 0.7521
Epoch 14/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1226 - acc: 0.9281 - val_loss: 0.1777 - val_acc: 0.7605
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1206 - acc: 0.9428 - val_loss: 0.1704 - val_acc: 0.7731
Epoch 16/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1204 - acc: 0.9396 - val_loss: 0.1788 - val_acc: 0.7605
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1194 - acc: 0.9426 - val_loss: 0.1708 - val_acc: 0.7689
Epoch 18/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1190 - acc: 0.9370 - val_loss: 0.1743 - val_acc: 0.7647
Manual evaluation: (didn't understand why I made this)
True 7568
False 1503
True percentage 0.83430713262
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.96      7318
      B-PER       0.67      0.55      0.60       438
      B-LOC       0.56      0.60      0.58       218
      B-ORG       0.42      0.44      0.43       296
      I-ORG       0.16      0.39      0.23       151
      I-PER       0.72      0.19      0.30       214
      I-LOC       0.34      0.38      0.36       141
     B-MISC       0.57      0.03      0.05       141
     I-MISC       0.17      0.01      0.01       154

avg / total       0.88      0.83      0.85      9071

F-1 Score:
0.407145056976
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 49ms/step - loss: 0.2730 - acc: 0.4592 - val_loss: 0.1870 - val_acc: 0.7800
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1577 - acc: 0.8248 - val_loss: 0.1748 - val_acc: 0.7800
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1489 - acc: 0.8476 - val_loss: 0.1664 - val_acc: 0.7950
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1428 - acc: 0.8669 - val_loss: 0.1605 - val_acc: 0.8050
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1379 - acc: 0.8869 - val_loss: 0.1527 - val_acc: 0.8100
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1353 - acc: 0.8919 - val_loss: 0.1453 - val_acc: 0.8300
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1324 - acc: 0.8933 - val_loss: 0.1469 - val_acc: 0.8300
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1303 - acc: 0.9007 - val_loss: 0.1403 - val_acc: 0.8550
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1271 - acc: 0.9151 - val_loss: 0.1413 - val_acc: 0.8400
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1251 - acc: 0.9227 - val_loss: 0.1465 - val_acc: 0.8350
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1254 - acc: 0.9237 - val_loss: 0.1384 - val_acc: 0.8550
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1254 - acc: 0.9221 - val_loss: 0.1344 - val_acc: 0.8600
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1231 - acc: 0.9299 - val_loss: 0.1371 - val_acc: 0.8550
Epoch 14/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1231 - acc: 0.9327 - val_loss: 0.1292 - val_acc: 0.9150
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1208 - acc: 0.9341 - val_loss: 0.1381 - val_acc: 0.8550
Epoch 16/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1204 - acc: 0.9311 - val_loss: 0.1286 - val_acc: 0.9150
Epoch 17/70

74/74 [==============================] - 2s 23ms/step - loss: 0.1195 - acc: 0.9468 - val_loss: 0.1314 - val_acc: 0.8850
Epoch 18/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1199 - acc: 0.9398 - val_loss: 0.1283 - val_acc: 0.9200
Epoch 19/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1182 - acc: 0.9452 - val_loss: 0.1331 - val_acc: 0.8750
Epoch 20/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1179 - acc: 0.9457 - val_loss: 0.1318 - val_acc: 0.8750
Epoch 21/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1168 - acc: 0.9529 - val_loss: 0.1318 - val_acc: 0.8850
Manual evaluation: (didn't understand why I made this)
True 7583
False 1488
True percentage 0.835960754051
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-ORG       0.39      0.56      0.46       296
      B-LOC       0.73      0.46      0.57       218
      I-ORG       0.19      0.46      0.27       151
     B-MISC       0.19      0.06      0.10       141
     I-MISC       0.38      0.10      0.16       154
      B-PER       0.72      0.50      0.59       438
      I-PER       0.66      0.38      0.48       214
      I-LOC       0.59      0.29      0.39       141

avg / total       0.89      0.84      0.86      9071

F-1 Score:
0.431456548348
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 48ms/step - loss: 0.2555 - acc: 0.4811 - val_loss: 0.2577 - val_acc: 0.6261
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1647 - acc: 0.8092 - val_loss: 0.1986 - val_acc: 0.6849
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1461 - acc: 0.8562 - val_loss: 0.1917 - val_acc: 0.7185
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1409 - acc: 0.8649 - val_loss: 0.1972 - val_acc: 0.7185
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1370 - acc: 0.8861 - val_loss: 0.1873 - val_acc: 0.7395
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1337 - acc: 0.8916 - val_loss: 0.1781 - val_acc: 0.7395
Epoch 7/70

74/74 [==============================] - 2s 23ms/step - loss: 0.1305 - acc: 0.8967 - val_loss: 0.1777 - val_acc: 0.7437
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1286 - acc: 0.9093 - val_loss: 0.1783 - val_acc: 0.7479
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1276 - acc: 0.9115 - val_loss: 0.1811 - val_acc: 0.7269
Epoch 10/70

74/74 [==============================] - 2s 23ms/step - loss: 0.1270 - acc: 0.9062 - val_loss: 0.1771 - val_acc: 0.7437
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1258 - acc: 0.9164 - val_loss: 0.1809 - val_acc: 0.7647
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1252 - acc: 0.9151 - val_loss: 0.1695 - val_acc: 0.7689
Epoch 13/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1233 - acc: 0.9208 - val_loss: 0.1776 - val_acc: 0.7605
Epoch 14/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1213 - acc: 0.9376 - val_loss: 0.1793 - val_acc: 0.7647
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1188 - acc: 0.9417 - val_loss: 0.1793 - val_acc: 0.7857
Manual evaluation: (didn't understand why I made this)
True 7583
False 1488
True percentage 0.835960754051
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.95      0.95      7318
      B-PER       0.62      0.58      0.60       438
      B-LOC       0.54      0.70      0.61       218
      B-ORG       0.48      0.25      0.33       296
      I-ORG       0.17      0.21      0.19       151
      I-PER       0.71      0.32      0.44       214
      I-LOC       0.31      0.50      0.38       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.86      0.84      0.84      9071

F-1 Score:
0.418962203716
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2607 - acc: 0.5400 - val_loss: 0.1951 - val_acc: 0.7850
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1597 - acc: 0.8279 - val_loss: 0.1684 - val_acc: 0.7950
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1486 - acc: 0.8458 - val_loss: 0.1605 - val_acc: 0.8000
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1432 - acc: 0.8624 - val_loss: 0.1431 - val_acc: 0.8500
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1393 - acc: 0.8849 - val_loss: 0.1512 - val_acc: 0.8100
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1354 - acc: 0.8840 - val_loss: 0.1436 - val_acc: 0.8500
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1323 - acc: 0.8979 - val_loss: 0.1428 - val_acc: 0.8500
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1314 - acc: 0.8985 - val_loss: 0.1356 - val_acc: 0.8750
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1309 - acc: 0.9078 - val_loss: 0.1360 - val_acc: 0.8650
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1285 - acc: 0.9102 - val_loss: 0.1436 - val_acc: 0.8400
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1263 - acc: 0.9209 - val_loss: 0.1409 - val_acc: 0.8650
Manual evaluation: (didn't understand why I made this)
True 7489
False 1582
True percentage 0.825598059751
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-ORG       0.40      0.43      0.41       296
      B-LOC       0.84      0.42      0.56       218
      I-ORG       0.16      0.40      0.23       151
     B-MISC       0.38      0.04      0.06       141
     I-MISC       0.38      0.17      0.23       154
      B-PER       0.52      0.55      0.53       438
      I-PER       0.42      0.37      0.39       214
      I-LOC       0.60      0.04      0.08       141

avg / total       0.88      0.83      0.84      9071

F-1 Score:
0.38554948391
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 47ms/step - loss: 0.2821 - acc: 0.4990 - val_loss: 0.2738 - val_acc: 0.6218
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1712 - acc: 0.8118 - val_loss: 0.1972 - val_acc: 0.6723
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1496 - acc: 0.8510 - val_loss: 0.1926 - val_acc: 0.7059
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1445 - acc: 0.8537 - val_loss: 0.1923 - val_acc: 0.6891
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1410 - acc: 0.8674 - val_loss: 0.1844 - val_acc: 0.7269
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1387 - acc: 0.8714 - val_loss: 0.1793 - val_acc: 0.7395
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1347 - acc: 0.8866 - val_loss: 0.1806 - val_acc: 0.7479
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1323 - acc: 0.8965 - val_loss: 0.1889 - val_acc: 0.7101
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1337 - acc: 0.8868 - val_loss: 0.1763 - val_acc: 0.7521
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1293 - acc: 0.8993 - val_loss: 0.1813 - val_acc: 0.7521
Epoch 11/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1275 - acc: 0.9043 - val_loss: 0.1804 - val_acc: 0.7269
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1266 - acc: 0.9131 - val_loss: 0.1846 - val_acc: 0.7437
Manual evaluation: (didn't understand why I made this)
True 7451
False 1620
True percentage 0.821408885459
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.95      7318
      B-PER       0.68      0.53      0.59       438
      B-LOC       0.45      0.66      0.54       218
      B-ORG       0.39      0.43      0.41       296
      I-ORG       0.16      0.58      0.25       151
      I-PER       0.78      0.14      0.23       214
      I-LOC       0.29      0.20      0.24       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.87      0.82      0.84      9071

F-1 Score:
0.37815619495
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 4s 47ms/step - loss: 0.2493 - acc: 0.4944 - val_loss: 0.1729 - val_acc: 0.7800
Epoch 2/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1577 - acc: 0.8274 - val_loss: 0.1574 - val_acc: 0.8100
Epoch 3/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1454 - acc: 0.8551 - val_loss: 0.1458 - val_acc: 0.8250
Epoch 4/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1412 - acc: 0.8693 - val_loss: 0.1507 - val_acc: 0.7900
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1367 - acc: 0.8893 - val_loss: 0.1449 - val_acc: 0.8300
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1338 - acc: 0.8991 - val_loss: 0.1456 - val_acc: 0.8350
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1312 - acc: 0.9002 - val_loss: 0.1422 - val_acc: 0.8450
Epoch 8/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1300 - acc: 0.9096 - val_loss: 0.1406 - val_acc: 0.8550
Epoch 9/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1271 - acc: 0.9189 - val_loss: 0.1404 - val_acc: 0.8600
Epoch 10/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1258 - acc: 0.9233 - val_loss: 0.1401 - val_acc: 0.8600
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1248 - acc: 0.9244 - val_loss: 0.1445 - val_acc: 0.8300
Epoch 12/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1243 - acc: 0.9260 - val_loss: 0.1386 - val_acc: 0.8650
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1218 - acc: 0.9359 - val_loss: 0.1358 - val_acc: 0.8650
Epoch 14/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1206 - acc: 0.9417 - val_loss: 0.1330 - val_acc: 0.8950
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1213 - acc: 0.9388 - val_loss: 0.1411 - val_acc: 0.8500
Epoch 16/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1186 - acc: 0.9453 - val_loss: 0.1371 - val_acc: 0.8650
Epoch 17/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1174 - acc: 0.9504 - val_loss: 0.1331 - val_acc: 0.8800
Manual evaluation: (didn't understand why I made this)
True 7621
False 1450
True percentage 0.840149928343
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.96      7318
      B-ORG       0.46      0.49      0.48       296
      B-LOC       0.71      0.49      0.58       218
      I-ORG       0.18      0.30      0.23       151
     B-MISC       0.18      0.06      0.09       141
     I-MISC       0.36      0.16      0.22       154
      B-PER       0.70      0.53      0.61       438
      I-PER       0.49      0.46      0.47       214
      I-LOC       0.67      0.38      0.48       141

avg / total       0.88      0.84      0.86      9071

F-1 Score:
0.448340638698
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 46ms/step - loss: 0.2615 - acc: 0.4907 - val_loss: 0.2425 - val_acc: 0.6218
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1646 - acc: 0.8138 - val_loss: 0.1998 - val_acc: 0.6681
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1506 - acc: 0.8402 - val_loss: 0.1953 - val_acc: 0.6849
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1447 - acc: 0.8617 - val_loss: 0.1913 - val_acc: 0.7227
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1397 - acc: 0.8798 - val_loss: 0.1819 - val_acc: 0.7269
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1361 - acc: 0.8826 - val_loss: 0.1821 - val_acc: 0.7227
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1346 - acc: 0.8883 - val_loss: 0.1975 - val_acc: 0.7227
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1327 - acc: 0.8920 - val_loss: 0.1855 - val_acc: 0.7395
Manual evaluation: (didn't understand why I made this)
True 7469
False 1602
True percentage 0.823393231176
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-PER       0.60      0.50      0.55       438
      B-LOC       0.64      0.56      0.60       218
      B-ORG       0.34      0.46      0.39       296
      I-ORG       0.16      0.60      0.26       151
      I-PER       0.67      0.14      0.24       214
      I-LOC       0.19      0.04      0.07       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.87      0.82      0.84      9071

F-1 Score:
0.363145258103
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 46ms/step - loss: 0.2638 - acc: 0.4881 - val_loss: 0.1800 - val_acc: 0.7850
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1559 - acc: 0.8358 - val_loss: 0.1616 - val_acc: 0.7950
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1444 - acc: 0.8583 - val_loss: 0.1476 - val_acc: 0.8100
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1403 - acc: 0.8772 - val_loss: 0.1457 - val_acc: 0.8250
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1376 - acc: 0.8759 - val_loss: 0.1502 - val_acc: 0.8200
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1336 - acc: 0.8957 - val_loss: 0.1463 - val_acc: 0.8100
Epoch 7/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1322 - acc: 0.8953 - val_loss: 0.1498 - val_acc: 0.7950
Manual evaluation: (didn't understand why I made this)
True 7248
False 1823
True percentage 0.799029875427
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.92      0.95      7318
      B-ORG       0.24      0.61      0.34       296
      B-LOC       0.80      0.04      0.07       218
      I-ORG       0.16      0.50      0.24       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.45      0.03      0.06       154
      B-PER       0.53      0.36      0.43       438
      I-PER       0.62      0.26      0.36       214
      I-LOC       0.62      0.04      0.07       141

avg / total       0.88      0.80      0.81      9071

F-1 Score:
0.285126396238
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103663 unique words.
3659 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 275
OOV word occurences: 468
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6634496     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,143,170
Trainable params: 7,143,170
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 47ms/step - loss: 0.2550 - acc: 0.5716 - val_loss: 0.2230 - val_acc: 0.6513
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1557 - acc: 0.8315 - val_loss: 0.2077 - val_acc: 0.6597
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1473 - acc: 0.8502 - val_loss: 0.2008 - val_acc: 0.6849
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1416 - acc: 0.8656 - val_loss: 0.1908 - val_acc: 0.7143
Epoch 5/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1372 - acc: 0.8802 - val_loss: 0.1919 - val_acc: 0.7101
Epoch 6/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1342 - acc: 0.8844 - val_loss: 0.1918 - val_acc: 0.7311
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1324 - acc: 0.8922 - val_loss: 0.2007 - val_acc: 0.7311
Manual evaluation: (didn't understand why I made this)
True 7405
False 1666
True percentage 0.816337779738
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.96      7318
      B-PER       0.67      0.49      0.56       438
      B-LOC       0.39      0.75      0.52       218
      B-ORG       0.37      0.30      0.33       296
      I-ORG       0.15      0.53      0.24       151
      I-PER       0.74      0.09      0.17       214
      I-LOC       0.27      0.32      0.29       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.87      0.82      0.83      9071

F-1 Score:
0.354408352668
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.05 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103694 unique words.
3690 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 276
OOV word occurences: 511
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6636480     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,145,154
Trainable params: 7,145,154
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 74 samples, validate on 9 samples
Epoch 1/70

74/74 [==============================] - 3s 46ms/step - loss: 0.2606 - acc: 0.4964 - val_loss: 0.1868 - val_acc: 0.7850
Epoch 2/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1582 - acc: 0.8319 - val_loss: 0.1593 - val_acc: 0.8050
Epoch 3/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1464 - acc: 0.8525 - val_loss: 0.1595 - val_acc: 0.7850
Epoch 4/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1413 - acc: 0.8661 - val_loss: 0.1456 - val_acc: 0.8300
Epoch 5/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1367 - acc: 0.8823 - val_loss: 0.1420 - val_acc: 0.8550
Epoch 6/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1364 - acc: 0.8878 - val_loss: 0.1488 - val_acc: 0.8300
Epoch 7/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1328 - acc: 0.8931 - val_loss: 0.1455 - val_acc: 0.8200
Epoch 8/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1309 - acc: 0.8959 - val_loss: 0.1390 - val_acc: 0.8750
Epoch 9/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1288 - acc: 0.9129 - val_loss: 0.1376 - val_acc: 0.8600
Epoch 10/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1269 - acc: 0.9114 - val_loss: 0.1359 - val_acc: 0.8500
Epoch 11/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1258 - acc: 0.9262 - val_loss: 0.1382 - val_acc: 0.8450
Epoch 12/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1249 - acc: 0.9167 - val_loss: 0.1412 - val_acc: 0.8400
Epoch 13/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1221 - acc: 0.9325 - val_loss: 0.1337 - val_acc: 0.8650
Epoch 14/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1234 - acc: 0.9217 - val_loss: 0.1385 - val_acc: 0.8500
Epoch 15/70

74/74 [==============================] - 2s 22ms/step - loss: 0.1207 - acc: 0.9330 - val_loss: 0.1371 - val_acc: 0.8500
Epoch 16/70

74/74 [==============================] - 2s 21ms/step - loss: 0.1200 - acc: 0.9430 - val_loss: 0.1362 - val_acc: 0.8600
Manual evaluation: (didn't understand why I made this)
True 7553
False 1518
True percentage 0.83265351119
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.94      0.96      7318
      B-ORG       0.39      0.58      0.46       296
      B-LOC       0.74      0.45      0.56       218
      I-ORG       0.20      0.51      0.29       151
     B-MISC       0.14      0.04      0.06       141
     I-MISC       0.29      0.03      0.06       154
      B-PER       0.69      0.47      0.56       438
      I-PER       0.50      0.41      0.45       214
      I-LOC       0.69      0.31      0.43       141

avg / total       0.89      0.83      0.85      9071

F-1 Score:
0.421307506053
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 88ms/step - loss: 0.3439 - acc: 0.0551 - val_loss: 0.2088 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2021 - acc: 0.7940 - val_loss: 0.2058 - val_acc: 0.7113
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2150 - acc: 0.6874 - val_loss: 0.1722 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1659 - acc: 0.7957 - val_loss: 0.1509 - val_acc: 0.8454
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1486 - acc: 0.8544 - val_loss: 0.1462 - val_acc: 0.8557
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1433 - acc: 0.8597 - val_loss: 0.1441 - val_acc: 0.8660
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1396 - acc: 0.8881 - val_loss: 0.1412 - val_acc: 0.8660
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1388 - acc: 0.8757 - val_loss: 0.1401 - val_acc: 0.8866
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1364 - acc: 0.8863 - val_loss: 0.1390 - val_acc: 0.8866
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1315 - acc: 0.9130 - val_loss: 0.1383 - val_acc: 0.8660
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1286 - acc: 0.9147 - val_loss: 0.1371 - val_acc: 0.8969
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1262 - acc: 0.9325 - val_loss: 0.1365 - val_acc: 0.8763
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1247 - acc: 0.9272 - val_loss: 0.1358 - val_acc: 0.8763
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1228 - acc: 0.9414 - val_loss: 0.1355 - val_acc: 0.8763
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1215 - acc: 0.9503 - val_loss: 0.1339 - val_acc: 0.8763
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1205 - acc: 0.9467 - val_loss: 0.1345 - val_acc: 0.8660
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1195 - acc: 0.9432 - val_loss: 0.1343 - val_acc: 0.8763
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1174 - acc: 0.9503 - val_loss: 0.1344 - val_acc: 0.8660
Manual evaluation: (didn't understand why I made this)
True 7351
False 1720
True percentage 0.810384742586
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.50      0.47      0.48       438
      B-LOC       0.52      0.58      0.55       218
      B-ORG       0.36      0.32      0.34       296
      I-ORG       0.15      0.40      0.21       151
      I-PER       0.94      0.07      0.13       214
      I-LOC       0.13      0.11      0.12       141
     B-MISC       0.33      0.02      0.04       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.86      0.81      0.82      9071

F-1 Score:
0.322500773754
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3619 - acc: 0.0527 - val_loss: 0.1635 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1966 - acc: 0.8122 - val_loss: 0.1531 - val_acc: 0.8675
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1669 - acc: 0.8081 - val_loss: 0.1391 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1517 - acc: 0.8419 - val_loss: 0.1359 - val_acc: 0.9157
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1447 - acc: 0.8676 - val_loss: 0.1336 - val_acc: 0.8916
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1406 - acc: 0.8784 - val_loss: 0.1329 - val_acc: 0.9277
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1383 - acc: 0.8784 - val_loss: 0.1317 - val_acc: 0.9277
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1356 - acc: 0.9027 - val_loss: 0.1306 - val_acc: 0.9398
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1347 - acc: 0.8878 - val_loss: 0.1310 - val_acc: 0.9277
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1313 - acc: 0.9081 - val_loss: 0.1301 - val_acc: 0.9398
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1298 - acc: 0.9216 - val_loss: 0.1300 - val_acc: 0.9277
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1287 - acc: 0.9162 - val_loss: 0.1300 - val_acc: 0.9398
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1264 - acc: 0.9162 - val_loss: 0.1303 - val_acc: 0.9398
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1260 - acc: 0.9230 - val_loss: 0.1309 - val_acc: 0.9398
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1232 - acc: 0.9378 - val_loss: 0.1304 - val_acc: 0.9277
Manual evaluation: (didn't understand why I made this)
True 7338
False 1733
True percentage 0.808951604013
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.95      0.95      7318
      B-ORG       0.27      0.29      0.28       296
      B-LOC       0.75      0.15      0.25       218
      I-ORG       0.17      0.42      0.25       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.39      0.08      0.14       154
      B-PER       0.56      0.34      0.43       438
      I-PER       0.46      0.30      0.37       214
      I-LOC       1.00      0.01      0.01       141

avg / total       0.85      0.81      0.81      9071

F-1 Score:
0.28096369189
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 92ms/step - loss: 0.3698 - acc: 0.0568 - val_loss: 0.1962 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1956 - acc: 0.7940 - val_loss: 0.1699 - val_acc: 0.8557
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1752 - acc: 0.7957 - val_loss: 0.1591 - val_acc: 0.8144
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1572 - acc: 0.8064 - val_loss: 0.1461 - val_acc: 0.8969
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1462 - acc: 0.8668 - val_loss: 0.1431 - val_acc: 0.8557
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1411 - acc: 0.8792 - val_loss: 0.1406 - val_acc: 0.8763
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1365 - acc: 0.8970 - val_loss: 0.1400 - val_acc: 0.8969
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1342 - acc: 0.8952 - val_loss: 0.1392 - val_acc: 0.8866
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1304 - acc: 0.9059 - val_loss: 0.1382 - val_acc: 0.8866
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1293 - acc: 0.9112 - val_loss: 0.1383 - val_acc: 0.8763
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1280 - acc: 0.9041 - val_loss: 0.1369 - val_acc: 0.8866
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1255 - acc: 0.9147 - val_loss: 0.1380 - val_acc: 0.8557
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1253 - acc: 0.9218 - val_loss: 0.1371 - val_acc: 0.8866
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1216 - acc: 0.9432 - val_loss: 0.1367 - val_acc: 0.8660
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1205 - acc: 0.9520 - val_loss: 0.1369 - val_acc: 0.8660
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1198 - acc: 0.9449 - val_loss: 0.1366 - val_acc: 0.8763
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1171 - acc: 0.9609 - val_loss: 0.1357 - val_acc: 0.8660
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1170 - acc: 0.9538 - val_loss: 0.1368 - val_acc: 0.8660
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1182 - acc: 0.9467 - val_loss: 0.1355 - val_acc: 0.8763
Epoch 20/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1153 - acc: 0.9627 - val_loss: 0.1351 - val_acc: 0.8660
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1151 - acc: 0.9627 - val_loss: 0.1367 - val_acc: 0.8660
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1155 - acc: 0.9645 - val_loss: 0.1348 - val_acc: 0.8660
Epoch 23/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1140 - acc: 0.9663 - val_loss: 0.1355 - val_acc: 0.8763
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1129 - acc: 0.9769 - val_loss: 0.1355 - val_acc: 0.8763
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1116 - acc: 0.9734 - val_loss: 0.1352 - val_acc: 0.8763
Manual evaluation: (didn't understand why I made this)
True 7283
False 1788
True percentage 0.802888325433
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.92      0.95      7318
      B-PER       0.49      0.42      0.46       438
      B-LOC       0.47      0.66      0.55       218
      B-ORG       0.29      0.33      0.31       296
      I-ORG       0.16      0.45      0.23       151
      I-PER       0.73      0.09      0.16       214
      I-LOC       0.18      0.18      0.18       141
     B-MISC       0.08      0.01      0.01       141
     I-MISC       0.50      0.01      0.01       154

avg / total       0.87      0.80      0.82      9071

F-1 Score:
0.319764011799
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 86ms/step - loss: 0.3264 - acc: 0.2149 - val_loss: 0.1560 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1956 - acc: 0.8122 - val_loss: 0.2395 - val_acc: 0.5663
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2844 - acc: 0.4297 - val_loss: 0.1492 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1750 - acc: 0.8135 - val_loss: 0.1393 - val_acc: 0.8795
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1565 - acc: 0.8311 - val_loss: 0.1351 - val_acc: 0.8554
Epoch 6/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1476 - acc: 0.8500 - val_loss: 0.1335 - val_acc: 0.8916
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1456 - acc: 0.8622 - val_loss: 0.1325 - val_acc: 0.9036
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1410 - acc: 0.8865 - val_loss: 0.1312 - val_acc: 0.9277
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1378 - acc: 0.8905 - val_loss: 0.1305 - val_acc: 0.9157
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1335 - acc: 0.8959 - val_loss: 0.1303 - val_acc: 0.9277
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1348 - acc: 0.8932 - val_loss: 0.1294 - val_acc: 0.9277
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1342 - acc: 0.8905 - val_loss: 0.1289 - val_acc: 0.9277
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1307 - acc: 0.9041 - val_loss: 0.1283 - val_acc: 0.9277
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1305 - acc: 0.9081 - val_loss: 0.1280 - val_acc: 0.9277
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1298 - acc: 0.9068 - val_loss: 0.1281 - val_acc: 0.9277
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1285 - acc: 0.9230 - val_loss: 0.1278 - val_acc: 0.9277
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1283 - acc: 0.9176 - val_loss: 0.1276 - val_acc: 0.9398
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1250 - acc: 0.9257 - val_loss: 0.1272 - val_acc: 0.9277
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1250 - acc: 0.9297 - val_loss: 0.1272 - val_acc: 0.9277
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1232 - acc: 0.9338 - val_loss: 0.1268 - val_acc: 0.9277
Epoch 21/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1229 - acc: 0.9405 - val_loss: 0.1269 - val_acc: 0.9277
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1221 - acc: 0.9419 - val_loss: 0.1268 - val_acc: 0.9277
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1212 - acc: 0.9405 - val_loss: 0.1268 - val_acc: 0.9277
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1221 - acc: 0.9324 - val_loss: 0.1274 - val_acc: 0.9277
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1185 - acc: 0.9500 - val_loss: 0.1268 - val_acc: 0.9277
Epoch 26/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1180 - acc: 0.9608 - val_loss: 0.1272 - val_acc: 0.9277
Manual evaluation: (didn't understand why I made this)
True 7284
False 1787
True percentage 0.802998566861
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.23      0.32      0.27       296
      B-LOC       0.70      0.17      0.28       218
      I-ORG       0.17      0.61      0.26       151
     B-MISC       0.10      0.04      0.05       141
     I-MISC       0.12      0.01      0.02       154
      B-PER       0.59      0.34      0.43       438
      I-PER       0.71      0.21      0.32       214
      I-LOC       0.75      0.02      0.04       141

avg / total       0.87      0.80      0.82      9071

F-1 Score:
0.272208121827
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 86ms/step - loss: 0.3440 - acc: 0.0373 - val_loss: 0.1947 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1855 - acc: 0.7940 - val_loss: 0.2414 - val_acc: 0.5979
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2436 - acc: 0.5702 - val_loss: 0.1833 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1747 - acc: 0.7940 - val_loss: 0.1579 - val_acc: 0.8247
Epoch 5/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1560 - acc: 0.8348 - val_loss: 0.1495 - val_acc: 0.8351
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1500 - acc: 0.8348 - val_loss: 0.1467 - val_acc: 0.8454
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1421 - acc: 0.8721 - val_loss: 0.1439 - val_acc: 0.8557
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1394 - acc: 0.8828 - val_loss: 0.1424 - val_acc: 0.8557
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1366 - acc: 0.9041 - val_loss: 0.1401 - val_acc: 0.8866
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1327 - acc: 0.9112 - val_loss: 0.1395 - val_acc: 0.8866
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1311 - acc: 0.9059 - val_loss: 0.1386 - val_acc: 0.8763
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1281 - acc: 0.9290 - val_loss: 0.1378 - val_acc: 0.8763
Epoch 13/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1263 - acc: 0.9254 - val_loss: 0.1377 - val_acc: 0.8969
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1261 - acc: 0.9307 - val_loss: 0.1362 - val_acc: 0.8866
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1242 - acc: 0.9361 - val_loss: 0.1361 - val_acc: 0.8969
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1210 - acc: 0.9414 - val_loss: 0.1359 - val_acc: 0.8763
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1215 - acc: 0.9414 - val_loss: 0.1350 - val_acc: 0.8969
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1210 - acc: 0.9414 - val_loss: 0.1355 - val_acc: 0.8969
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1180 - acc: 0.9609 - val_loss: 0.1348 - val_acc: 0.8969
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1183 - acc: 0.9556 - val_loss: 0.1348 - val_acc: 0.8969
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1185 - acc: 0.9485 - val_loss: 0.1351 - val_acc: 0.8763
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1165 - acc: 0.9716 - val_loss: 0.1346 - val_acc: 0.8866
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1153 - acc: 0.9609 - val_loss: 0.1339 - val_acc: 0.8969
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1149 - acc: 0.9680 - val_loss: 0.1343 - val_acc: 0.8866
Epoch 25/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1146 - acc: 0.9663 - val_loss: 0.1336 - val_acc: 0.8866
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1156 - acc: 0.9574 - val_loss: 0.1337 - val_acc: 0.9072
Epoch 27/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1121 - acc: 0.9716 - val_loss: 0.1333 - val_acc: 0.8969
Epoch 28/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1112 - acc: 0.9751 - val_loss: 0.1335 - val_acc: 0.8866
Epoch 29/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1123 - acc: 0.9734 - val_loss: 0.1332 - val_acc: 0.8866
Epoch 30/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1130 - acc: 0.9663 - val_loss: 0.1331 - val_acc: 0.8969
Epoch 31/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1122 - acc: 0.9751 - val_loss: 0.1329 - val_acc: 0.8969
Epoch 32/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1117 - acc: 0.9787 - val_loss: 0.1332 - val_acc: 0.8866
Epoch 33/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1099 - acc: 0.9858 - val_loss: 0.1336 - val_acc: 0.8763
Epoch 34/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1105 - acc: 0.9822 - val_loss: 0.1341 - val_acc: 0.8866
Manual evaluation: (didn't understand why I made this)
True 7341
False 1730
True percentage 0.809282328299
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.49      0.43      0.46       438
      B-LOC       0.54      0.58      0.56       218
      B-ORG       0.33      0.31      0.32       296
      I-ORG       0.16      0.44      0.23       151
      I-PER       0.71      0.08      0.14       214
      I-LOC       0.22      0.17      0.19       141
     B-MISC       0.16      0.03      0.05       141
     I-MISC       0.17      0.01      0.01       154

avg / total       0.86      0.81      0.82      9071

F-1 Score:
0.32101047443
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 88ms/step - loss: 0.3643 - acc: 0.2149 - val_loss: 0.1735 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2140 - acc: 0.8122 - val_loss: 0.1778 - val_acc: 0.8434
Epoch 3/70

29/29 [==============================] - 1s 22ms/step - loss: 0.2142 - acc: 0.7095 - val_loss: 0.1488 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1756 - acc: 0.8135 - val_loss: 0.1355 - val_acc: 0.8675
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1533 - acc: 0.8392 - val_loss: 0.1323 - val_acc: 0.8916
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1459 - acc: 0.8770 - val_loss: 0.1297 - val_acc: 0.9277
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1418 - acc: 0.8784 - val_loss: 0.1283 - val_acc: 0.9398
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1379 - acc: 0.8865 - val_loss: 0.1272 - val_acc: 0.9277
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1358 - acc: 0.8919 - val_loss: 0.1262 - val_acc: 0.9398
Epoch 10/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1360 - acc: 0.8946 - val_loss: 0.1258 - val_acc: 0.9518
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1353 - acc: 0.8946 - val_loss: 0.1254 - val_acc: 0.9518
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1330 - acc: 0.9000 - val_loss: 0.1248 - val_acc: 0.9398
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1304 - acc: 0.9122 - val_loss: 0.1245 - val_acc: 0.9518
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1286 - acc: 0.9108 - val_loss: 0.1244 - val_acc: 0.9518
Epoch 15/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1269 - acc: 0.9243 - val_loss: 0.1241 - val_acc: 0.9518
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1268 - acc: 0.9311 - val_loss: 0.1237 - val_acc: 0.9518
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1258 - acc: 0.9257 - val_loss: 0.1238 - val_acc: 0.9518
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1234 - acc: 0.9297 - val_loss: 0.1237 - val_acc: 0.9518
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1244 - acc: 0.9284 - val_loss: 0.1239 - val_acc: 0.9518
Epoch 20/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1225 - acc: 0.9405 - val_loss: 0.1238 - val_acc: 0.9518
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1209 - acc: 0.9324 - val_loss: 0.1238 - val_acc: 0.9518
Manual evaluation: (didn't understand why I made this)
True 7327
False 1744
True percentage 0.807738948297
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-ORG       0.27      0.43      0.34       296
      B-LOC       0.62      0.19      0.29       218
      I-ORG       0.17      0.58      0.26       151
     B-MISC       0.11      0.01      0.02       141
     I-MISC       0.54      0.09      0.16       154
      B-PER       0.62      0.38      0.47       438
      I-PER       0.78      0.24      0.37       214
      I-LOC       0.67      0.01      0.03       141

avg / total       0.88      0.81      0.82      9071

F-1 Score:
0.307740520213
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3497 - acc: 0.0639 - val_loss: 0.2095 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2056 - acc: 0.7940 - val_loss: 0.2386 - val_acc: 0.5567
Epoch 3/70

29/29 [==============================] - 1s 22ms/step - loss: 0.2367 - acc: 0.5897 - val_loss: 0.1752 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1738 - acc: 0.7975 - val_loss: 0.1532 - val_acc: 0.8557
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1549 - acc: 0.8277 - val_loss: 0.1497 - val_acc: 0.8557
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1479 - acc: 0.8472 - val_loss: 0.1468 - val_acc: 0.8660
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1425 - acc: 0.8721 - val_loss: 0.1446 - val_acc: 0.8763
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1416 - acc: 0.8810 - val_loss: 0.1425 - val_acc: 0.8660
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1373 - acc: 0.8934 - val_loss: 0.1408 - val_acc: 0.8763
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1338 - acc: 0.9130 - val_loss: 0.1394 - val_acc: 0.8763
Epoch 11/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1304 - acc: 0.9201 - val_loss: 0.1384 - val_acc: 0.8763
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1300 - acc: 0.9165 - val_loss: 0.1375 - val_acc: 0.8866
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1275 - acc: 0.9236 - val_loss: 0.1369 - val_acc: 0.8866
Epoch 14/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1260 - acc: 0.9307 - val_loss: 0.1354 - val_acc: 0.8866
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1243 - acc: 0.9254 - val_loss: 0.1350 - val_acc: 0.8866
Epoch 16/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1234 - acc: 0.9307 - val_loss: 0.1341 - val_acc: 0.8969
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1236 - acc: 0.9361 - val_loss: 0.1348 - val_acc: 0.8866
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1212 - acc: 0.9414 - val_loss: 0.1348 - val_acc: 0.8866
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1206 - acc: 0.9378 - val_loss: 0.1339 - val_acc: 0.8866
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1170 - acc: 0.9645 - val_loss: 0.1346 - val_acc: 0.8866
Epoch 21/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1194 - acc: 0.9485 - val_loss: 0.1343 - val_acc: 0.8866
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1160 - acc: 0.9591 - val_loss: 0.1332 - val_acc: 0.8866
Epoch 23/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1158 - acc: 0.9609 - val_loss: 0.1336 - val_acc: 0.8866
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1156 - acc: 0.9609 - val_loss: 0.1326 - val_acc: 0.8866
Epoch 25/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1139 - acc: 0.9663 - val_loss: 0.1330 - val_acc: 0.8763
Epoch 26/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1135 - acc: 0.9680 - val_loss: 0.1332 - val_acc: 0.8763
Epoch 27/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1130 - acc: 0.9751 - val_loss: 0.1329 - val_acc: 0.8866
Manual evaluation: (didn't understand why I made this)
True 7339
False 1732
True percentage 0.809061845442
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.93      0.95      7318
      B-PER       0.53      0.48      0.51       438
      B-LOC       0.53      0.64      0.58       218
      B-ORG       0.30      0.39      0.34       296
      I-ORG       0.15      0.35      0.21       151
      I-PER       0.83      0.05      0.09       214
      I-LOC       0.19      0.21      0.20       141
     B-MISC       0.25      0.01      0.01       141
     I-MISC       0.33      0.01      0.01       154

avg / total       0.87      0.81      0.83      9071

F-1 Score:
0.338062179294
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3481 - acc: 0.0784 - val_loss: 0.1830 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.2258 - acc: 0.8122 - val_loss: 0.1977 - val_acc: 0.8072
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2213 - acc: 0.7108 - val_loss: 0.1505 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1811 - acc: 0.8135 - val_loss: 0.1376 - val_acc: 0.9036
Epoch 5/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1518 - acc: 0.8392 - val_loss: 0.1336 - val_acc: 0.9157
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1463 - acc: 0.8703 - val_loss: 0.1326 - val_acc: 0.9157
Epoch 7/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1427 - acc: 0.8662 - val_loss: 0.1313 - val_acc: 0.9036
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1406 - acc: 0.8838 - val_loss: 0.1303 - val_acc: 0.9036
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1385 - acc: 0.8838 - val_loss: 0.1295 - val_acc: 0.9398
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1369 - acc: 0.8838 - val_loss: 0.1291 - val_acc: 0.9398
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1330 - acc: 0.9068 - val_loss: 0.1281 - val_acc: 0.9398
Epoch 12/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1321 - acc: 0.9081 - val_loss: 0.1280 - val_acc: 0.9277
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1304 - acc: 0.9068 - val_loss: 0.1271 - val_acc: 0.9398
Epoch 14/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1305 - acc: 0.9243 - val_loss: 0.1268 - val_acc: 0.9398
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1281 - acc: 0.9189 - val_loss: 0.1267 - val_acc: 0.9277
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1290 - acc: 0.9135 - val_loss: 0.1263 - val_acc: 0.9398
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1247 - acc: 0.9311 - val_loss: 0.1262 - val_acc: 0.9277
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1253 - acc: 0.9230 - val_loss: 0.1253 - val_acc: 0.9398
Epoch 19/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1233 - acc: 0.9311 - val_loss: 0.1253 - val_acc: 0.9398
Epoch 20/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1232 - acc: 0.9392 - val_loss: 0.1249 - val_acc: 0.9277
Epoch 21/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1208 - acc: 0.9297 - val_loss: 0.1251 - val_acc: 0.9277
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1209 - acc: 0.9338 - val_loss: 0.1252 - val_acc: 0.9398
Epoch 23/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1201 - acc: 0.9446 - val_loss: 0.1246 - val_acc: 0.9398
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1217 - acc: 0.9297 - val_loss: 0.1248 - val_acc: 0.9277
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1190 - acc: 0.9446 - val_loss: 0.1253 - val_acc: 0.9277
Epoch 26/70

29/29 [==============================] - 1s 23ms/step - loss: 0.1186 - acc: 0.9527 - val_loss: 0.1250 - val_acc: 0.9277
Manual evaluation: (didn't understand why I made this)
True 7310
False 1761
True percentage 0.805864844008
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.27      0.38      0.31       296
      B-LOC       0.69      0.17      0.27       218
      I-ORG       0.17      0.56      0.26       151
     B-MISC       0.08      0.01      0.01       141
     I-MISC       0.44      0.14      0.21       154
      B-PER       0.58      0.36      0.45       438
      I-PER       0.73      0.17      0.27       214
      I-LOC       0.75      0.02      0.04       141

avg / total       0.87      0.81      0.82      9071

F-1 Score:
0.290115532734
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103615 unique words.
3611 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631424     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,098
Trainable params: 7,140,098
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 3s 87ms/step - loss: 0.3858 - acc: 0.0089 - val_loss: 0.2019 - val_acc: 0.7938
Epoch 2/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1983 - acc: 0.7940 - val_loss: 0.2123 - val_acc: 0.7732
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.2125 - acc: 0.6963 - val_loss: 0.1730 - val_acc: 0.7938
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1728 - acc: 0.8028 - val_loss: 0.1513 - val_acc: 0.8247
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1518 - acc: 0.8419 - val_loss: 0.1476 - val_acc: 0.8454
Epoch 6/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1461 - acc: 0.8632 - val_loss: 0.1446 - val_acc: 0.8557
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1429 - acc: 0.8615 - val_loss: 0.1421 - val_acc: 0.8557
Epoch 8/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1388 - acc: 0.8899 - val_loss: 0.1407 - val_acc: 0.8763
Epoch 9/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1356 - acc: 0.9094 - val_loss: 0.1395 - val_acc: 0.8763
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1347 - acc: 0.9059 - val_loss: 0.1378 - val_acc: 0.8866
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1308 - acc: 0.9218 - val_loss: 0.1367 - val_acc: 0.8969
Epoch 12/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1291 - acc: 0.9183 - val_loss: 0.1362 - val_acc: 0.8969
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1282 - acc: 0.9094 - val_loss: 0.1354 - val_acc: 0.8969
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1260 - acc: 0.9130 - val_loss: 0.1359 - val_acc: 0.8969
Epoch 15/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1252 - acc: 0.9343 - val_loss: 0.1348 - val_acc: 0.8969
Epoch 16/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1231 - acc: 0.9396 - val_loss: 0.1353 - val_acc: 0.8969
Epoch 17/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1227 - acc: 0.9378 - val_loss: 0.1338 - val_acc: 0.8866
Epoch 18/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1219 - acc: 0.9361 - val_loss: 0.1335 - val_acc: 0.8969
Epoch 19/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1189 - acc: 0.9520 - val_loss: 0.1327 - val_acc: 0.8969
Epoch 20/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1197 - acc: 0.9449 - val_loss: 0.1342 - val_acc: 0.8969
Epoch 21/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1163 - acc: 0.9574 - val_loss: 0.1321 - val_acc: 0.8969
Epoch 22/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1166 - acc: 0.9591 - val_loss: 0.1327 - val_acc: 0.8969
Epoch 23/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1178 - acc: 0.9520 - val_loss: 0.1320 - val_acc: 0.8969
Epoch 24/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1158 - acc: 0.9663 - val_loss: 0.1315 - val_acc: 0.9072
Epoch 25/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1148 - acc: 0.9663 - val_loss: 0.1325 - val_acc: 0.8866
Epoch 26/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1134 - acc: 0.9680 - val_loss: 0.1332 - val_acc: 0.9072
Epoch 27/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1136 - acc: 0.9680 - val_loss: 0.1334 - val_acc: 0.8763
Manual evaluation: (didn't understand why I made this)
True 7356
False 1715
True percentage 0.81093594973
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.94      0.95      7318
      B-PER       0.56      0.41      0.47       438
      B-LOC       0.52      0.52      0.52       218
      B-ORG       0.29      0.34      0.32       296
      I-ORG       0.18      0.44      0.26       151
      I-PER       1.00      0.03      0.06       214
      I-LOC       0.24      0.23      0.23       141
     B-MISC       0.20      0.03      0.05       141
     I-MISC       0.33      0.01      0.01       154

avg / total       0.87      0.81      0.82      9071

F-1 Score:
0.319269521411
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.02 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103629 unique words.
3625 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 282
OOV word occurences: 558
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6632320     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,140,994
Trainable params: 7,140,994
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 29 samples, validate on 4 samples
Epoch 1/70

29/29 [==============================] - 2s 85ms/step - loss: 0.3719 - acc: 0.0257 - val_loss: 0.1617 - val_acc: 0.8795
Epoch 2/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1893 - acc: 0.8108 - val_loss: 0.1530 - val_acc: 0.8675
Epoch 3/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1722 - acc: 0.8270 - val_loss: 0.1454 - val_acc: 0.8795
Epoch 4/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1628 - acc: 0.8135 - val_loss: 0.1415 - val_acc: 0.9036
Epoch 5/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1506 - acc: 0.8473 - val_loss: 0.1343 - val_acc: 0.8795
Epoch 6/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1439 - acc: 0.8635 - val_loss: 0.1326 - val_acc: 0.9157
Epoch 7/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1401 - acc: 0.8797 - val_loss: 0.1315 - val_acc: 0.9277
Epoch 8/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1351 - acc: 0.8905 - val_loss: 0.1308 - val_acc: 0.9398
Epoch 9/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1352 - acc: 0.8946 - val_loss: 0.1306 - val_acc: 0.9398
Epoch 10/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1331 - acc: 0.9014 - val_loss: 0.1305 - val_acc: 0.9398
Epoch 11/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1292 - acc: 0.9108 - val_loss: 0.1301 - val_acc: 0.9398
Epoch 12/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1300 - acc: 0.9054 - val_loss: 0.1304 - val_acc: 0.9398
Epoch 13/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1254 - acc: 0.9230 - val_loss: 0.1299 - val_acc: 0.9398
Epoch 14/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1259 - acc: 0.9216 - val_loss: 0.1302 - val_acc: 0.9398
Epoch 15/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1249 - acc: 0.9257 - val_loss: 0.1298 - val_acc: 0.9398
Epoch 16/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1264 - acc: 0.9108 - val_loss: 0.1305 - val_acc: 0.9398
Epoch 17/70

29/29 [==============================] - 1s 22ms/step - loss: 0.1224 - acc: 0.9351 - val_loss: 0.1305 - val_acc: 0.9398
Epoch 18/70

29/29 [==============================] - 1s 21ms/step - loss: 0.1209 - acc: 0.9378 - val_loss: 0.1303 - val_acc: 0.9398
Manual evaluation: (didn't understand why I made this)
True 7278
False 1793
True percentage 0.802337118289
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-ORG       0.25      0.51      0.33       296
      B-LOC       0.75      0.15      0.25       218
      I-ORG       0.18      0.59      0.27       151
     B-MISC       0.08      0.01      0.01       141
     I-MISC       0.38      0.02      0.04       154
      B-PER       0.63      0.30      0.40       438
      I-PER       0.61      0.22      0.32       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.86      0.80      0.82      9071

F-1 Score:
0.282155091872
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 169ms/step - loss: 0.3305 - acc: 0.1352 - val_loss: 0.1319 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.2244 - acc: 0.7829 - val_loss: 0.1416 - val_acc: 0.8667
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1719 - acc: 0.7722 - val_loss: 0.1176 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1528 - acc: 0.8221 - val_loss: 0.1176 - val_acc: 0.9667
Epoch 5/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1455 - acc: 0.8719 - val_loss: 0.1157 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1402 - acc: 0.8719 - val_loss: 0.1149 - val_acc: 0.9667
Epoch 7/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1351 - acc: 0.9039 - val_loss: 0.1147 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1344 - acc: 0.9075 - val_loss: 0.1161 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1302 - acc: 0.9181 - val_loss: 0.1139 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1279 - acc: 0.9146 - val_loss: 0.1147 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1266 - acc: 0.9324 - val_loss: 0.1132 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1228 - acc: 0.9466 - val_loss: 0.1144 - val_acc: 0.9000
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1230 - acc: 0.9431 - val_loss: 0.1133 - val_acc: 0.9667
Epoch 14/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1212 - acc: 0.9395 - val_loss: 0.1121 - val_acc: 0.9667
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1168 - acc: 0.9680 - val_loss: 0.1130 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1166 - acc: 0.9680 - val_loss: 0.1108 - val_acc: 0.9667
Epoch 17/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1148 - acc: 0.9715 - val_loss: 0.1097 - val_acc: 0.9667
Epoch 18/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1151 - acc: 0.9786 - val_loss: 0.1109 - val_acc: 0.9333
Epoch 19/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1140 - acc: 0.9680 - val_loss: 0.1110 - val_acc: 0.9667
Epoch 20/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1125 - acc: 0.9822 - val_loss: 0.1100 - val_acc: 1.0000
Manual evaluation: (didn't understand why I made this)
True 7263
False 1808
True percentage 0.800683496858
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.40      0.42      0.41       438
      B-LOC       0.42      0.61      0.50       218
      B-ORG       0.29      0.15      0.20       296
      I-ORG       0.11      0.16      0.13       151
      I-PER       0.80      0.02      0.04       214
      I-LOC       0.20      0.38      0.27       141
     B-MISC       0.13      0.04      0.06       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.279676817899
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 160ms/step - loss: 0.3331 - acc: 0.0712 - val_loss: 0.1529 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1798 - acc: 0.8074 - val_loss: 0.2058 - val_acc: 0.6833
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2105 - acc: 0.6359 - val_loss: 0.1400 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1635 - acc: 0.8127 - val_loss: 0.1363 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1457 - acc: 0.8813 - val_loss: 0.1328 - val_acc: 0.9167
Epoch 6/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1417 - acc: 0.8654 - val_loss: 0.1320 - val_acc: 0.9167
Epoch 7/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1378 - acc: 0.8945 - val_loss: 0.1291 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1352 - acc: 0.8945 - val_loss: 0.1272 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1279 - acc: 0.9156 - val_loss: 0.1260 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1282 - acc: 0.9208 - val_loss: 0.1255 - val_acc: 0.9167
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1246 - acc: 0.9367 - val_loss: 0.1255 - val_acc: 0.9167
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1275 - acc: 0.9103 - val_loss: 0.1235 - val_acc: 0.9333
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1229 - acc: 0.9340 - val_loss: 0.1227 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1195 - acc: 0.9446 - val_loss: 0.1224 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1186 - acc: 0.9472 - val_loss: 0.1239 - val_acc: 0.9167
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1199 - acc: 0.9472 - val_loss: 0.1215 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1195 - acc: 0.9420 - val_loss: 0.1211 - val_acc: 0.9167
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1154 - acc: 0.9551 - val_loss: 0.1199 - val_acc: 0.9333
Epoch 19/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1149 - acc: 0.9604 - val_loss: 0.1204 - val_acc: 0.9167
Epoch 20/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1136 - acc: 0.9631 - val_loss: 0.1196 - val_acc: 0.9167
Epoch 21/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1142 - acc: 0.9657 - val_loss: 0.1193 - val_acc: 0.9500
Epoch 22/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1094 - acc: 0.9894 - val_loss: 0.1194 - val_acc: 0.9333
Epoch 23/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1120 - acc: 0.9789 - val_loss: 0.1194 - val_acc: 0.9167
Epoch 24/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1094 - acc: 0.9789 - val_loss: 0.1182 - val_acc: 0.9167
Epoch 25/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1090 - acc: 0.9842 - val_loss: 0.1178 - val_acc: 0.9500
Epoch 26/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1089 - acc: 0.9868 - val_loss: 0.1184 - val_acc: 0.9500
Epoch 27/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1102 - acc: 0.9815 - val_loss: 0.1186 - val_acc: 0.9333
Epoch 28/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1075 - acc: 0.9921 - val_loss: 0.1186 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7235
False 1836
True percentage 0.797596736854
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.19      0.24      0.21       296
      B-LOC       0.65      0.17      0.26       218
      I-ORG       0.16      0.50      0.24       151
     B-MISC       0.09      0.05      0.06       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.58      0.35      0.44       438
      I-PER       0.64      0.19      0.29       214
      I-LOC       0.64      0.05      0.09       141

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.251928020566
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 159ms/step - loss: 0.3458 - acc: 0.0427 - val_loss: 0.1415 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2252 - acc: 0.7829 - val_loss: 0.1455 - val_acc: 0.9000
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1735 - acc: 0.8078 - val_loss: 0.1219 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1554 - acc: 0.8078 - val_loss: 0.1224 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1442 - acc: 0.8577 - val_loss: 0.1221 - val_acc: 0.9000
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1387 - acc: 0.8790 - val_loss: 0.1226 - val_acc: 0.9000
Manual evaluation: (didn't understand why I made this)
True 7069
False 2002
True percentage 0.779296659685
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.98      0.91      0.94      7318
      B-PER       0.28      0.37      0.32       438
      B-LOC       0.31      0.70      0.43       218
      B-ORG       0.20      0.11      0.15       296
      I-ORG       0.12      0.14      0.13       151
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.18      0.38      0.25       141
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.82      0.78      0.80      9071

F-1 Score:
0.24449594438
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 162ms/step - loss: 0.3116 - acc: 0.2744 - val_loss: 0.1678 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2190 - acc: 0.8074 - val_loss: 0.1918 - val_acc: 0.7833
Epoch 3/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2107 - acc: 0.6992 - val_loss: 0.1422 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1721 - acc: 0.8074 - val_loss: 0.1378 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1476 - acc: 0.8443 - val_loss: 0.1353 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1431 - acc: 0.8654 - val_loss: 0.1350 - val_acc: 0.8833
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1387 - acc: 0.8945 - val_loss: 0.1326 - val_acc: 0.9167
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1353 - acc: 0.9024 - val_loss: 0.1338 - val_acc: 0.9167
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1307 - acc: 0.9156 - val_loss: 0.1311 - val_acc: 0.9167
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1307 - acc: 0.9077 - val_loss: 0.1302 - val_acc: 0.9167
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1279 - acc: 0.9340 - val_loss: 0.1284 - val_acc: 0.9167
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1242 - acc: 0.9288 - val_loss: 0.1293 - val_acc: 0.9167
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1243 - acc: 0.9367 - val_loss: 0.1281 - val_acc: 0.9167
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1222 - acc: 0.9367 - val_loss: 0.1271 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1213 - acc: 0.9446 - val_loss: 0.1256 - val_acc: 0.9167
Epoch 16/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1201 - acc: 0.9340 - val_loss: 0.1283 - val_acc: 0.9000
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1196 - acc: 0.9472 - val_loss: 0.1258 - val_acc: 0.9167
Epoch 18/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1195 - acc: 0.9367 - val_loss: 0.1253 - val_acc: 0.9167
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1161 - acc: 0.9604 - val_loss: 0.1261 - val_acc: 0.9000
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1144 - acc: 0.9657 - val_loss: 0.1261 - val_acc: 0.9000
Epoch 21/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1150 - acc: 0.9604 - val_loss: 0.1249 - val_acc: 0.9167
Epoch 22/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1156 - acc: 0.9525 - val_loss: 0.1230 - val_acc: 0.9333
Epoch 23/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1135 - acc: 0.9604 - val_loss: 0.1241 - val_acc: 0.9167
Epoch 24/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1136 - acc: 0.9631 - val_loss: 0.1237 - val_acc: 0.9167
Epoch 25/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1113 - acc: 0.9789 - val_loss: 0.1240 - val_acc: 0.9167
Manual evaluation: (didn't understand why I made this)
True 7223
False 1848
True percentage 0.796273839709
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.95      7318
      B-ORG       0.20      0.29      0.24       296
      B-LOC       0.68      0.09      0.15       218
      I-ORG       0.16      0.62      0.26       151
     B-MISC       0.07      0.02      0.03       141
     I-MISC       0.25      0.01      0.01       154
      B-PER       0.58      0.32      0.42       438
      I-PER       0.64      0.20      0.31       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.245480494767
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 163ms/step - loss: 0.3226 - acc: 0.2100 - val_loss: 0.1241 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2106 - acc: 0.7829 - val_loss: 0.1398 - val_acc: 0.9000
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1754 - acc: 0.7972 - val_loss: 0.1175 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1545 - acc: 0.8149 - val_loss: 0.1199 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1419 - acc: 0.8826 - val_loss: 0.1168 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1364 - acc: 0.8968 - val_loss: 0.1165 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1334 - acc: 0.9110 - val_loss: 0.1141 - val_acc: 0.9667
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1306 - acc: 0.9217 - val_loss: 0.1158 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1273 - acc: 0.9431 - val_loss: 0.1141 - val_acc: 0.9667
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1260 - acc: 0.9359 - val_loss: 0.1144 - val_acc: 0.9000
Manual evaluation: (didn't understand why I made this)
True 7251
False 1820
True percentage 0.799360599713
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.93      0.95      7318
      B-PER       0.39      0.47      0.42       438
      B-LOC       0.39      0.67      0.49       218
      B-ORG       0.34      0.12      0.18       296
      I-ORG       0.14      0.19      0.16       151
      I-PER       1.00      0.00      0.01       214
      I-LOC       0.18      0.34      0.23       141
     B-MISC       0.10      0.01      0.01       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.285187461586
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 160ms/step - loss: 0.3569 - acc: 0.0449 - val_loss: 0.1593 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1936 - acc: 0.8074 - val_loss: 0.1732 - val_acc: 0.8333
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1963 - acc: 0.7230 - val_loss: 0.1464 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1747 - acc: 0.8074 - val_loss: 0.1408 - val_acc: 0.9333
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1527 - acc: 0.8443 - val_loss: 0.1336 - val_acc: 0.9500
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1438 - acc: 0.8602 - val_loss: 0.1321 - val_acc: 0.9500
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1402 - acc: 0.8786 - val_loss: 0.1304 - val_acc: 0.9500
Epoch 8/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1365 - acc: 0.9024 - val_loss: 0.1271 - val_acc: 0.9500
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1339 - acc: 0.8918 - val_loss: 0.1259 - val_acc: 0.9500
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1282 - acc: 0.9129 - val_loss: 0.1239 - val_acc: 0.9500
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1267 - acc: 0.9182 - val_loss: 0.1232 - val_acc: 0.9500
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1271 - acc: 0.9314 - val_loss: 0.1223 - val_acc: 0.9500
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1219 - acc: 0.9499 - val_loss: 0.1201 - val_acc: 0.9667
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1229 - acc: 0.9393 - val_loss: 0.1208 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1200 - acc: 0.9420 - val_loss: 0.1190 - val_acc: 0.9667
Epoch 16/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1172 - acc: 0.9551 - val_loss: 0.1179 - val_acc: 0.9667
Epoch 17/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1173 - acc: 0.9525 - val_loss: 0.1172 - val_acc: 0.9667
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1166 - acc: 0.9604 - val_loss: 0.1172 - val_acc: 0.9500
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1149 - acc: 0.9657 - val_loss: 0.1162 - val_acc: 0.9500
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1129 - acc: 0.9736 - val_loss: 0.1156 - val_acc: 0.9667
Epoch 21/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1133 - acc: 0.9683 - val_loss: 0.1150 - val_acc: 0.9667
Epoch 22/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1123 - acc: 0.9710 - val_loss: 0.1150 - val_acc: 0.9667
Epoch 23/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1112 - acc: 0.9710 - val_loss: 0.1138 - val_acc: 0.9833
Epoch 24/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1120 - acc: 0.9789 - val_loss: 0.1140 - val_acc: 0.9833
Epoch 25/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1111 - acc: 0.9631 - val_loss: 0.1131 - val_acc: 0.9667
Epoch 26/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1099 - acc: 0.9815 - val_loss: 0.1143 - val_acc: 0.9833
Epoch 27/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1096 - acc: 0.9815 - val_loss: 0.1132 - val_acc: 0.9833
Epoch 28/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1104 - acc: 0.9736 - val_loss: 0.1128 - val_acc: 0.9833
Epoch 29/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1081 - acc: 0.9947 - val_loss: 0.1119 - val_acc: 0.9833
Epoch 30/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1081 - acc: 0.9868 - val_loss: 0.1130 - val_acc: 0.9667
Epoch 31/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1072 - acc: 0.9894 - val_loss: 0.1124 - val_acc: 0.9667
Epoch 32/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1078 - acc: 0.9894 - val_loss: 0.1114 - val_acc: 0.9667
Epoch 33/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1073 - acc: 0.9868 - val_loss: 0.1112 - val_acc: 0.9667
Epoch 34/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1064 - acc: 0.9947 - val_loss: 0.1113 - val_acc: 0.9667
Epoch 35/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1066 - acc: 0.9921 - val_loss: 0.1108 - val_acc: 0.9667
Epoch 36/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1060 - acc: 0.9868 - val_loss: 0.1097 - val_acc: 0.9667
Epoch 37/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1057 - acc: 0.9894 - val_loss: 0.1096 - val_acc: 0.9667
Epoch 38/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1053 - acc: 0.9974 - val_loss: 0.1099 - val_acc: 0.9833
Epoch 39/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1063 - acc: 0.9894 - val_loss: 0.1102 - val_acc: 0.9833
Epoch 40/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1057 - acc: 0.9868 - val_loss: 0.1095 - val_acc: 0.9667
Epoch 41/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1038 - acc: 0.9921 - val_loss: 0.1096 - val_acc: 0.9667
Epoch 42/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1049 - acc: 0.9974 - val_loss: 0.1095 - val_acc: 0.9667
Epoch 43/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1041 - acc: 0.9947 - val_loss: 0.1097 - val_acc: 0.9667
Epoch 44/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1039 - acc: 0.9974 - val_loss: 0.1090 - val_acc: 0.9667
Epoch 45/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1036 - acc: 0.9974 - val_loss: 0.1094 - val_acc: 0.9667
Epoch 46/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1040 - acc: 0.9974 - val_loss: 0.1093 - val_acc: 0.9667
Epoch 47/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1053 - acc: 0.9842 - val_loss: 0.1086 - val_acc: 0.9667
Epoch 48/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1032 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9667
Epoch 49/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1028 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9667
Epoch 50/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1047 - acc: 0.9947 - val_loss: 0.1099 - val_acc: 0.9667
Epoch 51/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1049 - acc: 0.9868 - val_loss: 0.1101 - val_acc: 0.9667
Manual evaluation: (didn't understand why I made this)
True 7260
False 1811
True percentage 0.800352772572
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.95      7318
      B-ORG       0.23      0.31      0.26       296
      B-LOC       0.69      0.19      0.30       218
      I-ORG       0.18      0.58      0.27       151
     B-MISC       0.15      0.06      0.08       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.51      0.35      0.42       438
      I-PER       0.70      0.19      0.30       214
      I-LOC       0.90      0.06      0.12       141

avg / total       0.86      0.80      0.81      9071

F-1 Score:
0.27487244898
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 158ms/step - loss: 0.3949 - acc: 0.0320 - val_loss: 0.1393 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 24ms/step - loss: 0.2208 - acc: 0.7829 - val_loss: 0.1375 - val_acc: 0.9333
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1817 - acc: 0.7829 - val_loss: 0.1233 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1631 - acc: 0.7972 - val_loss: 0.1210 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1528 - acc: 0.8256 - val_loss: 0.1184 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1437 - acc: 0.8826 - val_loss: 0.1181 - val_acc: 0.9000
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1385 - acc: 0.8897 - val_loss: 0.1173 - val_acc: 0.9000
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1364 - acc: 0.9004 - val_loss: 0.1171 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1297 - acc: 0.9146 - val_loss: 0.1168 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1285 - acc: 0.9181 - val_loss: 0.1162 - val_acc: 0.9000
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1262 - acc: 0.9466 - val_loss: 0.1165 - val_acc: 0.9000
Epoch 12/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1231 - acc: 0.9431 - val_loss: 0.1140 - val_acc: 0.9667
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1214 - acc: 0.9537 - val_loss: 0.1155 - val_acc: 0.9000
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1201 - acc: 0.9609 - val_loss: 0.1149 - val_acc: 0.9333
Epoch 15/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1202 - acc: 0.9466 - val_loss: 0.1153 - val_acc: 0.9000
Manual evaluation: (didn't understand why I made this)
True 7176
False 1895
True percentage 0.791092492559
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.97      0.92      0.95      7318
      B-PER       0.37      0.44      0.40       438
      B-LOC       0.39      0.59      0.47       218
      B-ORG       0.26      0.17      0.20       296
      I-ORG       0.12      0.19      0.15       151
      I-PER       0.43      0.01      0.03       214
      I-LOC       0.15      0.27      0.19       141
     B-MISC       0.11      0.04      0.05       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.79      0.81      9071

F-1 Score:
0.265830346476
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 161ms/step - loss: 0.3727 - acc: 0.0158 - val_loss: 0.1592 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.2097 - acc: 0.8074 - val_loss: 0.1518 - val_acc: 0.8667
Epoch 3/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1718 - acc: 0.8179 - val_loss: 0.1344 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1546 - acc: 0.8232 - val_loss: 0.1369 - val_acc: 0.8833
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1462 - acc: 0.8654 - val_loss: 0.1301 - val_acc: 0.9333
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1387 - acc: 0.8865 - val_loss: 0.1305 - val_acc: 0.9333
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1348 - acc: 0.8865 - val_loss: 0.1283 - val_acc: 0.9333
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1318 - acc: 0.8945 - val_loss: 0.1285 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1296 - acc: 0.9129 - val_loss: 0.1277 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1275 - acc: 0.9050 - val_loss: 0.1268 - val_acc: 0.9167
Epoch 11/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1243 - acc: 0.9261 - val_loss: 0.1272 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1255 - acc: 0.9050 - val_loss: 0.1248 - val_acc: 0.9167
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1233 - acc: 0.9446 - val_loss: 0.1251 - val_acc: 0.9167
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1194 - acc: 0.9472 - val_loss: 0.1244 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1193 - acc: 0.9499 - val_loss: 0.1235 - val_acc: 0.9167
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1183 - acc: 0.9472 - val_loss: 0.1229 - val_acc: 0.9333
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1167 - acc: 0.9551 - val_loss: 0.1229 - val_acc: 0.9167
Epoch 18/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1140 - acc: 0.9657 - val_loss: 0.1214 - val_acc: 0.9500
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1155 - acc: 0.9578 - val_loss: 0.1214 - val_acc: 0.9500
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1146 - acc: 0.9525 - val_loss: 0.1212 - val_acc: 0.9500
Epoch 21/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1112 - acc: 0.9736 - val_loss: 0.1214 - val_acc: 0.9333
Epoch 22/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1121 - acc: 0.9763 - val_loss: 0.1208 - val_acc: 0.9500
Epoch 23/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1117 - acc: 0.9736 - val_loss: 0.1207 - val_acc: 0.9333
Epoch 24/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1131 - acc: 0.9736 - val_loss: 0.1203 - val_acc: 0.9500
Epoch 25/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1103 - acc: 0.9815 - val_loss: 0.1207 - val_acc: 0.9333
Epoch 26/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1115 - acc: 0.9710 - val_loss: 0.1206 - val_acc: 0.9500
Epoch 27/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1099 - acc: 0.9763 - val_loss: 0.1192 - val_acc: 0.9500
Epoch 28/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1090 - acc: 0.9789 - val_loss: 0.1196 - val_acc: 0.9500
Epoch 29/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1085 - acc: 0.9789 - val_loss: 0.1202 - val_acc: 0.9333
Epoch 30/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1096 - acc: 0.9736 - val_loss: 0.1187 - val_acc: 0.9667
Epoch 31/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1088 - acc: 0.9815 - val_loss: 0.1179 - val_acc: 0.9500
Epoch 32/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1077 - acc: 0.9815 - val_loss: 0.1191 - val_acc: 0.9500
Epoch 33/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1065 - acc: 0.9947 - val_loss: 0.1179 - val_acc: 0.9500
Epoch 34/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1077 - acc: 0.9842 - val_loss: 0.1189 - val_acc: 0.9500
Manual evaluation: (didn't understand why I made this)
True 7224
False 1847
True percentage 0.796384081138
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.95      7318
      B-ORG       0.21      0.28      0.24       296
      B-LOC       0.65      0.17      0.27       218
      I-ORG       0.15      0.48      0.23       151
     B-MISC       0.10      0.04      0.06       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.51      0.35      0.42       438
      I-PER       0.52      0.20      0.28       214
      I-LOC       0.67      0.03      0.05       141

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.25452237385
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103602 unique words.
3598 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 281
OOV word occurences: 562
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630592     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,266
Trainable params: 7,139,266
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 163ms/step - loss: 0.3883 - acc: 0.0142 - val_loss: 0.1404 - val_acc: 0.9333
Epoch 2/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1955 - acc: 0.7829 - val_loss: 0.1469 - val_acc: 0.8667
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1896 - acc: 0.7473 - val_loss: 0.1254 - val_acc: 0.9333
Epoch 4/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1862 - acc: 0.7829 - val_loss: 0.1323 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1567 - acc: 0.8327 - val_loss: 0.1184 - val_acc: 0.9667
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1439 - acc: 0.8719 - val_loss: 0.1185 - val_acc: 0.9667
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1377 - acc: 0.8826 - val_loss: 0.1172 - val_acc: 0.9667
Epoch 8/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1345 - acc: 0.9110 - val_loss: 0.1176 - val_acc: 0.9000
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1326 - acc: 0.8897 - val_loss: 0.1161 - val_acc: 0.9333
Epoch 10/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1280 - acc: 0.9395 - val_loss: 0.1164 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1248 - acc: 0.9431 - val_loss: 0.1157 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1251 - acc: 0.9253 - val_loss: 0.1169 - val_acc: 0.9000
Epoch 13/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1240 - acc: 0.9502 - val_loss: 0.1158 - val_acc: 0.9333
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1199 - acc: 0.9644 - val_loss: 0.1162 - val_acc: 0.9333
Manual evaluation: (didn't understand why I made this)
True 7227
False 1844
True percentage 0.796714805424
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.94      7318
      B-PER       0.40      0.39      0.40       438
      B-LOC       0.40      0.68      0.50       218
      B-ORG       0.35      0.15      0.21       296
      I-ORG       0.14      0.19      0.16       151
      I-PER       0.75      0.03      0.05       214
      I-LOC       0.16      0.35      0.22       141
     B-MISC       0.14      0.04      0.07       141
     I-MISC       0.00      0.00      0.00       154

avg / total       0.84      0.80      0.81      9071

F-1 Score:
0.280593325093
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.01 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103611 unique words.
3607 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6631168     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,842
Trainable params: 7,139,842
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 14 samples, validate on 2 samples
Epoch 1/70

14/14 [==============================] - 2s 157ms/step - loss: 0.3631 - acc: 0.1135 - val_loss: 0.1634 - val_acc: 0.9000
Epoch 2/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1975 - acc: 0.8074 - val_loss: 0.1583 - val_acc: 0.8667
Epoch 3/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1688 - acc: 0.8153 - val_loss: 0.1410 - val_acc: 0.9000
Epoch 4/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1545 - acc: 0.8338 - val_loss: 0.1415 - val_acc: 0.9000
Epoch 5/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1437 - acc: 0.8707 - val_loss: 0.1349 - val_acc: 0.9500
Epoch 6/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1381 - acc: 0.8734 - val_loss: 0.1337 - val_acc: 0.9167
Epoch 7/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1347 - acc: 0.9103 - val_loss: 0.1315 - val_acc: 0.9500
Epoch 8/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1298 - acc: 0.9077 - val_loss: 0.1309 - val_acc: 0.9333
Epoch 9/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1275 - acc: 0.9235 - val_loss: 0.1317 - val_acc: 0.9000
Epoch 10/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1256 - acc: 0.9314 - val_loss: 0.1286 - val_acc: 0.9333
Epoch 11/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1224 - acc: 0.9340 - val_loss: 0.1287 - val_acc: 0.9333
Epoch 12/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1228 - acc: 0.9340 - val_loss: 0.1277 - val_acc: 0.9167
Epoch 13/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1196 - acc: 0.9420 - val_loss: 0.1274 - val_acc: 0.9167
Epoch 14/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1198 - acc: 0.9393 - val_loss: 0.1258 - val_acc: 0.9167
Epoch 15/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1168 - acc: 0.9604 - val_loss: 0.1248 - val_acc: 0.9333
Epoch 16/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1168 - acc: 0.9578 - val_loss: 0.1268 - val_acc: 0.9167
Epoch 17/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1135 - acc: 0.9710 - val_loss: 0.1237 - val_acc: 0.9333
Epoch 18/70

14/14 [==============================] - 0s 24ms/step - loss: 0.1143 - acc: 0.9578 - val_loss: 0.1245 - val_acc: 0.9167
Epoch 19/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1156 - acc: 0.9578 - val_loss: 0.1226 - val_acc: 0.9333
Epoch 20/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1126 - acc: 0.9683 - val_loss: 0.1222 - val_acc: 0.9500
Epoch 21/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1122 - acc: 0.9631 - val_loss: 0.1243 - val_acc: 0.9167
Epoch 22/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1134 - acc: 0.9657 - val_loss: 0.1235 - val_acc: 0.9333
Epoch 23/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1118 - acc: 0.9710 - val_loss: 0.1213 - val_acc: 0.9500
Epoch 24/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1121 - acc: 0.9683 - val_loss: 0.1223 - val_acc: 0.9667
Epoch 25/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1107 - acc: 0.9657 - val_loss: 0.1214 - val_acc: 0.9500
Epoch 26/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1076 - acc: 0.9868 - val_loss: 0.1211 - val_acc: 0.9333
Epoch 27/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1094 - acc: 0.9815 - val_loss: 0.1216 - val_acc: 0.9333
Epoch 28/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1095 - acc: 0.9763 - val_loss: 0.1212 - val_acc: 0.9333
Epoch 29/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1079 - acc: 0.9947 - val_loss: 0.1209 - val_acc: 0.9500
Epoch 30/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1072 - acc: 0.9947 - val_loss: 0.1206 - val_acc: 0.9333
Epoch 31/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1079 - acc: 0.9894 - val_loss: 0.1203 - val_acc: 0.9500
Epoch 32/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1067 - acc: 0.9894 - val_loss: 0.1208 - val_acc: 0.9500
Epoch 33/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1073 - acc: 0.9763 - val_loss: 0.1190 - val_acc: 0.9333
Epoch 34/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1056 - acc: 0.9974 - val_loss: 0.1202 - val_acc: 0.9333
Epoch 35/70

14/14 [==============================] - 0s 26ms/step - loss: 0.1061 - acc: 0.9894 - val_loss: 0.1198 - val_acc: 0.9333
Epoch 36/70

14/14 [==============================] - 0s 25ms/step - loss: 0.1056 - acc: 0.9894 - val_loss: 0.1198 - val_acc: 0.9500
Manual evaluation: (didn't understand why I made this)
True 7274
False 1797
True percentage 0.801896152574
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.94      0.95      7318
      B-ORG       0.24      0.31      0.27       296
      B-LOC       0.73      0.19      0.30       218
      I-ORG       0.17      0.59      0.26       151
     B-MISC       0.11      0.06      0.08       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.58      0.33      0.42       438
      I-PER       0.58      0.17      0.26       214
      I-LOC       0.55      0.04      0.08       141

avg / total       0.85      0.80      0.81      9071

F-1 Score:
0.267008985879
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 306ms/step - loss: 0.4014 - acc: 0.0556 - val_loss: 0.1870 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2075 - acc: 0.7778 - val_loss: 0.1748 - val_acc: 0.8966
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1757 - acc: 0.8810 - val_loss: 0.1888 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1637 - acc: 0.8333 - val_loss: 0.1711 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1470 - acc: 0.9206 - val_loss: 0.1680 - val_acc: 0.8621
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1441 - acc: 0.9206 - val_loss: 0.1756 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1661 - val_acc: 0.8621
Epoch 8/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1318 - acc: 0.9683 - val_loss: 0.1719 - val_acc: 0.8621
Epoch 9/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1353 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.8621
Epoch 10/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1313 - acc: 0.9762 - val_loss: 0.1649 - val_acc: 0.8621
Epoch 11/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1340 - acc: 0.9444 - val_loss: 0.1565 - val_acc: 0.8621
Epoch 12/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1264 - acc: 0.9762 - val_loss: 0.1578 - val_acc: 0.8621
Epoch 13/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1228 - acc: 0.9683 - val_loss: 0.1606 - val_acc: 0.8621
Epoch 14/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1231 - acc: 0.9921 - val_loss: 0.1586 - val_acc: 0.8621
Manual evaluation: (didn't understand why I made this)
True 7160
False 1757
True percentage 0.802960636986
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.92      0.94      7318
      B-PER       0.43      0.36      0.39       438
      B-LOC       0.34      0.61      0.44       218
      B-ORG       0.21      0.16      0.18       296
      I-ORG       0.14      0.42      0.21       151
      I-PER       0.26      0.05      0.08       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.80      0.81      8917

F-1 Score:
0.26588845655
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 303ms/step - loss: 0.3380 - acc: 0.1296 - val_loss: 0.2176 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2037 - acc: 0.7963 - val_loss: 0.2792 - val_acc: 0.5000
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2293 - acc: 0.5802 - val_loss: 0.1892 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1620 - acc: 0.8025 - val_loss: 0.1769 - val_acc: 0.8421
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1419 - acc: 0.8519 - val_loss: 0.1747 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1349 - acc: 0.8951 - val_loss: 0.1757 - val_acc: 0.8421
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1334 - acc: 0.9074 - val_loss: 0.1742 - val_acc: 0.8421
Epoch 8/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1258 - acc: 0.9259 - val_loss: 0.1763 - val_acc: 0.8421
Epoch 9/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1240 - acc: 0.9383 - val_loss: 0.1747 - val_acc: 0.8421
Epoch 10/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1231 - acc: 0.9198 - val_loss: 0.1780 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7123
False 1948
True percentage 0.785249696836
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.94      0.94      7318
      B-ORG       0.21      0.29      0.24       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.14      0.60      0.22       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.57      0.17      0.26       438
      I-PER       0.33      0.01      0.02       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.80      0.79      0.78      9071

F-1 Score:
0.170385395538
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 303ms/step - loss: 0.3675 - acc: 0.0873 - val_loss: 0.2189 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2368 - acc: 0.7698 - val_loss: 0.2046 - val_acc: 0.7931
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2100 - acc: 0.7540 - val_loss: 0.1847 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1736 - acc: 0.7778 - val_loss: 0.1779 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1656 - acc: 0.8333 - val_loss: 0.1803 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1484 - acc: 0.9048 - val_loss: 0.1851 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1451 - acc: 0.8889 - val_loss: 0.1834 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7245
False 1672
True percentage 0.812492990916
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.94      0.94      7318
      B-PER       0.40      0.45      0.42       438
      B-LOC       0.44      0.47      0.46       218
      B-ORG       0.28      0.12      0.17       296
      I-ORG       0.16      0.40      0.23       151
      I-PER       0.50      0.02      0.04       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.81      0.81      8917

F-1 Score:
0.281690140845
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 300ms/step - loss: 0.3394 - acc: 0.0617 - val_loss: 0.2026 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1919 - acc: 0.7963 - val_loss: 0.2309 - val_acc: 0.6842
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1797 - acc: 0.7531 - val_loss: 0.1722 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1476 - acc: 0.8148 - val_loss: 0.1797 - val_acc: 0.8158
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1342 - acc: 0.9012 - val_loss: 0.1744 - val_acc: 0.8684
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1286 - acc: 0.9074 - val_loss: 0.1771 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7188
False 1883
True percentage 0.792415389703
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.94      0.94      7318
      B-ORG       0.25      0.47      0.33       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.16      0.49      0.24       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.77      0.14      0.24       438
      I-PER       0.60      0.11      0.19       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.82      0.79      0.79      9071

F-1 Score:
0.207279029463
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 302ms/step - loss: 0.3645 - acc: 0.1984 - val_loss: 0.2135 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 35ms/step - loss: 0.2080 - acc: 0.7698 - val_loss: 0.1983 - val_acc: 0.7931
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1976 - acc: 0.7937 - val_loss: 0.2195 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1765 - acc: 0.8095 - val_loss: 0.1979 - val_acc: 0.7931
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1554 - acc: 0.8651 - val_loss: 0.1944 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1510 - acc: 0.9048 - val_loss: 0.1948 - val_acc: 0.7931
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1495 - acc: 0.8571 - val_loss: 0.1872 - val_acc: 0.8276
Epoch 8/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1401 - acc: 0.9286 - val_loss: 0.1876 - val_acc: 0.7931
Epoch 9/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1340 - acc: 0.9762 - val_loss: 0.1898 - val_acc: 0.7931
Epoch 10/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1352 - acc: 0.9524 - val_loss: 0.1870 - val_acc: 0.7931
Epoch 11/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1290 - acc: 0.9444 - val_loss: 0.1913 - val_acc: 0.7931
Epoch 12/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1289 - acc: 0.9683 - val_loss: 0.1897 - val_acc: 0.7931
Epoch 13/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1265 - acc: 0.9683 - val_loss: 0.1865 - val_acc: 0.7931
Epoch 14/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1221 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.8276
Epoch 15/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1264 - acc: 0.9683 - val_loss: 0.1901 - val_acc: 0.7931
Epoch 16/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1222 - acc: 0.9841 - val_loss: 0.1864 - val_acc: 0.8276
Epoch 17/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1214 - acc: 0.9921 - val_loss: 0.1904 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7204
False 1713
True percentage 0.807895031961
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.95      0.93      0.94      7318
      B-PER       0.38      0.32      0.35       438
      B-LOC       0.42      0.48      0.45       218
      B-ORG       0.29      0.23      0.25       296
      I-ORG       0.15      0.36      0.21       151
      I-PER       0.43      0.08      0.14       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.83      0.81      0.81      8917

F-1 Score:
0.266206896552
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 306ms/step - loss: 0.3736 - acc: 0.0185 - val_loss: 0.1951 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1992 - acc: 0.7963 - val_loss: 0.2052 - val_acc: 0.7632
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1686 - acc: 0.8148 - val_loss: 0.1769 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1543 - acc: 0.8086 - val_loss: 0.1862 - val_acc: 0.7368
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1363 - acc: 0.9012 - val_loss: 0.1680 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1309 - acc: 0.9012 - val_loss: 0.1721 - val_acc: 0.8158
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1257 - acc: 0.9383 - val_loss: 0.1709 - val_acc: 0.8158
Epoch 8/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1185 - acc: 0.9630 - val_loss: 0.1704 - val_acc: 0.8158
Manual evaluation: (didn't understand why I made this)
True 7200
False 1871
True percentage 0.793738286848
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.92      0.95      0.93      7318
      B-ORG       0.25      0.26      0.26       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.15      0.46      0.23       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.67      0.17      0.28       438
      I-PER       0.54      0.12      0.19       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.80      0.79      0.78      9071

F-1 Score:
0.184867685427
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 300ms/step - loss: 0.4023 - acc: 0.0317 - val_loss: 0.2030 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2334 - acc: 0.7698 - val_loss: 0.1825 - val_acc: 0.9310
Epoch 3/70

7/7 [==============================] - 0s 34ms/step - loss: 0.2379 - acc: 0.6429 - val_loss: 0.1899 - val_acc: 0.8276
Epoch 4/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1893 - acc: 0.7778 - val_loss: 0.1769 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1590 - acc: 0.8730 - val_loss: 0.1771 - val_acc: 0.8276
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1532 - acc: 0.8889 - val_loss: 0.1761 - val_acc: 0.8276
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1510 - acc: 0.9286 - val_loss: 0.1752 - val_acc: 0.8276
Epoch 8/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1464 - acc: 0.9365 - val_loss: 0.1748 - val_acc: 0.8276
Epoch 9/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1382 - acc: 0.9365 - val_loss: 0.1760 - val_acc: 0.8276
Epoch 10/70

7/7 [==============================] - 0s 35ms/step - loss: 0.1390 - acc: 0.9206 - val_loss: 0.1731 - val_acc: 0.8276
Epoch 11/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1325 - acc: 0.9603 - val_loss: 0.1745 - val_acc: 0.8276
Epoch 12/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1292 - acc: 0.9683 - val_loss: 0.1698 - val_acc: 0.8276
Epoch 13/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1312 - acc: 0.9921 - val_loss: 0.1720 - val_acc: 0.8276
Epoch 14/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1271 - acc: 0.9841 - val_loss: 0.1730 - val_acc: 0.8276
Epoch 15/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1271 - acc: 0.9683 - val_loss: 0.1754 - val_acc: 0.8276
Manual evaluation: (didn't understand why I made this)
True 7216
False 1701
True percentage 0.809240776046
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.96      0.93      0.94      7318
      B-PER       0.37      0.40      0.39       438
      B-LOC       0.47      0.52      0.49       218
      B-ORG       0.25      0.21      0.23       296
      I-ORG       0.16      0.42      0.23       151
      I-PER       0.38      0.07      0.11       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.84      0.81      0.82      8917

F-1 Score:
0.284391534392
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 299ms/step - loss: 0.3179 - acc: 0.1543 - val_loss: 0.2063 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1887 - acc: 0.7963 - val_loss: 0.2158 - val_acc: 0.7368
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1638 - acc: 0.7963 - val_loss: 0.1786 - val_acc: 0.8158
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1416 - acc: 0.8395 - val_loss: 0.1819 - val_acc: 0.8158
Epoch 5/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1335 - acc: 0.8951 - val_loss: 0.1770 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1275 - acc: 0.9012 - val_loss: 0.1830 - val_acc: 0.8158
Epoch 7/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1221 - acc: 0.9444 - val_loss: 0.1768 - val_acc: 0.8421
Epoch 8/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1209 - acc: 0.9259 - val_loss: 0.1779 - val_acc: 0.8158
Epoch 9/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1187 - acc: 0.9691 - val_loss: 0.1756 - val_acc: 0.8421
Epoch 10/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1166 - acc: 0.9444 - val_loss: 0.1781 - val_acc: 0.8158
Epoch 11/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1159 - acc: 0.9444 - val_loss: 0.1737 - val_acc: 0.8421
Epoch 12/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1117 - acc: 0.9691 - val_loss: 0.1801 - val_acc: 0.8158
Epoch 13/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1119 - acc: 0.9753 - val_loss: 0.1820 - val_acc: 0.8158
Epoch 14/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1125 - acc: 0.9568 - val_loss: 0.1813 - val_acc: 0.8158
Manual evaluation: (didn't understand why I made this)
True 7193
False 1878
True percentage 0.792966596847
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.94      0.94      0.94      7318
      B-ORG       0.25      0.29      0.27       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.15      0.48      0.23       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.40      0.26      0.32       438
      I-PER       0.48      0.11      0.18       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.80      0.79      0.79      9071

F-1 Score:
0.204600068658
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 0
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 8 unique labels.
Found additional 103598 unique words.
3594 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 284
OOV word occurences: 568
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630336     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 9)        3564        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,138,604
Trainable params: 7,138,604
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 301ms/step - loss: 0.3820 - acc: 0.0635 - val_loss: 0.2183 - val_acc: 0.8276
Epoch 2/70

7/7 [==============================] - 0s 32ms/step - loss: 0.2197 - acc: 0.7698 - val_loss: 0.1969 - val_acc: 0.8276
Epoch 3/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1901 - acc: 0.8175 - val_loss: 0.1872 - val_acc: 0.8621
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1622 - acc: 0.8333 - val_loss: 0.1805 - val_acc: 0.8276
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1540 - acc: 0.9048 - val_loss: 0.1847 - val_acc: 0.8621
Epoch 6/70

7/7 [==============================] - 0s 34ms/step - loss: 0.1490 - acc: 0.8889 - val_loss: 0.1853 - val_acc: 0.7931
Epoch 7/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1417 - acc: 0.9365 - val_loss: 0.1831 - val_acc: 0.8621
Manual evaluation: (didn't understand why I made this)
True 7198
False 1719
True percentage 0.807222159919
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.92      0.94      0.93      7318
      B-PER       0.36      0.35      0.36       438
      B-LOC       0.30      0.50      0.37       218
      B-ORG       0.26      0.14      0.18       296
      I-ORG       0.17      0.06      0.09       151
      I-PER       0.47      0.07      0.11       214
      I-LOC       0.00      0.00      0.00       141
     B-MISC       0.00      0.00      0.00       141

avg / total       0.80      0.81      0.80      8917

F-1 Score:
0.248213614141
Opening file ner_3_train.ner
Opening file ner_3_test.ner
Cut percentage 0.005 with seed 1
Found 100004 word vectors.
Found 84 char vectors.
Found 103589 unique words.
Found 181 unique chars.
Found 9 unique labels.
Found additional 103600 unique words.
3596 unique words not found in embedding.
97 unique chars not found in embedding.
Number of OOV: 283
OOV word occurences: 567
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Padded until 24 chars.
Padded until 57 tokens.
Model Choice:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 57, 24)       0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 24, 64)       11648       input_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 64)       0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 57)           0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 24, 64)       0           dropout_2[0][0]                  
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 57, 64)       6630464     input_1[0][0]                    
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57, 64)       0           embedding_1[0][0]                
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 57, 128)      0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 57, 192)      0           dropout_1[0][0]                  
                                                                 lambda_2[0][0]                   
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 57, 384)      443520      concatenate_1[0][0]              
__________________________________________________________________________________________________
crf_1 (CRF)                     (None, 57, 10)       3970        bidirectional_2[0][0]            
==================================================================================================
Total params: 7,139,138
Trainable params: 7,139,138
Non-trainable params: 0
__________________________________________________________________________________________________
Loading layer 0
Loading layer 1
Loading layer 2
Loading layer 3
Loading layer 4
Loading layer 5
Loading layer 6
Loading layer 7
Loading layer 8
Loading layer 9
Loading layer 10
Train on 7 samples, validate on 1 samples
Epoch 1/70

7/7 [==============================] - 2s 300ms/step - loss: 0.2931 - acc: 0.3272 - val_loss: 0.2475 - val_acc: 0.8421
Epoch 2/70

7/7 [==============================] - 0s 33ms/step - loss: 0.2436 - acc: 0.7963 - val_loss: 0.2214 - val_acc: 0.6579
Epoch 3/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1734 - acc: 0.8025 - val_loss: 0.1830 - val_acc: 0.8421
Epoch 4/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1607 - acc: 0.8025 - val_loss: 0.1718 - val_acc: 0.8421
Epoch 5/70

7/7 [==============================] - 0s 33ms/step - loss: 0.1370 - acc: 0.9074 - val_loss: 0.1780 - val_acc: 0.8421
Epoch 6/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1319 - acc: 0.8889 - val_loss: 0.1763 - val_acc: 0.8421
Epoch 7/70

7/7 [==============================] - 0s 32ms/step - loss: 0.1277 - acc: 0.9198 - val_loss: 0.1770 - val_acc: 0.8421
Manual evaluation: (didn't understand why I made this)
True 7135
False 1936
True percentage 0.786572593981
Sklearn evaluation:
             precision    recall  f1-score   support

          O       0.93      0.95      0.94      7318
      B-ORG       0.28      0.24      0.26       296
      B-LOC       0.00      0.00      0.00       218
      I-ORG       0.13      0.67      0.22       151
     B-MISC       0.00      0.00      0.00       141
     I-MISC       0.00      0.00      0.00       154
      B-PER       0.60      0.08      0.13       438
      I-PER       0.00      0.00      0.00       214
      I-LOC       0.00      0.00      0.00       141

avg / total       0.79      0.79      0.78      9071

F-1 Score:
0.145428873985
